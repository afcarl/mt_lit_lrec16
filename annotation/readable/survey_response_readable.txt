<SURVEYSTART>
id:  N10-1140 
title: Accurate Non-Hierarchical Phrase-Based Translation
link: http://www.aclweb.org/anthology/
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	various news corpora from LDC	28M English words, 23.3M Chinese words	Chinese	English		
2	train	monolingual	Xinhua and AFP sections of Gigaword	700M words		English		
3	test	bitext	MT03-MT08		Chinese	English		
4	tune	bitext	MT06	1664 sentences	Chinese	English		
=====result=====
1	1,2,4	3	Baseline Joshua	BLEU	31.90	
1	1,2,4	3	Baseline Moses	BLEU	32.16	
1	1,2,4	3	My-Own-System	BLEU	32.93	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W13-0801
title: A Semantic Evaluation of Machine Translation Lexical Choice
link: http://www.aclweb.org/anthology/W13-0801
first_name: Matic
last_name: Horvat
goal #1 : find better MT evaluation metric
tech #1 : add better rule context
------data------
1	train	bitext	Europarl	900k sentences	Spanish	English		
2	train	bitext	WMT2012		Spanish	English		
3	tune	bitext	WMT2012	3000	Spanish	English		
4	test	bitext	SemEval2010 Cross-Lingual WSD task		Spanish	English		
=====result=====
1	1,2,3	4	PBSMT	Precision	23.72	
1	1,2,3	4	PBSMT	Recall	23.69	
1	1,2,3	4	PBSMT	BLEU	62.72	
1	1,2,3	4	WSD	Precision	25.96	
1	1,2,3	4	WSD	Recall	25.58	
1	1,2,3	4	WSD	BLEU	76.06	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P10-1049
title: Training Phrase Translation Models with Leaving-One-Out
link: http://www.aclweb.org/anthology/P10-1049
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : reduce overfitting
------data------
1	train	bitext	WMT08	1 311 815 sentences	German	English		
2	tune	bitext	WMT08	2 000 sentences	German	English		
3	test	bitext	WMT08	2 000 sentences	German	English		
4	train	monolingual	WMT08			English		
=====result=====
1	1,4	2	baseline	BLEU	25.7	
1	1,4	2	fixed interpol.	BLEU	27.0	
1	1,4	3	baseline	BLEU	26.3	
1	1,4	3	fixed interpol.	BLEU	27.7	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P10-1062
title: Error Detection for Statistical Machine Translation Using Linguistic Features
link: http://www.aclweb.org/anthology/P10-1062
first_name: Eunsol
last_name: Choi
goal #1 : post edit results
tech #1 : improve post-processing
------data------
1	train	bitext	MT-02	878 sentences	Chinese	English		
2	tune	bitext	MT-05	1082 sentences	Chinese	English		
3	test	bitext	MT-03	919 sentences	Chinese	English		
=====result=====
1	1,2	3	Baseline	other	47.57	
1	1,2	3	MaxEnt (dwpp + wd + pos + link)	other	38.76	
diff_metric:CER (%)
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W09-0432
title: Domain Adaptation for Statistical Machine Translation with Monolingual Resources
link: http://www.aclweb.org/anthology/W09-0432
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : use more data
------data------
1	train	bitext	UN	2.5M sentences	Spanish	English		
2	train	bitext	EP 2008 training set	1.3M sentences	Spanish	English		
3	train	bitext	synthetic English Europarl	1.3M sentences	Spanish	English		
4	train	bitext	synthetic Spanish Europarl	1.3M sentences	Spanish	English		
5	tune	bitext	European Parliament corpus dev2006	2000 sentences	Spanish	English		
6	test	bitext	European Parliament corpus test2008	2000 sentences	Spanish	English		
7	test	bitext	European Parliament corpus test2008	2000 sentences	English	Spanish		
8	train	monolingual	UN	45.2M word, 224K dict		English		
9	train	monolingual	EP	35.0M word, 109K dict		English		
10	train	monolingual	synthetic English Europarl	35.4M word		English		
11	train	monolingual	synthetic Spanish Europarl	35.0M word		English		
=====result=====
1	1,5,8	6	UN UN	BLEU	22.60	
1	1,5,9	6	UN EP	BLEU	27.83	
1	2,5,9	6	EP EP	BLEU	32.80	
1	1,10,5	6	UN synthetic English-Europarl	BLEU	23.52	
1	3,5,10	6	synthetic English-Europarl synthetic English-Europarl	BLEU	23.68	
1	4,5,9	6	synthetic Spanish-EP EP	BLEU	28.10	
1		6	Google	BLEU	28.60	
1		6	Euromatric	BLEU	32.99	
1	1,8,5	7	UN UN	BLEU	23.24	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D13-1112
title: Max-Violation Perceptron and Forced Decoding for Scalable MT Training
link: http://www.aclweb.org/anthology/D13-1112
first_name: Eunsol
last_name: Choi
goal #1 : detect parallel documents
tech #1 : improve search
------data------
2	train	bitext		230k	Chinese	English		
3	train	bitext		174k	Spanish	English		
5	test	bitext	newswire portion of 2006 NIST MT	691	Chinese	English		
6	test	bitext	newstest2013		Spanish	English		
7	tune	bitext	newswire portion of 2006 NIST MT	616	Chinese	English		
8	tune	bitext	newstest2012		Spanish	Chinese		
=====result=====
1	2,7	5	Moses MERT	BLEU	22.5	
1	2,7	5	Cubit MAXFORCE	BLEU	24.5	
1	3,6	6	Moses MERT	BLEU	24.4	
1	3,6	6	Cubit MAXFORCE	BLEU	25.5	
diff_metric:
extra:monolingual data not listed, just saying "SRLIM" toolkit.
<SURVEYEND>
<SURVEYSTART>
id:  D13-1112
title: Max-Violation Perceptron and Forced Decoding for Scalable MT Training
link: http://www.aclweb.org/anthology/D13-1112
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : improve search
------data------
1	train	bitext		30K	Chinese	English		
2	train	bitext		230K	Chinese	English		
3	tune	bitext	newswire portion of 2006 NIST MT Evaluation	616 sentences	Chinese	English		
4	test	bitext	newswire portion of 2008 NIST MT Evaluation	691 sentences	Chinese	English		
5	train	bitext		174K	Spanish	English		
6	tune	bitext	newstest2012		Spanish	English		
7	test	bitext	newstest2013		Spanish	English		
=====result=====
1	1,3	4		BLEU	+2.0	
1	2,3	4	Cubit MERT	BLEU	22.5	
1	2,3	4	Cubit MAXFORCE	BLEU	24.5	
1	5,6	7	Moses MERT	BLEU	24.4	
1	5,6	7	Cubit MAXFORCE	BLEU	25.5	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D12-1077
title: Inducing a Discriminative Parser to Optimize Machine Translation Reordering
link: http://www.aclweb.org/anthology/D12-1077
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve pre-ordering
------data------
1	train	bitext	Kyoto Free Translation Task training set	602 sent	Japanese	English		
2	train	bitext	Kyoto Free Translation Task training set	555 sent	Japanese	English		
3	tune	bitext	Kyoto Free Translation Task tuning set	555 sent	Japanese	English		
4	test	bitext	Kyoto Free Translation Task testing set	555 sent	Japanese	English		
5	train	bitext	Kyoto Free Translation Task training set	329k sent	Japanese	English		
6	test	bitext	Kyoto Free Translation Task testing set	555 sent	English	Japanese		
=====result=====
1	1,2,5	4	ORIG	BLEU	21.87	
1	1,2,5	4	LADER	BLEU	23.11	
1	1,2,5	4	LADER+pos	BLEU	23.32	
1	1,2,5	4	LADER+cfg	BLEU	23.36	
1	1,2,5	6	ORIG	BLEU	18.34	
1	1,2,5	6	LADER	BLEU	19.54	
1	1,2,5	6	LADER+pos	BLEU	19.89	
1	1,2,5	6	LADER+cfg	BLEU	19.35	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D12-1078
title: Re-training Monolingual Parser Bilingually for Syntactic SMT
link: http://www.aclweb.org/anthology/D12-1078
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	train	bitext	IWSLT 2009	81k sentences	Chinese	English		
2	train	monolingual	IWSLT 2009	81k sentences		English		
3	tune	bitext	dev8 + dialog		Chinese	English		
4	train	bitext	dev9		Chinese	English		
5	train	bitext	NIST 2008	10m words	Chinese	English		
6	train	monolingual	Gigaword + English side of bitext			English		
7	tune	bitext	NIST 2003		Chinese	English		
8	test	bitext	NIST 2005		Chinese	English		
9	train	bitext	NIST 2008		Chinese	English		
=====result=====
1	1,2	3	Baseline	BLEU	50.58	
1	1,2	4	Baseline	BLEU	49.85	
1	5,6	7	Baseline	BLEU	37.57	
1	5,6	8	Baseline	BLEU	36.44	
1	5,6	9	Baseline	BLEU	24.87	
1	1,2	3	FA-PR then IDSG	BLEU	53.81	
1	1,2	4	FA-PR then IDSG	BLEU	53.26	
1	5,6	7	FA-PR then IDSG	BLEU	38.90	
1	5,6	8	FA-PR then IDSG	BLEU	37.94	
1	5,6	9	FA-PR then IDSG	BLEU	26.52	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D12-1078
title: Re-training Monolingual Parser Bilingually for Syntactic SMT
link: http://www.aclweb.org/anthology/D12-1078
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve alignment
------data------
1	train	bitext	IWSLT 2009	81k sentence pairs	Chinese	English		
3	train	bitext	NIST 2008 training	354k sentence pairs	Chinese	English		
4	train	monolingual	Giga-Word corpus			English		
5	tune	bitext	NIST 2003 evaluation set		Chinese	English		
6	test	bitext	NIST 2005		Chinese	English		
7	train	bitext	NIST 2008		Chinese	English		
8	test	bitext	IWSLT 2009 dev9		Chinese	English		
=====result=====
1	3,4,5	6	Baseline	BLEU	24.87	
1	3,4,5	6	IDSG then FA-PR	BLEU	26.74	
1	3,4,5	6	FA-PR then IDSG	BLEU	26.52	
1	3,4,5	7	Baseline	BLEU	36.44	
1	3,4,5	7	IDSG then FA-PR	BLEU	37.95	
1	3,4,5	7	FA-PR then IDSG	BLEU	37.94	
1	1	8	Baseline	BLEU	49.85	
1	1	8	IDSG then FA-PR	BLEU	53.32	
1	1	8	FA-PR then IDSG	BLEU	53.26	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W06-1606
title: SPMT: Statistical Machine Translation with Syntactified Target Language Phrases
link: http://www.aclweb.org/anthology/W06-1606
first_name: Daniel
last_name: Marcu
goal #1 : improve translation quality
tech #1 : add better rule context
------data------
1	train	bitext	LDC Chinese-English parallel corpus	138.7M words	Chinese	English		
2	tune	bitext	2002 NIST	1k sentences	Chinese	English		
3	test	bitext	2003 NIST test data	(<20 words)	Chinese	English	
4	test	bitext	2003 NIST test data		Chinese	English
=====result=====
1	1,2	3	PBMT	BLEU		34.83
1	1,2	3	SPMT-Comb	BLEU	39.56	
1	1,2	4	PBMT	BLEU	31.46	
1	1,2	4	SPMT-Comb	BLEU	34.1
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N09-1013
title: Context-Dependent Alignment Models for Statistical Machine Translation
link: http://www.aclweb.org/anthology/N09-1013
first_name: Adri
last_name: de Gispert
goal #1 : improve word/phrase alignment
goal #2 : improve translation quality
tech #1 : improve alignment
tech #2 : improve alignment
------data------
1	train	bitext	NIST 08, excluding UN collections	300k sentences	Arabic	English		
2	test	bitext	IBM Arabic-English manually aligned corpus + LDC2006E86 + LDC2006E93	28k sentences	Arabic	English		
3	train	bitext	NIST 08 random subset	600k sentences	Chinese	English		
4	tune	bitext	mt02_05_tune	2k sentences	Arabic	English		
5	test	bitext	mt02_05_test	2k sentences	Arabic	English		
6	test	bitext	MT08 newswire		Arabic	English		
7	tune	bitext	mt02_05_tune	2k sentences	Chinese	English		
8	test	bitext	mt02_05_test	2k sentences	Chinese	English		
9	test	bitext	MT08 newswire		Chinese	English		
10	train	monolingual	Target-side of parallel corpus + 965M words subset from English GigaWord 3rd Edition			English		
=====result=====
1	1	2	baseline (context-independent HMM model)	AER	35.0	
1	1	2	context-dependent HMM model	AER	34.4	
2	2, 10	5	baseline (context-independent HMM model)	BLEU	49.4	
2	2, 10	5	context-dependent HMM model	BLEU	49.7	
2	2, 10	6	baseline (context-independent HMM model)	BLEU	46.3	
2	2, 10	6	context-dependent HMM model	BLEU	46.9	
2	3, 10	8	baseline (context-independent HMM model)	BLEU	28.5	
2	3, 10	8	context-dependent HMM model	BLEU	29.0	
2	3, 10	9	baseline (context-independent HMM model)	BLEU	26.9	
2	3, 10	9	context-dependent HMM model	BLEU	27.7	
diff_metric:
extra:I find the form a bit hard to work with... it takes a very long time to introduce a small table with four numbers, and it's very easy to make mistakes in selecting the right IDs to each number
<SURVEYEND>
<SURVEYSTART>
id:  E14-1026
title: Source-side Preordering for Translation using Logistic Regression and Depth-first Branch-and-Bound Search
link: http://www.aclweb.org/anthology/E14-1026
first_name: Adri
last_name: de Gispert
goal #1 : improve translation quality
tech #1 : improve pre-ordering
------data------
1	train	bitext	unknown	6M sentences	English	Japanese		
2	test	bitext	unknown	903 sentences	English	Japanese		
3	train	bitext	unknown	6M sentences	English	Korean		
4	test	bitext	unknown	903 sentences	English	Korean		
=====result=====
diff_metric:
extra:Genzel 2010 is a reimplementation of this paper: C10-1043
<SURVEYEND>
<SURVEYSTART>
id:  W02-1018
title: A Phrase-Based, Joint Probability Model for Statistical Machine Translation
link: http://www.aclweb.org/anthology/W02-1018
first_name: Daniel
last_name: Marcu
goal #1 : improve translation quality
tech #1 :  improve alignment
------data------
1	train	bitext		100k sentences	French	English		
2	test	bitext		500 sentences	French	English		
=====result=====
1	1	2	baseline	BLEU	21.58	
1	1	2	phrase-based alignment model	BLEU	23.25	
1	1	2	baseline - % perfect translations	other	22	
1	1	2	phase-based alignment model - % perfect translations	other	28	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P13-2069
title: Generalized Reordering Rules for Improved SMT
link: http://www.aclweb.org/anthology/P13-2069
first_name: Jon
last_name: May
goal #1 : improve translation quality
tech #1 : improve reordering
------data------
1	train	bitext	LDC released bilingual corpora and technical documents	20m sentences	English	Chinese		
2	train	bitext	In-house software documents	20m sentences	English	Japanese		
3	tune	bitext	In-house software documents		English	Chinese		
4	tune	bitext	In-house software documents		English	Japanese		
5	test	bitext	in-house online technical support documents		English	Chinese		
6	test	bitext	in-house online technical support documents		English	Japanese		
7	test	bitext	NIST MT 08		English	Chinese		
8	test	bitext	NIST MT 08		English	Japanese		
=====result=====
1	1,3	5	PBMT	BLEU	31.35	
1	1,3	5	MPML	BLEU	32.64	
1	1,3	7	PBMT	BLEU	36.81	
1	1,3	7	MPML	BLEU	38.02	
1	2,4	6	PBMT	BLEU	35.45	
1	2,4	6	MPML	BLEU	38.62	
1	2,4	8	PBMT	BLEU	21.7	
1	2,4	8	MPML	BLEU	23.3	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P13-2069
title: Generalized Reordering Rules for Improved SMT
link: http://www.aclweb.org/anthology/P13-2069
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
3	train	bitext	LDC bilingual, in-house software manual domain	20 million sentence pairs	English	Chinese		
2	train	bitext	in-house software manual domain	20M sentence pairs	English	Japanese		
1	test	bitext	NIST MT08	1859 sentences	English	Chinese		
4	test	bitext	News	600 sentences	English	Japanese		
=====result=====
1	3	1	MPML	BLEU	38.02	
1	3	1	PBMT	BLEU	36.81	
1	2	4	MPML	BLEU	21.70	
1	2	4	PBMT	BLEU	23.31	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D11-1017
title: Training a Parser for Machine Translation Reordering
link: http://www.aclweb.org/anthology/D11-1017
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve preprocessing
------data------
1	test	bitext	Web-Test	5000 sentences	English	Korean		
2	test	bitext	Web-Test	5000 sentences	English	Japanese		
3	test	bitext	Web-Test	5000 sentences	English	Turkish		
4	train	bitext	unknown	13595 sentences		English		
5	train	bitext	unknown	300 million source words	English	Korean		
6	train	bitext	unknown	300 million source words	English	Japanese		
7	train	bitext	unknown	300 million source words	English	Turkish		
=====result=====
1	4,5	1	WSJ-only	BLEU	0.3229	
1	4,5	1	Targeted	BLEU	0.3259	
1	4,6	2	WSJ-only	BLEU	0.1777	
1	4,6	2	Targeted	BLEU	0.1802	
1	4,7	3	WSJ-only	BLEU	0.1344	
1	4,7	3	Targeted	BLEU	0.1370	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D11-1017
title: Training a Parser for Machine Translation Reordering
link: http://www.aclweb.org/anthology/D11-1017
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : improve reordering
------data------
1	train	monolingual	Wall Street Journal (WSJ) section of the Penn Treebank			English		
4	test	bitext	Web-Test	5000 sentences	Japanese	English		
5	test	bitext	Web-Test	5000 sentences	Korean	English		
6	test	bitext	Web-Test	5000 sentences	Turkish	English		
7	train	monolingual	Web-Train	6268 sentence		English		
8	train	bitext	QTB-Train	2000 sentences	Japanese	English		
9	test	bitext	QTB-Test	1000 sentences	Japanese	English		
=====result=====
1	1,7	4	WSJ-only	BLEU	0.1777	
1	1,7	4	Targeted	BLEU	0.1802	
1	1,7	5	WSJ-only	BLEU	0.3229	
1	1,7	5	Targeted	BLEU	0.3259	
1	1,7	6	WSJ-only	BLEU	0.1344	
1	1,7	6	Targeted	BLEU	0.1370	
1	1,8	9	WSJ-only	BLEU	0.2379	
1	1,8	9	Targeted	BLEU	0.2615	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D13-1110
title: Efficient Left-to-Right Hierarchical Phrase-based Translation with Improved Reordering
link: http://www.aclweb.org/anthology/D13-1110
first_name: Eunsol
last_name: Choi
goal #1 : improve translation speed
goal #2 : improve translation quality
tech #1 : make decoding efficient
tech #2 : provide more features
------data------
1	train	bitext	Europarl(v7)	7.95M	Chinese	English		
2	tune	bitext	CzEng(v0.9)	3000	Chinese	English		
3	test	bitext	News commentary	3003	Chinese	English		
4	train	bitext	Europarl(v7)	1.5M	German	English		
5	tune	bitext	News commentary	2000	German	English		
6	test	bitext	News commentary	2000	German	English		
7	train	monolingual	Gigaword corpus			English		
=====result=====
1	1,2,7	3	LR-Hiero+CP	Time	4.2	
1	1,2,7	3	LR-Hiero+CP	Time	5.67	
1	4,5,7	6	Hiero	Time	16.12	
1	4,5,7	6	Hiero	Time	20.33	
2	1,2,7	3	Phrase-based	BLEU	20.32	
2	1,2,7	3	CKY Hiero + reordering feats	BLEU	20.77	
2	4,5,7	6	Phrase-based	BLEU	24.71	
2	4,5,7	6	CKY Hiero + reordering feats	BLEU	25.72	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1036
title: A Syntax-Driven Bracketing Model for Phrase-Based Translation
link: http://www.aclweb.org/anthology/P09-1036
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	train	bitext	FBIS		Chinese	English		
2	train	monolingual	Xinhua section of the English Gigaword	181.1M words		English		
3	tune	bitext	NIST MT-02		Chinese	English		
4	test	bitext	NIST MT-05		Chinese	English		
=====result=====
1	1,2,3	4	BiSDB	BLEU	0.2779	
1	1,2,3	4	Baseline	BLEU	0.2612	
1	1,2,3	4	XP+	BLEU	0.2720	
1	1,2,3	4	UniSDB	BLEU	0.2762	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P13-2061
title: Bilingual Data Cleaning for SMT using Graph-based Random Walk
link: http://www.aclweb.org/anthology/P13-2061
first_name: Jon
last_name: May
goal #1 : improve translation quality
tech #1 : data cleaning/filtering
------data------
1	train	bitext	web mined + UN + CWMT	30m sentences	Chinese	English		
2	train	monolingual	LDC English Gigaword 4.0			English		
3	tune	bitext	NIST 2003	919 sentences	Chinese	English		
4	test	bitext	NIST 2005	1,082 sentences	Chinese	English		
5	test	bitext	NIST 2006	1,664 sentences	Chinese	English		
6	test	bitext	NIST 2008	1,357 sentences	Chinese	English		
7	test	bitext	CWMT 2008	1,006 sentences	Chinese	English		
8	test	bitext	In-house dataset 1	1,002 sentences	Chinese	English		
9	test	bitext	In-house dataset 2	5,000 sentences	Chinese	English		
10	test	bitext	In-house dataset 3	2,999 sentences	Chinese	English		
=====result=====
1	1,2,3	3	baseline	BLEU	41.24	
1	1,2,3	3	+CW	BLEU	41.75	
1	1,2,3	4	baseline	BLEU	37.34	
1	1,2,3	4	+CW	BLEU	38.08	
1	1,2,3	5	baseline	BLEU	35.2	
1	1,2,3	5	+CW	BLEU	35.84	
1	1,2,3	6	baseline	BLEU	29.38	
1	1,2,3	6	+CW	BLEU	30.03	
1	1,2,3	7	baseline	BLEU	31.14	
1	1,2,3	7	+CW	BLEU	31.82	
1	1,2,3	8	baseline	BLEU	24.29	
1	1,2,3	8	+CW	BLEU	25.23	
1	1,2,3	9	baseline	BLEU	22.61	
1	1,2,3	9	+CW	BLEU	23.18	
1	1,2,3	10	baseline	BLEU	24.19	
1	1,2,3	10	+CW	BLEU	24.8	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N10-1140
title: Accurate Non-Hierarchical Phrase-Based Translation
link: http://www.aclweb.org/anthology/N10-1140
first_name: Michel
last_name: Galley
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	parallel corpora distributed by the Linguistic Data Consortium	28 million English words and 23.3 million Chinese words	Chinese	English		
2	train	monolingual	Gigaword	700 million words		English		
3	tune	bitext	MT06	1664 sentences	Chinese	English		
4	test	bitext	MT03	919 sentences	Chinese	English		
5	test	bitext	MT04	1788 sentences	Chinese	English		
6	test	bitext	MT05	1082 sentences	Chinese	English		
7	test	bitext	MT08	1357 sentences	Chinese	English		
8	test	bitext	ALL	6810 sentences	Chinese	English		
=====result=====
1	1,2	4	hierarchical (Joshua)	BLEU	33.47	
1	1,2	5	hierarchical (Joshua)	BLEU	36.10	
1	1,2	6	hierarchical (Joshua)	BLEU	32.17	
1	1,2	7	hierarchical (Joshua)	BLEU	26.61	
1	1,2	8	hierarchical (Joshua)	BLEU	31.90	
1	1,2	4	discontinuous phrase-based (this work)	BLEU	34.96	
1	1,2	5	discontinuous phrase-based (this work)	BLEU	37.44	
1	1,2	6	discontinuous phrase-based (this work)	BLEU	33.39	
1	1,2	7	discontinuous phrase-based (this work)	BLEU	26.74	
1	1,2	8	discontinuous phrase-based (this work)	BLEU	32.93	
diff_metric:n/a
extra:My browser seems to complain when I enter BLEU scores that are not integer. So multiplied all percentages by 100.
<SURVEYEND>
<SURVEYSTART>
id:  W11-2143
title: CMU Syntax-Based Machine Translation at WMT 2011
link: http://www.aclweb.org/anthology/W11-2143
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : use more data
------data------
1	train	bitext	Europarl	1,614,111 sentences	French	English		
2	train	bitext	News commentary	95,138 sentences	French	English		
3	train	bitext	UN documents	9,352,232 sentences	French	English		
4	train	bitext	Giga-FrEn	2,839,466 sentences	French	English		
5	tune	bitext	newstest2008		French	English		
6	test	bitext	newstest2009		French	English		
7	test	bitext	newstest2010		French	English		
8	train	bitext	WMT 2010 training data	8.6 million sentences	French	English		
=====result=====
1	8	6	WMT 2010 10k	BLEU	24.77	
1	8	6	WMT 2010 2k+100k	BLEU	24.88	
1	1,2,3,4,5	6	WMT 2011 10k	BLEU	26.02	
1	1,2,3,4,5	6	WMT 2011 2k+100k	BLEU	26.01	
1	8	7	WMT 2010 10k	BLEU	25.78	
1	8	7	WMT 2010 2k+100k	BLEU	26.05	
1	1,2,3,4,5	7	WMT 2011 10k	BLEU	27.71	
1	1,2,3,4,5	7	WMT 2011 2k+100k	BLEU	27.38	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P11-1003
title: Effective Use of Function Words for Rule Generalization in Forest-Based Translation
link: http://www.aclweb.org/anthology/P11-1003
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	train	bitext	JST	994k sentences	English	Japanese		
2	train	monolingual	JST	994k sentences		Japanese		
3	tune	bitext	JST	4k sentences	English	Japanese		
4	test	bitext	JST	4k sentences	English	Japanese		
=====result=====
1	1,2	4	M&H-F	BLEU	27.07	
1	1,2	4	C3-F	BLEU	28.89	
1		1	Joshua	BLEU	24.79	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D13-1173
title: Dependency-Based Decipherment for Resource-Limited Machine Translation
link: http://www.aclweb.org/anthology/D13-1173
first_name: qing
last_name: dou
goal #1 : improve decipherment and translation quality
tech #1 : use dependency parsing and finding oov translations
------data------
1	train	bitext	Europarl	1.1 million tokens 1.0 million tokens	Spanish	English	http://www.statmt.org/europar	
2	train	monolingual	GigaWord	894 million tokens 940 million tokens	Spanish	English		
3	tune	bitext	WMT 2008	52k tokens 49k tokens	Spanish	English	http://www.statmt.org/wmt	
4	train	bitext	WMT 2009	68k tokens 66k tokens	Spanish	English		
=====result=====
1	1,2	3	Baseline	BLEU	19.1	
1	1,2	3	Decipherment	BLEU	20.0	
1	1,2	4	Baseline	BLEU	19.6	
1	1,2	4	Decipherment	BLEU	20.5	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P13-2067
title: Improving machine translation by training against an automatic semantic frame based evaluation metric
link: http://www.aclweb.org/anthology/P13-2067
first_name: Kevin
last_name: Knight
goal #1 : find better MT evaluation metric
tech #1 : improve semantics
------data------
1	train	bitext	LDC newswire		Chinese	English		
2	tune	bitext	NIST 02-06	6331 sentences	Chinese	English		
3	test	bitext	NIST 08	1357 sentences	Chinese	English		
4	tune	bitext	BOLT Phase 1	2000 sentences	Chinese	English		
5	test	bitext	BOLT Phase 1	1697 sentences	Chinese	English		
6	train	bitext	LDC newswire + forum			English		
=====result=====
1	1,6	3	BLEU-tuned	BLEU	29.85	
1	1,6	3	BLEU-tuned	MEANT	0.1667	
1	1,6	3	MEANT-tuned	BLEU	25.91	
1	1,6	3	MEANT-tuned	MEANT	0.1676	
1	1,6	5	BLEU-tuned	BLEU	9.58	
1	1,6	5	BLEU-tuned	MEANT	0.1711	
1	1,6	5	MEANT-tuned	BLEU	7.92	
1	1,6	5	MEANT-tuned	MEANT	0.1727	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  C10-1056
title: Feature-Rich Discriminative Phrase Rescoring for SMT
link: http://www.aclweb.org/anthology/C10-1056
first_name: Jon
last_name: May
goal #1 : improve translation quality
goal #2 : reduce model size
tech #1 : provide more features
tech #2 : provide more features
------data------
1	train	bitext	Newswire and UN corpora	10m sentences	English	Chinese		
2	test	bitext	NIST MT08	1859 sentences	English	Chinese		
=====result=====
1	1	2	Baseline	char_BLEU	38.67	
1	1	2	LR-disc tuning	char_BLEU	39.87	
2	1	2	Baseline	other	3.65M	
2	1	2	LR-disc tuning	other	3.05M	
diff_metric:phrase table size
extra:
<SURVEYEND>
<SURVEYSTART>
id:  C10-1056
title: Feature-Rich Discriminative Phrase Rescoring for SMT
link: http://www.aclweb.org/anthology/C10-1056
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : improve tuning
------data------
1	test	bitext	NIST MT08	1859 sentences	English	Chinese		
2	train	bitext	LDC newswire, UN, and other	10m sentences	English	Chinese		
=====result=====
1	2	1	Baseline	char_BLEU	38.67	
1	2	1	LR-disc tuning	char_BLEU	39.87	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W14-3326
title: Machine Translation of Medical Texts in the Khresmoi Project
link: http://www.aclweb.org/anthology/W14-3326
first_name: Ondej
last_name: Duek
goal #1 : improve translation quality
goal #2 : improve translation quality
tech #1 : use domain adaptation
tech #2 : use domain adaptation
------data------
1	train	bitext		2498k sentences	Czech	English		
2	train	bitext		4998k sentences	German	English		
3	train	bitext		6139k sentences	French	English		
4	train	bitext		15778k sentences	Czech	English		
5	train	bitext		4520k sentences	German	English		
6	train	bitext		40842k sentences	French	English		
7	train	bitext		9320k sentences	German	English		
8	train	bitext		13809k sentences	French	English		
9	train	monolingual		172991k tokens	English			
10	train	monolingual		6132107k tokens	English			
11	train	monolingual		3275272k tokens	English			
12	train	monolingual		618084k tokens	English			
13	train	monolingual		1848k tokens	Czech			
14	train	monolingual		627493k tokens	Czech			
15	train	monolingual		36348k tokens	Czech			
16	train	monolingual		63499k tokens	German			
17	train	monolingual		1728065k tokens	German			
18	train	monolingual		361881k tokens	German			
19	train	monolingual		339595k tokens	German			
20	train	monolingual		63022k tokens	French			
21	train	monolingual		1837457k tokens	French			
22	train	monolingual		908911k tokens	French			
23	train	monolingual		204025k tokens	French			
24	tune	bitext	WMT News		English	French		
24	tune	bitext	WMT News		English	German		
24	tune	bitext	WMT News		English	Czech		
25	test	bitext	Khresmoi Query		English	French		
25	test	bitext	Khresmoi Query		English	German		
25	test	bitext	Khresmoi Query		English	Czech		
26	test	bitext	Khresmoi Summary		English	Czech		
26	test	bitext	Khresmoi Summary		English	German		
26	test	bitext	Khresmoi Summary		English	Czech		
=====result=====
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P10-2004
title: Filtering Syntactic Constraints for Statistical Machine Translation
link: http://www.aclweb.org/anthology/P10-2004
first_name: Jon
last_name: May
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	FBIS	243698 sentences	Chinese	English		
2	train	monolingual	Xinhua subset of Gigaword	19049757		English		
3	tune	bitext	NIST MT 08	1664 sentences	Chinese	English		
4	test	bitext	NIST MT 08	1357 sentences	Chinese	English		
=====result=====
1	1,2,3	4	Baseline	BLEU	17.26	
1	1,2,3	4	frontier nodes	BLEU	17.63	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  E12-1026
title: Adapting Translation Models to Translationese Improves SMT
link: http://www.aclweb.org/anthology/E12-1026
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : adapting to language direction
------data------
1	train	bitext	Hansard	1.5m sentences	French	English		
2	tune	bitext	Hansard	1000 sentences	French	English		
3	tune	bitext	Hansard	1000 sentences	English	French		
4	test	bitext	Hansard	1000 sentences	French	English		
5	test	bitext	Hansard	1000 sentences	English	French		
6	train	bitext	Hansard (500k F original + 500k E original)	1m sentences	French	English		
7	train	bitext	Hansard (500k F original + 1m E original)	1.5m sentences	French	English		
8	train	bitext	Hansard (500k F original + 1m E original)	1.5m sentences	French	English		
=====result=====
1	6	4	Union	BLEU	35.27	
1	6	4	PplRatio	BLEU	35.59	
1	7	4	Union	BLEU	35.36	
1	7	4	PplRatio	BLEU	35.78	
1	8	4	Union	BLEU	35.94	
1	8	4	PplRatio	BLEU	36.22	
diff_metric:
extra:I couldn't do this paper too well.  The paper is about mixing and matching French-original bitext with English-original bitext, and using the mixes to translate French-to-English and English-to-French.  So the language direction has to be part of each experiment.
<SURVEYEND>
<SURVEYSTART>
id:  P04-1068
title: Hindi-to-Urdu Machine Translation Through Transliteration
link: http://www.aclweb.org/anthology/P04-1068
first_name: Michael
last_name: Pust
goal #1 : improve translation quality
tech #1 : add better rule context
------data------
1	train	bitext	EMILLE	5600 sentences	Hindi	Urdu		
2	train	monolingual	University of Leipzig	108K sentences		Urdu	http://corpora.informatik.uni-leipzig.d	
3	test	bitext	EMILLE	1400 sentences	Hindi	Urdu		
=====result=====
1	1,2	3	Baseline	BLEU	16.25	
1	1,2	3	Transliteration	BLEU	19.35	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  C14-1195
title: Effective Incorporation of Source Syntax into Hierarchical Phrase-based Translation
link: http://www.aclweb.org/anthology/C14-1195
first_name: Adri
last_name: de Gispert
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	NIST12	9.2M sentences	Chinese	English		
2	test	bitext	newswire test set; contains MT08, MT12 and MT08 progress set	1779 sentences	Chinese	English		
3	test	bitext	web test set; contains MT08, MT12 and MT08 progress set	1768 sentences	Chinese	English		
4	train	monolingual	NIST12 monolingual + Google Ngrams			English		
=====result=====
1	1	2	baseline	BLEU	35.63	
2	1	2	baseline += tree-to-string rules and features	BLEU	36.38	
3	1	2	baseline += tree-to-string rules and features + forest binarization	BLEU	36.98	
4	1	3	baseline	BLEU	25.33	
5	1	3	baseline += tree-to-string rules and features	BLEU	25.98	
6	1	3	baseline += tree-to-string rules and features + forest binarization	BLEU	26.15	
diff_metric:
extra:This was case-insensitive BLEU
<SURVEYEND>
<SURVEYSTART>
id:  P12-1002
title: Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT
link: http://www.aclweb.org/anthology/P12-1002
first_name: Eunsol
last_name: Choi
goal #1 : detect parallel documents
tech #1 : improve tuning
------data------
1	train	bitext	News Commentary (train-nc)	132,753 sentences	German	English		
2	train	monolingual	News Commentary (lm-train-nc)	180,657 sentences		English		
3	tune	bitext	News Commentary (dev-nc)	1057 sentences	German	English		
4	tune	bitext	News Commentary (devtest-nc)	1064 sentences	German	English		
5	test	bitext	News Commentary (test-nc)	2007 sentences	German	English		
6	tune	bitext	News Crawl (dev-crawl)	2051 sentences	German	English		
7	tune	bitext	News Crawl (test-crawl10)	2489 sentences	German	English		
8	test	bitext	News Crawl (test-crawl11)	3003 sentences	German	English		
9	train	bitext	Europarl (train-ep)	1,655,238 sentences	German	English		
10	train	monolingual	Europarl (lm-train-ep)	2,015,440 sentences		English		
11	tune	bitext	Europarl (dev-ep)	2000 sentences	German	English		
12	tune	bitext	Europarl (devtest-ep)	2000 sentences	German	English		
13	test	bitext	Europarl (test-ep)	2000 sentences	German	English		
=====result=====
1	1,2,3,4	5	MIRA	BLEU	27.10	
1	1,2,3,4	5	algorithm 1 +idngshape	BLEU	28.15	
1	1,2,4	5	algorithm 2 +idngshape	BLEU	27.86	
1	1,2,4	5	algorithm 3 +idngshape	BLEU	28.55	
1	1,2,4	1	algorithm 4 +idngshape	BLEU	28.81	
1	9,10,11	13	algorithm 1 default	BLEU	26.42	
1	9,10,11	13	algorithm 4 +idngshape	BLEU	28.37	
1	9,10,11	13	algorithm 4 +idngshape	BLEU	28.62	
1	9,10,11	8	algorithm 1 default	BLEU	14.43	
1	6,9,10	8	algorithm 4 idngshape	BLEU	16.83	
1	6,9,10	8	algorithm 4 idngshape	BLEU	17.33	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  A11-2121
title: test
link: http://www.aclweb.org/anthology/A11-2121
first_name: Eunsol
last_name: Choi
goal #1 : detect parallel documents
tech #1 : add better rule context
------data------
1	train	bitext	12	1	2	2		
1	train	bitext	31	2	1	1		
=====result=====
1	1	1	3	BLEU	112	
1	2	1	2	BLEU	223	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N09-2036
title: Faster MT Decoding through Pervasive Laziness
link: http://www.aclweb.org/anthology/N09-2036
first_name: Kevin
last_name: Knight
goal #1 : improve translation speed
tech #1 : lazy search algorithms
------data------
1	train	bitext	unknown	unknown	Arabic	English		
2	test	bitext	unknown	unknown	Arabic	English		
=====result=====
1	1	2	Cube Pruning Bleu = 52.9	Time	91000	
1	1	2	Fully Lazy Decoding Bleu = 52.9	Time	62000	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W12-3131
title: The CMU-Avenue French-English Translation System
link: http://www.aclweb.org/anthology/W12-3131
first_name: Jon
last_name: May
goal #1 : improve translation quality
tech #1 : use weighted data
------data------
1	train	bitext	Europarl	1857436 sentences	French	English		
2	train	bitext	News commentary	130193 sentences	French	English		
3	train	bitext	UN doc	11684454 sentences	French	English		
4	train	bitext	Giga FrEn 1stdev	7535699 sentences	French	English		
5	train	bitext	Giga FrEn 2stdev	5801759 sentences	French	English		
6	train	monolingual	Europarl	59659916 words		English		
7	train	monolingual	News commentary	5081368 words		English		
8	train	monolingual	UN doc	286300902 words		English		
9	train	monolingual	News crawl	1109346008 words		English		
10	train	monolingual	Giga-FrEn	481929410 words		English		
11	train	monolingual	Gigaword 4th edition	1960921287 words		English		
12	test	bitext	WMT 12		French	English		
=====result=====
1	1,2,3,4,5,6,7,8,9,10,11	12	base 5-gram	BLEU	28.4	
1	1,2,3,4,5,6,7,8,9,10,11	12	+post-process	BLEU	30.2	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W12-3132
title: Formemes in English-Czech Deep Syntactic MT
link: http://www.aclweb.org/anthology/W12-3132
first_name: Ondej
last_name: Duek
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	tune	bitext	PCEDT2.0		Czech	English		
2	test	monolingual	PDT2.0		Czech			
4	test	bitext	WMT12		English	Czech		
3	train	bitext	CzEng1.0		English	Czech		
=====result=====
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D12-1025
title: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning , pages 266-275, Jeju Island, Korea, 12-14 July 2012. c  2012 Association for Computational Linguistics Large Scale Decipherment for Out-of-Domain Machine Translation
link: http://www.aclweb.org/anthology/D12-1025
first_name: qing
last_name: dou
goal #1 : improve translation quality
tech #1 : use decipherment to find translation for OOV
------data------
1	train	bitext	EMEA	28 million tokens	French	Spanish	http://opus.lingfil.uu.se/EMEA.p	
2	train	bitext	Europarl	30 million tokens	French	Spanish	http://www.statmt.org/europar	
3	test	bitext	EMEA	28k tokens	French	Spanish	http://opus.lingfil.uu.se/EMEA.p	
=====result=====
1	2	1	Baseline	BLEU	37.3	
1	1,2	1	Decipherment	BLEU	41.1	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D09-1073
title: Tree Kernel-based SVM with Structured Syntactic Knowledge for BTG-based Phrase Reordering
link: http://www.aclweb.org/anthology/D09-1073
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	test	bitext	NIST MT-2005		Chinese	English		
2	tune	bitext	NIST MT-2002 test set		Chinese	English		
3	train	bitext	FBIS		Chinese	English		
4	train	monolingual	Xinhua portion of the English Gigaword			English		
=====result=====
1	2,3,4	1	Composite Kernel (Kc)	BLEU	27.65	
1	2,3,4	1	Moses (B1)	BLEU	25.71	
1	2,3,4	1	MaxEnt+boundary word(B2)	BLEU	25.99	
1	2,3,4	1	MaxEnt+LABTG (B3)	BLEU	26.63	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P12-1027
title: Source Language Adaptation for Resource-Poor Machine Translation
link: http://www.aclweb.org/anthology/P12-1027
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : cross-language adaptation
------data------
1	train	bitext	IN2EN	28k sentences	Indonesian	English		
2	tune	bitext	IN2EN-dev	2k sentences	Indonesian	English		
3	test	bitext	IN2EN-test	2k sentences	Indonesian	English		
4	train	monolingual	EN-LM	5M tokens		English		
5	train	bitext	ML2EN	8.6M English words	Malay	English		
6	train	monolingual	IN-LM	20.5M words		Indonesian		
7	train	bitext	MK2EN	160k sentences	Macedonian	English		
8	train	bitext	BG2EN	1.5M sentences	Bulgarian	English		
9	test	bitext	MK2EN-test	10k sentences	Macedonian	English		
10	train	monolingual	MK-LM	9.2M words		Macedonian		
11	train	monolingual	EN-LM	433M words		English		
=====result=====
1	1,2,4,5,6	3	Baseline	BLEU	20.10	
1	1,2,4,5,6	3	CN:pivot' + morph	BLEU	21.05	
1	1,2,4,5,6	3	PPT:4::CN:morph	BLEU	20.98	
1	1,2,4,5,6	3	CN:pivot' + morph and PPT:4::CN:morph combination	BLEU	21.62	
1	7,8,10,11	9	Baseline	BLEU	26.46	
1	7,8,10,11	9	Combination	BLEU	29.05	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W12-3138
title: Machine Learning for Hybrid Machine Translation
link: http://www.aclweb.org/anthology/W12-3138
first_name: Kevin
last_name: Knight
goal #1 : improve translation quality
tech #1 : system combination
------data------
1	train	bitext			English	German		
2	tune	bitext	WMT12 newstest2011		English	German		
3	test	bitext	WMT12 newstest2012		English	German		
4	train	monolingual				German		
=====result=====
1	1,4	3	Baseline Systems Lucy	BLEU	14.0	
1	1,4	3	Baseline Systems Moses	BLEU	15.9	
1	1,4	3	Hybrid + MERT	BLEU	14.3	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P13-1036
title: Scalable Decipherment for Machine Translation via Hash Sampling
link: http://www.aclweb.org/anthology/P13-1036
first_name: Jon
last_name: May
goal #1 : improve translation quality
tech #1 : make decoding efficient
goal #2 : improve translation speed
tech #2 : make decoding efficient
------data------
1	train	monolingual	OPUS	13181 sentences	Spanish			
2	train	monolingual	OPUS	19770 sentences		English		
3	train	monolingual	EMEA	550,000 sentences	French			
4	train	monolingual	EMEA	550,000 sentences		Spanish		
=====result=====
1	1,2	2	identity translations	BLEU	6.9	
1	1,2	2	EM with whole-segment LM	BLEU	19.3	
2	1,2	2	EM with whole-segment LM	Time	850h	
1	1,2	2	Bayesian Hash Sampling with 3-gram LM	BLEU	21.2	
2	1,2	2	Bayesian Hash Sampling with 3-gram LM	Time	2.7h	
1	3,4	4	identity translations	BLEU	3.0	
1	3,4	4	Bayesian Hash Sampling with 2-gram LM	BLEU	5.3	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P08-1045
title: Name Translation in Statistical Machine Translation: Learning When to Transliterate
link: http://www.aclweb.org/anthology/P08-1045
first_name: Kevin
last_name: Knight
goal #1 : improve word/phrase alignment
tech #1 : transliteration
------data------
1	train	bitext	unknown	6m sentences	Arabic	English		
2	train	bitext	unknown	10,000 sentences	Arabic	English		
1	train	bitext						
=====result=====
1	1	2	Transliterate-me tagger	F1	91.4	
1	1	2	Transliterate-me tagger adjusted for gold deficiencies	F1	94.0	
1	1	2	Our transliterator (NEWA metric)	None of above		
1	1	2	Human 1 (NEWA metric)	None of above	85.0	
1	1	2	Human 2 (NEWA metric)	None of above	86.9	
1	1	2	Human 3 (NEWA metric)	None of above	91.8	
1	1	2	Human 4 (NEWA metric)	None of above	88.3	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N09-1025
title: 11,001 New Features for Statistical Machine Translation
link: http://www.aclweb.org/anthology/N09-1025
first_name: Knight, Kevin
last_name: 
goal #1 : improve translation quality
tech #1 : provide more features
------data------
2	tune	bitext	portions of NIST04 and NIST05	2010 sentences	Chinese	English		
1	train	bitext	available LDC data	260m words	Chinese	English		
3	test	bitext	portions of NIST04 and NIST05	1994 sentences	Chinese	English		
=====result=====
1	1	2	Hiero baseline	BLEU	35.4	
1	1	2	Hiero	BLEU	38.4	
1	1	2	Syntax-based baseline	BLEU	38.6	
1	1	2	Syntax-based	BLEU	39.6	
1	1	3	Hiero baseline	BLEU	36.1	
1	1	3	Hiero	BLEU	37.6	
1	1	3	Syntax-Based	BLEU	40.6	
1	1	3	Syntax-Based baseline	BLEU	39.5	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1065
title: Joint Decoding with Multiple Translation Models
link: http://www.aclweb.org/anthology/P09-1065
first_name: Ashish
last_name: Vaswani
goal #1 : System Combination
tech #1 : provide richer model
------data------
1	train	bitext	FBIS	6.9M + 8.9M	Chinese	English		
2	train	monolingual	Xinhua portion of Gigaword			English		
3	tune	bitext	NIST 2002 MT Evaluation test		Chinese	English		
4	test	bitext	NIST 2005 test		Chinese	English		
=====result=====
1	1,2	3	Baseline hierarchical Max-derivation decoding	BLEU	30.11	
1	1,2	3	Baseline hierarchical Max-translation decoding	BLEU	29.82	
1	1,2	3	Baseline tree-to-string Max-derivation decoding	BLEU	27.23	
1	1,2	3	Baseline tree-to-string Max-translation decoding	BLEU	27.11	
1	1,2	3	Both translation Max-translation decoding	BLEU	30.79	
1	1,2	3	Both derivation Max-derivation decoding	BLEU	31.63	
1	1,2	3	both derivation Max-translation decoding	BLEU	31.49	
1	1,2	3	Baseline hierarchical Max-derivation decoding	Time	40.53
1	1,2	3	Baseline hierarchical Max-translation decoding	Time	44.87
1	1,2	3	Baseline tree-to-string Max-derivation decoding	Time	6.13
1	1,2	3	Baseline tree-to-string Max-translation decoding	Time	6.69
1	1,2	3	both translation Max-translation decoding	Time	55.89
1	1,2	3	both derivation Max-derivation decoding	Time	48.45
1	1,2	3	both derivation Max-translation decoding	Time	54.91
1	1,2	3	Baseline system combination both decoding	BLEU	31.50	
1	1,2	3	Baseline individual Max-derivation training	BLEU	30.7	
1	1,2	3	Baseline individual Max-translation training	BLEU	29.95	
1	1,2	3	joint Max-derivation training	BLEU	31.63	
1	1,2	3	joint Max-translation training	BLEU	30.79	
diff_metric: seconds/sentence	
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N09-1049
title: Hierarchical Phrase-Based Translation with Weighted Finite State Transducers
link: http://www.aclweb.org/anthology/N09-1049
first_name: Gonzalo
last_name: Iglesias
goal #1 : improve translation quality
tech #1 : use new decoder architecture
------data------
1	train	bitext	NIST08	150M words	Arabic	English		
2	train	bitext	GALE2008		Chinese	English		
3	train	monolingual	subset of Gigaword Third Edition	965M words		English		
4	tune	bitext	mt02-05-tune	2,075 sentences		Arabic	English		
5	test	bitext	mt02-05-test		Arabic	English		
7	tune	bitext	tune-nw	1,755 sentences	Chinese	English		
8	test	bitext	test-nw		Chinese	English		
6	test	bitext	mt08		Arabic	English		
9	test	bitext	mt08		Chinese	English		
=====result=====
1	1,3	4	Baseline HCP+mbr	BLEU	53.2	
1	1,3	5	Baseline HCP+mbr	BLEU	52.6	
1	1,3	6	Baseline HCP+mbr	BLEU	43.4	
1	1,3	4	HiFST+mbr	BLEU	53.7	
1	1,3	5	HiFST+mbr	BLEU	53.3	
1	1,3	6	HiFST+mbr	BLEU	44.0	
1	2,3	7	Baseline HCP + mbr	BLEU	32.4	
1	2,3	8	Baseline HCP + mbr	BLEU	32.7	
1	2,3	7	HiFST+mbr	BLEU	32.9	
1	2,3	8	HiFST+mbr	BLEU	33.4	
1	2,3	9	HiFST+mbr	BLEU	28.9	
1	2,3	9	Baseline HCP + mbr	BLEU	28.1	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D13-1201
title: Regularized Minimum Error Rate Training
link: http://www.aclweb.org/anthology/D13-1201
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve search
------data------
2	test	bitext	mt08	1,357	Chinese	English		
3	test	bitext	mt09	1,313	Arabic	English		
4	test	bitext	unknown	4,855	Finnish	English		
5	train	monolingual	Xinhua portion of the English Gigaword			English		
6	train	bitext	FBIS and Hong Kong portions of the LDC data for the NIST MT evaluation	0.99M, one million	Chinese	English		
7	train	monolingual	NIST 2012 MT evaluation, target side of the parallel training data for Arabic			English		
8	train	monolingual	NIST 2012 MT evaluation, target side of the parallel training data for Chinese			English		
9	train	bitext	NIST 2012 MT	3.51M	Chinese	English		
10	train	bitext	NIST 2012 MT	1.49M	Arabic	English		
11	train	monolingual	unknown			English		
12	train	bitext	unknown	2.20M	Finnish	English		
13	test	bitext	mt05	1,082	Chinese	English		
=====result=====
1	7,10	3	l2 MERT (v1: ||w  w0||) GBM Features	BLEU	46.0	
1	7,10	3	MERT GBM Features	BLEU	45.5	
1	7,10	3	PRO GBM Features	BLEU	46.1	
1	8,9	2	l2 MERT (v1: ||w  w0||) GBM Features	BLEU	28.3	
1	8,9	2	MERT GBM Features	BLEU	27.8	
1	8,9	2	PRO GBM Features	BLEU	28.1	
1	5,6	13	l2 MERT (v1: ||w  w0||) SparseHRM features	BLEU	33.5	
1	5,6	13	MERT SparseHRM features	BLEU	32.9	
1	5,6	13	PRO SparseHRM features	BLEU	33.3	
1	12,11	4	l2 MERT (v1: ||w  w0||) SparseHRM features	BLEU	55.2	
1	12,11	4	MERT SparseHRM features	BLEU	54.8	
1	12,11	4	PRO SparseHRM features	BLEU	55.3	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1103
title: A non-contiguous Tree Sequence Alignment-based Model for Statistical Machine Translation
link: http://www.aclweb.org/anthology/P09-1103
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	FBIS	9.2M English words, 7.2M Chinese words	Chinese	English		
2	train	monolingual	Gigaword Xinhua	181M words		English		
3	tune	bitext	MT-2002 test set		Chinese	English		
4	test	bitext	MT-2005 test set		Chinese	English		
=====result=====
1	1,2,3	4	Moses	BLEU	23.86	
1	1,2,3	4	Pisces	BLEU	25.92	
1	1,2,3	4	SncTSSG	BLEU	26.53	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1105
title: Confidence Measure for Word Alignment
link: http://www.aclweb.org/anthology/P09-1105
first_name: Matic
last_name: Horvat
goal #1 : improve word/phrase alignment
tech #1 : provide richer model
------data------
1	train	bitext	unknown		Chinese	English		
2	test	bitext	unknown		Chinese	English		
3	train	bitext	unknown		Arabic	English		
4	test	bitext	unknown		Arabic	English		
=====result=====
1	1	2	ME	Precision	72.66	
1	1	2	ME	Recall	66.17	
1	1	2	Link-Select	Precision	69.19	
1	1	2	Link-Select	Recall	72.49	
1	1	2	ALF	Precision	78.14	
1	1	2	ALF	Recall	64.36	
1	3	4	Baseline	Precision	84.43	
1	3	4	Baseline	Recall	83.64	
1	3	4	ALF	Precision	88.29	
1	3	4	ALF	Recall	83.14	
1	1	2	Baseline	BLEU	28.05	
1	1	2	ALF	BLEU	28.52	
1	1	2	Baseline	BLEU	25.08	
1	1	2	ALF	BLEU	28.52	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1107
title: Incremental HMM Alignment for MT System Combination
link: http://www.aclweb.org/anthology/P09-1107
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve alignment
------data------
1	test	bitext	2008 NIST		Chinese	English		
2	train	bitext	newswire and newsgroup sections of MT06		Chinese	English		
=====result=====
1	2	1	best single system	BLEU	27.75	
1	2	1	pair-wise TER	BLEU	30.96	
1	2	1	incremental TER	BLEU	31.23	
1	2	1	pair-wise IHMM	BLEU	31.65	
1	2	1	incremental IHMM	BLEU	32.63	
1	2	1	IncIHMM2	BLEU	32.60	
1	2	1	CD-IHMM	BLEU	31.87	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D11-1127
title: Hierarchical Phrase-Based Translation Representations
link: http://www.aclweb.org/anthology/D11-1127
first_name: Gonzalo
last_name: Iglesias
goal #1 : improve translation quality
tech #1 : better decoder
------data------
3	train	bitext	GALE 2008 Excluding the UN material and the LDC2002E18, LDC2004T08, LDC2007E08 and CUDonga collections	2.1M sentences	Chinese	English	http://projects.ldc.upenn.edu/gale/data/catalog.h	
1	tune	bitext	GALE, portions of MT02 through MT06	1755 sentences	Chinese	English		
2	test	bitext	GALE, portions of MT02 through MT06	1671 sentences	Chinese	English		
4	train	monolingual	AFP and Xinhua portions of mono- lingual data from the English Gigaword Fourth Edi- tion (LDC2009T13)	1.3B words				
=====result=====
1	3,4	1	Baseline	BLEU	34.8	
1	3,4	2	Baseline	BLEU	35.6	
1	3,4	1	G1 theta=7.5e-9 beta=10	BLEU	34.8	
1	3,4	2	G1 theta=7.5e-9 beta=10	BLEU	35.6	
1	3,4	1	G1 theta=7.5e-9 beta=9	BLEU	34.9	
1	3,4	2	G1 theta=7.5e-9 beta=9	BLEU	35.5	
1	3,4	1	G1 theta=7.5e-8 beta=12	BLEU	34.7	
1	3,4	2	G1 theta=7.5e-8 beta=12	BLEU	35.6	
1	3,4	1	G1 theta=7.5e-8 beta=9	BLEU	34.8	
1	3,4	2	G1 theta=7.5e-8 beta=9	BLEU	35.2	
1	3,4	1	G1 theta=7.5e-8 beta=8	BLEU	34.8	
1	3,4	2	G1 theta=7.5e-8 beta=8	BLEU	35.1	
1	3,4	1	G1 theta=7.5e-7 beta=15	BLEU	34.7	
1	3,4	2	G1 theta=7.5e-7 beta=15	BLEU	35.6	
1	3,4	1	G1 theta=7.5e-7 beta=12	BLEU	34.7	
1	3,4	2	G1 theta=7.5e-7 beta=12	BLEU	35.5	
1	3,4	1	G2 theta=7.5e-7 beta=15	BLEU	35.2	
1	3,4	2	G2 theta=7.5e-7 beta=15	BLEU	36.1	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D11-1125
title: Tuning as Ranking
link: http://www.aclweb.org/anthology/D11-1125
first_name: Jonathan
last_name: May
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
1	train	bitext	NIST09train	515k sentences	Urdu	English		
2	tune	bitext	NIST08eval	923 sentences	Urdu	English		
3	test	bitext	NIST08eval	938 sentences	Urdu	English		
4	train	bitext	NIST08train	6.5m sentences	Arabic	English		
5	tune	bitext	NIST03-06eval+GALEdev	1994 sentences	Arabic	English		
6	test	bitext	NIST08eval	1357 sentences	Arabic	English		
7	train	bitext	GALE08train	7.9m sentences	Chinese	English		
8	tune	bitext	NIST03-06eval	1615 sentences	Chinese	English		
9	test	bitext	NIST08eval	1357 sentences	Chinese	English		
=====result=====
1	1,2	3	pbmt Urdu-English base MERT test	BLEU	17.7	
1	1,2	3	pbmt Urdu-English base MIRA test	BLEU	17.9	
1	1,2	3	pbmt Urdu-English base PRO test	BLEU	18.2
1	1,2	3	pbmt Urdu-English ext MIRA test	BLEU	17.8
1	1,2	3	pbmt Urdu-English ext PRO test	BLEU	18.1
1	4,5	6	pbmt Arabic-English base MERT test	BLEU	41.2
1	4,5	6	pbmt Arabic-English base MIRA test	BLEU	41.1
1	4,5	6	pbmt Arabic-English base PRO test	BLEU	41.1
1	4,5	6	pbmt Arabic-English ext MIRA test	BLEU	41.7
1	4,5	6	pbmt Arabic-English ext PRO test	BLEU	41.9	
1	7,8	9	pbmt Chinese-English base MERT test	BLEU	23.8	
1	7,8	9	pbmt Chinese-English base MERT test	BLEU	22.2	
1	7,8	9	pbmt Chinese-English base MIRA test	BLEU	24.1	
1	7,8	9	pbmt Chinese-English base MIRA test	BLEU	22.5
1	7,8	9	pbmt Chinese-English base PRO test	BLEU	22.5
1	7,8	9	pbmt Chinese-English ext MIRA test	BLEU	22.6
1	7,8	9	pbmt Chinese-English ext PRO test	BLEU	22.7
1	1,2	3	sbmt Urdu-English base MERT test	BLEU	21.4
1	1,2	3	sbmt Urdu-English base MIRA test	BLEU	22.3
1	1,2	3	sbmt Urdu-English base PRO test	BLEU	22.2
1	1,2	3	sbmt Urdu-English ext MIRA test	BLEU	22.8
1	1,2	3	sbmt Urdu-English ext PRO test	BLEU	22.8	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W11-2145
title: The Karlsruhe Institute of Technology Translation Systems for the WMT 2011
link: http://www.aclweb.org/anthology/W11-2145
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	test	bitext	news-test2010		French	English		
2	train	bitext	News Commentary		French	English		
3	train	bitext	UN		French	English		
4	train	bitext	Giga corpus		French	English		
5	train	bitext	news-test2008 data set		French	English		
6	train	bitext	EPPS		French	English		
7	tune	bitext	news-test2009		German	English		
8	train	bitext	News Commentary		English	French		
9	train	monolingual	UN			French		
10	train	bitext	Giga corpus		English	French		
11	train	bitext	news-test2008 data set		English	French		
12	train	bitext	EPPS		English	French		
13	test	bitext	news-test2010		English	French		
14	train	bitext	News Commentary		German	English		
15	train	bitext	UN		German	English		
16	train	bitext	Giga corpus		German	English		
17	train	bitext	news-test2008 data set		German	English		
18	train	bitext	EPPS		German	English		
19	test	bitext	news-test2010		German	English		
20	train	bitext	News Commentary		English	German		
21	train	bitext	UN		English	German		
22	train	bitext	Giga corpus		English	German		
23	train	bitext	news-test2008 data set		English	German		
24	train	bitext	EPPS		English	German		
25	test	bitext	news-test2010		English	German		
26	train	monolingual	EPPS			French		
26	train	monolingual	News Commentary			French		
28	train	monolingual	EPPS			English		
28	train	monolingual	News Commentary			English		
29	train	monolingual	News Shuffle			English		
28	train	monolingual	Gigaword			English		
30	train	monolingual	EPPS			German		
30	train	monolingual	News Commentary			German		
26	train	monolingual	News Shuffle			German		
=====result=====
1	8,9,10,11,12,26	13	Baseline	BLEU	22.36	
1	8,9,10,11,12,26	13	+ Merged LMs	BLEU	28.28	
1	2,3,4,5,6,28	1	Baseline	BLEU	23.78	
1	2,3,4,5,6,28,29	1	+ BiLM	BLEU	28.34	
1	20,21,22,23,24,28	25	Baseline	BLEU	14.19	
1	20,21,22,23,24,28,29	25	+ POS LM	BLEU	16.88	
1	14,15,16,17,18,7,30	19	Baseline	BLEU	19.10	
1	14,15,16,17,18,7,30,27	19	+ Bilingual LM	BLEU	23.35	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W08-0306
title: Using Syntax to Improve Word Alignment Precision for Syntax-Based Machine Translation
link: http://www.aclweb.org/anthology/W08-0306
first_name: Kevin
last_name: Knight
goal #1 : improve word/phrase alignment
tech #1 : improve syntax
------data------
1	train	bitext	unknown	400 sentences	Chinese	English		
2	test	bitext	unknown	400 sentences	Chinese	English		
3	train	bitext	unknown	1500 sentences	Chinese	English		
4	test	bitext	unknown	1500 sentences	Chinese	English		
5	train	bitext	unknown	1500 sentences	Arabic	English		
6	test	bitext	unknown	1500 sentences	Arabic	English		
7	train	bitext	unknown	9.8m words	Chinese	English		
8	tune	bitext	NIST02	25.9k words	Chinese	English		
9	test	bitext	NIST03	29.0k words	Chinese	English		
10	train	bitext	unknown	12.3m words	Chinese	English		
11	tune	bitext	unknown	42.9k words	Chinese	English		
12	test	bitext	unknown	42.1k words	Chinese	English		
13	train	bitext	unknown	174.8m words	Arabic	English		
14	tune	bitext	NIST04-05	35.8k words	Arabic	English		
15	test	bitext	NIST04-05	40.3k words	Arabic	English		
16	test	bitext	unknown	53.0k words	Arabic	English		
=====result=====
1	1	2	GIZA++ union	F1	63.44	
1	1	2	Link deletion	F1	75.14	
1	3	4	GIZA++ union	F1	47.16	
1	3	4	Link deletion	F1	62.24	
1	5	6	GIZA++ union	F1	73.87	
1	5	6	Link deletion	F1	75.85	
1	7	9	GIZA++ union	BLEU	41.17	
1	7	9	Link deletion	BLEU	41.93	
1	10	12	GIZA++ union	BLEU	41.39	
1	10	12	Link deletion	BLEU	41.88	
1	13	12	GIZA++ union	BLEU	54.73	
1	13	12	Link deletion	BLEU	55.57	
1	13	12	GIZA++ union	BLEU	50.9	
1	13	12	Link deletion	BLEU	51.08	
1	13	12	GIZA++ union	BLEU	38.16	
1	13	12	Link deletion	BLEU	38.72	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W08-0306
title: Using Syntax to Improve Word Alignment Precision for Syntax-Based Machine Translation
link: http://www.aclweb.org/anthology/W08-0306
first_name: Victoria
last_name: Fossum
goal #1 : improve word/phrase alignment
goal #2 : improve translation quality
tech #1 : provide more features
tech #2 : improve alignment
------data------
1	train	bitext		9.8M words	Chinese	English		
2	tune	bitext	NIST02	25.9K words	Chinese	English		
3	test	bitext	NIST03	29.0K words	Chinese	English		
4	train	bitext		12.3M words	Chinese	English		
5	tune	bitext		42.9K words	Chinese	English		
6	test	bitext		42.1K words	Chinese	English		
7	train	bitext		174.8M words	Arabic	English		
8	tune	bitext	NIST04-05	35.8K words	Arabic	English		
9	test	bitext	NIST04-05	40.3K words	Arabic	English		
=====result=====
1	1,2	3	GIZA++ union	F1	63.44	
1	1,2	3	Link deletion	F1	75.14	
1	4,5	6	GIZA++ union	F1	47.16	
1	4,5	6	Link deletion	F1	62.24	
1	7,8	9	GIZA++ union	F1	73.87	
1	7,8	9	Link deletion	F1	75.85	
2	1,2	3	GIZA++ union	BLEU	41.47	
2	1,2	3	Link deletion	BLEU	41.93	
2	4,5	6	GIZA++ union	BLEU	41.39	
2	4,5	6	Link deletion	BLEU	41.88	
2	7,8	9	GIZA++ union	BLEU	50.9	
2	7,8	9	Link deletion	BLEU	51.08	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  E09-3008
title: A Comparison of Merging Strategies for Translation of German Compounds
link: http://www.aclweb.org/anthology/E09-3008
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve preprocessing
------data------
1	train	bitext	Europarl	701157 sentences	German	English		
2	tune	bitext	Europarl	500 sentences	German	English		
3	test	bitext	Europarl	2000 sentences	German	English		
=====result=====
1	1,2	3	Baseline with POS	BLEU	20.19	
1	1,2	3	Baseline without POS	BLEU	19.66	
1	1,2	3	POS-match + coord with POS unmarked	BLEU	20.10	
1	1,2	3	POS-match + coord without POS unmarked	BLEU	19.85	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W14-1617
title: Hallucinating Phrase Translations for Low Resource MT
link: http://www.aclweb.org/anthology/W14-1617
first_name: Chris
last_name: Callison-Burch
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	Europarl	2k	Spanish	English	http://www.statmt.org/wmt13/translation-task.ht	
2	train	bitext	Crowdsourced translations	2k	Hindi	English	http://joshua-decoder.org/data/indian-parallel-corpor	
3	test	bitext	WMT 2010 test set	2.5k	Spanish	English	http://statmt.org/wmt10/translation-task.ht	
4	test	bitext	Crowdsourced translations	1k	Hindi	English	http://joshua-decoder.org/data/indian-parallel-corpor	
=====result=====
1	1	3	Baseline	BLEU	13.47	
1	1	3	+ Phrase Trans, k=200	BLEU	14.57	
1	2	4	Baseline	BLEU	8.49	
1	2	4	+ Phrase Trans, k=200	BLEU	9.04	
1	1	3	Low Resource Baseline (Baseline Features)	BLEU	13.47	
1	1	3	+ Composeable Oracle from Initial Model	BLEU (Baseline Features)	14.90	
1	1	3	+ Composeable Oracle w/ Induced Unigram Trans. (Baseline Features)	BLEU	15.47	
1	1	3	Low Resource Baseline (Monolingually Estimated Feats)	BLEU	13.35	
1	1	3	+ Composeable Oracle from Initial Model (Monolingually Estimated Feats)	BLEU	15.18	
1	1	3	+ Composeable Oracle w/ Induced Unigram Trans. (Monolingually Estimated Feats)	BLEU	15.94	
diff_metric:
extra:You didn't enough Experiment IDs in your drop down list.
<SURVEYEND>
<SURVEYSTART>
id:  W10-2916
title: A Semi-Supervised Batch-Mode Active Learning Strategy for Improved Statistical Machine Translation
link: http://www.aclweb.org/anthology/W10-2916
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve data selection
------data------
1	train	bitext	unknown	33.9k sentences	English	Pashto		
2	tune	bitext	unknown	2.4k sentences	English	Pashto		
3	test	bitext	unknown	1.1k sentences	English	Pashto		
4	train	bitext	unknown	76.5k sentence	Pashto	English		
=====result=====
1		1		BLEU		
1		1		BLEU		
diff_metric:
extra:no result (just graph/relative gain)
<SURVEYEND>
<SURVEYSTART>
id:  D09-1008
title: Effective Use of Linguistic and Contextual Information for Statistical Machine Translation
link: http://www.aclweb.org/anthology/D09-1008
first_name: Eunsol
last_name: Choi
goal #1 : detect parallel documents
tech #1 : provide more features
------data------
1	test	bitext	MT06 newswire		Arabic	English		
2	test	bitext	MT08 newswire		Arabic	English		
3	test	bitext	MT06 newswire		Chinese	English		
4	test	bitext	MT08 newswire		Chinese	English		
5	tune	bitext	NIST MT02-05		Arabic	English		
6	tune	bitext	NIST MT02-05		Chinese	English		
7	train	bitext	GALE		Arabic	English		
8	train	bitext	GALE		Chinese	English		
9	train	monolingual	Gigaword corpus V3.0			English		
=====result=====
1	5,7,9	1	BASE Decoding (3-gram LM)	BLEU	48.75	
1	5,7,9	1	LBL+LEN+CLM Decoding (3-gram LM)	BLEU	50.75	
1	5,7,9	1	BASE Rescoring (5-gram LM)	BLEU	51.24	
1	5,7,9	1	LBL+LEN+CLM Rescoring (5-gram LM)	BLEU	52.61	
1	5,7,9	2	BASE Decoding (3-gram LM)	BLEU	49.58	
1	5,7,9	2	LBL+LEN+CLM Decoding (3-gram LM)	BLEU	51.24	
1	5,7,9	2	BASE Rescoring (5-gram LM)	BLEU	51.23	
1	5,7,9	2	LBL+LEN+CLM Rescoring (5-gram LM)	BLEU	52.60	
1	6,8,9	3	BASE Decoding (3-gram LM)	BLEU	37.44	
1	6,8,9	3	LBL+LEN+CLM Decoding (3-gram LM)	BLEU	38.41	
1	6,8,9	3	BASE Rescoring (5-gram LM)	BLEU	38.91	
1	6,8,9	3	LBL+LEN+CLM Rescoring (5-gram LM)	BLEU	39.58	
1	6,8,9	4	BASE Decoding (3-gram LM)	BLEU	33.05	
1	6,8,9	4	LBL+LEN+CLM Decoding (3-gram LM)	BLEU	33.83	
1	6,8,9	4	BASE Rescoring (5-gram LM)	BLEU	34.34	
1	6,8,9	4	LBL+LEN+CLM Rescoring (5-gram LM)	BLEU	35.72	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D10-1014
title: Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions
link: http://www.aclweb.org/anthology/D10-1014
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : add better rule context
------data------
1	train	bitext	a filtered subset of the Europarl	300k parallel bitext	English	German		
2	tune	bitext	a filtered subset of the Europarl	1k sentences	English	German		
3	test	bitext	a filtered subset of the Europarl	1k sentences	English	German		
4	train	bitext	transcription and human translation of conversations in travel domain	~500k parallel bitext	English	Chinese		
5	tune	bitext	transcription and human translation of conversations in travel domain	1.3k sentences	English	Chinese		
6	test	bitext	transcription and human translation of conversations in travel domain	1.3k sentences	English	Chinese		
=====result=====
1	1,2	3	Baseline	BLEU	17.06	
1	1,2	3	+Syntax	BLEU	17.01	
1	4,5	6	Baseline	BLEU	47.39	
1	4,5	6	+Syntax	BLEU	45.86	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N13-1002
title: Beyond Left-to-Right: Multiple Decomposition Structures for SMT
link: http://www.aclweb.org/anthology/N13-1002
first_name: Hui
last_name: Zhang
goal #1 : improve translation quality
tech #1 : add better rule context
------data------
1	train	bitext		4M sentences	English	Bulgarian		
2	tune	bitext	Microsoft in house data	1,497 sentences	English	Bulgarian		
3	test	bitext	Microsoft in house data	2,498	English	Bulgarian		
=====result=====
1	1	3	Baseline	BLEU	45.75	
1	1	3	4 5-gram	BLEU	48.57	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W12-3126
title: CCG Syntactic Reordering Models for Phrase-based Machine Translation
link: http://www.aclweb.org/anthology/W12-3126
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : improve syntax
------data------
2	tune	bitext	OpenMT 2008 evaluation	900 sentences	Urdu	English		
3	train	bitext	OpenMT 2008 training set	88 thousand sentences	Urdu	English		
1	test	bitext	OpenMT 2009 evaluation (NIST-09 TEST)		Urdu	English		
4	train	monolingual	WMT 2011 NEWSCRAWL, NEWSCOMENTARY and EUROPARL			English		
=====result=====
1	2,3,4	1	lexicalized reordering baseline (LR) NON-MBR	BLEU	28.8	
1	2,3,4	1	CCG chart-derived reordering model (CCG+LR) NON-MBR	BLEU	29.2	
1	2,3,4	1	lexicalized reordering baseline (LR) MBR	BLEU	29.1	
1	2,3,4	1	CCG chart-derived reordering model (CCG+LR) MBR	BLEU	29.1	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P09-1020
title: Forest-based Tree Sequence to String Translation Model
link: http://www.aclweb.org/anthology/P09-1020
first_name: Hui
last_name: Zhang
goal #1 : improve translation quality
tech #1 : add better rule context
------data------
1	train	bitext	FBIS	250k sentences	Chinese	English		
3	test	bitext	NIST MT-2003	1k sentences	Chinese	English		
2	tune	bitext	NIST MT-2002	1k sentences	Chinese	English		
=====result=====
1	1,2	3	Moses	BLEU	25.68	
1	1,2	3	FTS2S	BLEU	28.83	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D10-1043
title: Non-isomorphic Forest Pair Translation
link: http://www.aclweb.org/anthology/D10-1043
first_name: Hui
last_name: Zhang
goal #1 : improve training quality
tech #1 : add better rule context
goal #2 : improve training speed
tech #2 : make decoding efficient
------data------
1	train	bitext	FBIS	250K sentences	Chinese	English		
2	tune	bitext	NIST 2002	1K sentences	Chinese	English		
3	test	bitext	NIST2005	1K sentences	Chinese	English		
=====result=====
1	1,2	3	MOSES	BLEU	27.53	
1	1,2	3	FT2TS	BLEU	31.50	
2	1,2	3	Traditional: FT2TS (1toN) (noPPS)	second	152.6	
2	1,2	3	Ours: FT2TS (1toN) (withPPS)	second	5.22	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P14-1072
title: Kneser-Ney Smoothing on Expected Counts
link: http://www.aclweb.org/anthology/P14-1072
first_name: Hui
last_name: Zhang
goal #1 : improve word/phrase alignment
tech #1 : reduce overfitting
------data------
1	train	bitext	NIST 2009 constrained task	5M sentences	Arabic	English	All data was used except for: United Nations pro- ceedings (LDC2004E1	
2	tune	bitext	NIST 2008		Arabic	English			
3	test	bitext	NIST 2009		Arabic	English		
=====result=====
1	1	3	none (baseline)	BLEU	37.0	
1	1	3	expected KN	BLEU	38.2	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P12-1033
title: Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the l0-norm
link: http://www.aclweb.org/anthology/P12-1033
first_name: Ashish
last_name: Vaswani
goal #1 : improve word/phrase alignment
tech #1 : improve alignment
------data------
1	train	bitext	News Commentary	4 million words	Czech	English		
2	train	bitext	NIST 2009	9.7 million words	Arabic	English		
3	train	bitext	NIST	81 million words	Arabic	English		
4	train	bitext	NIST	21.6 million words	Chinese	English		
5	train	bitext	NIST	3.2 million words	Urdu	English		
6	test	monolingual	WMT10		Czech	English	http://www.statmt.org/wmt10
7	test	monolingual	WMT09		Czech	English		
8	test	monolingual	NIST 2009		Urdu	English		
9	test	monolingual	NIST 2008		Arabic	English		
10	test	monolingual	NIST 2009		Arabic	English		
11	test	monolingual	NIST 2008		Chinese	English		
12	train	monolingual	NIST 2008		Urdu	English		
=====result=====
1	1	6	Baseline	BLEU	17.3	
1	1	6	l0-norm 	BLEU	17.9	
1	2	9	Baseline	BLEU	39.8	
1	2	9	l0-norm 	BLEU	41.1	
1	3	9	Baseline	BLEU	41.6	
1	3	9	l0-norm 	BLEU	42.5	
1	2	10	Baseline	BLEU	42.5	
1	2	10	l0-norm 	BLEU	43.7	
1	3	10	Baseline	BLEU	44.9	
1	3	10	l0-norm 	BLEU	45.3	
1	4	11	Baseline	BLEU	28.7	
1	4	11	l0-norm 	BLEU	29.5	
1	5	8	Baseline	BLEU	29.8	
1	5	8	l0-norm 	BLEU	31.2	
1	5	12	Baseline	BLEU	25.3	
1	5	12	l0-norm 	BLEU	25.9	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D09-1108
title: Fast Translation Rule Matching for Syntax-based Statistical Machine Translation
link: http://www.aclweb.org/anthology/D09-1108
first_name: Hui
last_name: Zhang
goal #1 : improve translation speed
tech #1 : improve search
------data------
1	train	bitext	FBIS	250k sentences	Chinese	English		
2	tune	bitext	NIST 2002	1k sentences	Chinese	English		
3	test	bitext	NIST 2003	1k sentences	Chinese	English		
=====result=====
1	1	3	Exhaustive by tree	second	133.6	
1	1	3	Hyper-tree-based	second	0.873	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  P10-1017
title: Hierarchical Search for Word Alignment
link: http://www.aclweb.org/anthology/P10-1017
first_name: Jason
last_name: Riesa
goal #1 : improve word/phrase alignment
goal #2 : improve translation quality
tech #1 : improve search
tech #2 : improve alignment
------data------
1	train	bitext	LDC2006E86	800 sentence pairs	Arabic	English		
2	tune	bitext	LDC2006E86	100 sentence pairs	Arabic	English		
3	test	bitext	LDC2006E86	100 sentence pairs	Arabic	English		
4	train	bitext		50M words	Arabic	English		
5	tune	bitext	NIST 04/06	1172 sentence-pairs	Arabic	English		
6	test	bitext	NIST 04/06	746 sentence-pairs	Arabic	English		
=====result=====
1	4	3	Baseline (GIZA++ Model-4 with grow-diag-final)	F1	.688	
1	1,4	3	New model	F1	.751	
2	4	6	Baseline (GIZA++ Model-4 with grow-diag-final)	BLEU	45.1	
2	1,4	6	With alignments from new model	BLEU	47.5	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  W11-2153
title: Influence of Parser Choice on Dependency-Based MT
link: http://www.aclweb.org/anthology/W11-2153
first_name: Martin
last_name: Popel
goal #1 : improve translation quality
tech #1 : improve preprocessing
------data------
1	train	bitext	CzEng 0.9	8M sentence pairs	Czech	English		
2	train	monolingual	PennTB	990180 tokens	English			
3	test	bitext	new-dev2009 (WMT)					
=====result=====
1	1,2	3	TectoMT with MST and SentChunk	BLEU	0.1280	
1	1,2	3	TectoMT with MST	BLEU	0.1236	
1	1,2	3	TectoMT with Malt and SentChunk	BLEU	0.1253	
1	1,2	3	TectoMT with Malt	BLEU	0.1214	
1	1,2	3	TectoMT with ZPar and SentChunk	BLEU	0.1176	
1	1,2	3	TectoMT with ZPar	BLEU	0.1127	
1	1,2	3	TectoMT with CJ	BLEU	0.1284	
1	1,2	3	TectoMT with Stanford	BLEU	0.1277	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D11-1046
title: Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation
link: http://www.aclweb.org/anthology/D11-1046
first_name: Jason
last_name: Riesa
goal #1 : improve word/phrase alignment
goal #2 : improve translation quality
tech #1 : provide richer model
tech #2 : improve alignment
------data------
1	train	bitext	LDC2006E86	2280 aligned sentence pairs	Arabic	English		
2	train	bitext	LDC2006E83	1102 aligned sentence pairs	Chinese	English		
3	tune	bitext	LDC2006E86	100 aligned sentence pairs	Arabic	English		
4	tune	bitext	LDC2006E83	100 aligned sentence pairs	Chinese	English		
5	test	bitext	LDC2006E86	364	Arabic	English		
6	test	bitext	LDC2006E83	184	Chinese	English		
7	train	bitext		223Mw (English side)	Arabic	English		
8	train	bitext		264Mw (English side)	Chinese	English		
9	tune	bitext	NIST 04/06	1172 sentence pairs	Arabic	English		
10	tune	bitext	NIST 04/06	4089 sentence pairs	Chinese	English		
11	test	bitext	NIST 04/06	746 sentence pairs	Arabic	English		
12	test	bitext	NIST 04/06	4060 sentence pairs	Chinese	English		
=====result=====
1	7	5	Baseline (GIZA++ Model-4 with grow-diag-final)	F1	72.5	
1	1,7	5	New model (target tree alignments)	F1	86.8	
1	1,7	5	New model (iterative inference with grow-diag-final)	F1	87.6	
1	1,7	5	New model (iterative inference with intersection)	F1	83.4	
1	8	5	Baseline (GIZA++ Model-4 with grow-diag-final)	F1	71.7	
1	2,8	6	New model (target tree alignments)	F1	84.4	
1	2,8	6	New model (iterative inference with grow-diag-final)	F1	87.0	
1	2,8	6	New model (iterative inference with intersection)	F1	83.1	
2	7	11	Baseline	BLEU	47.6	
2	7	11	With alignments from "New model (target tree alignments)"	BLEU	48.3	
2	7	11	With alignments from "New model (iterative inference with grow-diag-final)"	BLEU	48.4	
2	7	11	With alignments from "New model (iterative inference with intersection)"	BLEU	48.6	
2	8	12	Baseline	BLEU	26.2	
2	8	12	With alignments from "New model (target tree alignments)"	BLEU	26.4	
2	8	12	With alignments from "New model (iterative inference with grow-diag-final)"	BLEU	27.0	
2	8	12	With alignments from "New model (iterative inference with intersection)"	BLEU	27.5	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D10-1053
title: Hierarchical Phrase-based Translation Grammars Extracted from Alignment Posterior Probabilities
link: http://www.aclweb.org/anthology/D10-1053
first_name: Adri
last_name: de Gispert
goal #1 : improve translation quality
tech #1 : provide richer model
------data------
1	train	bitext	GALE 2008 subset (excludes UN data, LDC2002E18, LDC2004T08, LDC2007E08 and CUDonga collections)	50M words per language	Chinese	English		
2	train	monolingual	English side of the parallel text, AFP and Xinhua portions of English GigaWord 4th edition, and 6.6B words of English newswire text			English		
3	test	bitext	portions of the newswire sections of MT02 through MT06	1671 sentences	Chinese	English		
4	test	bitext	60% of the NIST newswire portion of MT06	369 sentences	Chinese	English		
=====result=====
1	1,2	3	baseline (hiero grammar)	BLEU	35.6	
1	1,2	4	baseline (hiero grammar)	BLEU	37.6	
1	1,2	3	G2 grammar (rules extracted from phrase posteriors PP-st)	BLEU	36.4	
1	1,2	4	G2 grammar (rules extracted from phrase posteriors PP-st)	BLEU	38.2	
1	1,2	3	G2 grammar (LMBR system combination of PP-st and PP-ts)	BLEU	36.9	
1	1,2	4	G2 grammar (LMBR system combination of PP-st and PP-ts)	BLEU	39.3	
diff_metric:
extra:
<SURVEYEND>

