<SURVEYSTART>
id:  W12-4201
title: WSD for n -best reranking and local language modeling in SMT
link: http://www.aclweb.org/anthology/W12-4201
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : improve semantics
------data------
1	train	bitext	TED-talk corpus	107,268 sentences	French	English		
2	train	monolingual	TED-talk corpus	111,431 sentences	English			
3	tune	bitext	dev-2010	934 sentences	French	English		
4	test	bitext	test-2010	1,664 sentences	French	English		
=====result=====
1	1,2,3	4	baseline	BLEU	29.63	
1	1,2,3	4	rescoring	BLEU	30.00	
1	1,2,3	4	additional LM	BLEU	30.51	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  N09-2038
title: Incremental Adaptation of Speech-to-Speech Translation
link: http://www.aclweb.org/anthology/N09-2038
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : use domain adaptation
------data------
1	train	bitext	TransTac	650K sentence pairs	Iraqi	English		
3	test	bitext		824 utterance pairs	Iraqi	English		
2	tune	bitext		864 utterance pairs	Iraqi	English		
=====result=====
1	1,2	3	1gramLM ASR hypo 1gramLM MT Ref	BLEU	27.41	
1	1,2	3	No adaptation No adaptation	BLEU	28.83	
diff_metric:
extra:speech
<SURVEYEND>
<SURVEYSTART>
id:  Paper's ACL Anthology ID
title: Your Paper's Title
link: http://www.aclweb.org/anthology/Paper's ACL Anthology ID
first_name: Your First Name
last_name: Your Last Name
------data------
=====result=====
diff_metric:If you chose "other" for metric, please write it here.
extra:Feel free to give us feedback/comments.
<SURVEYEND>
<SURVEYSTART>
id:  C10-1138
title: Contextual Modeling for Meeting Translation Using Unsupervised Word Sense Disambiguation
link: http://www.aclweb.org/anthology/C10-1138
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
goal #2 : improve translation quality
tech #1 : use domain adaptation
tech #2 : improve semantics
------data------
1	train	bitext	AMI corpus		English	German		
2	train	bitext	de-news	1.5M words	English	German		
3	train	bitext	Europarl	24M words	English	German		
4	train	bitext	JRC Acquis	35M words	English	German		
5	train	bitext	generic English-German machine-readable dictio- naries	672k entries	English	German		
6	train	bitext	generic English-German machine-readable dictio- naries	140k entries	English	German		
7	tune	bitext	AMI corpus		English	German		
8	test	bitext	AMI corpus		English	German		
=====result=====
1	1,2,3,4,5,6,7	8	System 1	BLEU	21.1	
1	1,2,3,4,5,6,7	8	System 5	BLEU	22.1	
2	1,2,3,4,5,6,7	8	No WSD	BLEU	22.0	
2	1,2,3,4,5,6,7	8	No WSD	other	48.2	
2	1,2,3,4,5,6,7	8	With WSD	BLEU	22.0	
2	1,2,3,4,5,6,7	8	With WSD	other	47.9	
diff_metric:PER
extra:
<SURVEYEND>
<SURVEYSTART>
id:  E09-1011
title: Syntactic Phrase Reordering for English-to-Arabic Statistical Machine Translation
link: http://www.aclweb.org/anthology/E09-1011
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : improve pre-ordering
------data------
1	train	bitext	LDC corpora	3 million English words	English	Arabic		
2	tune	bitext	LDC corpora	2000 sentences	English	Arabic		
3	test	bitext	LDC corpora	2000 sentences	English	Arabic		
4	test	bitext	NIST MT 05 test set		English	Arabic		
5	tune	bitext	NIST MT 03 and 04 test sets		English	Arabic		
6	train	monolingual	35 million words	LDC Arabic Gigaword corpus, plus the Arabic side of the 3 million word training corpus	Arabic			
7	train	bitext	UN English- Arabic parallel text	30 million and 3 million words.				
8	tune	bitext	UN English- Arabic parallel text	1500 sentences	English	Arabic		
9	test	bitext	UN English- Arabic parallel text	500 sentences	English	Arabic		
10	train	bitext	BTEC 2007 Arabic-English corpus	200K words	English	Arabic		
11	tune	bitext	BTEC 2007 Arabic-English corpus	500 sentences	English	Arabic		
12	test	bitext	BTEC 2007 Arabic-English corpus	500 sentences	English	Arabic		
13	train	monolingual	BTEC 2007 Arabic-English corpus	200K words	Arabic			
=====result=====
1	1,2,6	3	Baseline	BLEU	21.3	
1	1,2,6	3	NP+PP+VP	BLEU	21.8	
1	1,4,6	5	Baseline	BLEU	23.44	
1	1,4,6	5	NP+PP	BLEU	23.68	
1	7,8	9	Baseline	BLEU	32.17	
1	7,8	9	VP	BLEU	32.46	
1	10,11,13	12	Baseline	BLEU	25.4	
1	10,11,13	12	NP	BLEU	26.83	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D09-1024
title: Improved Word Alignment with Statistics and Linguistic Heuristics
link: http://www.aclweb.org/anthology/D09-1024
first_name: Eunsol
last_name: Choi
goal #1 : improve word/phrase alignment
tech #1 : provide more features
------data------
1	test	bitext	LDC2006E86	837-sentence	English	Arabic		
2	train	bitext		6.6 million sentence pairs	English	Arabic		
3	tune	bitext	LDC2006E86	100-sentence	English	Arabic		
4	test	bitext		1298 sentences	English	Arabic		
=====result=====
1	2,3	1	GIZA	F1	69.5	
1	2,3	1	UALIGN GS-style	F1	83.0	
1	2,3	4	GIZA	BLEU	47.4	
1	2,3	4	U ALIGN using LEAF alignment-lexicon	BLEU	48.7	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D12-1037
title: Locally Training the Log-Linear Model for SMT
link: http://www.aclweb.org/anthology/D12-1037
first_name: Matic
last_name: Horvat
goal #1 : improve translation quality
tech #1 : improve tuning
------data------
1	train	bitext	FBIS corpus	240k sentence pairs	Chinese	English		
2	tune	bitext	NIST02 evaluation data		Chinese	English		
3	tune	bitext	NIST05		Chinese	English		
4	test	bitext	NIST06		Chinese	English		
5	test	bitext	NIST08		Chinese	English		
=====result=====
1	1,2	4	MERT	BLEU	26.32	
1	1,2,3	4	MBUU	BLEU	27 . 88	
1	1,2,3	4	EBUU	BLEU	27 . 99	
1	1,2	5	MERT	BLEU	19.03	
1	1,2,3	5	MBUU	BLEU	20 . 84	
1	1,2,3	5	EBUU	BLEU	21 . 08	
diff_metric:
extra:
<SURVEYEND>
<SURVEYSTART>
id:  D09-1147
title: Consensus Training for Consensus Decoding in Machine Translation
link: http://www.aclweb.org/anthology/D09-1147
first_name: Eunsol
last_name: Choi
goal #1 : improve translation quality
tech #1 : reduce overfitting
------data------
1	train	bitext	Europarl corpus	8.5 million words	Spanish	English		
2	train	bitext	Europarl corpus	8.5 million words	French	English		
3	tune	bitext	SMT shared task	880 sentences	Spanish	English		
4	tune	bitext	SMT shared task	923 sentences	French	English		
5	test	bitext	SMT shared task	447 sentences	Spanish	English		
6	test	bitext	SMT shared task	512 sentences	French	English		
=====result=====
1	1,3	5	MERT (Consensus decoding)	BLEU	30.2	
1	1,3	5	MERTCoBLEU (Consensus decoding)	BLEU	30.8	
1	2,4	6	MERT (Consensus decoding)	BLEU	31.1	
1	2,4	6	MERTCoBLEU (Consensus decoding)	BLEU	31.2	
1	1,3	5	MERT (Viterbi decoding)	BLEU	30.2	
1	1,3	5	MERTCoBLEU (Viterbi decoding)	BLEU	30.9	
1	2,4	6	MERT (Viterbi decoding)	BLEU	31.0	
1	2,4	6	MERTCoBLEU (Viterbi decoding)	BLEU	30.9	
diff_metric:
extra:
<SURVEYEND>
