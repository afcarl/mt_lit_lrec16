<document>
  <filename>W13-2209</filename>
  <authors>
    <author>Alexey Borisov</author>
    <author>Jacob Dlougach</author>
  </authors>
  <title>Yandex School of Data Analysis machine translation systems for WMT13</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>This paper describes the English-Russian and Russian-English statistical machine translation (SMT) systems developed at Yandex School of Data Analysis for the shared translation task of the ACL 2013 Eighth Workshop on Statistical Machine Translation. We adopted phrase-based SMT approach and evaluated a number of different techniques, including data filtering, spelling correction, alignment of lemmatized word forms and transliteration. Altogether they yielded +2.0 and +1.5 BLEU improvement for ru-en and enru language pairs. We also report on the experiments that did not have any positive effect and provide an analysis of the problems we encountered during the development of our systems.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This paper describes the English-Russian and Russian-English statistical machine translation (SMT) systems developed at Yandex School of Data Analysis for the shared translation task of the ACL 2013 Eighth Workshop on Statistical Machine Translation.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We adopted phrase-based SMT approach and evaluated a number of different techniques, including data filtering, spelling correction, alignment of lemmatized word forms and transliteration.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Altogether they yielded +2.0 and +1.5 BLEU improvement for ru-en and enru language pairs.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We also report on the experiments that did not have any positive effect and provide an analysis of the problems we encountered during the development of our systems.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>We participated in the shared translation task of the ACL 2013 Workshop on Statistical Machine Translation (WMT13) for ru-en and en-ru language pairs. We provide a detailed description of the experiments carried out for the development of our systems.
The rest of the paper is organized as follows. Section 2 describes the tools and data we used. Our Russian&#8594;English and English&#8594;Russian setups are discussed in Section 3. In Section 4 we report on the experiments that did not have any positive effect despite our expectations. We provide a thorough analysis of erroneous outputs in Section 5 and draw conclusions in Section 6.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We participated in the shared translation task of the ACL 2013 Workshop on Statistical Machine Translation (WMT13) for ru-en and en-ru language pairs.</text>
              <doc_id>4</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We provide a detailed description of the experiments carried out for the development of our systems.</text>
              <doc_id>5</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The rest of the paper is organized as follows.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 2 describes the tools and data we used.</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Our Russian&#8594;English and English&#8594;Russian setups are discussed in Section 3.</text>
              <doc_id>8</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Section 4 we report on the experiments that did not have any positive effect despite our expectations.</text>
              <doc_id>9</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We provide a thorough analysis of erroneous outputs in Section 5 and draw conclusions in Section 6.</text>
              <doc_id>10</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Tools and data</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>11</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Tools</title>
            <text>We used an open source SMT system Moses (Koehn et al., 2007) for all our experiments excluding the one described in Section 4.1 due to its performance constraints. To overcome the limitation we employed our in-house decoder. Language models (LM) were created with an open source IRSTLM toolkit (Federico et al., 2008). We computed 4-gram LMs with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We used an open source MGIZA++ tool (Gao and Vogel, 2008) to compute word alignment. To obtain part of speech (POS) tags we used an open source Stanford POS tagger for English (Toutanova et al., 2003) and an open source suite of language analyzers, FreeLing 3.0 (Carreras et al., 2004; Padr&#243; and Stanilovsky, 2012), for Russian. We utilized a closed source free for noncommercial use morphological analyzer, Mystem (Segalovich, 2003), that used a limited dictionary to obtain lemmas. We also made use of the in-house language recognizer based on (Dunning, 1994) and a spelling corrector designed on the basis of the work of Cucerzan and Brill (2004). We report all results in case-sensitive BLEU (Papineni et al., 2002) using mt-eval13a script from Moses distribution.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We used an open source SMT system Moses (Koehn et al., 2007) for all our experiments excluding the one described in Section 4.1 due to its performance constraints.</text>
                  <doc_id>12</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To overcome the limitation we employed our in-house decoder.</text>
                  <doc_id>13</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Language models (LM) were created with an open source IRSTLM toolkit (Federico et al., 2008).</text>
                  <doc_id>14</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We computed 4-gram LMs with modified Kneser-Ney smoothing (Kneser and Ney, 1995).</text>
                  <doc_id>15</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We used an open source MGIZA++ tool (Gao and Vogel, 2008) to compute word alignment.</text>
                  <doc_id>16</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>To obtain part of speech (POS) tags we used an open source Stanford POS tagger for English (Toutanova et al., 2003) and an open source suite of language analyzers, FreeLing 3.0 (Carreras et al., 2004; Padr&#243; and Stanilovsky, 2012), for Russian.</text>
                  <doc_id>17</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>We utilized a closed source free for noncommercial use morphological analyzer, Mystem (Segalovich, 2003), that used a limited dictionary to obtain lemmas.</text>
                  <doc_id>18</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>We also made use of the in-house language recognizer based on (Dunning, 1994) and a spelling corrector designed on the basis of the work of Cucerzan and Brill (2004).</text>
                  <doc_id>19</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>We report all results in case-sensitive BLEU (Papineni et al., 2002) using mt-eval13a script from Moses distribution.</text>
                  <doc_id>20</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Data Training data</title>
            <text>We used News Commentary and News Crawl monolingual corpora provided by the organizers of the workshop. Bilingual training data comprised English- Russian parallel corpus release by Yandex 1 , News Commentary and Common Crawl corpora provided by the organizers. We also exploited Wiki Headlines collection of three parallel corpora provided by CMU 2 as a
The newstest2012 test set (Callison-Burch et al., 2012) was divided in the ratio 2:1 into a tuning set and a test set. The latter is referred to as newstest2012-test in the rest of the paper.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We used News Commentary and News Crawl monolingual corpora provided by the organizers of the workshop.</text>
                  <doc_id>21</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Bilingual training data comprised English- Russian parallel corpus release by Yandex 1 , News Commentary and Common Crawl corpora provided by the organizers.</text>
                  <doc_id>22</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We also exploited Wiki Headlines collection of three parallel corpora provided by CMU 2 as a</text>
                  <doc_id>23</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The newstest2012 test set (Callison-Burch et al., 2012) was divided in the ratio 2:1 into a tuning set and a test set.</text>
                  <doc_id>24</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The latter is referred to as newstest2012-test in the rest of the paper.</text>
                  <doc_id>25</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Primary setups</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>26</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Baseline</title>
            <text>We built the baseline systems according to the instructions available at the Moses website 3 .</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We built the baseline systems according to the instructions available at the Moses website 3 .</text>
                  <doc_id>27</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Preprocessing</title>
            <text>The first thing we noticed was that some sentences marked as Russian appeared to be sentences in other languages (most commonly English). We applied a language recognizer for both monolingual and bilingual corpora. Results are given in Table 1.
The next thing we came across was the presence of a lot of spelling errors in our training data, so we applied a spelling corrector. Statistics are presented in Table 2.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The first thing we noticed was that some sentences marked as Russian appeared to be sentences in other languages (most commonly English).</text>
                  <doc_id>28</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We applied a language recognizer for both monolingual and bilingual corpora.</text>
                  <doc_id>29</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Results are given in Table 1.</text>
                  <doc_id>30</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The next thing we came across was the presence of a lot of spelling errors in our training data, so we applied a spelling corrector.</text>
                  <doc_id>31</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Statistics are presented in Table 2.</text>
                  <doc_id>32</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Alignment of lemmatized word forms</title>
            <text>Russian is a language with rich morphology. The diversity of word forms results in data sparseness that makes translation of rare words difficult. In some cases inflections do not contain any additional information and are used
3 http://www.statmt.org/moses/?n=moses.
baseline
only to make an agreement between two words. E.g. ADJ + NOUN: &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1072;&#1103; &#1072;&#1088;&#1092;&#1072; (beautiful harp), &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1086;&#1077; &#1087;&#1080;&#1072;&#1085;&#1080;&#1085;&#1086; (beautiful piano), &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1099;&#1081; &#1088;&#1086;&#1103;&#1083;&#1100; (beautiful grand piano). These inflections reflect the gender of the noun words, that has no equivalent in English.
In this particular case we can drop the inflections, but for other categories they can still be useful for translation, because the information they contain appears in function words in English. On the other hand, most of Russian morphology is useless for word alignment. We applied a morphological analyzer Mystem (Segalovich, 2003) to the Russian text and converted each word to its dictionary form. Next we computed word alignment between the original English text and the lemmatized Russian text. All the other steps were executed according to the standard procedure with the original texts.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Russian is a language with rich morphology.</text>
                  <doc_id>33</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The diversity of word forms results in data sparseness that makes translation of rare words difficult.</text>
                  <doc_id>34</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In some cases inflections do not contain any additional information and are used</text>
                  <doc_id>35</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3 http://www.statmt.org/moses/?n=moses.</text>
                  <doc_id>36</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>baseline</text>
                  <doc_id>37</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>only to make an agreement between two words.</text>
                  <doc_id>38</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. ADJ + NOUN: &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1072;&#1103; &#1072;&#1088;&#1092;&#1072; (beautiful harp), &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1086;&#1077; &#1087;&#1080;&#1072;&#1085;&#1080;&#1085;&#1086; (beautiful piano), &#1082;&#1088;&#1072;&#1089;&#1080;&#1074; &#1099;&#1081; &#1088;&#1086;&#1103;&#1083;&#1100; (beautiful grand piano).</text>
                  <doc_id>39</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>These inflections reflect the gender of the noun words, that has no equivalent in English.</text>
                  <doc_id>40</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In this particular case we can drop the inflections, but for other categories they can still be useful for translation, because the information they contain appears in function words in English.</text>
                  <doc_id>41</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>On the other hand, most of Russian morphology is useless for word alignment.</text>
                  <doc_id>42</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We applied a morphological analyzer Mystem (Segalovich, 2003) to the Russian text and converted each word to its dictionary form.</text>
                  <doc_id>43</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Next we computed word alignment between the original English text and the lemmatized Russian text.</text>
                  <doc_id>44</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>All the other steps were executed according to the standard procedure with the original texts.</text>
                  <doc_id>45</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>3.4 Phrase score adjustment</title>
            <text>Sometimes phrases occur one or two times in the training corpus. In this case the corresponding phrase translation probability would be overestimated. We used Good-Turing technique described in (Gale, 1994) to decrease it to some more realistic value.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Sometimes phrases occur one or two times in the training corpus.</text>
                  <doc_id>46</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In this case the corresponding phrase translation probability would be overestimated.</text>
                  <doc_id>47</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We used Good-Turing technique described in (Gale, 1994) to decrease it to some more realistic value.</text>
                  <doc_id>48</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>4</index>
            <title>3.5 Decoding</title>
            <text>Minimum Bayes-Risk (MBR) MBR decoding (Kumar and Byrne, 2004) aims to minimize the expected loss of translation errors. As it is not possible to explore the space of all possible translations, we approximated it with the 1,000 most probable translations. A minus smoothed BLEU score (Lin and Och, 2004) was used for the loss function.
Reordering constrains We forbade reordering over punctuation and translated quoted phrases independently.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Minimum Bayes-Risk (MBR) MBR decoding (Kumar and Byrne, 2004) aims to minimize the expected loss of translation errors.</text>
                  <doc_id>49</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As it is not possible to explore the space of all possible translations, we approximated it with the 1,000 most probable translations.</text>
                  <doc_id>50</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A minus smoothed BLEU score (Lin and Och, 2004) was used for the loss function.</text>
                  <doc_id>51</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Reordering constrains We forbade reordering over punctuation and translated quoted phrases independently.</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>5</index>
            <title>3.6 Handling unknown words</title>
            <text>The news texts contained a lot of proper names that did not appear in the training data. E.g. almost 25% of our translations contained unknown words. Dropping the unknown words would lead to better BLEU scores, but it might had caused bad effect on human judgement. To leave them in Cyrillic was not an option, so we exploited two approaches: incorporating reliable data from Wiki Headlines and transliteration.
Wiki Headlines
We replaced the names occurring in the text with their translations, based on the information in "guessed-names" corpus from Wiki Headlines.
As has been mentioned in Section 3.3, Russian is a morphologically rich language. This often makes it hard to find exactly the same phrases, so we applied lemmatization of Russian language both for the input text and the Russian side of the reference corpus.
Russian&#8594;English transliteration
We gained considerable improvement from incorporating Wiki Headlines, but still 17% of translations contained Cyrillic symbols.
We applied a transliteration algorithm based on (Knight and Graehl, 1998). This technique yielded us a significant improvement, but introduced a lot of errors. E.g. &#1044;&#1078;&#1077;&#1081;&#1084;&#1089; &#1041;&#1086;&#1085;&#1076; (James Bond) was converted to Dzhejms Bond.
English&#8594;Russian transliteration
In Russian, it is a common practice to leave some foreign words in Latin. E.g. the names of companies: Apple, Google, Microsoft look inadmissible when either translated directly or transliterated.
Taking this into account, we applied the same transliteration algorithm (Knight and Graehl, 1998), but replaced an unknown word with its transliteration only if we found a sufficient number of occurrences of its transliterated form in the monolingual corpus. We used five for such number.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The news texts contained a lot of proper names that did not appear in the training data.</text>
                  <doc_id>53</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. almost 25% of our translations contained unknown words.</text>
                  <doc_id>54</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Dropping the unknown words would lead to better BLEU scores, but it might had caused bad effect on human judgement.</text>
                  <doc_id>55</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To leave them in Cyrillic was not an option, so we exploited two approaches: incorporating reliable data from Wiki Headlines and transliteration.</text>
                  <doc_id>56</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Wiki Headlines</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We replaced the names occurring in the text with their translations, based on the information in "guessed-names" corpus from Wiki Headlines.</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As has been mentioned in Section 3.3, Russian is a morphologically rich language.</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This often makes it hard to find exactly the same phrases, so we applied lemmatization of Russian language both for the input text and the Russian side of the reference corpus.</text>
                  <doc_id>60</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Russian&#8594;English transliteration</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We gained considerable improvement from incorporating Wiki Headlines, but still 17% of translations contained Cyrillic symbols.</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We applied a transliteration algorithm based on (Knight and Graehl, 1998).</text>
                  <doc_id>63</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This technique yielded us a significant improvement, but introduced a lot of errors.</text>
                  <doc_id>64</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. &#1044;&#1078;&#1077;&#1081;&#1084;&#1089; &#1041;&#1086;&#1085;&#1076; (James Bond) was converted to Dzhejms Bond.</text>
                  <doc_id>65</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>English&#8594;Russian transliteration</text>
                  <doc_id>66</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Russian, it is a common practice to leave some foreign words in Latin.</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. the names of companies: Apple, Google, Microsoft look inadmissible when either translated directly or transliterated.</text>
                  <doc_id>68</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Taking this into account, we applied the same transliteration algorithm (Knight and Graehl, 1998), but replaced an unknown word with its transliteration only if we found a sufficient number of occurrences of its transliterated form in the monolingual corpus.</text>
                  <doc_id>69</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We used five for such number.</text>
                  <doc_id>70</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>6</index>
            <title>3.7 Experimental results</title>
            <text>We summarized the gains from the described techniques for Russian&#8594;English and English&#8594;Russian tasks on Table 3.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We summarized the gains from the described techniques for Russian&#8594;English and English&#8594;Russian tasks on Table 3.</text>
                  <doc_id>71</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 What did not work</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>72</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 Translation in two stages</title>
            <text>Frequently machine translations contain errors that can be easily corrected by human post-editors. Since human aided machine translation is costefficient, we decided to address this problem to the computer.
We propose to translate sentences in two stages. At the first stage a SMT system is used to translate the input text into a preliminary form (in target language). At the next stage the preliminary form is translated again with an auxiliary SMT system trained on the translated and the target sides of the parallel corpus.
We encountered a technical challenge, when we had to build a SMT system for the second stage. A training corpus with one side generated with the first stage SMT system was not possible to be acquired with Moses due to its performance constraints. Thereupon we utilized our in-house SMT decoder and managed to translate 2M sentences in time.
We applied this technique both for ru-en and enru language pairs. Approximately 20% of the sen-
tences had changed, but the BLEU score remained the same.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Frequently machine translations contain errors that can be easily corrected by human post-editors.</text>
                  <doc_id>73</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Since human aided machine translation is costefficient, we decided to address this problem to the computer.</text>
                  <doc_id>74</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We propose to translate sentences in two stages.</text>
                  <doc_id>75</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>At the first stage a SMT system is used to translate the input text into a preliminary form (in target language).</text>
                  <doc_id>76</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>At the next stage the preliminary form is translated again with an auxiliary SMT system trained on the translated and the target sides of the parallel corpus.</text>
                  <doc_id>77</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We encountered a technical challenge, when we had to build a SMT system for the second stage.</text>
                  <doc_id>78</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A training corpus with one side generated with the first stage SMT system was not possible to be acquired with Moses due to its performance constraints.</text>
                  <doc_id>79</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Thereupon we utilized our in-house SMT decoder and managed to translate 2M sentences in time.</text>
                  <doc_id>80</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We applied this technique both for ru-en and enru language pairs.</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Approximately 20% of the sen-</text>
                  <doc_id>82</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>tences had changed, but the BLEU score remained the same.</text>
                  <doc_id>83</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Factored model</title>
            <text>We tried to build a factored model for ru-en language pair with POS tags produced by Stanford POS tagger (Toutanova et al., 2003). Unfortunately, we did not gain any improvements from it.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We tried to build a factored model for ru-en language pair with POS tags produced by Stanford POS tagger (Toutanova et al., 2003).</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Unfortunately, we did not gain any improvements from it.</text>
                  <doc_id>85</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Analysis</title>
        <text>We carefully examined the erroneous outputs of our system and compared it with the outputs of the other systems participating in ru-en and en-ru tasks, and with the commercial systems available online (Bing, Google, Yandex).</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We carefully examined the erroneous outputs of our system and compared it with the outputs of the other systems participating in ru-en and en-ru tasks, and with the commercial systems available online (Bing, Google, Yandex).</text>
              <doc_id>86</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>5.1 Transliteration Russian&#8594;English</title>
            <text>The standard transliteration procedure is not invertible. This means that a Latin word being transfered into Cyrillic and then transliterated back to Latin produces an artificial word form. E.g. &#1061;&#1072;&#1074;&#1072;&#1088;&#1076; &#1061;&#1072;&#1083;&#1100;&#1074;&#1072;&#1088;&#1089;&#1077;&#1085; / Havard Halvarsen was correctly transliterated by only four out of 23 systems, including ours. Twelve systems either dropped one of the words or left it in Cyrillic. We provide a list of typical mistakes in order of their frequency: Khavard Khalvarsen, Khavard Khal&#8217;varsen, Xavard Xaljvarsen. Another example: &#1052;&#1080;&#1089;&#1089; &#1059;&#1072;&#1081;&#1101;&#1090;&#1090; (Miss Wyatt) &#8594; Miss Uayett (all the systems failed). The next issue is the presence of non-null inflections that most certainly would result in wrong translation by any straight-forward algorithm. E.g. &#1061;&#1072;&#1081;&#1076;&#1077;&#1083;&#1100;&#1073;&#1077;&#1088;&#1075; &#1072; (Heidelberg) &#8594; Heidelberga. English&#8594;Russian In Russian, most words of foreign origin are written phonetically. Thereby, in order to obtain the best quality we should transliterate the transcription, not the word itself. E.g. the French derived name Elsie Monereau [&#8217;elsi mon@&#8217;r@V] being translated by letters would result in &#1069;&#1083;&#1089;&#1080; &#1052;&#1086;&#1085;&#1077;&#1088;&#1077;&#1072;&#1091; while the transliteration of the transcription would result in the correct form &#1069;&#1083;&#1089;&#1080; &#1052;&#1086;&#1085;&#1088;&#1086;.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The standard transliteration procedure is not invertible.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This means that a Latin word being transfered into Cyrillic and then transliterated back to Latin produces an artificial word form.</text>
                  <doc_id>88</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. &#1061;&#1072;&#1074;&#1072;&#1088;&#1076; &#1061;&#1072;&#1083;&#1100;&#1074;&#1072;&#1088;&#1089;&#1077;&#1085; / Havard Halvarsen was correctly transliterated by only four out of 23 systems, including ours.</text>
                  <doc_id>89</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Twelve systems either dropped one of the words or left it in Cyrillic.</text>
                  <doc_id>90</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We provide a list of typical mistakes in order of their frequency: Khavard Khalvarsen, Khavard Khal&#8217;varsen, Xavard Xaljvarsen.</text>
                  <doc_id>91</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Another example: &#1052;&#1080;&#1089;&#1089; &#1059;&#1072;&#1081;&#1101;&#1090;&#1090; (Miss Wyatt) &#8594; Miss Uayett (all the systems failed).</text>
                  <doc_id>92</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The next issue is the presence of non-null inflections that most certainly would result in wrong translation by any straight-forward algorithm.</text>
                  <doc_id>93</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. &#1061;&#1072;&#1081;&#1076;&#1077;&#1083;&#1100;&#1073;&#1077;&#1088;&#1075; &#1072; (Heidelberg) &#8594; Heidelberga.</text>
                  <doc_id>94</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>English&#8594;Russian In Russian, most words of foreign origin are written phonetically.</text>
                  <doc_id>95</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>Thereby, in order to obtain the best quality we should transliterate the transcription, not the word itself.</text>
                  <doc_id>96</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. the French derived name Elsie Monereau [&#8217;elsi mon@&#8217;r@V] being translated by letters would result in &#1069;&#1083;&#1089;&#1080; &#1052;&#1086;&#1085;&#1077;&#1088;&#1077;&#1072;&#1091; while the transliteration of the transcription would result in the correct form &#1069;&#1083;&#1089;&#1080; &#1052;&#1086;&#1085;&#1088;&#1086;.</text>
                  <doc_id>97</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>5.2 Grammars</title>
            <text>English and Russian make use of different grammars. When the difference in their sentence structure becomes fundamental the phrase-based approach might get inapplicable.
Word order
Both Russian and English are classified as subjectverb-object (SOV) languages, but Russian has rather flexible word order compared to English and might frequently appear in other forms. This often results in wrong structure of the translated sentence. A common mistake made by our system and reproduced by the major online services: &#1085;&#1077; &#1080;&#1079;&#1084;&#1077;&#1085;&#1080;&#1083;&#1080;&#1089;&#1100; &#1080; &#1087;&#1088;&#1072;&#1074;&#1080;&#1083;&#1072; (rules have not been changed either) &#8594; have not changed and the rules.
Constructions
&#8226; there is / there are is a non-local construction that has no equivalent in Russian. In most cases it can not be produced from the Russian text. E.g. &#1085;&#1072; &#1089;&#1090;&#1086;&#1083;&#1077; &#1089;&#1090;&#1086;&#1080;&#1090; &#1084;&#1072;&#1090;&#1088;&#1105;&#1096;&#1082;&#1072; (there is a matryoshka doll on the table) &#8594; on the table is a matryoshka.
&#8226; multiple negatives in Russian are grammatically correct ways to express negation (a single negative is sometimes incorrect) while they are undesirable in standard English. E.g. &#1058;&#1072;&#1084; &#1085;&#1080;&#1082;&#1090;&#1086; &#1085;&#1080;&#1082;&#1086;&#1075;&#1076;&#1072; &#1085;&#1077; &#1073;&#1099;&#1083; (nobody has ever been there) being translated word by word would result in there nobody never not was.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>English and Russian make use of different grammars.</text>
                  <doc_id>98</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>When the difference in their sentence structure becomes fundamental the phrase-based approach might get inapplicable.</text>
                  <doc_id>99</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Word order</text>
                  <doc_id>100</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Both Russian and English are classified as subjectverb-object (SOV) languages, but Russian has rather flexible word order compared to English and might frequently appear in other forms.</text>
                  <doc_id>101</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This often results in wrong structure of the translated sentence.</text>
                  <doc_id>102</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A common mistake made by our system and reproduced by the major online services: &#1085;&#1077; &#1080;&#1079;&#1084;&#1077;&#1085;&#1080;&#1083;&#1080;&#1089;&#1100; &#1080; &#1087;&#1088;&#1072;&#1074;&#1080;&#1083;&#1072; (rules have not been changed either) &#8594; have not changed and the rules.</text>
                  <doc_id>103</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Constructions</text>
                  <doc_id>104</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; there is / there are is a non-local construction that has no equivalent in Russian.</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In most cases it can not be produced from the Russian text.</text>
                  <doc_id>106</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. &#1085;&#1072; &#1089;&#1090;&#1086;&#1083;&#1077; &#1089;&#1090;&#1086;&#1080;&#1090; &#1084;&#1072;&#1090;&#1088;&#1105;&#1096;&#1082;&#1072; (there is a matryoshka doll on the table) &#8594; on the table is a matryoshka.</text>
                  <doc_id>107</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; multiple negatives in Russian are grammatically correct ways to express negation (a single negative is sometimes incorrect) while they are undesirable in standard English.</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. &#1058;&#1072;&#1084; &#1085;&#1080;&#1082;&#1090;&#1086; &#1085;&#1080;&#1082;&#1086;&#1075;&#1076;&#1072; &#1085;&#1077; &#1073;&#1099;&#1083; (nobody has ever been there) being translated word by word would result in there nobody never not was.</text>
                  <doc_id>109</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>5.3 Idioms</title>
            <text>Idiomatic expressions are hard to discover and dangerous to translate literary. E.g. a Russian idiom &#1073;&#1099;&#1083;&#1072; &#1085;&#1077; &#1073;&#1099;&#1083;&#1072; (let come what may) being translated word by word would result in was not was. Neither of the commercial systems we checked managed to collect sufficient statistic to translate this very popular expression.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Idiomatic expressions are hard to discover and dangerous to translate literary.</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>E.g. a Russian idiom &#1073;&#1099;&#1083;&#1072; &#1085;&#1077; &#1073;&#1099;&#1083;&#1072; (let come what may) being translated word by word would result in was not was.</text>
                  <doc_id>111</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Neither of the commercial systems we checked managed to collect sufficient statistic to translate this very popular expression.</text>
                  <doc_id>112</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>6</index>
        <title>6 Conclusion</title>
        <text>We have described the primary systems developed by the team of Yandex School of Data Analysis for WMT13 shared translation task. We have reported on the experiments and demonstrated considerable improvements over the respective baseline. Among the most notable techniques are data filtering, spelling correction, alignment of lemmatized word forms and transliteration. We have analyzed the drawbacks of our systems and shared the ideas for further research.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We have described the primary systems developed by the team of Yandex School of Data Analysis for WMT13 shared translation task.</text>
              <doc_id>113</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We have reported on the experiments and demonstrated considerable improvements over the respective baseline.</text>
              <doc_id>114</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Among the most notable techniques are data filtering, spelling correction, alignment of lemmatized word forms and transliteration.</text>
              <doc_id>115</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We have analyzed the drawbacks of our systems and shared the ideas for further research.</text>
              <doc_id>116</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: Results of the language recognizer: percentage of filtered out sentences.</caption>
        <reference_text></reference_text>
        <page_num>1</page_num>
        <head>
          <rows>
            <row>
              <cell>Corpus</cell>
              <cell>Filtered out (%)</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Bilingual</cell>
              <cell>3.39</cell>
            </row>
            <row>
              <cell>Monolingual (English)</cell>
              <cell>0.41</cell>
            </row>
            <row>
              <cell>Monolingual (Russian)</cell>
              <cell>0.58</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TableSeer</source>
        <caption>Table 2: Results of the spelling corrector: percentage of modified sentences.</caption>
        <reference_text>None</reference_text>
        <page_num>2</page_num>
        <head>
          <rows>
            <row>
              <cell>presented in Table 2.</cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Corpus</cell>
              <cell>Modified (%)</cell>
            </row>
            <row>
              <cell>Bilingual (English)</cell>
              <cell>0.79</cell>
            </row>
            <row>
              <cell>Bilingual (Russian)</cell>
              <cell>1.45</cell>
            </row>
            <row>
              <cell>Monolingual (English)</cell>
              <cell>0.61</cell>
            </row>
            <row>
              <cell>Monolingual (Russian)</cell>
              <cell>0.52</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TableSeer</source>
        <caption>Table 3: Experimental results in case-sensitive BLEU for Russian&#8594;English and English&#8594;Russian tasks.</caption>
        <reference_text>None</reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>Russian?English</cell>
              <cell>newstest2012-test</cell>
              <cell>newstest2013</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Baseline</cell>
              <cell>28.96</cell>
              <cell>21.82</cell>
            </row>
            <row>
              <cell>+ Preprocessing</cell>
              <cell>29.59</cell>
              <cell>22.28</cell>
            </row>
            <row>
              <cell>+ Alignment of lemmatized word forms</cell>
              <cell>29.97</cell>
              <cell>22.61</cell>
            </row>
            <row>
              <cell>+ Good-Turing</cell>
              <cell>30.31</cell>
              <cell>22.87</cell>
            </row>
            <row>
              <cell>+ MBR</cell>
              <cell>30.45</cell>
              <cell>23.21</cell>
            </row>
            <row>
              <cell>+ Reordering constraints</cell>
              <cell>30.54</cell>
              <cell>23.33</cell>
            </row>
            <row>
              <cell>+ Wiki Headlines</cell>
              <cell>30.68</cell>
              <cell>23.46</cell>
            </row>
            <row>
              <cell>+ Transliteration</cell>
              <cell>30.93</cell>
              <cell>23.73</cell>
            </row>
            <row>
              <cell>E</cell>
              <cell>n</cell>
              <cell>g</cell>
              <cell>l</cell>
              <cell>i</cell>
              <cell>s</cell>
              <cell>h</cell>
              <cell>?</cell>
              <cell>R</cell>
              <cell>u</cell>
              <cell>s</cell>
              <cell>s</cell>
              <cell>i</cell>
              <cell>a</cell>
              <cell>n</cell>
            </row>
            <row>
              <cell>Baseline</cell>
              <cell>21.96</cell>
              <cell>16.24</cell>
            </row>
            <row>
              <cell>+ Preprocessing</cell>
              <cell>22.48</cell>
              <cell>16.76</cell>
            </row>
            <row>
              <cell>+ Good-Turing</cell>
              <cell>22.84</cell>
              <cell>17.13</cell>
            </row>
            <row>
              <cell>+ MBR and Reordering constraints</cell>
              <cell>23.27</cell>
              <cell>17.45</cell>
            </row>
            <row>
              <cell>+ Wiki Headlines and Transliteration</cell>
              <cell>23.54</cell>
              <cell>17.80</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Chris Callison-Burch</author>
          <author>Philipp Koehn</author>
          <author>Christof Monz</author>
          <author>Matt Post</author>
          <author>Radu Soricut</author>
          <author>Lucia Specia</author>
        </authors>
        <title>Findings of the 2012 workshop on statistical machine translation.</title>
        <publication>In Proceedings of the Seventh Workshop on Statistical Machine Translation (WMT12),</publication>
        <pages>10--51</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Xavier Carreras</author>
          <author>Isaac Chao</author>
          <author>Llu&#237;s Padr&#243;</author>
          <author>Muntsa Padr&#243;</author>
        </authors>
        <title>FreeLing: An open-source suite of language analyzers.</title>
        <publication>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC).</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Silviu Cucerzan</author>
          <author>Eric Brill</author>
        </authors>
        <title>Spelling correction as an iterative process that exploits the collective knowledge of web users.</title>
        <publication>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP),</publication>
        <pages>293--300</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Ted Dunning</author>
        </authors>
        <title>Statistical identification of language.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1994</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Marcello Federico</author>
          <author>Nicola Bertoldi</author>
          <author>Mauro Cettolo</author>
        </authors>
        <title>IRSTLM: an open source toolkit for handling large scale language models.</title>
        <publication>In Proceedings of 9th Annual Conference of the International Speech Communication Association (INTERSPEECH),</publication>
        <pages>1618--1621</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>William Gale</author>
        </authors>
        <title>Good-Turing smoothing without tears.</title>
        <publication>None</publication>
        <pages>2--217</pages>
        <date>1994</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Qin Gao</author>
          <author>Stephan Vogel</author>
        </authors>
        <title>Parallel implementations of word alignment tool.</title>
        <publication>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</publication>
        <pages>49--57</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Shankar Kumar</author>
          <author>William Byrne</author>
        </authors>
        <title>Minimum bayes-risk decoding for statistical machine translation.</title>
        <publication>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</publication>
        <pages>163--171</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Chin-Yew Lin</author>
          <author>Franz Josef Och</author>
        </authors>
        <title>ORANGE: a method for evaluating automatic evaluation metrics for machine translation.</title>
        <publication>In Proceedings of the 20th international conference on Computational Linguistics (COLING),</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Llu&#237;s Padr&#243;</author>
          <author>Evgeny Stanilovsky</author>
        </authors>
        <title>FreeLing 3.0: Towards wider multilinguality.</title>
        <publication>In Proceedings of the Language Resources and Evaluation Conference (LREC),</publication>
        <pages>None</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Kishore Papineni</author>
          <author>Salim Roukos</author>
          <author>Todd Ward</author>
          <author>Wei jing Zhu</author>
        </authors>
        <title>BLEU: a method for automatic evaluation of machine translation.</title>
        <publication>In Processings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</publication>
        <pages>311--318</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Ilya Segalovich</author>
        </authors>
        <title>A fast morphological algorithm with unknown word guessing induced by a dictionary for a web search engine.</title>
        <publication>Proceedings of the International Conference on Machine Learning; Models, Technologies and Applications (MLMTA),</publication>
        <pages>273--280</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Kristina Toutanova</author>
          <author>Dan Klein</author>
          <author>Christopher D Manning</author>
          <author>Yoram Singer</author>
        </authors>
        <title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
        <publication>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL),</publication>
        <pages>252--259</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Reinhard Kneser</author>
          <author>Hermann Ney</author>
        </authors>
        <title>Improved backing-off for m-gram language modeling.</title>
        <publication>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</publication>
        <pages>181--184</pages>
        <date>1995</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Kevin Knight</author>
          <author>Jonathan Graehl</author>
        </authors>
        <title>None</title>
        <publication>Machine transliteration. Computational Linguistics,</publication>
        <pages>24--4</pages>
        <date>1998</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Callison-Burch et al., 2012</string>
        <sentence_id>53284</sentence_id>
        <char_offset>27</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Carreras et al., 2004</string>
        <sentence_id>53277</sentence_id>
        <char_offset>178</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>2</reference_id>
        <string>Cucerzan and Brill (2004)</string>
        <sentence_id>53279</sentence_id>
        <char_offset>140</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>Dunning, 1994</string>
        <sentence_id>53279</sentence_id>
        <char_offset>63</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>4</reference_id>
        <string>Federico et al., 2008</string>
        <sentence_id>53274</sentence_id>
        <char_offset>70</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>5</reference_id>
        <string>Gale, 1994</string>
        <sentence_id>53308</sentence_id>
        <char_offset>44</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>6</reference_id>
        <string>Gao and Vogel, 2008</string>
        <sentence_id>53276</sentence_id>
        <char_offset>37</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>7</reference_id>
        <string>Kumar and Byrne, 2004</string>
        <sentence_id>53309</sentence_id>
        <char_offset>39</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>8</reference_id>
        <string>Lin and Och, 2004</string>
        <sentence_id>53311</sentence_id>
        <char_offset>29</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>9</reference_id>
        <string>Padr&#243; and Stanilovsky, 2012</string>
        <sentence_id>53277</sentence_id>
        <char_offset>201</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>10</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>53280</sentence_id>
        <char_offset>46</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>11</reference_id>
        <string>Segalovich, 2003</string>
        <sentence_id>53278</sentence_id>
        <char_offset>87</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>11</reference_id>
        <string>Segalovich, 2003</string>
        <sentence_id>53303</sentence_id>
        <char_offset>44</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>12</reference_id>
        <string>Toutanova et al., 2003</string>
        <sentence_id>53277</sentence_id>
        <char_offset>92</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>12</reference_id>
        <string>Toutanova et al., 2003</string>
        <sentence_id>53344</sentence_id>
        <char_offset>106</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>13</reference_id>
        <string>Kneser and Ney, 1995</string>
        <sentence_id>53275</sentence_id>
        <char_offset>59</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>14</reference_id>
        <string>Knight and Graehl, 1998</string>
        <sentence_id>53323</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>14</reference_id>
        <string>Knight and Graehl, 1998</string>
        <sentence_id>53329</sentence_id>
        <char_offset>73</char_offset>
      </citation>
    </citations>
  </content>
</document>
