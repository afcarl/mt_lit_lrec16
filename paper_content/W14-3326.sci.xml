<PAPER>
  <FILENO/>
  <TITLE>Machine Translation of Medical Texts in the Khresmoi Project</TITLE>
  <AUTHORS>
    <AUTHOR>Ond&#345;ej Du&#353;ek</AUTHOR>
    <AUTHOR>Jan Haji&#269;</AUTHOR>
    <AUTHOR>Jaroslava Hlav&#225;&#269;ov&#225;</AUTHOR>
    <AUTHOR>Michal Nov&#225;k</AUTHOR>
    <AUTHOR>Pavel Pecina</AUTHOR>
    <AUTHOR>Rudolf Rosa</AUTHOR>
    <AUTHOR>Ale&#353; Tamchyna</AUTHOR>
    <AUTHOR>Zde&#328;ka Ure&#353;ov&#225;</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-7755">This paper presents the participation of the Charles University team in the WMT 2014 Medical Translation Task.</A-S>
    <A-S ID="S-7756">Our systems are developed within the Khresmoi project, a large integrated project aiming to deliver a multi-lingual multi-modal search and access system for biomedical information and documents.</A-S>
    <A-S ID="S-7757">Being involved in the organization of the Medical Translation Task, our primary goal is to set up a baseline for both its subtasks (summary translation and query translation) and for all translation directions.</A-S>
    <A-S ID="S-7758">Our systems are based on the phrasebased Moses system and standard methods for domain adaptation.</A-S>
    <A-S ID="S-7759">The constrained/unconstrained systems differ in the training data only.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-7760">The WMT 2014 Medical Translation Task poses an interesting challenge for Machine Translation (MT).</S>
        <S ID="S-7761">In the &#8220;standard&#8221; translation task, the end application is the translation itself.</S>
        <S ID="S-7762">In the Medical Translation Task, the MT system is considered a part of a larger system for Cross-Lingual Information Retrieval (CLIR) and is used to solve two different problems: (i) translation of user search queries, and (ii) translation of summaries of retrieved documents.</S>
      </P>
      <P>
        <S ID="S-7763">In query translation, the end user does not even necessarily see the MT output as their queries are translated and search is performed on documents in the target language.</S>
        <S ID="S-7764">In summary translation, the sentences to be translated come from document summaries (snippets) displayed to provide information on each of the documents retrieved by the search.</S>
        <S ID="S-7765">Therefore, translation quality may not be the most important measure in this task &#8211; the performance of the CLIR system as a whole is the final criterion.</S>
        <S ID="S-7766">Another fundamental difference from the standard task is the nature of the translated texts.</S>
        <S ID="S-7767">While we can consider document summaries to be ordinary texts (despite their higher information density in terms of terminology from a narrow domain), search queries in the medical domain are an extremely specific type of data, and traditional techniques for system development and domain adaptation are truly put to a test here.</S>
      </P>
      <P>
        <S ID="S-7768">This work is a part of the of the large integrated EU-funded Khresmoi project.</S>
        <S ID="S-7769">1 Among other goals, such as joint text and image retrieval of radiodiagnostic records, Khresmoi aims to develop technology for transparent cross-lingual search of medical sources for both professionals and laypeople, with the emphasis primarily on publicly available web sources.</S>
        <S ID="S-7770">In this paper, we describe the Khresmoi systems submitted to the WMT 2014 Medical Translation Task.</S>
        <S ID="S-7771">We participate in both subtasks (summary translation and query translation) for all language pairs (Czech&#8211;English, German&#8211;English, and French&#8211;English) in both directions (to English and from English).</S>
        <S ID="S-7772">Our systems are based on the Moses phrase-based translation toolkit and standard methods for domain adaptation.</S>
        <S ID="S-7773">We submit one constrained and one unconstrained system for each subtask and translation direction.</S>
        <S ID="S-7774">The constrained and unconstrained systems differ in training data only: The former use all allowed training data, the latter take advantage of additional webcrawled data.</S>
      </P>
      <P>
        <S ID="S-7775">We first summarize previous works in MT domain adaptation in Section 2, then describe the data we used for our systems in Section 3.</S>
        <S ID="S-7776">Sec-</S>
      </P>
      <P>
        <S ID="S-7777">1 http://www.khresmoi.eu/</S>
      </P>
      <P>
        <S ID="S-7778">tion 4 contains an account of the submitted systems and their performance in translation of search queries and document summaries.</S>
        <S ID="S-7779">Section 5 concludes the paper.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Related work</HEADER>
      <P>
        <S ID="S-7799">To put our work in the context of other approaches, we first describe previous work on domain adaptation in Statistical Machine Translation (SMT), then focus specifically on SMT in the medical domain.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>2.1 Domain adaptation of Statistical machine translation</HEADER>
        <P>
          <S ID="S-7780">Many works on domain adaptation examine the usage of available in-domain data to directly improve in-domain performance of SMT.</S>
          <S ID="S-7781">Some authors attempt to combine the predictions of two separate (in-domain and general-domain) translation models (<REF ID="R-19" RPTR="20">Langlais, 2002</REF>; <REF ID="R-29" RPTR="31">Sanchis-Trilles and Casacuberta, 2010</REF>; <REF ID="R-01" RPTR="3">Bisazza et al., 2011</REF>; <REF ID="R-24" RPTR="27">Nakov, 2008</REF>) or language models (<REF ID="R-15" RPTR="16">Koehn and Schroeder, 2007</REF>).</S>
          <S ID="S-7782"><REF ID="R-37" RPTR="38">Wu and Wang (2004)</REF> use in-domain data to improve word alignment in the training phase.</S>
          <S ID="S-7783"><REF ID="R-06" RPTR="8">Carpuat et al. (2012)</REF> explore the possibility of using word sense disambiguation to discriminate between domains.</S>
        </P>
        <P>
          <S ID="S-7784">Other approaches concentrate on the acquisition of larger in-domain corpora.</S>
          <S ID="S-7785">Some of them exploit existing general-domain corpora by selecting data that resemble the properties of in-domain data (e.g., using cross-entropy), thus building a larger pseudo-in-domain training corpus.</S>
          <S ID="S-7786">This technique is used to adapt language models (<REF ID="R-09" RPTR="11">Eck et al., 2004</REF>b; <REF ID="R-22" RPTR="24">Moore and Lewis, 2010</REF>) as well as translation models (<REF ID="R-11" RPTR="12">Hildebrand et al., 2005</REF>; <REF ID="R-00" RPTR="0">Axelrod et al., 2011</REF>) or their combination (<REF ID="R-21" RPTR="22">Mansour et al., 2011</REF>).</S>
          <S ID="S-7787">Similar approaches to domain adaptation are also applied in other tasks, e.g., automatic speech recognition (<REF ID="R-04" RPTR="6">Byrne et al., 2004</REF>).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.2 Statistical machine translation in the medical domain</HEADER>
        <P>
          <S ID="S-7788">Eck et al. (2004a) employ an SMT system for the translation of dialogues between doctors and patients and show that according to automatic metrics, a dictionary extracted from the Unified Medical Language System (UMLS) Metathesaurus and its semantic type classification (U.S. National Library of Medicine, 2009) significantly improves translation quality from Spanish to English when applied to generalize the training data.</S>
        </P>
        <P>
          <S ID="S-7789"><REF ID="R-38" RPTR="39">Wu et al. (2011)</REF> analyze the quality of MT on PubMed 2 titles and whether it is sufficient for patients.</S>
          <S ID="S-7790">The conclusions are very positive especially for languages with large training resources (English, Spanish, German) &#8211; the average fluency and content scores (based on human evaluation) are above four on a five-point scale.</S>
          <S ID="S-7791">In automatic evaluation, their systems substantially outperform Google Translate.</S>
          <S ID="S-7792">However, the SMT systems are specifically trained, tuned, and tested on the domain of PubMed titles, and it is not evident how they would perform on other medical texts.</S>
        </P>
        <P>
          <S ID="S-7793"><REF ID="R-07" RPTR="9">Costa-juss&#224; et al. (2012)</REF> are less optimistic regarding SMT quality in the medical domain.</S>
          <S ID="S-7794">They analyze and evaluate the quality of public webbased MT systems (such as Google Translate) and conclude that in both automatic and manual evaluation (on 7 language pairs), the performance of these systems is still not good enough to be used in daily routines of medical doctors in hospitals.</S>
          <S ID="S-7795">Jimeno <REF ID="R-12" RPTR="13">Yepes et al. (2013)</REF> propose a method for obtaining in-domain parallel corpora from titles and abstracts of publications in the MED- LINE 3 database.</S>
          <S ID="S-7796">The acquired corpora contain from 30,000 to 130,000 sentence pairs (depending on the language pair) and are reported to improve translation quality when used for SMT training, compared to a baseline trained on out-of-domain data.</S>
          <S ID="S-7797">However, the authors use only one source of in-domain parallel data to adapt the translation model, and do not use any in-domain monolingual data to adapt the language model.</S>
        </P>
        <P>
          <S ID="S-7798">In this work, we investigate methods combining the different kinds of data &#8211; general-domain, indomain, and pseudo-in-domain &#8211; to find the optimal approach to this problem.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Data description</HEADER>
      <P>
        <S ID="S-7825">This section includes an overview of the parallel and monolingual data sources used to train our systems.</S>
        <S ID="S-7826">Following the task specification, they are split into constrained and unconstrained sections.</S>
        <S ID="S-7827">The constrained section includes medicaldomain data provided for this task (extracted by the provided scripts), and general-domain texts provided as constrained data for the standard task (&#8220;general domain&#8221; here is used to denote data</S>
      </P>
      <P>
        <S ID="S-7828">2 http://www.ncbi.nlm.nih.gov/pubmed/ 3 http://www.nlm.nih.gov/pubs/</S>
      </P>
      <P>
        <S ID="S-7829">factsheets/medline.html</S>
      </P>
      <P>
        <S ID="S-7830">which comes from a mixture of various different domains, mostly news, parliament proceedings, web-crawls, etc.).</S>
        <S ID="S-7831">The unconstrained section contains automatically crawled data from medical and health websites and non-medical data from patent collections.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Parallel data</HEADER>
        <P>
          <S ID="S-7800">The parallel data summary is presented in Table 1.</S>
        </P>
        <P>
          <S ID="S-7801">The main sources of the medical-domain data for all the language pairs include the EMEA corpus (<REF ID="R-34" RPTR="36">Tiedemann, 2009</REF>), the UMLS metathesaurus of health and biomedical vocabularies and standards (U.S. National Library of Medicine, 2009), and bilingual titles of Wikipedia articles belonging to the categories identified to be medical domain.</S>
          <S ID="S-7802">Additional medical-domain data comes from the MAREC patent collection: PatTR (<REF ID="R-36" RPTR="37">W&#228;schle and Riezler, 2012</REF>) available for DE&#8211;EN and FR&#8211;EN, and COPPA (<REF ID="R-27" RPTR="30">Pouliquen and Mazenc, 2011</REF>) for FR&#8211;EN (only patents from the medical categories A61, C12N, and C12P are allowed in the constrained systems).</S>
          <S ID="S-7803">The constrained general-domain data include three parallel corpora for all the language pairs: CommonCrawl (<REF ID="R-31" RPTR="33">Smith et al., 2013</REF>), Europarl version 6 (<REF ID="R-17" RPTR="18">Koehn, 2005</REF>), the News Commentary corpus (<REF ID="R-05" RPTR="7">Callison-Burch et al., 2012</REF>).</S>
          <S ID="S-7804">Further, the constrained data include CzEng (<REF ID="R-02" RPTR="4">Bojar et al., 2012</REF>) for CS&#8211;EN and the UN corpus for FR&#8211;EN.</S>
        </P>
        <P>
          <S ID="S-7805">For our unconstrained experiments, we also employ parallel data from the non-medical patents from the PatTR and COPPA collections (other categories than A61, C12N, and C12P).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Monolingual data</HEADER>
        <P>
          <S ID="S-7806">The monolingual data is summarized in Table 2.</S>
        </P>
        <P>
          <S ID="S-7807">The main sources of the medical-domain monolingual data for all languages involve Wikipedia pages, UMLS concept descriptions, and nonparallel texts extracted from the medical patents of the PatTR collections.</S>
          <S ID="S-7808">For English, the main source is the AACT collection of texts from ClinicalTrials.gov.</S>
          <S ID="S-7809">Smaller resources include: Drug- Bank (<REF ID="R-14" RPTR="15">Knox et al., 2011</REF>), GENIA (<REF ID="R-13" RPTR="14">Kim et al., 2003</REF>), FMA (Rosse and Mejino Jr., 2008), GREC (<REF ID="R-33" RPTR="35">Thompson et al., 2009</REF>), and PIL (<REF ID="R-03" RPTR="5">Bouayad-Agha et al., 2000</REF>).</S>
        </P>
        <P>
          <S ID="S-7810">In the unconstrained systems, we use additional monolingual data from web pages crawled within the Khresmoi project: a collection of about one million HON-certified 4 webpages in English released as the test collection for the CLEF 2013 eHealth Task 3 evaluation campaign, 5 additional web-crawled HON-certified pages (not publicly available), and other webcrawled medical-domain related webpages.</S>
          <S ID="S-7811">The constrained general-domain resources include: the News corpus for CS, DE, EN, and FR collected for the purpose of the WMT 2014 Standard Task, monolingual parts of the Europarl and News-Commentary corpora, and the Gigaword for EN and FR.</S>
        </P>
        <P>
          <S ID="S-7812">For the FR&#8211;EN and DE&#8211;EN unconstrained systems, the additional general domain monolingual data is taken from monolingual texts of nonmedical patents in the PatTR collection.</S>
        </P>
        <P>
          <S ID="S-7813">4 https://www.hon.ch/ 5 https://sites.google.com/site/</S>
        </P>
        <P>
          <S ID="S-7814">shareclefehealth/</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 Data preprocessing</HEADER>
        <P>
          <S ID="S-7815">The data consisting of crawled web pages, namely CLEF, HON, and non-HON, needed to be cleaned and transformed into a set of sentences.</S>
          <S ID="S-7816">The Boilerpipe (<REF ID="R-18" RPTR="19">Kohlsch&#252;tter et al., 2010</REF>) and Justext (<REF ID="R-26" RPTR="29">Pomik&#225;lek, 2011</REF>) tools were used to remove boilerplate texts and extract just the main content from the web pages.</S>
          <S ID="S-7817">The YALI language detection tool (<REF ID="R-20" RPTR="21">Majli&#353;, 2012</REF>) trained on both in-domain and general domain data then filtered out those cleaned pages which were not identified as written in one of the concerned languages.</S>
        </P>
        <P>
          <S ID="S-7818">The rest of the preprocessing procedure was applied to all the datasets mentioned above, both parallel and monolingual.</S>
          <S ID="S-7819">The data were tokenized and normalized by converting or omitting some (mostly punctuation) characters.</S>
          <S ID="S-7820">A set of language-dependent heuristics was applied in an attempt to restore and normalize the opening/closing quotation marks, i.e. convert "quoted" to &#8220;quoted&#8221; (Zeman, 2012).</S>
          <S ID="S-7821">The motivation here is twofold: First, we hope that paired quotation marks could occasionally work as brackets and better denote parallel phrases for Moses; second, if Moses learns to output directed quotation marks, the subsequent detokenization will be easier.</S>
          <S ID="S-7822">For all systems which translate from German, decompounding is employed to reduce source-side data sparsity.</S>
          <S ID="S-7823">We used BananaSplit for this task (<REF ID="R-23" RPTR="26">M&#252;ller and Gurevych, 2006</REF>).</S>
        </P>
        <P>
          <S ID="S-7824">We perform all training and internal evaluation on lowercased data; we trained recasers to postprocess the final submissions.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Submitted systems</HEADER>
      <P>
        <S ID="S-7874">We first describe our technique of psedo-indomain data selection in Section 4.1, then compare two methods of combining the selected data in Section 4.2.</S>
        <S ID="S-7875">This, along with using constrained and unconstrained data sets to train the systems (see Section 3), amounts to a total of four system variants submitted for each task.</S>
        <S ID="S-7876">A description of the system settings used is given in Section 4.3.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Data selection</HEADER>
        <P>
          <S ID="S-7832">We follow an approach originally proposed for selection of monolingual sentences for language modeling (<REF ID="R-22" RPTR="25">Moore and Lewis, 2010</REF>) and its modification applied to selection of parallel sentences (<REF ID="R-00" RPTR="1">Axelrod et al., 2011</REF>).</S>
          <S ID="S-7833">This technique assumes two language models for sentence scoring, one trained on (true) in-domain text and one trained on (any) general-domain text in the same language (e.g., English).</S>
          <S ID="S-7834">For both data domains (general and medical), we score each sentence by the difference of its cross-perplexity given the in-domain language model and cross-perplexity given the general-domain language model (in this order).</S>
          <S ID="S-7835">We only keep sentences with a negative score in our data, assuming that these are the most &#8220;medical-like&#8221;.</S>
          <S ID="S-7836">Visualisation of the domainspecificity scores (cross-perplexity difference) in the FR&#8211;EN parallel data and FR monolingual data is illustrated in Figures 1 and 2, respectively.</S>
          <S ID="S-7837">6 The scores (Y axis) are presented for each sentence in increasing order from left to right (X axis).</S>
        </P>
        <P>
          <S ID="S-7838">6 For the medical domain, constrained and unconstrained</S>
        </P>
        <P>
          <S ID="S-7839">parallel data are identical.</S>
        </P>
        <P>
          <S ID="S-7840">The two language models for sentence scoring are trained with a restricted vocabulary extracted from the in-domain training data as words occurring at least twice (singletons and other words are treated as out-of-vocabulary).</S>
          <S ID="S-7841">In our experiments, we apply this technique to select both monolingual data for language models and parallel data for translation models.</S>
          <S ID="S-7842">Selection of parallel data is based on the English side only.</S>
          <S ID="S-7843">The in-domain models are trained on the monolingual data in the target language (constrained or unconstrained, depending on the setting).</S>
          <S ID="S-7844">The general-domain models are trained on the WMT News data.</S>
        </P>
        <P>
          <S ID="S-7845">Compared to the approach of <REF ID="R-22" RPTR="23">Moore and Lewis (2010)</REF> and <REF ID="R-00" RPTR="2">Axelrod et al. (2011)</REF>, we prune the model vocabulary more aggressively &#8211; we discard not only the singletons, but also all words with non-Latin characters, which helps clean the models from noise introduced by the automatic process of data acquisition by web crawling.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Data combination</HEADER>
        <P>
          <S ID="S-7846">For both parallel and monolingual data, we obtain two data sets after applying the data selection:</S>
        </P>
        <P>
          <S ID="S-7847">&#8226; &#8220;medical-like&#8221; data from the medical domain</S>
        </P>
        <P>
          <S ID="S-7848">&#8226; &#8220;medical-like&#8221; data from the general domain.</S>
        </P>
        <P>
          <S ID="S-7849">For each language pair and for each system type (constrained/unconstrained), we submitted two system variants which differ in how the selected data are combined.</S>
          <S ID="S-7850">The first variant uses a simple concatenation of the two datasets both for parallel data and for language model data.</S>
          <S ID="S-7851">In the second variant, we train separate models for each section and use linear interpolation to combine them into a single model.</S>
          <S ID="S-7852">For language models, we use the SRILM linear interpolation feature (<REF ID="R-32" RPTR="34">Stolcke, 2002</REF>).</S>
          <S ID="S-7853">We interpolate phrase tables using Tmcombine (<REF ID="R-30" RPTR="32">Sennrich, 2012</REF>).</S>
          <S ID="S-7854">In both cases, the held-out set for minimizing the perplexity is the system development set.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.3 System details</HEADER>
        <P>
          <S ID="S-7855">We compute word alignment on lowercase 4-character stems using fast align (<REF ID="R-08" RPTR="10">Dyer et al., 2013</REF>).</S>
          <S ID="S-7856">We create phrase tables using the Moses toolkit (<REF ID="R-16" RPTR="17">Koehn et al., 2007</REF>) with standard settings.</S>
          <S ID="S-7857">We train 5-gram language models on the target-side lowercase forms using SRILM.</S>
          <S ID="S-7858">We use MERT (<REF ID="R-25" RPTR="28">Och, 2003</REF>) to tune model weights in our systems on the development data provided for the task.</S>
        </P>
        <P>
          <S ID="S-7859">The only difference between the system variants for query and summary translation is the tuning set.</S>
          <S ID="S-7860">In both cases, we use the respective sets provided offcially for the shared task.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.4 Results</HEADER>
        <P>
          <S ID="S-7861">Tables 3 and 4 show case-insensitive BLEU scores of our systems.</S>
          <S ID="S-7862">7 As expected, the unconstrained systems outperform the constrained ones.</S>
          <S ID="S-7863">Linear interpolation outperforms data concatenation quite reliably across language pairs for summary translation.</S>
          <S ID="S-7864">While the picture for query translation is similar, there is more variance in the results, so we cannot state that interpolation definitely works</S>
        </P>
        <P>
          <S ID="S-7865">7 As we use the same recasers for both summary and query</S>
        </P>
        <P>
          <S ID="S-7866">translation, our systems are heavily penalized for wrong letter case in query translation.</S>
          <S ID="S-7867">However, letter case is not taken into account in most CLIR systems.</S>
          <S ID="S-7868">All BLEU scores reported in this paper will be case-insensitive for this reason.</S>
        </P>
        <P>
          <S ID="S-7869">better in this case.</S>
          <S ID="S-7870">This is due to the sizes of the development and test sets and most importantly due to sentence lengths &#8211; queries are very short, making BLEU unreliable, MERT unstable, and bootstrap resampling intervals wide.</S>
        </P>
        <P>
          <S ID="S-7871">If we compare our score to the other competitors, we are clearly worse than the best systems for summary translation.</S>
          <S ID="S-7872">From this perspective, our data filtering seems overly eager (i.e., discarding all sentence pairs with a positive perplexity difference).</S>
          <S ID="S-7873">An experiment which we leave for future work is doing one more round of interpolation to combine a model trained on the data with negative perplexity with models trained on the remainder.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Conclusions</HEADER>
      <P>
        <S ID="S-7877">We described the Charles University MT system used in the Shared Medical Translation Task of WMT 2014.</S>
        <S ID="S-7878">Our primary goal was to set up a baseline for both the subtasks and all translation directions.</S>
        <S ID="S-7879">The systems are based on the Moses toolkit, pseudo-in-domain data selection based on perplexity difference and two different methods of in-domain and out-of-domain data combination: simple data concatenation and linear model interpolation.</S>
        <S ID="S-7880">We report results of constrained and unconstrained systems which differ in the training data only.</S>
        <S ID="S-7881">In most experiments, using additional data improved the results compared to the constrained systems and using linear model interpolation outperformed data concatenation.</S>
        <S ID="S-7882">While our systems are on par with best results for case-insensitive BLEU score in query translation, our overly eager data selection techniques caused lower scores in summary translation.</S>
        <S ID="S-7883">In future work, we plan to include a special out-of-domain model in our setup to compensate for this problem.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-7884">This work was supported by the EU FP7 project Khresmoi (contract no.</S>
      <S ID="S-7885">257528), the Czech Science Foundation (grant no.</S>
      <S ID="S-7886">P103/12/G084), and SVV project number 260 104.</S>
      <S ID="S-7887">This work has been using language resources developed, stored, and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2010013).</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>A Axelrod</RAUTHOR>
      <REFTITLE>Domain adaptation via pseudo in-domain data selection.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>A Bisazza</RAUTHOR>
      <REFTITLE>Fillup versus interpolation methods for phrase-based SMT adaptation.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>O Bojar</RAUTHOR>
      <REFTITLE>The joy of parallelism with CzEng 1.0.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>N Bouayad-Agha</RAUTHOR>
      <REFTITLE>Integrating content and style in documents: A case study of patient information leaflets.</REFTITLE>
      <DATE>2000</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>W Byrne</RAUTHOR>
      <REFTITLE>Automatic recognition of spontaneous speech for access to multilingual oral history archives. Speech and Audio Processing,</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>C Callison-Burch</RAUTHOR>
      <REFTITLE></REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>M Carpuat</RAUTHOR>
      <REFTITLE>Domain adaptation in machine translation: Final report.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>M R Costa-juss&#224;</RAUTHOR>
      <REFTITLE>Machine translation in medicine. A quality analysis of statistical machine translation in the medical domain.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>C Dyer</RAUTHOR>
      <REFTITLE>A simple, fast, and effective reparameterization of IBM model 2.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>M Eck</RAUTHOR>
      <REFTITLE>Improving statistical machine translation in the medical domain using the Unified Medical Language System.</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>S Vogel Eck</RAUTHOR>
      <REFTITLE>Language model adaptation for statistical machine translation based on information retrieval.</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>A S Hildebrand</RAUTHOR>
      <REFTITLE>Adaptation of the translation model for statistical machine translation based on information retrieval.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>A Jimeno Yepes</RAUTHOR>
      <REFTITLE>Combining MEDLINE and publisher data to create parallel corpora for the automatic translation of biomedical text.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>J-D Kim</RAUTHOR>
      <REFTITLE>GENIA corpus &#8211; a semantically annotated corpus for bio-textmining. Bioinformatics, 19(suppl 1):i180&#8211; i182.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>C Knox</RAUTHOR>
      <REFTITLE>DrugBank 3.0: a comprehensive resource for &#8216;Omics&#8217; research on drugs. Nucleic acids research, 39(suppl 1):D1035&#8211;D1041.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>P Koehn</RAUTHOR>
      <REFTITLE>Experiments in domain adaptation for statistical machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>P Koehn</RAUTHOR>
      <REFTITLE>Moses: Open Source Toolkit for Statistical Machine Translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>P Koehn</RAUTHOR>
      <REFTITLE>Europarl: a parallel corpus for statistical machine translation.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>C Kohlsch&#252;tter</RAUTHOR>
      <REFTITLE>Boilerplate detection using shallow text features.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>P Langlais</RAUTHOR>
      <REFTITLE>Improving a general-purpose statistical translation engine by terminological lexicons.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="20">
      <RAUTHOR>M Majli&#353;</RAUTHOR>
      <REFTITLE>Yet another language identifier.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="21">
      <RAUTHOR>S Mansour</RAUTHOR>
      <REFTITLE>Combining translation and language model scoring for domain-specific data filtering.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="22">
      <RAUTHOR>R C Moore</RAUTHOR>
      <REFTITLE>Intelligent selection of language model training data.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="23">
      <RAUTHOR>C M&#252;ller</RAUTHOR>
      <REFTITLE>Exploring the potential of semantic relatedness in information retrieval.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="24">
      <RAUTHOR>P Nakov</RAUTHOR>
      <REFTITLE>Improving English&#8211;Spanish statistical machine translation: Experiments in domain adaptation, sentence paraphrasing, tokenization, and recasing.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="25">
      <RAUTHOR>F J Och</RAUTHOR>
      <REFTITLE>Minimum error rate training in statistical machine translation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="26">
      <RAUTHOR>J Pomik&#225;lek</RAUTHOR>
      <REFTITLE>Removing Boilerplate and Duplicate Content from Web Corpora.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="27">
      <RAUTHOR>B Pouliquen</RAUTHOR>
      <REFTITLE>COPPA, CLIR and TAPTA: three tools to assist in overcoming the patent barrier at WIPO.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="28">
      <RAUTHOR>C Rosse</RAUTHOR>
      <REFTITLE>The foundational model of anatomy ontology.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="29">
      <RAUTHOR>G Sanchis-Trilles</RAUTHOR>
      <REFTITLE>Loglinear weight optimisation via Bayesian adaptation in statistical machine translation.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="30">
      <RAUTHOR>Sennrich</RAUTHOR>
      <REFTITLE>Perplexity minimization for translation model domain adaptation in statistical machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="31">
      <RAUTHOR>J R Smith</RAUTHOR>
      <REFTITLE>Dirt cheap web-scale parallel text from the common crawl.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="32">
      <RAUTHOR>A Stolcke</RAUTHOR>
      <REFTITLE>SRILM &#8211; an extensible language modeling toolkit.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="33">
      <RAUTHOR>P Thompson</RAUTHOR>
      <REFTITLE>Construction of an annotated corpus to support biomedical information extraction.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="34">
      <RAUTHOR>J Tiedemann</RAUTHOR>
      <REFTITLE>News from OPUS &#8211; a collection of multilingual parallel corpora with tools and interfaces.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="35">
      <RAUTHOR>U S National</RAUTHOR>
      <REFTITLE>Library of Medicine.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="36">
      <RAUTHOR>K W&#228;schle</RAUTHOR>
      <REFTITLE>Analyzing parallelism and domain similarities in the MAREC patent corpus.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="37">
      <RAUTHOR>H Wu</RAUTHOR>
      <REFTITLE>Improving domain-specific word alignment with a general bilingual corpus.</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="38">
      <RAUTHOR>C Wu</RAUTHOR>
      <REFTITLE>Statistical machine translation for biomedical text: are we there yet? AMIA Annual Symposium proceedings,</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
