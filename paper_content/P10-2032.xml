<document>
  <filename>P10-2032</filename>
  <authors/>
  <title>None</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>1 Introduction</title>
        <text>In Statistical Machine Translation (SMT), the translation is modelled as a decission process. For a given source string f1 J = f 1 . . .f j . . .f J , we seek for the target string e I 1 = e 1 . . .e i . . .e I which maximises posterior probability:
&#234;&#206;1 = argmax Pr(e I 1|f1 J ) . (1) I,e I 1
Within the Interactive-predictive Machine Translation (IMT) framework, a state-of-the-art SMT system is employed in the following way: For a given source sentence, the SMT system fully automatically generates an initial translation. A human translator checks this translation from left to right, correcting the first error. The SMT system then proposes a new extension, taking the correct prefix e i 1 = e 1 . . .e i into account. These steps are repeated until the whole input sentence has been correctly translated. In the resulting decision rule, we maximise over all possible extensions e I i+1 of ei 1 :
&#234;&#206;i+1 = argmax Pr(e I i+1|e i 1, f1 J ) . (2) I,e I i+1
An implementation of the IMT famework was performed in the TransType project (Foster et al., 1997; Langlais et al., 2002) and further improved within the TransType2 project (Esteban et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In Statistical Machine Translation (SMT), the translation is modelled as a decission process.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>For a given source string f1 J = f 1 .</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>.f j .</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>.f J , we seek for the target string e I 1 = e 1 .</text>
              <doc_id>5</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>.</text>
              <doc_id>6</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>.e i .</text>
              <doc_id>7</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>.</text>
              <doc_id>8</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>.e I which maximises posterior probability:</text>
              <doc_id>9</doc_id>
              <sec_id>9</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#234;&#206;1 = argmax Pr(e I 1|f1 J ) .</text>
              <doc_id>10</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>(1) I,e I 1</text>
              <doc_id>11</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Within the Interactive-predictive Machine Translation (IMT) framework, a state-of-the-art SMT system is employed in the following way: For a given source sentence, the SMT system fully automatically generates an initial translation.</text>
              <doc_id>12</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>A human translator checks this translation from left to right, correcting the first error.</text>
              <doc_id>13</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The SMT system then proposes a new extension, taking the correct prefix e i 1 = e 1 .</text>
              <doc_id>14</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>.</text>
              <doc_id>15</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>.e i into account.</text>
              <doc_id>16</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>These steps are repeated until the whole input sentence has been correctly translated.</text>
              <doc_id>17</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>In the resulting decision rule, we maximise over all possible extensions e I i+1 of ei 1 :</text>
              <doc_id>18</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#234;&#206;i+1 = argmax Pr(e I i+1|e i 1, f1 J ) .</text>
              <doc_id>19</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>(2) I,e I i+1</text>
              <doc_id>20</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>An implementation of the IMT famework was performed in the TransType project (Foster et al., 1997; Langlais et al., 2002) and further improved within the TransType2 project (Esteban et al., 2004; Barrachina et al., 2009).</text>
              <doc_id>21</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation.</text>
              <doc_id>22</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort.</text>
              <doc_id>23</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>As will be shown, our proposal allows to balance the ratio between user effort and final translation error.</text>
              <doc_id>24</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>1.1 Confidence Measures</title>
            <text>Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007).
Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions.
To compute CMs we have to select suitable confidence features and define a binary classifier. Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Confidence estimation have been extensively studied for speech recognition.</text>
                  <doc_id>25</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007).</text>
                  <doc_id>26</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005).</text>
                  <doc_id>27</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions.</text>
                  <doc_id>28</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To compute CMs we have to select suitable confidence features and define a binary classifier.</text>
                  <doc_id>29</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not.</text>
                  <doc_id>30</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>1</index>
        <title>2 IMT with Sentence CMs</title>
        <text>In the conventional IMT scenario a human translator and a SMT system collaborate in order to obtain the translation the user has in mind. Once the user has interactively translated the source sentences, the output translations are error-free. We propose an alternative scenario where not all the source sentences are interactively translated by the user. Specifically, only those source sentences
whose initial fully automatic translation are incorrect, according to some quality criterion, are interactively translated. We propose to use CMs as the quality criterion to classify those initial translations.
Our approach implies a modification of the user-machine interaction protocol. For a given source sentence, the SMT system generates an initial translation. Then, if the CM classifies this translation as correct, we output it as our final translation. On the contrary, if the initial translation is classified as incorrect, we perform a conventional IMT procedure, validating correct prefixes and generating new suffixes, until the sentence that the user has in mind is reached.
In our scenario, we allow the final translations to be different from the ones the user has in mind. This implies that the output may contain errors. If a small loss in translation can be tolerated for the sake of efficiency, user effort can be saved by interactively translating only those sentences that the CMs classify as incorrect.
It is worth of notice that our proposal can be seen as a generalisation of the conventional IMT approach. Varying the value of the CM classification threshold, we can range from a fully automatic SMT system where all sentences are classified as correct to a conventional IMT system where all sentences are classified as incorrect.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In the conventional IMT scenario a human translator and a SMT system collaborate in order to obtain the translation the user has in mind.</text>
              <doc_id>31</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Once the user has interactively translated the source sentences, the output translations are error-free.</text>
              <doc_id>32</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We propose an alternative scenario where not all the source sentences are interactively translated by the user.</text>
              <doc_id>33</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Specifically, only those source sentences</text>
              <doc_id>34</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>whose initial fully automatic translation are incorrect, according to some quality criterion, are interactively translated.</text>
              <doc_id>35</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We propose to use CMs as the quality criterion to classify those initial translations.</text>
              <doc_id>36</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our approach implies a modification of the user-machine interaction protocol.</text>
              <doc_id>37</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>For a given source sentence, the SMT system generates an initial translation.</text>
              <doc_id>38</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Then, if the CM classifies this translation as correct, we output it as our final translation.</text>
              <doc_id>39</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>On the contrary, if the initial translation is classified as incorrect, we perform a conventional IMT procedure, validating correct prefixes and generating new suffixes, until the sentence that the user has in mind is reached.</text>
              <doc_id>40</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In our scenario, we allow the final translations to be different from the ones the user has in mind.</text>
              <doc_id>41</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This implies that the output may contain errors.</text>
              <doc_id>42</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>If a small loss in translation can be tolerated for the sake of efficiency, user effort can be saved by interactively translating only those sentences that the CMs classify as incorrect.</text>
              <doc_id>43</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>It is worth of notice that our proposal can be seen as a generalisation of the conventional IMT approach.</text>
              <doc_id>44</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Varying the value of the CM classification threshold, we can range from a fully automatic SMT system where all sentences are classified as correct to a conventional IMT system where all sentences are classified as incorrect.</text>
              <doc_id>45</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Selecting a CM for IMT</title>
            <text>We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004). We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005). We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems. Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show. The word confidence value of word e i , c w (e i ), is given by
c w (e i ) = max
0&#8804;j&#8804;J p(e i|f j ) , (3)
where p(e i |f j ) is the IBM model 1 lexicon probability, and f 0 is the empty source word.
From this word CM, we compute two sentence CMs which differ in the way the word confidence
Train Dev. Test
scores c w (e i ) are combined:
MEAN CM (c M (e I 1 )) is computed as the geometric mean of the confidence scores of the words in the sentence: c M (e I &#8719;
1) = &#8730; I I c w (e i ) . (4)
i=1
RATIO CM (c R (e I 1 )) is computed as the percentage of words classified as correct in the sentence. A word is classified as correct if its confidence exceeds a word classification threshold &#964; w .
c R (e I 1) = |{e i / c w (e i ) &gt; &#964; w }| I (5)
After computing the confidence value, each sentence is classified as either correct or incorrect, depending on whether its confidence value exceeds or not a sentence clasiffication threshold &#964; s . If &#964; s = 0.0 then all the sentences will be classified as correct whereas if &#964; s = 1.0 all the sentences will be classified as incorrect.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004).</text>
                  <doc_id>46</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005).</text>
                  <doc_id>47</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems.</text>
                  <doc_id>48</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show.</text>
                  <doc_id>49</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The word confidence value of word e i , c w (e i ), is given by</text>
                  <doc_id>50</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>c w (e i ) = max</text>
                  <doc_id>51</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0&#8804;j&#8804;J p(e i|f j ) , (3)</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where p(e i |f j ) is the IBM model 1 lexicon probability, and f 0 is the empty source word.</text>
                  <doc_id>53</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>From this word CM, we compute two sentence CMs which differ in the way the word confidence</text>
                  <doc_id>54</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Train Dev.</text>
                  <doc_id>55</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Test</text>
                  <doc_id>56</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>scores c w (e i ) are combined:</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>MEAN CM (c M (e I 1 )) is computed as the geometric mean of the confidence scores of the words in the sentence: c M (e I &#8719;</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1) = &#8730; I I c w (e i ) .</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>(4)</text>
                  <doc_id>60</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>i=1</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>RATIO CM (c R (e I 1 )) is computed as the percentage of words classified as correct in the sentence.</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A word is classified as correct if its confidence exceeds a word classification threshold &#964; w .</text>
                  <doc_id>63</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>c R (e I 1) = |{e i / c w (e i ) &gt; &#964; w }| I (5)</text>
                  <doc_id>64</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>After computing the confidence value, each sentence is classified as either correct or incorrect, depending on whether its confidence value exceeds or not a sentence clasiffication threshold &#964; s .</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>If &#964; s = 0.0 then all the sentences will be classified as correct whereas if &#964; s = 1.0 all the sentences will be classified as incorrect.</text>
                  <doc_id>66</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>2</index>
        <title>3 Experimentation</title>
        <text>The aim of the experimentation was to study the possibly trade-off between saved user effort and translation error obtained when using sentence CMs within the IMT framework.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The aim of the experimentation was to study the possibly trade-off between saved user effort and translation error obtained when using sentence CMs within the IMT framework.</text>
              <doc_id>67</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 System evaluation</title>
            <text>In this paper, we report our results as measured by Word Stroke Ratio (WSR) (Barrachina et al., 2009). WSR is used in the context of IMT to measure the effort required by the user to generate her
0 0 0.2 0.4 0.6 0.8 1 0
Threshold (&#964; s )
translations. WSR is computed as the ratio between the number of word-strokes a user would need to achieve the translation she has in mind and the total number of words in the sentence. In this context, a word-stroke is interpreted as a single action, in which the user types a complete word, and is assumed to have constant cost. Additionally, and because our proposal allows differences between its output and the reference translation, we will also present translation quality results in terms of BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002). BLEU computes a geometric mean of the precision of n- grams multiplied by a factor to penalise short sentences.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>In this paper, we report our results as measured by Word Stroke Ratio (WSR) (Barrachina et al., 2009).</text>
                  <doc_id>68</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>WSR is used in the context of IMT to measure the effort required by the user to generate her</text>
                  <doc_id>69</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0 0 0.2 0.4 0.6 0.8 1 0</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Threshold (&#964; s )</text>
                  <doc_id>71</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>translations.</text>
                  <doc_id>72</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>WSR is computed as the ratio between the number of word-strokes a user would need to achieve the translation she has in mind and the total number of words in the sentence.</text>
                  <doc_id>73</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In this context, a word-stroke is interpreted as a single action, in which the user types a complete word, and is assumed to have constant cost.</text>
                  <doc_id>74</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Additionally, and because our proposal allows differences between its output and the reference translation, we will also present translation quality results in terms of BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002).</text>
                  <doc_id>75</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>BLEU computes a geometric mean of the precision of n- grams multiplied by a factor to penalise short sentences.</text>
                  <doc_id>76</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Experimental Setup</title>
            <text>Our experiments were carried out on the EU corpora (Barrachina et al., 2009). The EU corpora were extracted from the Bulletin of the European Union. The EU corpora is composed of sentences given in three different language pairs. Here, we will focus on the Spanish&#8211;English part of the EU corpora. The corpus is divided into training, development and test sets. The main figures of the corpus can be seen in Table 1.
As a first step, be built a SMT system to translate from Spanish into English. This was done by means of the Thot toolkit (Ortiz et al., 2005), which is a complete system for building phrasebased SMT models. This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) proce-
0 0 0.2 0.4 0.6 0.8 1 0
Threshold (&#964; s )
dure, optimising the BLEU score on the development set. The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix. A word graph has to be generated for each sentence to be interactively translated. For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit. We discarded to use the state-of-the-art Moses toolkit (Koehn et al., 2007) because preliminary experiments performed with it revealed that the decoder by Ortiz- Mart&#237;nez et al. (2005) performs better in terms of WSR when used to generate word graphs for their use in IMT (Sanchis-Trilles et al., 2008). Moreover, the performance difference in regular SMT is negligible. The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive response time for the user. Finally, the obtained word graphs were used within the IMT procedure to produce the reference translations in the test set, measuring WSR and BLEU.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Our experiments were carried out on the EU corpora (Barrachina et al., 2009).</text>
                  <doc_id>77</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The EU corpora were extracted from the Bulletin of the European Union.</text>
                  <doc_id>78</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The EU corpora is composed of sentences given in three different language pairs.</text>
                  <doc_id>79</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Here, we will focus on the Spanish&#8211;English part of the EU corpora.</text>
                  <doc_id>80</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The corpus is divided into training, development and test sets.</text>
                  <doc_id>81</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>The main figures of the corpus can be seen in Table 1.</text>
                  <doc_id>82</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As a first step, be built a SMT system to translate from Spanish into English.</text>
                  <doc_id>83</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This was done by means of the Thot toolkit (Ortiz et al., 2005), which is a complete system for building phrasebased SMT models.</text>
                  <doc_id>84</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) proce-</text>
                  <doc_id>85</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0 0 0.2 0.4 0.6 0.8 1 0</text>
                  <doc_id>86</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Threshold (&#964; s )</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>dure, optimising the BLEU score on the development set.</text>
                  <doc_id>88</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix.</text>
                  <doc_id>89</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A word graph has to be generated for each sentence to be interactively translated.</text>
                  <doc_id>90</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit.</text>
                  <doc_id>91</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We discarded to use the state-of-the-art Moses toolkit (Koehn et al., 2007) because preliminary experiments performed with it revealed that the decoder by Ortiz- Mart&#237;nez et al. (2005) performs better in terms of WSR when used to generate word graphs for their use in IMT (Sanchis-Trilles et al., 2008).</text>
                  <doc_id>92</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Moreover, the performance difference in regular SMT is negligible.</text>
                  <doc_id>93</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive response time for the user.</text>
                  <doc_id>94</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>Finally, the obtained word graphs were used within the IMT procedure to produce the reference translations in the test set, measuring WSR and BLEU.</text>
                  <doc_id>95</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Results</title>
            <text>We carried out a series of experiments ranging the value of the sentence classification threshold &#964; s , between 0.0 (equivalent to a fully automatic SMT system) and 1.0 (equivalent to a conventional IMT system), for both the MEAN and RATIO CMs. For each threshold value, we calculated the effort of the user in terms of WSR, and the translation quality of the final output as measured by BLEU.
src-1 ref-1 tra-1
src-2 ref-2 tra-2 DECLARACI&#211;N (No 17) relativa al derecho de acceso a la informaci&#243;n DECLARATION (No 17) on the right of access to information DECLARATION (No 17) on the right of access to information
Conclusiones del Consejo sobre el comercio electr&#243;nico y los impuestos indirectos. Council conclusions on electronic commerce and indirect taxation. Council conclusions on e-commerce and indirect taxation.
Figure 1 shows WSR (WSR IMT-CM) and BLEU (BLEU IMT-CM) scores obtained varying &#964; s for the MEAN CM. Additionally, we also show the BLEU score (BLEU SMT) obtained by a fully automatic SMT system as translation quality baseline, and the WSR score (WSR IMT) obtained by a conventional IMT system as user effort baseline. This figure shows a continuous transition between the fully automatic SMT system and the conventional IMT system. This transition occurs when ranging &#964; s between 0.0 and 0.6. This is an undesired effect, since for almost a half of the possible values for &#964; s there is no change in the behaviour of our proposed IMT system.
The RATIO CM confidence values depend on a word classification threshold &#964; w . We have carried out experimentation ranging &#964; w between 0.0 and 1.0 and found that this value can be used to solve the above mentioned undesired effect for the MEAN CM. Specifically, varying the value of &#964; w we can stretch the interval in which the transition between the fully automatic SMT system and the conventional IMT system is produced, allowing us to obtain smother transitions. Figure 2 shows WSR and BLEU scores for different values of the sentence classification threshold &#964; s using &#964; w = 0.4. We show results only for this value of &#964; w due to paper space limitations and because &#964; w = 0.4 produced the smoothest transition. According to Figure 2, using a sentence classification threshold value of 0.6 we obtain a WSR reduction of 20% relative and an almost perfect translation quality of 87 BLEU points.
It is worth of notice that the final translations are compared with only one reference, therefore, the reported translation quality scores are clearly pessimistic. Better results are expected using a multi-reference corpus. Example 1 shows the source sentence (src), the reference translation (ref) and the final translation (tra) for three of the initial fully automatically generated translations that were classified as correct by our CMs, and thus, were not interactively translated by the user. The first translation (tra-1) is identical to the corresponding reference translation (ref-1). The second translation (tra-2) corresponds to a correct translation of the source sentence (src-2) that is different from the corresponding reference (ref-2). Finally, the third translation (tra-3) is an example of a slightly incorrect translation.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We carried out a series of experiments ranging the value of the sentence classification threshold &#964; s , between 0.0 (equivalent to a fully automatic SMT system) and 1.0 (equivalent to a conventional IMT system), for both the MEAN and RATIO CMs.</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For each threshold value, we calculated the effort of the user in terms of WSR, and the translation quality of the final output as measured by BLEU.</text>
                  <doc_id>97</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>src-1 ref-1 tra-1</text>
                  <doc_id>98</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>src-2 ref-2 tra-2 DECLARACI&#211;N (No 17) relativa al derecho de acceso a la informaci&#243;n DECLARATION (No 17) on the right of access to information DECLARATION (No 17) on the right of access to information</text>
                  <doc_id>99</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Conclusiones del Consejo sobre el comercio electr&#243;nico y los impuestos indirectos.</text>
                  <doc_id>100</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Council conclusions on electronic commerce and indirect taxation.</text>
                  <doc_id>101</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Council conclusions on e-commerce and indirect taxation.</text>
                  <doc_id>102</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 1 shows WSR (WSR IMT-CM) and BLEU (BLEU IMT-CM) scores obtained varying &#964; s for the MEAN CM.</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Additionally, we also show the BLEU score (BLEU SMT) obtained by a fully automatic SMT system as translation quality baseline, and the WSR score (WSR IMT) obtained by a conventional IMT system as user effort baseline.</text>
                  <doc_id>104</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This figure shows a continuous transition between the fully automatic SMT system and the conventional IMT system.</text>
                  <doc_id>105</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This transition occurs when ranging &#964; s between 0.0 and 0.6.</text>
                  <doc_id>106</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This is an undesired effect, since for almost a half of the possible values for &#964; s there is no change in the behaviour of our proposed IMT system.</text>
                  <doc_id>107</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The RATIO CM confidence values depend on a word classification threshold &#964; w .</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We have carried out experimentation ranging &#964; w between 0.0 and 1.0 and found that this value can be used to solve the above mentioned undesired effect for the MEAN CM.</text>
                  <doc_id>109</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Specifically, varying the value of &#964; w we can stretch the interval in which the transition between the fully automatic SMT system and the conventional IMT system is produced, allowing us to obtain smother transitions.</text>
                  <doc_id>110</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Figure 2 shows WSR and BLEU scores for different values of the sentence classification threshold &#964; s using &#964; w = 0.4.</text>
                  <doc_id>111</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We show results only for this value of &#964; w due to paper space limitations and because &#964; w = 0.4 produced the smoothest transition.</text>
                  <doc_id>112</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>According to Figure 2, using a sentence classification threshold value of 0.6 we obtain a WSR reduction of 20% relative and an almost perfect translation quality of 87 BLEU points.</text>
                  <doc_id>113</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>It is worth of notice that the final translations are compared with only one reference, therefore, the reported translation quality scores are clearly pessimistic.</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Better results are expected using a multi-reference corpus.</text>
                  <doc_id>115</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Example 1 shows the source sentence (src), the reference translation (ref) and the final translation (tra) for three of the initial fully automatically generated translations that were classified as correct by our CMs, and thus, were not interactively translated by the user.</text>
                  <doc_id>116</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The first translation (tra-1) is identical to the corresponding reference translation (ref-1).</text>
                  <doc_id>117</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The second translation (tra-2) corresponds to a correct translation of the source sentence (src-2) that is different from the corresponding reference (ref-2).</text>
                  <doc_id>118</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Finally, the third translation (tra-3) is an example of a slightly incorrect translation.</text>
                  <doc_id>119</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>4 Concluding Remarks</title>
        <text>In this paper, we have presented a novel proposal that introduces sentence CMs into an IMT system to reduce user effort. Our proposal entails a modification of the user-machine interaction protocol that allows to achieve a balance between the user effort and the final translation error.
We have carried out experimentation using two different sentence CMs. Varying the value of the sentence classification threshold, we can range from a fully automatic SMT system to a conventional IMT system. Empirical results show that our proposal allows to obtain almost perfect translations while significantly reducing user effort.
Future research aims at the investigation of improved CMs to be integrated in our IMT system.
Acknowledgments
Work supported by the EC (FEDER/FSE) and the Spanish MEC/MICINN under the MIPRCV &#8220;Consolider Ingenio 2010&#8221; program (CSD2007- 00018), the iTransDoc (TIN2006-15694-CO2-01) and iTrans2 (TIN2009-14511) projects and the FPU scholarship AP2006-00691. Also supported by the Spanish MITyC under the erudito.com (TSI-020110-2009-439) project and by the Generalitat Valenciana under grant Prometeo/2009/014.
References
S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tom&#225;s, and E. Vidal. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3&#8211;28.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing. 2003. Confidence estimation for machine translation.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing. 2004. Confidence estimation for machine translation. In Proc. COLING, page 315.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263&#8211;311.
J. Esteban, J. Lorenzo, A. Valderr&#225;banos, and G. Lapalme. 2004. Transtype2: an innovative computerassisted translation system. In Proc. ACL, page 1.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Targettext mediated interactive machine translation. Machine Translation, 12:12&#8211;175.
S. Gandrabur and G. Foster. 2003. Confidence estimation for text prediction. In Proc. CoNLL, pages 315&#8211;321.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. pages 177&#8211;180. In Proc. ACL,
P. Langlais, G. Lapalme, and M. Loranger. 2002. Transtype: Development-evaluation cycles to boost translator&#8217;s productivity. Machine Translation, 15(4):77&#8211;98.
F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL, pages 160&#8211; 167.
D. Ortiz, I. Garc&#237;a-Varea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proc. MT Summit, pages 141&#8211;148.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a method for automatic evaluation of MT. In Proc. ACL, pages 311&#8211;318.
G. Sanchis-Trilles, D. Ortiz-Mart&#237;nez, J. Civera, F. Casacuberta, E. Vidal, and H. Hoang. 2008. Improving interactive machine translation via mouse actions. In Proc. EMNLP, pages 25&#8211;27.
N. Ueffing and H. Ney. 2005. Application of wordlevel confidence measures in interactive statistical machine translation. In Proc. EAMT, pages 262&#8211; 270.
N. Ueffing and H. Ney. 2007. Word-level confidence estimation for machine translation. Comput. Linguist., 33(1):9&#8211;40.
N. Ueffing, F.J. Och, and H. Ney. 2002. Generation of word graphs in statistical machine translation. In Proc. EMNLP, pages 156&#8211;163.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this paper, we have presented a novel proposal that introduces sentence CMs into an IMT system to reduce user effort.</text>
              <doc_id>120</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our proposal entails a modification of the user-machine interaction protocol that allows to achieve a balance between the user effort and the final translation error.</text>
              <doc_id>121</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We have carried out experimentation using two different sentence CMs.</text>
              <doc_id>122</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Varying the value of the sentence classification threshold, we can range from a fully automatic SMT system to a conventional IMT system.</text>
              <doc_id>123</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Empirical results show that our proposal allows to obtain almost perfect translations while significantly reducing user effort.</text>
              <doc_id>124</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Future research aims at the investigation of improved CMs to be integrated in our IMT system.</text>
              <doc_id>125</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Acknowledgments</text>
              <doc_id>126</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Work supported by the EC (FEDER/FSE) and the Spanish MEC/MICINN under the MIPRCV &#8220;Consolider Ingenio 2010&#8221; program (CSD2007- 00018), the iTransDoc (TIN2006-15694-CO2-01) and iTrans2 (TIN2009-14511) projects and the FPU scholarship AP2006-00691.</text>
              <doc_id>127</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Also supported by the Spanish MITyC under the erudito.com (TSI-020110-2009-439) project and by the Generalitat Valenciana under grant Prometeo/2009/014.</text>
              <doc_id>128</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>References</text>
              <doc_id>129</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tom&#225;s, and E. Vidal.</text>
              <doc_id>130</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>131</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Statistical approaches to computer-assisted translation.</text>
              <doc_id>132</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Computational Linguistics, 35(1):3&#8211;28.</text>
              <doc_id>133</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing.</text>
              <doc_id>134</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2003.</text>
              <doc_id>135</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Confidence estimation for machine translation.</text>
              <doc_id>136</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing.</text>
              <doc_id>137</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2004.</text>
              <doc_id>138</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Confidence estimation for machine translation.</text>
              <doc_id>139</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. COLING, page 315.</text>
              <doc_id>140</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>P. F. Brown, S.</text>
              <doc_id>141</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>A. Della Pietra, V.</text>
              <doc_id>142</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>J. Della Pietra, and R.</text>
              <doc_id>143</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>L. Mercer.</text>
              <doc_id>144</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>1993.</text>
              <doc_id>145</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>The Mathematics of Statistical Machine Translation: Parameter Estimation.</text>
              <doc_id>146</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Computational Linguistics, 19(2):263&#8211;311.</text>
              <doc_id>147</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>J. Esteban, J. Lorenzo, A. Valderr&#225;banos, and G. Lapalme.</text>
              <doc_id>148</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2004.</text>
              <doc_id>149</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Transtype2: an innovative computerassisted translation system.</text>
              <doc_id>150</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. ACL, page 1.</text>
              <doc_id>151</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>G. Foster, P. Isabelle, and P. Plamondon.</text>
              <doc_id>152</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>1997.</text>
              <doc_id>153</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Targettext mediated interactive machine translation.</text>
              <doc_id>154</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Machine Translation, 12:12&#8211;175.</text>
              <doc_id>155</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>S. Gandrabur and G. Foster.</text>
              <doc_id>156</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2003.</text>
              <doc_id>157</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Confidence estimation for text prediction.</text>
              <doc_id>158</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. CoNLL, pages 315&#8211;321.</text>
              <doc_id>159</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst.</text>
              <doc_id>160</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2007.</text>
              <doc_id>161</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Moses: Open source toolkit for statistical machine translation.</text>
              <doc_id>162</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>pages 177&#8211;180.</text>
              <doc_id>163</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. ACL,</text>
              <doc_id>164</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>P. Langlais, G. Lapalme, and M. Loranger.</text>
              <doc_id>165</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2002.</text>
              <doc_id>166</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Transtype: Development-evaluation cycles to boost translator&#8217;s productivity.</text>
              <doc_id>167</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Machine Translation, 15(4):77&#8211;98.</text>
              <doc_id>168</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>F. J. Och.</text>
              <doc_id>169</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2003.</text>
              <doc_id>170</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Minimum error rate training in statistical machine translation.</text>
              <doc_id>171</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. ACL, pages 160&#8211; 167.</text>
              <doc_id>172</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>D. Ortiz, I. Garc&#237;a-Varea, and F. Casacuberta.</text>
              <doc_id>173</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2005.</text>
              <doc_id>174</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Thot: a toolkit to train phrase-based statistical translation models.</text>
              <doc_id>175</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. MT Summit, pages 141&#8211;148.</text>
              <doc_id>176</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>K. Papineni, S. Roukos, T. Ward, and W. Zhu.</text>
              <doc_id>177</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2002.</text>
              <doc_id>178</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>BLEU: a method for automatic evaluation of MT.</text>
              <doc_id>179</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. ACL, pages 311&#8211;318.</text>
              <doc_id>180</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>G. Sanchis-Trilles, D. Ortiz-Mart&#237;nez, J. Civera, F. Casacuberta, E. Vidal, and H. Hoang.</text>
              <doc_id>181</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2008.</text>
              <doc_id>182</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Improving interactive machine translation via mouse actions.</text>
              <doc_id>183</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. EMNLP, pages 25&#8211;27.</text>
              <doc_id>184</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>N. Ueffing and H. Ney.</text>
              <doc_id>185</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2005.</text>
              <doc_id>186</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Application of wordlevel confidence measures in interactive statistical machine translation.</text>
              <doc_id>187</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. EAMT, pages 262&#8211; 270.</text>
              <doc_id>188</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>N. Ueffing and H. Ney.</text>
              <doc_id>189</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2007.</text>
              <doc_id>190</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Word-level confidence estimation for machine translation.</text>
              <doc_id>191</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Comput.</text>
              <doc_id>192</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Linguist., 33(1):9&#8211;40.</text>
              <doc_id>193</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>N. Ueffing, F.J.</text>
              <doc_id>194</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Och, and H. Ney.</text>
              <doc_id>195</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>2002.</text>
              <doc_id>196</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Generation of word graphs in statistical machine translation.</text>
              <doc_id>197</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In Proc. EMNLP, pages 156&#8211;163.</text>
              <doc_id>198</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: Statistics of the Spanish&#8211;English EU corpora. K and M denote thousands and millions of elements respectively.</caption>
        <reference_text></reference_text>
        <page_num>1</page_num>
        <head>
          <rows>
            <row>
              <cell>Spanish</cell>
              <cell>English</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Sentences</cell>
              <cell>214.5K</cell>
              <cell></cell>
            </row>
            <row>
              <cell>Running words</cell>
              <cell>5.8M</cell>
              <cell>5.2M</cell>
            </row>
            <row>
              <cell>Vocabulary</cell>
              <cell>97.4K</cell>
              <cell>83.7K</cell>
            </row>
            <row>
              <cell>Sentences</cell>
              <cell>400</cell>
              <cell></cell>
            </row>
            <row>
              <cell>Running words</cell>
              <cell>11.5K</cell>
              <cell>10.1K</cell>
            </row>
            <row>
              <cell>Perplexity (trigrams)</cell>
              <cell>46.1</cell>
              <cell>59.4</cell>
            </row>
            <row>
              <cell>Sentences</cell>
              <cell>800</cell>
              <cell></cell>
            </row>
            <row>
              <cell>Running words</cell>
              <cell>22.6K</cell>
              <cell>19.9K</cell>
            </row>
            <row>
              <cell>Perplexity (trigrams)</cell>
              <cell>45.2</cell>
              <cell>60.8</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references/>
    <citations/>
  </content>
</document>
