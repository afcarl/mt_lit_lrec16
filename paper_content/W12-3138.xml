<document>
  <filename>W12-3138</filename>
  <authors>
    <author>Sabine Hunsicker</author>
    <author>Chen Yu</author>
  </authors>
  <title>Machine Learning for Hybrid Machine Translation</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>We describe a substitution-based system for hybrid machine translation (MT) that has been extended with machine learning components controlling its phrase selection. The approach is based on a rule-based MT (RBMT) system which creates template translations. Based on the rule-based generation parse tree and target-to-target alignments, we identify the set of &#8220;interesting&#8221; translation candidates from one or more translation engines which could be substituted into our translation templates. The substitution process is either controlled by the output from a binary classifier trained on feature vectors from the different MT engines, or it is depending on weights for the decision factors, which have been tuned using MERT. We are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We describe a substitution-based system for hybrid machine translation (MT) that has been extended with machine learning components controlling its phrase selection.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The approach is based on a rule-based MT (RBMT) system which creates template translations.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Based on the rule-based generation parse tree and target-to-target alignments, we identify the set of &#8220;interesting&#8221; translation candidates from one or more translation engines which could be substituted into our translation templates.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The substitution process is either controlled by the output from a binary classifier trained on feature vectors from the different MT engines, or it is depending on weights for the decision factors, which have been tuned using MERT.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>In recent years, machine translation (MT) systems have achieved increasingly better translation quality. Still each paradigm has its own challenges: while statistical MT (SMT) systems suffer from a lack of grammatical structure, resulting in ungrammatical sentences, RBMT systems have to deal with a lack of lexical coverage. Hybrid architectures intend to combine the advantages of the individual paradigms to achieve an overall better translation.
Federmann et al. (2010) and Federmann and Hunsicker (2011) have shown that using a substitutionbased approach can improve the translation quality of a baseline RBMT system. Our submission to WMT12 is a new, improved version following these approaches. The output of an RBMT engine serves as our translation backbone, and we substitute noun phrases by translations mined from other systems.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In recent years, machine translation (MT) systems have achieved increasingly better translation quality.</text>
              <doc_id>5</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Still each paradigm has its own challenges: while statistical MT (SMT) systems suffer from a lack of grammatical structure, resulting in ungrammatical sentences, RBMT systems have to deal with a lack of lexical coverage.</text>
              <doc_id>6</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Hybrid architectures intend to combine the advantages of the individual paradigms to achieve an overall better translation.</text>
              <doc_id>7</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Federmann et al. (2010) and Federmann and Hunsicker (2011) have shown that using a substitutionbased approach can improve the translation quality of a baseline RBMT system.</text>
              <doc_id>8</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our submission to WMT12 is a new, improved version following these approaches.</text>
              <doc_id>9</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The output of an RBMT engine serves as our translation backbone, and we substitute noun phrases by translations mined from other systems.</text>
              <doc_id>10</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 System Architecture</title>
        <text>Our hybrid MT system combines translation output from:
a) the Lucy RBMT system, described in more detail in (Alonso and Thurmair, 2003);
b) the Linguatec RBMT system (Aleksic and Thurmair, 2011);
c) Moses (Koehn et al., 2007);
d) Joshua (Li et al., 2009).
Lucy provides us with the translation skeleton, which is described in more detail in Section 2.2 while systems b)&#8211;d) are aligned to this translation template and mined for substitution candidates. We give more detailed information on these systems in Section 2.3.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Our hybrid MT system combines translation output from:</text>
              <doc_id>11</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>a) the Lucy RBMT system, described in more detail in (Alonso and Thurmair, 2003);</text>
              <doc_id>12</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>b) the Linguatec RBMT system (Aleksic and Thurmair, 2011);</text>
              <doc_id>13</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>c) Moses (Koehn et al., 2007);</text>
              <doc_id>14</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>d) Joshua (Li et al., 2009).</text>
              <doc_id>15</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Lucy provides us with the translation skeleton, which is described in more detail in Section 2.2 while systems b)&#8211;d) are aligned to this translation template and mined for substitution candidates.</text>
              <doc_id>16</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We give more detailed information on these systems in Section 2.3.</text>
              <doc_id>17</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Basic Approach</title>
            <text>We first identify &#8220;interesting&#8221; phrases inside the rule-based translation and then compute the most probable correspondences in the translation output from the other systems. For the resulting phrases, we apply a factored substitution method that decides whether the original RBMT phrase should be kept or rather be replaced by one of the candidate phrases. A schematic overview of our hybrid system and its main components is given in Figure 1.
4. LM(phrase-1): phrase with left-context;
5. Part-of-speech match?: checks if the part-ofspeech tags of the left/right context match the current candidate phrase&#8217;s context;
6. LM(pos) LM score for part-of-speech (PoS);
7. LM(pos+1) PoS with right-context;
8. LM(pos-1) PoS with left-context;
9. Lemma checks if the lemma of the candidate phrase fits the reference;
10. LM(lemma) LM score for the lemma;
11. LM(lemma+1) lemma with right-context;
12. LM(lemma-1) lemma with left-context.
In previous years, it turned out that the alignment of the candidate translations to the source contained too many errors. In this version of our system, we thus changed the alignment method that connects the other translations. Only the rule-based template is aligned to the source. As we make use of the Lucy RBMT analysis parse trees, this alignment is very good. The other translations are now connected to the rule-based template using a confusion network approach. This also reduces computational efforts, as we now can compute the substitution candidates directly from the template without detouring over the source. During system training and tuning, this new approach has resulted in a reduced number of erroneous alignment links.
Additionally, we also changed our set of decision factors, increasing their total number. Whereas an older version of this system only used four factors, we now consider the following twelve factors:
1. frequency: frequency of a given candidate phrase compared to total number of candidates for the current phrase;
2. LM(phrase): language model (LM) score of the phrase;
3. LM(phrase+1): phrase with right-context;
The language model was trained using the SRILM toolkit (Stolcke, 2002), on the EuroParl (Koehn, 2005) corpus, and lemmatised or part-of-speech tagged versions, respectively. We used the Tree- Tagger (Schmid, 1994) for lemmatisation as well as part-of-speech tagging.
The substitution algorithm itself was also adapted. We investigated two machine learning approaches. In the previous version, the system used a handwritten decision tree to perform the substitution:
1. the first of the two new approaches consisted of machine learning this decision tree from annotated data;
2. the second approach was to assign a weight to each factor and using MERT tuning of these weights on a development set.
Both approaches are described in more detail later in Section 2.4.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We first identify &#8220;interesting&#8221; phrases inside the rule-based translation and then compute the most probable correspondences in the translation output from the other systems.</text>
                  <doc_id>18</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For the resulting phrases, we apply a factored substitution method that decides whether the original RBMT phrase should be kept or rather be replaced by one of the candidate phrases.</text>
                  <doc_id>19</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A schematic overview of our hybrid system and its main components is given in Figure 1.</text>
                  <doc_id>20</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4.</text>
                  <doc_id>21</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(phrase-1): phrase with left-context;</text>
                  <doc_id>22</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.</text>
                  <doc_id>23</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Part-of-speech match?</text>
                  <doc_id>24</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>: checks if the part-ofspeech tags of the left/right context match the current candidate phrase&#8217;s context;</text>
                  <doc_id>25</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>6.</text>
                  <doc_id>26</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(pos) LM score for part-of-speech (PoS);</text>
                  <doc_id>27</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>7.</text>
                  <doc_id>28</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(pos+1) PoS with right-context;</text>
                  <doc_id>29</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>8.</text>
                  <doc_id>30</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(pos-1) PoS with left-context;</text>
                  <doc_id>31</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>9.</text>
                  <doc_id>32</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Lemma checks if the lemma of the candidate phrase fits the reference;</text>
                  <doc_id>33</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>10.</text>
                  <doc_id>34</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(lemma) LM score for the lemma;</text>
                  <doc_id>35</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>11.</text>
                  <doc_id>36</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(lemma+1) lemma with right-context;</text>
                  <doc_id>37</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>12.</text>
                  <doc_id>38</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(lemma-1) lemma with left-context.</text>
                  <doc_id>39</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In previous years, it turned out that the alignment of the candidate translations to the source contained too many errors.</text>
                  <doc_id>40</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In this version of our system, we thus changed the alignment method that connects the other translations.</text>
                  <doc_id>41</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Only the rule-based template is aligned to the source.</text>
                  <doc_id>42</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>As we make use of the Lucy RBMT analysis parse trees, this alignment is very good.</text>
                  <doc_id>43</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The other translations are now connected to the rule-based template using a confusion network approach.</text>
                  <doc_id>44</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>This also reduces computational efforts, as we now can compute the substitution candidates directly from the template without detouring over the source.</text>
                  <doc_id>45</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>During system training and tuning, this new approach has resulted in a reduced number of erroneous alignment links.</text>
                  <doc_id>46</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Additionally, we also changed our set of decision factors, increasing their total number.</text>
                  <doc_id>47</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Whereas an older version of this system only used four factors, we now consider the following twelve factors:</text>
                  <doc_id>48</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1. frequency: frequency of a given candidate phrase compared to total number of candidates for the current phrase;</text>
                  <doc_id>49</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.</text>
                  <doc_id>50</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(phrase): language model (LM) score of the phrase;</text>
                  <doc_id>51</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3.</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>LM(phrase+1): phrase with right-context;</text>
                  <doc_id>53</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The language model was trained using the SRILM toolkit (Stolcke, 2002), on the EuroParl (Koehn, 2005) corpus, and lemmatised or part-of-speech tagged versions, respectively.</text>
                  <doc_id>54</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We used the Tree- Tagger (Schmid, 1994) for lemmatisation as well as part-of-speech tagging.</text>
                  <doc_id>55</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The substitution algorithm itself was also adapted.</text>
                  <doc_id>56</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We investigated two machine learning approaches.</text>
                  <doc_id>57</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In the previous version, the system used a handwritten decision tree to perform the substitution:</text>
                  <doc_id>58</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1. the first of the two new approaches consisted of machine learning this decision tree from annotated data;</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2. the second approach was to assign a weight to each factor and using MERT tuning of these weights on a development set.</text>
                  <doc_id>60</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Both approaches are described in more detail later in Section 2.4.</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Rule-Based Translation Templates</title>
            <text>The Lucy RBMT system provides us with parse tree structures for each of the three phases of its transferbased translation approach: analysis, transfer and generation. Out of these structures, we can extract linguistic phrases which later represent the &#8220;slots&#8221; for substitution. Previous work has shown that these structures are of a good grammatical quality due to the grammar Lucy uses.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The Lucy RBMT system provides us with parse tree structures for each of the three phases of its transferbased translation approach: analysis, transfer and generation.</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Out of these structures, we can extract linguistic phrases which later represent the &#8220;slots&#8221; for substitution.</text>
                  <doc_id>63</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Previous work has shown that these structures are of a good grammatical quality due to the grammar Lucy uses.</text>
                  <doc_id>64</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>2.3 Substitution Candidate Translations</title>
            <text>Whereas in our previous work, we solely relied on candidates retrieved from SMT systems, this time we also included an additional RBMT system into the architecture. Knowing that statistical systems make similar errors, we hope to balance out this fact by exploiting also a system of a different paradigm, namely RBMT.
To create the statistical translations, we used stateof-the-art SMT systems. Both our Moses and Joshua systems were trained on the EuroParl corpus and News Commentary 1 training data. We performed tuning on the &#8220;newstest2011&#8221; data set using MERT.
We compile alignments between translations with the alignment module of MANY (Barrault, 2010). This module uses a modified version of TERp (Snover et al., 2009) and a set of different costs to create the best alignment between any two given sentences. In our case, each single candidate translation is aligned to the translation template that has been produced by the Lucy RBMT system. As we do not use the source in this alignment technique, we can use any translation system, regardless of whether this system provides us with a source-totarget alignment.
In earlier versions of this system, we compiled the source-to-target alignments for the candidate translations using GIZA++ (Och and Ney, 2003), but these alignments contained many errors. By using target-to-target alignments, we are able to reduce the amount of those errors which is, of course, preferred.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Whereas in our previous work, we solely relied on candidates retrieved from SMT systems, this time we also included an additional RBMT system into the architecture.</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Knowing that statistical systems make similar errors, we hope to balance out this fact by exploiting also a system of a different paradigm, namely RBMT.</text>
                  <doc_id>66</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To create the statistical translations, we used stateof-the-art SMT systems.</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Both our Moses and Joshua systems were trained on the EuroParl corpus and News Commentary 1 training data.</text>
                  <doc_id>68</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We performed tuning on the &#8220;newstest2011&#8221; data set using MERT.</text>
                  <doc_id>69</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We compile alignments between translations with the alignment module of MANY (Barrault, 2010).</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This module uses a modified version of TERp (Snover et al., 2009) and a set of different costs to create the best alignment between any two given sentences.</text>
                  <doc_id>71</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In our case, each single candidate translation is aligned to the translation template that has been produced by the Lucy RBMT system.</text>
                  <doc_id>72</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>As we do not use the source in this alignment technique, we can use any translation system, regardless of whether this system provides us with a source-totarget alignment.</text>
                  <doc_id>73</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In earlier versions of this system, we compiled the source-to-target alignments for the candidate translations using GIZA++ (Och and Ney, 2003), but these alignments contained many errors.</text>
                  <doc_id>74</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>By using target-to-target alignments, we are able to reduce the amount of those errors which is, of course, preferred.</text>
                  <doc_id>75</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>2.4 Substitution Approaches</title>
            <text>Using the parse tree structures provided by Lucy, we extract &#8220;interesting&#8221; phrases for substitution. This includes noun phrases of various complexity, then simple verb phrases consisting of only the main verb, and finally adjective phrases. Through the target-to-target alignments we identify and collect the set of potential substitution candidates. Phrase substitution can be performed using two methods.
2.4.1 Machine-Learned Decision Tree
Previous work used hand-crafted rules. These are now replaced by a classifier which was trained on annotated data. Our training set D can formally be
1 Available at http://www.statmt.org/wmt12/
represented as
D = {(x i , y i )|x i &#8712; R p , y i &#8712; {&#8722;1, 1}} n i=1 (1)
where each x i represents the feature vector for some sentence i while the y i value contains the annotated class information. We use a binary classification scheme, simply defining 1 as &#8220;good&#8221; and &#8722;1 as &#8220;bad&#8221; translations.
In order to make use of machine (ML) learning methods such as decision trees (Breiman et al., 1984), Support Vector Machines (Vapnik, 1995), or the Perceptron (Rosenblatt, 1958) algorithm, we have to prepare our training set with a sufficiently large amount of annotated training instances.
To create the training data set, we computed the feature vectors and all possible substitution candidates for the WMT12 &#8220;newstest2011&#8221; development set. Human annotators were then given the task to assign to each candidate whether it was a &#8220;good&#8221; or a &#8220;bad&#8221; substitution. We used Appraise (Federmann, 2010) for the annotation, and collected a set of 24,996 labeled training instances with the help of six human annotators. Table 1 gives an overview of the data sets characteristics. The decision tree learned from this data replaces the hand-crafted rules.
2.4.2 Weights Tuned with MERT
Another approach we followed was to assign weights to the chosen decision factors and to use Minimal Error Rate Training to get the best weights. Using the twelve factors described in Section 2.1, we assign uniformly distributed weights and create n-best lists. Each n-best lists contains a total of n+2 hypotheses, with n being the number of candidate systems. It contains the Lucy template translations, the hybrid translation using the best candidates as well as a hypothesis for each candidate system. In the latter translation, each potential candidate for substitution is selected and replaces the original sub phrase in the baseline. The n-best list is
Translation Candidates
Total &#8220;good&#8221; &#8220;bad&#8221;
Count 24,996 10,666 14,330
Hybrid Systems Baseline Systems
Baseline +Decision Tree +MERT Lucy Linguatec Joshua Moses
BLEU 13.9 14.2 14.3 14.0 14.7 14.6 15.9
BLEU-cased 13.5 13.8 13.9 13.7 14.2 13.5 14.9
TER 0.776 0.773 0.768 0.774 0.775 0.772 0.774
sorted by the final score of the feature vectors making up each hypothesis. We used Z-MERT (Zaidan, 2009) to optimise the set of feature weights on the &#8220;newstest2011&#8221; development set.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Using the parse tree structures provided by Lucy, we extract &#8220;interesting&#8221; phrases for substitution.</text>
                  <doc_id>76</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This includes noun phrases of various complexity, then simple verb phrases consisting of only the main verb, and finally adjective phrases.</text>
                  <doc_id>77</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Through the target-to-target alignments we identify and collect the set of potential substitution candidates.</text>
                  <doc_id>78</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Phrase substitution can be performed using two methods.</text>
                  <doc_id>79</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.4.1 Machine-Learned Decision Tree</text>
                  <doc_id>80</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Previous work used hand-crafted rules.</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>These are now replaced by a classifier which was trained on annotated data.</text>
                  <doc_id>82</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Our training set D can formally be</text>
                  <doc_id>83</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1 Available at http://www.statmt.org/wmt12/</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>represented as</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>D = {(x i , y i )|x i &#8712; R p , y i &#8712; {&#8722;1, 1}} n i=1 (1)</text>
                  <doc_id>86</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where each x i represents the feature vector for some sentence i while the y i value contains the annotated class information.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We use a binary classification scheme, simply defining 1 as &#8220;good&#8221; and &#8722;1 as &#8220;bad&#8221; translations.</text>
                  <doc_id>88</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In order to make use of machine (ML) learning methods such as decision trees (Breiman et al., 1984), Support Vector Machines (Vapnik, 1995), or the Perceptron (Rosenblatt, 1958) algorithm, we have to prepare our training set with a sufficiently large amount of annotated training instances.</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To create the training data set, we computed the feature vectors and all possible substitution candidates for the WMT12 &#8220;newstest2011&#8221; development set.</text>
                  <doc_id>90</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Human annotators were then given the task to assign to each candidate whether it was a &#8220;good&#8221; or a &#8220;bad&#8221; substitution.</text>
                  <doc_id>91</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We used Appraise (Federmann, 2010) for the annotation, and collected a set of 24,996 labeled training instances with the help of six human annotators.</text>
                  <doc_id>92</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Table 1 gives an overview of the data sets characteristics.</text>
                  <doc_id>93</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The decision tree learned from this data replaces the hand-crafted rules.</text>
                  <doc_id>94</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.4.2 Weights Tuned with MERT</text>
                  <doc_id>95</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Another approach we followed was to assign weights to the chosen decision factors and to use Minimal Error Rate Training to get the best weights.</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Using the twelve factors described in Section 2.1, we assign uniformly distributed weights and create n-best lists.</text>
                  <doc_id>97</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Each n-best lists contains a total of n+2 hypotheses, with n being the number of candidate systems.</text>
                  <doc_id>98</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>It contains the Lucy template translations, the hybrid translation using the best candidates as well as a hypothesis for each candidate system.</text>
                  <doc_id>99</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>In the latter translation, each potential candidate for substitution is selected and replaces the original sub phrase in the baseline.</text>
                  <doc_id>100</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>The n-best list is</text>
                  <doc_id>101</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Translation Candidates</text>
                  <doc_id>102</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Total &#8220;good&#8221; &#8220;bad&#8221;</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Count 24,996 10,666 14,330</text>
                  <doc_id>104</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Hybrid Systems Baseline Systems</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Baseline +Decision Tree +MERT Lucy Linguatec Joshua Moses</text>
                  <doc_id>106</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU 13.9 14.2 14.3 14.0 14.7 14.6 15.9</text>
                  <doc_id>107</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU-cased 13.5 13.8 13.9 13.7 14.2 13.5 14.9</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>TER 0.776 0.773 0.768 0.774 0.775 0.772 0.774</text>
                  <doc_id>109</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>sorted by the final score of the feature vectors making up each hypothesis.</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We used Z-MERT (Zaidan, 2009) to optimise the set of feature weights on the &#8220;newstest2011&#8221; development set.</text>
                  <doc_id>111</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Evaluation</title>
        <text>Using the &#8220;newstest2012&#8221; test set, we created baseline translations for the four MT systems used in our hybrid system. Then we performed three runs of our hybrid system:
a) a baseline run, using the factors and uniformly distributed weights;
b) a run using the weights trained on the development set;
c) a run using the decision tree learned from annotated data.
Table 2 shows the results for automatic metrics&#8217; scores. Besides BLEU (Papineni et al., 2001), we also report its case-sensitive variant, BLEU-cased, and TER (Snover et al., 2006) scores.
Comparing the scores, we see that both advanced hybrid methods perform better than the original, baseline hybrid as well as the Lucy baseline system. The MERT approach performs slightly better than the decision tree. This proves that using machinelearning to adapt the substitution approach results in better translation quality.
Other baseline systems, however, still outperform the hybrid systems. In part this is due to the fact that we are preserving the basic structure of the RBMT translation and do not reorder the new hybrid translation. To improve the hybrid approach further, there is more research required.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Using the &#8220;newstest2012&#8221; test set, we created baseline translations for the four MT systems used in our hybrid system.</text>
              <doc_id>112</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Then we performed three runs of our hybrid system:</text>
              <doc_id>113</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>a) a baseline run, using the factors and uniformly distributed weights;</text>
              <doc_id>114</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>b) a run using the weights trained on the development set;</text>
              <doc_id>115</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>c) a run using the decision tree learned from annotated data.</text>
              <doc_id>116</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Table 2 shows the results for automatic metrics&#8217; scores.</text>
              <doc_id>117</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Besides BLEU (Papineni et al., 2001), we also report its case-sensitive variant, BLEU-cased, and TER (Snover et al., 2006) scores.</text>
              <doc_id>118</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Comparing the scores, we see that both advanced hybrid methods perform better than the original, baseline hybrid as well as the Lucy baseline system.</text>
              <doc_id>119</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The MERT approach performs slightly better than the decision tree.</text>
              <doc_id>120</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This proves that using machinelearning to adapt the substitution approach results in better translation quality.</text>
              <doc_id>121</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Other baseline systems, however, still outperform the hybrid systems.</text>
              <doc_id>122</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In part this is due to the fact that we are preserving the basic structure of the RBMT translation and do not reorder the new hybrid translation.</text>
              <doc_id>123</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>To improve the hybrid approach further, there is more research required.</text>
              <doc_id>124</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>4</index>
        <title>4 Conclusion and Outlook</title>
        <text>In this paper, we have described how machinelearning approaches can be used to improve the phrase substitution component of a hybrid machine translation system. We reported on two different approaches, the first using a binary classifier learned from annotated data, and the second using feature weights tuned with MERT. Both systems achieved improved automatic metrics&#8217; scores on the WMT12 &#8220;newstest2012&#8221; test set for the language pair English&#8594;German. Future work will have to investigate ways how to achieve a closer integration of the individual baseline translations. This might be done by also taking into account reordering of the linguistic phrases as shown in the tree structures. We will also need to examine the differences between the classifier and MERT approach, to see whether we can integrate them to improve the selection process even further. Also, we have to further evaluate the machine learning performance via, e.g., cross-validationbased tuning, to improve the prediction rate of the classifier model. We intend to explore other machine learning techniques such as SVMs as well.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this paper, we have described how machinelearning approaches can be used to improve the phrase substitution component of a hybrid machine translation system.</text>
              <doc_id>125</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We reported on two different approaches, the first using a binary classifier learned from annotated data, and the second using feature weights tuned with MERT.</text>
              <doc_id>126</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Both systems achieved improved automatic metrics&#8217; scores on the WMT12 &#8220;newstest2012&#8221; test set for the language pair English&#8594;German.</text>
              <doc_id>127</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Future work will have to investigate ways how to achieve a closer integration of the individual baseline translations.</text>
              <doc_id>128</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>This might be done by also taking into account reordering of the linguistic phrases as shown in the tree structures.</text>
              <doc_id>129</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We will also need to examine the differences between the classifier and MERT approach, to see whether we can integrate them to improve the selection process even further.</text>
              <doc_id>130</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Also, we have to further evaluate the machine learning performance via, e.g., cross-validationbased tuning, to improve the prediction rate of the classifier model.</text>
              <doc_id>131</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>We intend to explore other machine learning techniques such as SVMs as well.</text>
              <doc_id>132</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>5</index>
        <title>Acknowledgments</title>
        <text>This work has been funded under the Seventh Framework Programme for Research and Technological Development of the European Commission through the T4ME contract (grant agreement no.: 249119). It was also supported by the EuroMatrix- Plus project (IST-231720). We are grateful to the anonymous reviewers for their valuable feedback. Special thanks go to Herv&#233; Saint-Amand for help with fixing the automated metrics scores.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This work has been funded under the Seventh Framework Programme for Research and Technological Development of the European Commission through the T4ME contract (grant agreement no.</text>
              <doc_id>133</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>: 249119).</text>
              <doc_id>134</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>It was also supported by the EuroMatrix- Plus project (IST-231720).</text>
              <doc_id>135</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We are grateful to the anonymous reviewers for their valuable feedback.</text>
              <doc_id>136</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Special thanks go to Herv&#233; Saint-Amand for help with fixing the automated metrics scores.</text>
              <doc_id>137</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TableSeer</source>
        <caption>Table 1: Training data set characteristics</caption>
        <reference_text>In PAGE 3: ... We used Appraise (Federmann, 2010) for the annotation, and collected a set of 24,996 labeled training instances with the help of six human annotators.  Table1  gives an overview of the data sets characteristics. The decision tree learned from this data replaces the hand-crafted rules....</reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>None</cell>
              <cell>Translation Candidates  Total</cell>
              <cell>Translation Candidates    good</cell>
              <cell>Translation Candidates     bad</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Count</cell>
              <cell>24,996</cell>
              <cell>10,666</cell>
              <cell>14,330</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Vera Aleksic</author>
          <author>Gregor Thurmair</author>
        </authors>
        <title>Personal Translator at WMT</title>
        <publication>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</publication>
        <pages>303--308</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Juan A Alonso</author>
          <author>Gregor Thurmair</author>
        </authors>
        <title>The Comprendium Translator System.</title>
        <publication>In Proceedings of the Ninth Machine Translation Summit.</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Lo&#239;c Barrault</author>
        </authors>
        <title>MANY : Open Source Machine Translation System Combination.</title>
        <publication>Prague Bulletin of Mathematical Linguistics, Special Issue on Open Source Tools for Machine Translation,</publication>
        <pages>93--147</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>L Breiman</author>
          <author>J Friedman</author>
          <author>R Olshen</author>
          <author>C Stone</author>
        </authors>
        <title>Classification and Regression Trees. Wadsworth and Brooks,</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1984</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Christian Federmann</author>
          <author>Sabine Hunsicker</author>
        </authors>
        <title>Stochastic parse tree selection for an existing rbmt system.</title>
        <publication>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</publication>
        <pages>351--357</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Christian Federmann</author>
          <author>Andreas Eisele</author>
          <author>Yu Chen</author>
          <author>Sabine Hunsicker</author>
          <author>Jia Xu</author>
          <author>Hans Uszkoreit</author>
        </authors>
        <title>Further experiments with shallow hybrid mt systems.</title>
        <publication>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</publication>
        <pages>77--81</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Christian Federmann</author>
        </authors>
        <title>Appraise: An Open-Source Toolkit for Manual Phrase-Based Evaluation of Translations. In</title>
        <publication>Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&#8217;10),</publication>
        <pages>None</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Hieu Hoang</author>
          <author>Alexandra Birch</author>
          <author>Chris Callison-Burch</author>
          <author>Marcello Federico</author>
          <author>Nicola Bertoldi</author>
          <author>Brooke Cowan</author>
          <author>Wade Shen</author>
        </authors>
        <title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
        <publication>In Proceedings of ACL Demo and Poster Sessions,</publication>
        <pages>177--180</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Philipp Koehn</author>
        </authors>
        <title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
        <publication>In Proceedings of the MT</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Zhifei Li</author>
          <author>Chris Callison-Burch</author>
          <author>Chris Dyer</author>
          <author>Sanjeev Khudanpur</author>
          <author>Lane Schwartz</author>
          <author>Wren Thornton</author>
          <author>Jonathan Weese</author>
          <author>Omar Zaidan</author>
        </authors>
        <title>Joshua: An Open Source Toolkit for Parsing-Based Machine Translation.</title>
        <publication>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</publication>
        <pages>135--139</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Evgeny Matusov</author>
          <author>Nicola Ueffing</author>
          <author>Hermann Ney</author>
        </authors>
        <title>Computing Consensus Translation from Multiple Machine Translation Systems Using Enhanced Hypotheses Alignment.</title>
        <publication>In Conference of the European Chapter of the Association for Computational Linguistics,</publication>
        <pages>33--40</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Franz Josef Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>A Systematic Comparison of Various Statistical Alignment Models.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Kishore Papineni</author>
          <author>Salim Roukos</author>
          <author>Todd Ward</author>
          <author>WeiJing Zhu</author>
        </authors>
        <title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>F Rosenblatt</author>
        </authors>
        <title>The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain. Psychological Review,</title>
        <publication>None</publication>
        <pages>65--386</pages>
        <date>1958</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Helmut Schmid</author>
        </authors>
        <title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
        <publication>In Proceedings of the International Conference on New Methods in Language Processing,</publication>
        <pages>None</pages>
        <date>1994</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>Toby Segaran</author>
        </authors>
        <title>Programming Collective Intelligence: Building Smart Web 2.0 Applications.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Matthew Snover</author>
          <author>Bonnie Dorr</author>
          <author>Richard Schwartz</author>
          <author>Linnea Micciulla</author>
          <author>John Makhoul</author>
        </authors>
        <title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
        <publication>In Proceedings of the Conference of the Association for Machine Translation in the Americas,</publication>
        <pages>223--231</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Matthew Snover</author>
          <author>Nitin Madnani</author>
          <author>Bonnie Dorr</author>
          <author>Richard Schwartz</author>
        </authors>
        <title>Fluency, Adequacy, or HTER? Exploring Different Human Judgments with a Tunable MT Metric.</title>
        <publication>In Proceedings of the Fourth Workshop on Statistical Machine Translation at the 12th Meeting of the European Chapter of the Association for Computational Linguistics (EACL-2009),</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Andreas Stolcke</author>
        </authors>
        <title>SRILM - An Extensible Language Modeling Toolkit.</title>
        <publication>In Proceedings of the International Conference on Spoken Language Processing,</publication>
        <pages>257--286</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>V N Vapnik</author>
        </authors>
        <title>The Nature of Statistical Learning Theory.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1995</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Aleksic and Thurmair, 2011</string>
        <sentence_id>51298</sentence_id>
        <char_offset>30</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Alonso and Thurmair, 2003</string>
        <sentence_id>51297</sentence_id>
        <char_offset>54</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>2</reference_id>
        <string>Barrault, 2010</string>
        <sentence_id>51254</sentence_id>
        <char_offset>78</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>Breiman et al., 1984</string>
        <sentence_id>51273</sentence_id>
        <char_offset>78</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>4</reference_id>
        <string>Federmann and Hunsicker (2011)</string>
        <sentence_id>51199</sentence_id>
        <char_offset>28</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>5</reference_id>
        <string>Federmann et al. (2010)</string>
        <sentence_id>51199</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>6</reference_id>
        <string>Federmann, 2010</string>
        <sentence_id>51276</sentence_id>
        <char_offset>18</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>7</reference_id>
        <string>Koehn et al., 2007</string>
        <sentence_id>51299</sentence_id>
        <char_offset>10</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>8</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>51238</sentence_id>
        <char_offset>89</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>9</reference_id>
        <string>Li et al., 2009</string>
        <sentence_id>51300</sentence_id>
        <char_offset>11</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>11</reference_id>
        <string>Och and Ney, 2003</string>
        <sentence_id>51258</sentence_id>
        <char_offset>125</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>12</reference_id>
        <string>Papineni et al., 2001</string>
        <sentence_id>51309</sentence_id>
        <char_offset>14</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>13</reference_id>
        <string>Rosenblatt, 1958</string>
        <sentence_id>51273</sentence_id>
        <char_offset>160</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>14</reference_id>
        <string>Schmid, 1994</string>
        <sentence_id>51239</sentence_id>
        <char_offset>26</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>16</reference_id>
        <string>Snover et al., 2006</string>
        <sentence_id>51309</sentence_id>
        <char_offset>102</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>17</reference_id>
        <string>Snover et al., 2009</string>
        <sentence_id>51255</sentence_id>
        <char_offset>45</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>18</reference_id>
        <string>Stolcke, 2002</string>
        <sentence_id>51238</sentence_id>
        <char_offset>56</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>19</reference_id>
        <string>Vapnik, 1995</string>
        <sentence_id>51273</sentence_id>
        <char_offset>126</char_offset>
      </citation>
    </citations>
  </content>
</document>
