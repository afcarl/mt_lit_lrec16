<document>
  <filename>W09-2904</filename>
  <authors>
    <author>Sina Zarrie&#223;</author>
  </authors>
  <title>Exploiting Translational Correspondences for Pattern-Independent MWE Identification</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>Based on a study of verb translations in the Europarl corpus, we argue that a wide range of MWE patterns can be identified in translations that exhibit a correspondence between a single lexical item in the source language and a group of lexical items in the target language. We show that these correspondences can be reliably detected on dependency-parsed, word-aligned sentences. We propose an extraction method that combines word alignment with syntactic filters and is independent of the structural pattern of the translation.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Based on a study of verb translations in the Europarl corpus, we argue that a wide range of MWE patterns can be identified in translations that exhibit a correspondence between a single lexical item in the source language and a group of lexical items in the target language.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We show that these correspondences can be reliably detected on dependency-parsed, word-aligned sentences.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We propose an extraction method that combines word alignment with syntactic filters and is independent of the structural pattern of the translation.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>Parallel corpora have proved to be a valuable resource not only for statistical machine translation, but also for crosslingual induction of morphological, syntactic and semantic analyses (Yarowsky et al., 2001; Dyvik, 2004). In this paper, we propose an approach to the identification of multiword expressions (MWEs) that exploits translational correspondences in a parallel corpus. We will consider in translations of the following type:
(1) Der Rat sollte unsere Position ber&#252;cksichtigen. The Council should our position consider.
(2) The Council should take account of our position.
This sentence pair has been taken from the German - English section of the Europarl corpus (Koehn, 2005). It exemplifies a translational correspondence between an English MWE take account of and a German simplex verb ber&#252;cksichtigen. In the following, we refer to such correspondences as one-to-many translations. Based on a study of verb translations in Europarl, we will explore to what extent one-to-many translations provide evidence for MWE realization in the target language. It will turn out that crosslingual correspondences realize a wide range of different linguistic patterns that are relevant for MWE identification, but that they pose problems to automatic word alignment. We propose an extraction method that combines distributional word alignment with syntactic filters. We will show that these correspondences can be reliably detected on dependency-parsed, wordaligned sentences and are able to identify various MWE patterns.
In a monolingual setting, the task of MWE extraction is usually conceived of as a lexical association problem where distributional measures model the syntactic and semantic idiosyncracy exhibited by MWEs, e.g. (Pecina, 2008). This approach generally involves two main steps: 1) the extraction of a candidate list of potential MWEs, often constrained by a particular target pattern of the detection method, like verb particle constructions (Baldwin and Villavicencio, 2002) or verb PP combinations (Villada Moir&#243;n and Tiedemann, 2006), 2) the ranking of this candidate list by an appropriate assocation measure.
The crosslingual MWE identification we present in this paper is, a priori, independent of any specific association measure or syntactic pattern. The translation scenario allows us to adopt a completely data-driven definition of what constitutes an MWE: Given a parallel corpus, we propose to consider those tokens in a target language as MWEs which correspond to a single lexical item in the source language. The intuition is that if a group of lexical items in one language can be realized as a single item in another language, it can be considered as some kind of lexically fixed entity. By this means, we will not approach the MWE identification problem by asking for a given list of candidates whether these are MWEs or not. Instead, we will ask for a given list of lexical items in a source language whether there exists a one-to-many translation for this item in a target language (and whether these
one-to-many translations correspond to MWEs). This strategy offers a straightforward solution to the interpretation problem: As the translation can be related to the meaning of the source item and to its other translations in the target language, the interpretation is independent of the expression&#8217;s transparency. This solution has its limitations compared to other approaches that need to automatically establish the degree of compositionality of a given MWE candidate. However, for many NLP applications, coarse-grained knowledge about the semantic relation between a wide range of MWEs and their corresponding atomic realization is already very useful.
In this work, we therefore focus on a general method of MWE identification that captures the various patterns of translational correspondences that can be found in parallel corpora. Our experiments described in section 3 show that one-tomany translations should be extracted from syntactic configurations rather than from unstructured sets of aligned words. This syntax-driven method is less dependent on frequency distributions in a given corpus, but is based on the intuition that monolingual idiosyncracies like MWE realization of an entity are not likely to be mirrored in another language (see section 4 for discussion).
Our goal in this paper is twofold: First, we want to investigate to what extent one-to-many translational correspondences can serve as an empirical basis for MWE identification. To this end, Section 2 presents a corpus-based study of the relation between one-to-many translations and MWEs that we carried out on a translation gold standard. Second, we investigate methods for the automatic detection of complex lexical correspondences for a given parallel corpus. Therefore, Section 3 evaluates automatic word alignments against our gold standard and gives a method for high-precision one-to-many translation detection that relies on syntactic filters, in addition to word-alignments.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Parallel corpora have proved to be a valuable resource not only for statistical machine translation, but also for crosslingual induction of morphological, syntactic and semantic analyses (Yarowsky et al., 2001; Dyvik, 2004).</text>
              <doc_id>3</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In this paper, we propose an approach to the identification of multiword expressions (MWEs) that exploits translational correspondences in a parallel corpus.</text>
              <doc_id>4</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We will consider in translations of the following type:</text>
              <doc_id>5</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(1) Der Rat sollte unsere Position ber&#252;cksichtigen.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The Council should our position consider.</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(2) The Council should take account of our position.</text>
              <doc_id>8</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This sentence pair has been taken from the German - English section of the Europarl corpus (Koehn, 2005).</text>
              <doc_id>9</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It exemplifies a translational correspondence between an English MWE take account of and a German simplex verb ber&#252;cksichtigen.</text>
              <doc_id>10</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In the following, we refer to such correspondences as one-to-many translations.</text>
              <doc_id>11</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Based on a study of verb translations in Europarl, we will explore to what extent one-to-many translations provide evidence for MWE realization in the target language.</text>
              <doc_id>12</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>It will turn out that crosslingual correspondences realize a wide range of different linguistic patterns that are relevant for MWE identification, but that they pose problems to automatic word alignment.</text>
              <doc_id>13</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We propose an extraction method that combines distributional word alignment with syntactic filters.</text>
              <doc_id>14</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>We will show that these correspondences can be reliably detected on dependency-parsed, wordaligned sentences and are able to identify various MWE patterns.</text>
              <doc_id>15</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In a monolingual setting, the task of MWE extraction is usually conceived of as a lexical association problem where distributional measures model the syntactic and semantic idiosyncracy exhibited by MWEs, e.g. (Pecina, 2008).</text>
              <doc_id>16</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This approach generally involves two main steps: 1) the extraction of a candidate list of potential MWEs, often constrained by a particular target pattern of the detection method, like verb particle constructions (Baldwin and Villavicencio, 2002) or verb PP combinations (Villada Moir&#243;n and Tiedemann, 2006), 2) the ranking of this candidate list by an appropriate assocation measure.</text>
              <doc_id>17</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The crosslingual MWE identification we present in this paper is, a priori, independent of any specific association measure or syntactic pattern.</text>
              <doc_id>18</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The translation scenario allows us to adopt a completely data-driven definition of what constitutes an MWE: Given a parallel corpus, we propose to consider those tokens in a target language as MWEs which correspond to a single lexical item in the source language.</text>
              <doc_id>19</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The intuition is that if a group of lexical items in one language can be realized as a single item in another language, it can be considered as some kind of lexically fixed entity.</text>
              <doc_id>20</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>By this means, we will not approach the MWE identification problem by asking for a given list of candidates whether these are MWEs or not.</text>
              <doc_id>21</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Instead, we will ask for a given list of lexical items in a source language whether there exists a one-to-many translation for this item in a target language (and whether these</text>
              <doc_id>22</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>one-to-many translations correspond to MWEs).</text>
              <doc_id>23</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This strategy offers a straightforward solution to the interpretation problem: As the translation can be related to the meaning of the source item and to its other translations in the target language, the interpretation is independent of the expression&#8217;s transparency.</text>
              <doc_id>24</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This solution has its limitations compared to other approaches that need to automatically establish the degree of compositionality of a given MWE candidate.</text>
              <doc_id>25</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>However, for many NLP applications, coarse-grained knowledge about the semantic relation between a wide range of MWEs and their corresponding atomic realization is already very useful.</text>
              <doc_id>26</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In this work, we therefore focus on a general method of MWE identification that captures the various patterns of translational correspondences that can be found in parallel corpora.</text>
              <doc_id>27</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our experiments described in section 3 show that one-tomany translations should be extracted from syntactic configurations rather than from unstructured sets of aligned words.</text>
              <doc_id>28</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This syntax-driven method is less dependent on frequency distributions in a given corpus, but is based on the intuition that monolingual idiosyncracies like MWE realization of an entity are not likely to be mirrored in another language (see section 4 for discussion).</text>
              <doc_id>29</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our goal in this paper is twofold: First, we want to investigate to what extent one-to-many translational correspondences can serve as an empirical basis for MWE identification.</text>
              <doc_id>30</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>To this end, Section 2 presents a corpus-based study of the relation between one-to-many translations and MWEs that we carried out on a translation gold standard.</text>
              <doc_id>31</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Second, we investigate methods for the automatic detection of complex lexical correspondences for a given parallel corpus.</text>
              <doc_id>32</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Therefore, Section 3 evaluates automatic word alignments against our gold standard and gives a method for high-precision one-to-many translation detection that relies on syntactic filters, in addition to word-alignments.</text>
              <doc_id>33</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Multiword Translations as MWEs</title>
        <text>The idea to exploit one-to-many translations for the identification of MWE candidates has not received much attention in the literature. Thus, it is not a priori clear what can be expected from translational correspondences with respect to MWE identification. To corroborate the intuitions introduced in the last section, we carried out a corpusbased study that aims to discover linguistic pat-
Verb 1-1 1-n n-1 n-n N o
anheben (v 1) 53.5 21.2 9.2 16 325
bezwecken (v 2) 16.7 51.3 0.6 31.3 150
riskieren (v 3) 46.7 35.7 0.5 17 182
verschlimmern (v 4) 30.2 21.5 28.6 44.5 275
terns exhibited by one-to-many translations.
We constructed a gold standard covering all English translations of four German verb lemmas extracted from the Europarl Corpus. These verbs subcategorize for a nominative subject and an accusative object and are in the middle frequency layer (around 200 occurrences). We extracted all sentences in Europarl with occurences of these lemmas and their automatic word alignments produced by GIZA++ (Och and Ney, 2003). These alignments were manually corrected on the basis of the crosslingual word alignment guidelines developped by (Gra&#231;a et al., 2008). For each of the German source lemmas, our gold standard records four translation categories: one-to-one, one-to-many, many-to-one, many-tomany translations. Table 1 shows the distribution of these categories for each verb. Strikingly, the four verbs show very different proportions concerning the types of their translational correspondences. Thus, while the German verb anheben (en. increase) seems to have a frequent parallel realization, the verbs bezwecken (en. intend to) or verschlimmern (en. aggravate) tend to be realized by more complex phrasal translations. In any case, the percentage of one-to-many translations is relatively high which corroborates our hypothesis that parallel corpora constitute a very interesting resource for data-driven MWE discovery.
A closer look at the one-to-many translations reveals that these cover a wide spectrum of MWE phenomena traditionally considered in the literature, as well as constructions that one would usually not regard as an MWE. Below, we will shortly illustrate the different classes of one-tomany translations we found in our gold standard.
Morphological variations: This type of one-tomany translations is mainly due to non-parallel realization of tense. It&#8217;s rather irrelevant from an MWE perspective, but easy to discover and filter automatically.
(3) Sie verschlimmern die &#220;bel. They aggravate the misfortunes.
(4) Their action is aggravating the misfortunes.
Verb particle combinations: A typical MWE pattern, treated for instance in (Baldwin and Villavicencio, 2002). It further divides into transparent and non-transparent combinations, the latter is illustrated below.
(5) Der Ausschuss bezweckt, den Institutionen ein The committe intends, the institutions a politisches Instrument an die Hand zu geben. political instrument at the hand to give.
(6) The committee set out to equip the institutions with a political instrument.
Verb preposition combinations: While this class isn&#8217;t discussed very often in the MWE literature, it can nevertheless be considered as an idiosyncratic combination of lexical items. Sag et al (2002) propose an analysis within an MWE framework.
(7) Sie werden den Treibhauseffekt verschlimmern. They will the green house effect aggravate.
(8) They will add to the green house effect.
Light verb constructions (LVCs): This is the most frequent pattern in our gold standard. It actually subsumes various subpatterns depending on whether the light verbs complement is realized as a noun, adjective or PP. Generally, LVCs are syntactically and semantically more flexible than other MWE types, such that our gold standard contains variants of LVCs with similar, potentially modified adjectives or nouns, as in the example below. However, it can be considered an idiosyncratic combination since the LVCs exhibit specific lexical restrictions (Sag et al., 2002).
(9) Ich werde die Sache nur noch verschlimmern. Ich will the thing only just aggravate.
(10) I am just making things more difficult.
Idioms: This MWE type is probably the most discussed in the literature due to its semantic and syntactic idiosyncracy. It&#8217;s not very frequent in our gold standard which may be mainly due to its limited size and the source items we chose.
(12) They have in mind the conversion into a civil nation.
v 1 v 2 v 3 v 4
N type 22 (26) 41 (47) 26 (35) 17 (24)
V Part 22.7 4.9 0.0 0.0
V Prep 36.4 41.5 3.9 5.9
LVC 18.2 29.3 88.5 88.2
Idiom 0.0 2.4 0.0 0.0
Para 36.4 24.3 11.5 23.5
Paraphrases: From an MWE perspective, paraphrases are the most problematic and challenging type of translational correspondence in our gold standard. While the MWE literature typically discusses the distinction between collocations and MWEs, the boarderline between paraphrases and MWEs is not really clear. On the hand, paraphrases, as we classified them here, are transparent combinations of lexical items, like in the example below ensure that something increases. However, semantically, these transparent combinations can also be rendered by an atomic expression increase. A further problem raised by paraphrases is that they often involve translational shifts (Cyrus, 2006). These shifts are hard to identify automatically and present a general challenge for semantic processing of parallel corpora. An example is given below.
(13) Wir brauchen bessere Zusammenarbeit, um die We need better cooperation to the R&#252;ckzahlungen anzuheben . repayments.OBJ increase.
(14) We need greater cooperation in this respect to ensure that repayments increase .
Table 2 displays the proportions of the MWE categories for the number of types of one-to-many correspondences in our gold standard. We filtered the types due to morphological variations only (the overall number of types is indicated in brackets). Note that some types in our gold standard fall into several categories, e.g. they combine a verb preposition with a verb particle construction. For all of the verbs, the number of types belonging to core MWE categories largely outweighs the proportion of paraphrases. As we already observed in our analysis of general translation categories, here again, the different verb lemmas show striking differences with respect to their realization in English translations. For instance, anheben (en. increase) or bezwecken (en. intend) are frequently
translated with verb particle or preposition combinations, while the other verbs are much more often translated by means of LVCs. Also, the more specific LVC patterns differ largely among the verbs. While verschlimmern (en. aggravate) has many different adjectival LVC correspondences, the translations of riskieren (en. risk) are predominantly nominal LVCs. The fact that we found very few idioms in our gold standard may be simply related to our arbitrary choice of German source verbs that do not have an English idiom realization (see our experiment on a random set of verbs in Section 3.3).
In general, one-to-many translational correspondences seem to provide a very fruitful ground for the large-scale study of MWE phenomena. However, their reliable detection in parallel corpora is far from trivial, as we will show in the next section. Therefore, we will not further investigate the classification of MWE patterns in the rest of the paper, but concentrate on the highprecision detection of one-to-many translations. Such a pattern-independent identification method is crucial for the further data-driven study of oneto-many translations in parallel corpora.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The idea to exploit one-to-many translations for the identification of MWE candidates has not received much attention in the literature.</text>
              <doc_id>34</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Thus, it is not a priori clear what can be expected from translational correspondences with respect to MWE identification.</text>
              <doc_id>35</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>To corroborate the intuitions introduced in the last section, we carried out a corpusbased study that aims to discover linguistic pat-</text>
              <doc_id>36</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Verb 1-1 1-n n-1 n-n N o</text>
              <doc_id>37</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>anheben (v 1) 53.5 21.2 9.2 16 325</text>
              <doc_id>38</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>bezwecken (v 2) 16.7 51.3 0.6 31.3 150</text>
              <doc_id>39</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>riskieren (v 3) 46.7 35.7 0.5 17 182</text>
              <doc_id>40</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>verschlimmern (v 4) 30.2 21.5 28.6 44.5 275</text>
              <doc_id>41</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>terns exhibited by one-to-many translations.</text>
              <doc_id>42</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We constructed a gold standard covering all English translations of four German verb lemmas extracted from the Europarl Corpus.</text>
              <doc_id>43</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>These verbs subcategorize for a nominative subject and an accusative object and are in the middle frequency layer (around 200 occurrences).</text>
              <doc_id>44</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We extracted all sentences in Europarl with occurences of these lemmas and their automatic word alignments produced by GIZA++ (Och and Ney, 2003).</text>
              <doc_id>45</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>These alignments were manually corrected on the basis of the crosslingual word alignment guidelines developped by (Gra&#231;a et al., 2008).</text>
              <doc_id>46</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>For each of the German source lemmas, our gold standard records four translation categories: one-to-one, one-to-many, many-to-one, many-tomany translations.</text>
              <doc_id>47</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Table 1 shows the distribution of these categories for each verb.</text>
              <doc_id>48</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Strikingly, the four verbs show very different proportions concerning the types of their translational correspondences.</text>
              <doc_id>49</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Thus, while the German verb anheben (en.</text>
              <doc_id>50</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>increase) seems to have a frequent parallel realization, the verbs bezwecken (en.</text>
              <doc_id>51</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>intend to) or verschlimmern (en.</text>
              <doc_id>52</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>aggravate) tend to be realized by more complex phrasal translations.</text>
              <doc_id>53</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>In any case, the percentage of one-to-many translations is relatively high which corroborates our hypothesis that parallel corpora constitute a very interesting resource for data-driven MWE discovery.</text>
              <doc_id>54</doc_id>
              <sec_id>11</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>A closer look at the one-to-many translations reveals that these cover a wide spectrum of MWE phenomena traditionally considered in the literature, as well as constructions that one would usually not regard as an MWE.</text>
              <doc_id>55</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Below, we will shortly illustrate the different classes of one-tomany translations we found in our gold standard.</text>
              <doc_id>56</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Morphological variations: This type of one-tomany translations is mainly due to non-parallel realization of tense.</text>
              <doc_id>57</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It&#8217;s rather irrelevant from an MWE perspective, but easy to discover and filter automatically.</text>
              <doc_id>58</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(3) Sie verschlimmern die &#220;bel.</text>
              <doc_id>59</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>They aggravate the misfortunes.</text>
              <doc_id>60</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(4) Their action is aggravating the misfortunes.</text>
              <doc_id>61</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Verb particle combinations: A typical MWE pattern, treated for instance in (Baldwin and Villavicencio, 2002).</text>
              <doc_id>62</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It further divides into transparent and non-transparent combinations, the latter is illustrated below.</text>
              <doc_id>63</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(5) Der Ausschuss bezweckt, den Institutionen ein The committe intends, the institutions a politisches Instrument an die Hand zu geben.</text>
              <doc_id>64</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>political instrument at the hand to give.</text>
              <doc_id>65</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(6) The committee set out to equip the institutions with a political instrument.</text>
              <doc_id>66</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Verb preposition combinations: While this class isn&#8217;t discussed very often in the MWE literature, it can nevertheless be considered as an idiosyncratic combination of lexical items.</text>
              <doc_id>67</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Sag et al (2002) propose an analysis within an MWE framework.</text>
              <doc_id>68</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(7) Sie werden den Treibhauseffekt verschlimmern.</text>
              <doc_id>69</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>They will the green house effect aggravate.</text>
              <doc_id>70</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(8) They will add to the green house effect.</text>
              <doc_id>71</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Light verb constructions (LVCs): This is the most frequent pattern in our gold standard.</text>
              <doc_id>72</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It actually subsumes various subpatterns depending on whether the light verbs complement is realized as a noun, adjective or PP.</text>
              <doc_id>73</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Generally, LVCs are syntactically and semantically more flexible than other MWE types, such that our gold standard contains variants of LVCs with similar, potentially modified adjectives or nouns, as in the example below.</text>
              <doc_id>74</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>However, it can be considered an idiosyncratic combination since the LVCs exhibit specific lexical restrictions (Sag et al., 2002).</text>
              <doc_id>75</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(9) Ich werde die Sache nur noch verschlimmern.</text>
              <doc_id>76</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Ich will the thing only just aggravate.</text>
              <doc_id>77</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(10) I am just making things more difficult.</text>
              <doc_id>78</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Idioms: This MWE type is probably the most discussed in the literature due to its semantic and syntactic idiosyncracy.</text>
              <doc_id>79</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It&#8217;s not very frequent in our gold standard which may be mainly due to its limited size and the source items we chose.</text>
              <doc_id>80</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(12) They have in mind the conversion into a civil nation.</text>
              <doc_id>81</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>v 1 v 2 v 3 v 4</text>
              <doc_id>82</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>N type 22 (26) 41 (47) 26 (35) 17 (24)</text>
              <doc_id>83</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>V Part 22.7 4.9 0.0 0.0</text>
              <doc_id>84</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>V Prep 36.4 41.5 3.9 5.9</text>
              <doc_id>85</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>LVC 18.2 29.3 88.5 88.2</text>
              <doc_id>86</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Idiom 0.0 2.4 0.0 0.0</text>
              <doc_id>87</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Para 36.4 24.3 11.5 23.5</text>
              <doc_id>88</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Paraphrases: From an MWE perspective, paraphrases are the most problematic and challenging type of translational correspondence in our gold standard.</text>
              <doc_id>89</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>While the MWE literature typically discusses the distinction between collocations and MWEs, the boarderline between paraphrases and MWEs is not really clear.</text>
              <doc_id>90</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>On the hand, paraphrases, as we classified them here, are transparent combinations of lexical items, like in the example below ensure that something increases.</text>
              <doc_id>91</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>However, semantically, these transparent combinations can also be rendered by an atomic expression increase.</text>
              <doc_id>92</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>A further problem raised by paraphrases is that they often involve translational shifts (Cyrus, 2006).</text>
              <doc_id>93</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>These shifts are hard to identify automatically and present a general challenge for semantic processing of parallel corpora.</text>
              <doc_id>94</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>An example is given below.</text>
              <doc_id>95</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(13) Wir brauchen bessere Zusammenarbeit, um die We need better cooperation to the R&#252;ckzahlungen anzuheben .</text>
              <doc_id>96</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>repayments.OBJ increase.</text>
              <doc_id>97</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(14) We need greater cooperation in this respect to ensure that repayments increase .</text>
              <doc_id>98</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Table 2 displays the proportions of the MWE categories for the number of types of one-to-many correspondences in our gold standard.</text>
              <doc_id>99</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We filtered the types due to morphological variations only (the overall number of types is indicated in brackets).</text>
              <doc_id>100</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Note that some types in our gold standard fall into several categories, e.g. they combine a verb preposition with a verb particle construction.</text>
              <doc_id>101</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>For all of the verbs, the number of types belonging to core MWE categories largely outweighs the proportion of paraphrases.</text>
              <doc_id>102</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>As we already observed in our analysis of general translation categories, here again, the different verb lemmas show striking differences with respect to their realization in English translations.</text>
              <doc_id>103</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>For instance, anheben (en.</text>
              <doc_id>104</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>increase) or bezwecken (en.</text>
              <doc_id>105</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>intend) are frequently</text>
              <doc_id>106</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>translated with verb particle or preposition combinations, while the other verbs are much more often translated by means of LVCs.</text>
              <doc_id>107</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Also, the more specific LVC patterns differ largely among the verbs.</text>
              <doc_id>108</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>While verschlimmern (en.</text>
              <doc_id>109</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>aggravate) has many different adjectival LVC correspondences, the translations of riskieren (en.</text>
              <doc_id>110</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>risk) are predominantly nominal LVCs.</text>
              <doc_id>111</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>The fact that we found very few idioms in our gold standard may be simply related to our arbitrary choice of German source verbs that do not have an English idiom realization (see our experiment on a random set of verbs in Section 3.3).</text>
              <doc_id>112</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In general, one-to-many translational correspondences seem to provide a very fruitful ground for the large-scale study of MWE phenomena.</text>
              <doc_id>113</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>However, their reliable detection in parallel corpora is far from trivial, as we will show in the next section.</text>
              <doc_id>114</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Therefore, we will not further investigate the classification of MWE patterns in the rest of the paper, but concentrate on the highprecision detection of one-to-many translations.</text>
              <doc_id>115</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Such a pattern-independent identification method is crucial for the further data-driven study of oneto-many translations in parallel corpora.</text>
              <doc_id>116</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>3</index>
        <title>3 Multiword Translation Detection</title>
        <text>This section is devoted to the problem of highprecision detection of one-to-many translations. Section 3.1 describes an evaluation of automatic word alignments against our gold standard. In section 3.2, we describe a method that extracts loosely aligned syntactic configurations which yields much more promising results.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This section is devoted to the problem of highprecision detection of one-to-many translations.</text>
              <doc_id>117</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 3.1 describes an evaluation of automatic word alignments against our gold standard.</text>
              <doc_id>118</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In section 3.2, we describe a method that extracts loosely aligned syntactic configurations which yields much more promising results.</text>
              <doc_id>119</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 One-to-many Alignments</title>
            <text>To illustrate the problem of purely distributional one-to-many alignment, table 3 presents an evaluation of the automatic one-to-many word alignments produced by GIZA++ that uses the standard heuristics for bidirectional word alignment from phrase-based MT (Och and Ney, 2003). We evaluate the rate of translational correspondences on the type-level that the system discovers against the one-to-many translations in our gold standard. By type we mean the set of lemmatized English tokens that makes up the translation of the German source lemma. Generally, automatic word alignment yields a very high FPR if no frequency threshold is used. Increasing the threshold may help in some cases, however the frequency of the verb n &gt; 0 n &gt; 1 n &gt; 3
FPR FNR FPR FNR FPR FNR
v 1 0.97 0.93 1.0 1.0 1.0 1.0
v 2 0.93 0.9 0.5 0.96 0.0 0.98
v 3 0.88 0.83 0.8 0.97 0.67 0.97
v 4 0.98 0.92 0.8 0.92 0.34 0.92
translation types is so low, that already at a threshold of 3, almost all types get filtered. This does not mean that the automatic word alignment does not discover any correct correspondences at all, but it means that the detection of the exact set of tokens that correspond to the source token is rare. This low precision of one-to-many alignments isn&#8217;t very surprising. Many types of MWEs consist of items that contribute most of the lexical semantic content, while the other items belong to the class of semantically almost &#8220;empty&#8221; items (e.g. particles, light verbs). These semantically &#8220;light&#8221; items have a distribution that doesn&#8217;t necessarily correlate with the source item. For instance, in the following sentence pair taken from Europarl, GIZA++ was not able to capture the correspondence between the German main verb behindern (en. impede) and the LVC constitute an obstacle to, but only finds an alignment link between the verb and the noun obstacle.
(15) Die Korruption behindert die Entwicklung. The corruption impedes the development.
(16) Corruption constitutes an obstacle to development.
Another limitation of the word-alignment models is that are independent of whether the sentences are largely parallel or rather free translations. However, parallel corpora like Europarl are know to contain a very large number of free translations. In these cases, direct lexical correspondences are much more unlikely to be found.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>To illustrate the problem of purely distributional one-to-many alignment, table 3 presents an evaluation of the automatic one-to-many word alignments produced by GIZA++ that uses the standard heuristics for bidirectional word alignment from phrase-based MT (Och and Ney, 2003).</text>
                  <doc_id>120</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We evaluate the rate of translational correspondences on the type-level that the system discovers against the one-to-many translations in our gold standard.</text>
                  <doc_id>121</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>By type we mean the set of lemmatized English tokens that makes up the translation of the German source lemma.</text>
                  <doc_id>122</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Generally, automatic word alignment yields a very high FPR if no frequency threshold is used.</text>
                  <doc_id>123</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Increasing the threshold may help in some cases, however the frequency of the verb n &gt; 0 n &gt; 1 n &gt; 3</text>
                  <doc_id>124</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FPR FNR FPR FNR FPR FNR</text>
                  <doc_id>125</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>v 1 0.97 0.93 1.0 1.0 1.0 1.0</text>
                  <doc_id>126</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>v 2 0.93 0.9 0.5 0.96 0.0 0.98</text>
                  <doc_id>127</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>v 3 0.88 0.83 0.8 0.97 0.67 0.97</text>
                  <doc_id>128</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>v 4 0.98 0.92 0.8 0.92 0.34 0.92</text>
                  <doc_id>129</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>translation types is so low, that already at a threshold of 3, almost all types get filtered.</text>
                  <doc_id>130</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This does not mean that the automatic word alignment does not discover any correct correspondences at all, but it means that the detection of the exact set of tokens that correspond to the source token is rare.</text>
                  <doc_id>131</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This low precision of one-to-many alignments isn&#8217;t very surprising.</text>
                  <doc_id>132</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Many types of MWEs consist of items that contribute most of the lexical semantic content, while the other items belong to the class of semantically almost &#8220;empty&#8221; items (e.g. particles, light verbs).</text>
                  <doc_id>133</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>These semantically &#8220;light&#8221; items have a distribution that doesn&#8217;t necessarily correlate with the source item.</text>
                  <doc_id>134</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>For instance, in the following sentence pair taken from Europarl, GIZA++ was not able to capture the correspondence between the German main verb behindern (en.</text>
                  <doc_id>135</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>impede) and the LVC constitute an obstacle to, but only finds an alignment link between the verb and the noun obstacle.</text>
                  <doc_id>136</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(15) Die Korruption behindert die Entwicklung.</text>
                  <doc_id>137</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The corruption impedes the development.</text>
                  <doc_id>138</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(16) Corruption constitutes an obstacle to development.</text>
                  <doc_id>139</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Another limitation of the word-alignment models is that are independent of whether the sentences are largely parallel or rather free translations.</text>
                  <doc_id>140</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, parallel corpora like Europarl are know to contain a very large number of free translations.</text>
                  <doc_id>141</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In these cases, direct lexical correspondences are much more unlikely to be found.</text>
                  <doc_id>142</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Aligning Syntactic Configurations</title>
            <text>High-precision extraction of one-to-many translation detection thus involves two major problems: 1) How to identify sentences or configurations where reliable lexical correspondences can be found? 2) How to align target items that have a low occurrence correlation?
We argue that both of these problems can be adressed by taking syntactic information into ac-
count. As an example, consider the pair of parallel configurations in Figure 1 for the sentence pair given in (15) and (16). Although there is no strict one-to-one alignment for the German verb, the basic predicate-argument structure is parallel: The verbs arguments directly correspond to each other and are all dominated by a verbal root node.
Based on these intuitions, we propose a generate-and-filter strategy for our one-to-many translation detection which extracts partial, largely parallel dependency configurations. By admitting target dependency paths to be aligned to source single dependency relations, we admit configurations where the source item is translated by more than one word. For instance, given the configuration in Figure 1, we allow the German verb to be aligned to the path connecting constitute and the argument Y 2 .
Our one-to-many translation detection consists of the following steps: a) candidate generation of aligned syntactic configurations, b) filtering the configurations c) alignment post-editing, i.e. assembling the target tokens corresponding to the source item. The following paragraphs will briefly caracterize these steps.
X 2
an
behindert
X 1 Y 1
create
obstacle
to
Y 2
Data We word-aligned the German and English portion of the Europarl corpus by means of the GIZA++ tool. Both portions where assigned flat syntactic dependency analyses by means of the MaltParser (Nivre et al., 2006) such that we obtain a parallel resource of word-aligned dependency parses. Each sentence in our resource can be represented by the triple (D G , D E , A G,E ). D G is the set of dependency triples (s 1 , rel, s 2 ) such that s 2 is a dependent of s 1 of type rel and s 1 , s 2 are words of the source language. D E is the set of dependency triples of the target sentence. A G,E corresponds to the set of pairs (s 1 , t 1 ) such that s 1 , t 1 are aligned.
Candidate Generation This step generates a list of source configurations by searching for occurences of the source lexical verb where it is linked to some syntactic dependents (e.g. its arguments). An example input would be the configuration ( (verb,SB,%), (verb,OA,%)) for our German verbs.
Filtering Given our source candidates, a valid parallel configuration (D G , D E , A G,E ) is then defined by the following conditions: 1. The source configuration D G is the set of tuples (s 1 , rel, s n ) where s 1 is our source item and s n some dependent. 2. For each s n &#8712; D G , there is a tuple (s n , t n ) &#8712; A G,E , i.e. every dependent has an alignment. 3. There is a target item t 1 &#8712; D E such that for each t n , there is a p &#8834; D E such that p is a path (t 1 , rel, t x ), (t x , rel, t y )...(t z , rel, t n ) that connects t 1 and t n . Thus, the target dependents have a common root.
To filter noise due to parsing or alignment errors, we further introduce a filter on the length of the path that connects the target root and its dependents and w exclude paths cross contain sentence boundaries. Moreover, the above candidate filtering doesn&#8217;t exclude configurations which exhibit paraphrases involving head-switching or complex coordination. Head-switching can be detected with the help of alignment information: if there is a item in our target configuration that has an reliable alignment with an item not contained in our source configuration, our target configuration is likely to contain such a structural paraphrases and is excluded from our candidate set. Coordination can be discarded by imposing the condition on the configuration not to contain a coordination relation. This Generate-and-Filter strategy now extracts a set of sentences where we are likely to find a good one-to-one or one-to-many translation for the source verb.
Alignment Post-editing In the final alignment step, one now needs to figure out which lexical material in the aligned syntactic configurations actually corresponds to the translation of the source item. The intuition discussed in 3.2 was that all
the items lying on a path between the root item and the terminals belong to the translation of the source item. However, these items may have other syntactic dependents that may also be part of the one-to-many translation. As an example, consider the configuration in figure 1 where the article an which is part of the LVC create an obstacle to has to be aligned to the German source verb.
Thus, for a set of items t i for which there is a dependency relation (t x , rel, t i ) &#8712; D E such that t x is an element of our target configuration, we need to decide whether (s 1 , t i ) &#8712; A G,E . This translation problem now largely parallels collocation translation problems discussed in the literature, as in (Smadja and McKeown, 1994). But, crucially, our syntactic filtering strategy has substantially narrowed down the number of items that are possible parts of the one-to-many translation. Thus, a straightforward way to assemble the translational correspondence is to compute the correlation or association of the possibly missing items with the given translation pair as proposed in (Smadja and McKeown, 1994). Therefore, we propose the following alignment post-editing algorithm: Given the source item s 1 and the set of target items T , where each t i &#8712; T is an element of our target configuration,
1. Compute corr(s 1 , T), the correlation between s 1 and T .
2. For each t i , t x such that there is a (t i , rel, t x ) &#8712; D E , compute corr(s 1 , T + {t x })
3. if corr(s 1 , T + {t x }) &#8805; corr(s 1 , T), add t x to T .
As the Dice coefficient is often to give the best results, e.g. in (Smadja and McKeown, 1994), we also chose Dice as our correlation measure. In future work, we will experiment with other association measures. Our correlation scores are thus defined by the formula:
corr(s 1, T) =
2(freq(s1 &#8743; T)) freq(s 1) + freq(T)
We define freq(T) as the number of sentence pairs whose target sentence contains occurrences of all t i &#8712; T , and freq(s 1 ) accordingly. The observation frequency freq(s 1 &#8743;T) is the number of sentence pairs that where s 1 occurs in the source sentence, and T in the target sentence.
The output translation can then be represented as a dependency configuration of the following kind :((of,PMOD,%), (risk,NMOD,of),(risk,NMOD,the), (run,OBJ,risk), (run,SBJ,%)) which is the syntactic representation for the English MWE run the risk of.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>High-precision extraction of one-to-many translation detection thus involves two major problems: 1) How to identify sentences or configurations where reliable lexical correspondences can be found?</text>
                  <doc_id>143</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>2) How to align target items that have a low occurrence correlation?</text>
                  <doc_id>144</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We argue that both of these problems can be adressed by taking syntactic information into ac-</text>
                  <doc_id>145</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>count.</text>
                  <doc_id>146</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As an example, consider the pair of parallel configurations in Figure 1 for the sentence pair given in (15) and (16).</text>
                  <doc_id>147</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Although there is no strict one-to-one alignment for the German verb, the basic predicate-argument structure is parallel: The verbs arguments directly correspond to each other and are all dominated by a verbal root node.</text>
                  <doc_id>148</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Based on these intuitions, we propose a generate-and-filter strategy for our one-to-many translation detection which extracts partial, largely parallel dependency configurations.</text>
                  <doc_id>149</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>By admitting target dependency paths to be aligned to source single dependency relations, we admit configurations where the source item is translated by more than one word.</text>
                  <doc_id>150</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For instance, given the configuration in Figure 1, we allow the German verb to be aligned to the path connecting constitute and the argument Y 2 .</text>
                  <doc_id>151</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Our one-to-many translation detection consists of the following steps: a) candidate generation of aligned syntactic configurations, b) filtering the configurations c) alignment post-editing, i.e. assembling the target tokens corresponding to the source item.</text>
                  <doc_id>152</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The following paragraphs will briefly caracterize these steps.</text>
                  <doc_id>153</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>X 2</text>
                  <doc_id>154</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>an</text>
                  <doc_id>155</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>behindert</text>
                  <doc_id>156</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>X 1 Y 1</text>
                  <doc_id>157</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>create</text>
                  <doc_id>158</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>obstacle</text>
                  <doc_id>159</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>to</text>
                  <doc_id>160</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Y 2</text>
                  <doc_id>161</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Data We word-aligned the German and English portion of the Europarl corpus by means of the GIZA++ tool.</text>
                  <doc_id>162</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Both portions where assigned flat syntactic dependency analyses by means of the MaltParser (Nivre et al., 2006) such that we obtain a parallel resource of word-aligned dependency parses.</text>
                  <doc_id>163</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Each sentence in our resource can be represented by the triple (D G , D E , A G,E ).</text>
                  <doc_id>164</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>D G is the set of dependency triples (s 1 , rel, s 2 ) such that s 2 is a dependent of s 1 of type rel and s 1 , s 2 are words of the source language.</text>
                  <doc_id>165</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>D E is the set of dependency triples of the target sentence.</text>
                  <doc_id>166</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>A G,E corresponds to the set of pairs (s 1 , t 1 ) such that s 1 , t 1 are aligned.</text>
                  <doc_id>167</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Candidate Generation This step generates a list of source configurations by searching for occurences of the source lexical verb where it is linked to some syntactic dependents (e.g. its arguments).</text>
                  <doc_id>168</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>An example input would be the configuration ( (verb,SB,%), (verb,OA,%)) for our German verbs.</text>
                  <doc_id>169</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Filtering Given our source candidates, a valid parallel configuration (D G , D E , A G,E ) is then defined by the following conditions: 1.</text>
                  <doc_id>170</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The source configuration D G is the set of tuples (s 1 , rel, s n ) where s 1 is our source item and s n some dependent.</text>
                  <doc_id>171</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>2.</text>
                  <doc_id>172</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>For each s n &#8712; D G , there is a tuple (s n , t n ) &#8712; A G,E , i.e. every dependent has an alignment.</text>
                  <doc_id>173</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>3.</text>
                  <doc_id>174</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>There is a target item t 1 &#8712; D E such that for each t n , there is a p &#8834; D E such that p is a path (t 1 , rel, t x ), (t x , rel, t y )...(t z , rel, t n ) that connects t 1 and t n .</text>
                  <doc_id>175</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>Thus, the target dependents have a common root.</text>
                  <doc_id>176</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To filter noise due to parsing or alignment errors, we further introduce a filter on the length of the path that connects the target root and its dependents and w exclude paths cross contain sentence boundaries.</text>
                  <doc_id>177</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Moreover, the above candidate filtering doesn&#8217;t exclude configurations which exhibit paraphrases involving head-switching or complex coordination.</text>
                  <doc_id>178</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Head-switching can be detected with the help of alignment information: if there is a item in our target configuration that has an reliable alignment with an item not contained in our source configuration, our target configuration is likely to contain such a structural paraphrases and is excluded from our candidate set.</text>
                  <doc_id>179</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Coordination can be discarded by imposing the condition on the configuration not to contain a coordination relation.</text>
                  <doc_id>180</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This Generate-and-Filter strategy now extracts a set of sentences where we are likely to find a good one-to-one or one-to-many translation for the source verb.</text>
                  <doc_id>181</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Alignment Post-editing In the final alignment step, one now needs to figure out which lexical material in the aligned syntactic configurations actually corresponds to the translation of the source item.</text>
                  <doc_id>182</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The intuition discussed in 3.2 was that all</text>
                  <doc_id>183</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the items lying on a path between the root item and the terminals belong to the translation of the source item.</text>
                  <doc_id>184</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, these items may have other syntactic dependents that may also be part of the one-to-many translation.</text>
                  <doc_id>185</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>As an example, consider the configuration in figure 1 where the article an which is part of the LVC create an obstacle to has to be aligned to the German source verb.</text>
                  <doc_id>186</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Thus, for a set of items t i for which there is a dependency relation (t x , rel, t i ) &#8712; D E such that t x is an element of our target configuration, we need to decide whether (s 1 , t i ) &#8712; A G,E .</text>
                  <doc_id>187</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This translation problem now largely parallels collocation translation problems discussed in the literature, as in (Smadja and McKeown, 1994).</text>
                  <doc_id>188</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>But, crucially, our syntactic filtering strategy has substantially narrowed down the number of items that are possible parts of the one-to-many translation.</text>
                  <doc_id>189</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Thus, a straightforward way to assemble the translational correspondence is to compute the correlation or association of the possibly missing items with the given translation pair as proposed in (Smadja and McKeown, 1994).</text>
                  <doc_id>190</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Therefore, we propose the following alignment post-editing algorithm: Given the source item s 1 and the set of target items T , where each t i &#8712; T is an element of our target configuration,</text>
                  <doc_id>191</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1.</text>
                  <doc_id>192</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Compute corr(s 1 , T), the correlation between s 1 and T .</text>
                  <doc_id>193</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.</text>
                  <doc_id>194</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For each t i , t x such that there is a (t i , rel, t x ) &#8712; D E , compute corr(s 1 , T + {t x })</text>
                  <doc_id>195</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3. if corr(s 1 , T + {t x }) &#8805; corr(s 1 , T), add t x to T .</text>
                  <doc_id>196</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As the Dice coefficient is often to give the best results, e.g. in (Smadja and McKeown, 1994), we also chose Dice as our correlation measure.</text>
                  <doc_id>197</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In future work, we will experiment with other association measures.</text>
                  <doc_id>198</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Our correlation scores are thus defined by the formula:</text>
                  <doc_id>199</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>corr(s 1, T) =</text>
                  <doc_id>200</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2(freq(s1 &#8743; T)) freq(s 1) + freq(T)</text>
                  <doc_id>201</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We define freq(T) as the number of sentence pairs whose target sentence contains occurrences of all t i &#8712; T , and freq(s 1 ) accordingly.</text>
                  <doc_id>202</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The observation frequency freq(s 1 &#8743;T) is the number of sentence pairs that where s 1 occurs in the source sentence, and T in the target sentence.</text>
                  <doc_id>203</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The output translation can then be represented as a dependency configuration of the following kind :((of,PMOD,%), (risk,NMOD,of),(risk,NMOD,the), (run,OBJ,risk), (run,SBJ,%)) which is the syntactic representation for the English MWE run the risk of.</text>
                  <doc_id>204</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Evaluation</title>
            <text>Our translational approach to MWE extraction bears the advantage that evaluation is not exclusively bound to the manual judgement of candidate lists. Instead, we can first evaluate the system output against translation gold standards which are easier to obtain. The linguistic classification of the candidates according to their compositionality can then be treated as a separate problem. We present two experiments in this evaluation section: We will first evaluate the translation detection on our gold standard to assess the general quality of the extraction method. Since this gold standard is to small to draw conclusions about the quality of MWE patterns that the system detects, we further evaluate the translational correspondences for a larger set of verbs.
Translation evaluation: In the first experiment, we extracted all types of translational correspondences for the verbs we annotated in the gold standard. We converted the output dependency configurations to the lemmatized bag-of-word form we already applied for the alignment evaluation and calculated the FPR and FNR of the translation types. The evaluation is displayed in table 4. Nearly all translation types that our system detected are correct. This confirms our hypothesis that syntactic filtering yields more reliable translations that just coocurrence-based alignments. However, the false negative rate is also very high. This low recall is due to the fact that our syntactic filters are very restrictive such that a major part of the occurrences of the source lemma don&#8217;t figure in the prototypical syntactic configuration. Column two and three of the evaluation table present the FPR and FNR for experiments with a relaxed syntactic filter that doesn&#8217;t constrain the syntactic type of the parallel argument relations. While not decreasing the FNR, the FPR decreases significantly. This means that the syntactic filters mainly fire on noisy configurations and don&#8217;t decrease the recall. A manual error analysis has also shown that the relatively flat annotation scheme of our dependency parses significantly narrows down
the number of candidate configurations that our algorithm detects. As the dependency parses don&#8217;t provide deep analyses for tense or control phenomena, very often, a verb&#8217;s arguments don&#8217;t figure as its syntactic dependents and no configuration is found. Future work will explore the impact of deep syntactic analysis for the detection of translational correspondences.
MWE evaluation: In a second experiment, we evaluated the patterns of correspondences found by our extraction method for use in an MWE context. Therefore, we selected 50 random verbs occurring in the Europarl corpus and extracted their respective translational correspondences. This set of 50 verbs yields a set of 1592 one-to-many types of translational correspondences. We filtered the types wich display only morphological variation, such that the set of potential MWE types comprises 1302 types. Out of these, we evaluated a random sample of 300 types by labelling the types with the MWE categories we established for the analysis of our gold standard. During the classification, we encountered a further category of oneto- many correspondence which cannot be considered an MWE, the category of alternation. For instance, we found a translational correspondence between the active realization of the German verb begr&#252;&#223;en (en. appreciate) and the English passive be pleased by. The classification is displayed in table 5. Almost 83% of the translational correspondences that our system extracted are perfect translation types. Almost 60% of the extracted types can be considered MWEs that exhibit some kind of semantic idiosyncrasy. The other translations could be classified as paraphrases or alternations. In our random sample, the portions of idioms is significantly higher than in our gold standard which confirms our intuition that the MWE pattern of the one-to-many translations for a given verb are related to language-specific, semantic properties of the verbs and the lexical concepts they realize.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Our translational approach to MWE extraction bears the advantage that evaluation is not exclusively bound to the manual judgement of candidate lists.</text>
                  <doc_id>205</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Instead, we can first evaluate the system output against translation gold standards which are easier to obtain.</text>
                  <doc_id>206</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The linguistic classification of the candidates according to their compositionality can then be treated as a separate problem.</text>
                  <doc_id>207</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We present two experiments in this evaluation section: We will first evaluate the translation detection on our gold standard to assess the general quality of the extraction method.</text>
                  <doc_id>208</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Since this gold standard is to small to draw conclusions about the quality of MWE patterns that the system detects, we further evaluate the translational correspondences for a larger set of verbs.</text>
                  <doc_id>209</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Translation evaluation: In the first experiment, we extracted all types of translational correspondences for the verbs we annotated in the gold standard.</text>
                  <doc_id>210</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We converted the output dependency configurations to the lemmatized bag-of-word form we already applied for the alignment evaluation and calculated the FPR and FNR of the translation types.</text>
                  <doc_id>211</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The evaluation is displayed in table 4.</text>
                  <doc_id>212</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Nearly all translation types that our system detected are correct.</text>
                  <doc_id>213</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This confirms our hypothesis that syntactic filtering yields more reliable translations that just coocurrence-based alignments.</text>
                  <doc_id>214</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>However, the false negative rate is also very high.</text>
                  <doc_id>215</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>This low recall is due to the fact that our syntactic filters are very restrictive such that a major part of the occurrences of the source lemma don&#8217;t figure in the prototypical syntactic configuration.</text>
                  <doc_id>216</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>Column two and three of the evaluation table present the FPR and FNR for experiments with a relaxed syntactic filter that doesn&#8217;t constrain the syntactic type of the parallel argument relations.</text>
                  <doc_id>217</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>While not decreasing the FNR, the FPR decreases significantly.</text>
                  <doc_id>218</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>This means that the syntactic filters mainly fire on noisy configurations and don&#8217;t decrease the recall.</text>
                  <doc_id>219</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>A manual error analysis has also shown that the relatively flat annotation scheme of our dependency parses significantly narrows down</text>
                  <doc_id>220</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the number of candidate configurations that our algorithm detects.</text>
                  <doc_id>221</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As the dependency parses don&#8217;t provide deep analyses for tense or control phenomena, very often, a verb&#8217;s arguments don&#8217;t figure as its syntactic dependents and no configuration is found.</text>
                  <doc_id>222</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Future work will explore the impact of deep syntactic analysis for the detection of translational correspondences.</text>
                  <doc_id>223</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>MWE evaluation: In a second experiment, we evaluated the patterns of correspondences found by our extraction method for use in an MWE context.</text>
                  <doc_id>224</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Therefore, we selected 50 random verbs occurring in the Europarl corpus and extracted their respective translational correspondences.</text>
                  <doc_id>225</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This set of 50 verbs yields a set of 1592 one-to-many types of translational correspondences.</text>
                  <doc_id>226</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We filtered the types wich display only morphological variation, such that the set of potential MWE types comprises 1302 types.</text>
                  <doc_id>227</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Out of these, we evaluated a random sample of 300 types by labelling the types with the MWE categories we established for the analysis of our gold standard.</text>
                  <doc_id>228</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>During the classification, we encountered a further category of oneto- many correspondence which cannot be considered an MWE, the category of alternation.</text>
                  <doc_id>229</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>For instance, we found a translational correspondence between the active realization of the German verb begr&#252;&#223;en (en.</text>
                  <doc_id>230</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>appreciate) and the English passive be pleased by.</text>
                  <doc_id>231</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>The classification is displayed in table 5.</text>
                  <doc_id>232</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>Almost 83% of the translational correspondences that our system extracted are perfect translation types.</text>
                  <doc_id>233</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>Almost 60% of the extracted types can be considered MWEs that exhibit some kind of semantic idiosyncrasy.</text>
                  <doc_id>234</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
                <sentence>
                  <text>The other translations could be classified as paraphrases or alternations.</text>
                  <doc_id>235</doc_id>
                  <sec_id>11</sec_id>
                </sentence>
                <sentence>
                  <text>In our random sample, the portions of idioms is significantly higher than in our gold standard which confirms our intuition that the MWE pattern of the one-to-many translations for a given verb are related to language-specific, semantic properties of the verbs and the lexical concepts they realize.</text>
                  <doc_id>236</doc_id>
                  <sec_id>12</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 Related Work</title>
        <text>The problem sketched in this paper has clear conncetions to statistical MT. So-called phrase-based translation models generally target whole sentence alignment and do not necessarily recur to linguistically motivated phrase correspondences (Koehn et al., 2003). Syntax-based translation that specifies formal relations between bilingual parses was
Strict Filter Relaxed Filter
FPR FNR FPR FNR
v 1 0.0 0.96 0.5 0.96
v 2 0.25 0.88 0.47 0.79
v 3 0.25 0.74 0.56 0.63
v 4 0.0 0.875 0.56 0.84
Trans. type Proportion
MWEs 57.5%
Paraphrases 24.4%
Alternations 1.0%
Noise 17.1%
MWE type Proportion
V Part 8.2%
V Prep 51.8%
LVC 32.4%
Idiom 10.6%
established by (Wu, 1997). Our way to use syntactic configurations can be seen as a heuristic to check relaxed structural parallelism.
Work on MWEs in a crosslingual context has almost exclusively focussed on MWE translation (Smadja and McKeown, 1994; Anastasiou, 2008). In (Villada Moir&#243;n and Tiedemann, 2006), the authors make use of alignment information in a parallel corpus to rank MWE candidates. These approaches don&#8217;t rely on the lexical semantic knowledge about MWEs in form of one-to-many translations.
By contrast, previous approaches to paraphrase extraction made more explicit use of crosslingual semantic information. In (Bannard and Callison- Burch, 2005), the authors use the target language as a pivot providing contextual features for identifying semantically similar expressions. Paraphrasing is however only partially comparable to the crosslingual MWE detection we propose in this paper. Recently, the very pronounced context dependence of monolingual pairs of semantically similar expressions has been recognized as a major challenge in modelling word meaning (Erk and Pado, 2009).
The idea that parallel corpora can be used as a linguistic resource that provides empirical evidence for monolingual idiosyncrasies has already
been exploited in, e.g. morphology projection (Yarowsky et al., 2001) or word sense disambiguation (Dyvik, 2004). While in a monolingual setting, it is quite tricky to come up with theoretical or empirical definitions of sense discriminations, the crosslingual scenario offers a theory-neutral, data-driven solution: Since ambiguity is an idiosyncratic property of a lexical item in a given language, it is not likely to be mirrored in a target language. Similarly, our approach can also be seen as a projection idea: we project the semantic information of simplex realization in a source language to an idiosyncratic, multiword realization in the target language.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The problem sketched in this paper has clear conncetions to statistical MT.</text>
              <doc_id>237</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>So-called phrase-based translation models generally target whole sentence alignment and do not necessarily recur to linguistically motivated phrase correspondences (Koehn et al., 2003).</text>
              <doc_id>238</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Syntax-based translation that specifies formal relations between bilingual parses was</text>
              <doc_id>239</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Strict Filter Relaxed Filter</text>
              <doc_id>240</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>FPR FNR FPR FNR</text>
              <doc_id>241</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>v 1 0.0 0.96 0.5 0.96</text>
              <doc_id>242</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>v 2 0.25 0.88 0.47 0.79</text>
              <doc_id>243</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>v 3 0.25 0.74 0.56 0.63</text>
              <doc_id>244</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>v 4 0.0 0.875 0.56 0.84</text>
              <doc_id>245</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Trans.</text>
              <doc_id>246</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>type Proportion</text>
              <doc_id>247</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>MWEs 57.5%</text>
              <doc_id>248</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Paraphrases 24.4%</text>
              <doc_id>249</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Alternations 1.0%</text>
              <doc_id>250</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Noise 17.1%</text>
              <doc_id>251</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>MWE type Proportion</text>
              <doc_id>252</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>V Part 8.2%</text>
              <doc_id>253</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>V Prep 51.8%</text>
              <doc_id>254</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>LVC 32.4%</text>
              <doc_id>255</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Idiom 10.6%</text>
              <doc_id>256</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>established by (Wu, 1997).</text>
              <doc_id>257</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our way to use syntactic configurations can be seen as a heuristic to check relaxed structural parallelism.</text>
              <doc_id>258</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Work on MWEs in a crosslingual context has almost exclusively focussed on MWE translation (Smadja and McKeown, 1994; Anastasiou, 2008).</text>
              <doc_id>259</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In (Villada Moir&#243;n and Tiedemann, 2006), the authors make use of alignment information in a parallel corpus to rank MWE candidates.</text>
              <doc_id>260</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>These approaches don&#8217;t rely on the lexical semantic knowledge about MWEs in form of one-to-many translations.</text>
              <doc_id>261</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>By contrast, previous approaches to paraphrase extraction made more explicit use of crosslingual semantic information.</text>
              <doc_id>262</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In (Bannard and Callison- Burch, 2005), the authors use the target language as a pivot providing contextual features for identifying semantically similar expressions.</text>
              <doc_id>263</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Paraphrasing is however only partially comparable to the crosslingual MWE detection we propose in this paper.</text>
              <doc_id>264</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Recently, the very pronounced context dependence of monolingual pairs of semantically similar expressions has been recognized as a major challenge in modelling word meaning (Erk and Pado, 2009).</text>
              <doc_id>265</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The idea that parallel corpora can be used as a linguistic resource that provides empirical evidence for monolingual idiosyncrasies has already</text>
              <doc_id>266</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>been exploited in, e.g. morphology projection (Yarowsky et al., 2001) or word sense disambiguation (Dyvik, 2004).</text>
              <doc_id>267</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>While in a monolingual setting, it is quite tricky to come up with theoretical or empirical definitions of sense discriminations, the crosslingual scenario offers a theory-neutral, data-driven solution: Since ambiguity is an idiosyncratic property of a lexical item in a given language, it is not likely to be mirrored in a target language.</text>
              <doc_id>268</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Similarly, our approach can also be seen as a projection idea: we project the semantic information of simplex realization in a source language to an idiosyncratic, multiword realization in the target language.</text>
              <doc_id>269</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>5</index>
        <title>5 Conclusion</title>
        <text>We have explored the phenomenon of one-tomany translations in parallel corpora from the perspective of MWE identification. Our manual study on a translation gold standard as well as our experiments in automatic translation extraction have shown that one-to-many correspondences provide a rich resource and fruitful basis of study for data-driven MWE identification. The crosslingual perspective raises new research questions about the identification and interpretation of MWEs. It challenges the distinction between paraphrases and MWEs, a problem that does not arise at all in the context of monolingual MWE extraction. It also allows for the study of the relation between the semantics of lexical concepts and their MWE realization. Further research in this direction should investigate translational correspondences on a larger scale and further explore these for monolingual interpretation of MWEs. Our extraction method that is based on syntactic filters identifies MWE types with a much higher precision than purely cooccurence-based word alignment and captures the various patterns we found in our gold standard. Future work on the extraction method will have to focus on the generalization of these filters and the generalization to other items than verbs. The experiments presented in this paper also suggest that the MWE realization of certain lexical items in a target language is subject to certain linguistic patterns. Moreover, the method we propose is completely languageindependent such that further research has to study the impact of the relatedness of the considered languages on the patterns of one-to-many translational correspondences.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We have explored the phenomenon of one-tomany translations in parallel corpora from the perspective of MWE identification.</text>
              <doc_id>270</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our manual study on a translation gold standard as well as our experiments in automatic translation extraction have shown that one-to-many correspondences provide a rich resource and fruitful basis of study for data-driven MWE identification.</text>
              <doc_id>271</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The crosslingual perspective raises new research questions about the identification and interpretation of MWEs.</text>
              <doc_id>272</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>It challenges the distinction between paraphrases and MWEs, a problem that does not arise at all in the context of monolingual MWE extraction.</text>
              <doc_id>273</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>It also allows for the study of the relation between the semantics of lexical concepts and their MWE realization.</text>
              <doc_id>274</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Further research in this direction should investigate translational correspondences on a larger scale and further explore these for monolingual interpretation of MWEs.</text>
              <doc_id>275</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Our extraction method that is based on syntactic filters identifies MWE types with a much higher precision than purely cooccurence-based word alignment and captures the various patterns we found in our gold standard.</text>
              <doc_id>276</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Future work on the extraction method will have to focus on the generalization of these filters and the generalization to other items than verbs.</text>
              <doc_id>277</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>The experiments presented in this paper also suggest that the MWE realization of certain lexical items in a target language is subject to certain linguistic patterns.</text>
              <doc_id>278</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>Moreover, the method we propose is completely languageindependent such that further research has to study the impact of the relatedness of the considered languages on the patterns of one-to-many translational correspondences.</text>
              <doc_id>279</doc_id>
              <sec_id>9</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>2</id>
        <source>TableSeer</source>
        <caption>Table 2: Proportions of MWE types per lemma</caption>
        <reference_text>In PAGE 3: ... (14) We need greater cooperation in this respect to ensure that repayments increase .  Table2  displays the proportions of the MWE categories for the number of types of one-to-many correspondences in our gold standard. We filtered the types due to morphological variations only (the overall number of types is indicated in brackets)....</reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>None</cell>
              <cell>v1</cell>
              <cell>v2</cell>
              <cell>v3</cell>
              <cell>v4</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Ntype</cell>
              <cell>22 (26)</cell>
              <cell>41 (47)</cell>
              <cell>26 (35)</cell>
              <cell>17 (24)</cell>
            </row>
            <row>
              <cell>V Part</cell>
              <cell>22.7</cell>
              <cell>4.9</cell>
              <cell>0.0</cell>
              <cell>0.0</cell>
            </row>
            <row>
              <cell>V Prep</cell>
              <cell>36.4</cell>
              <cell>41.5</cell>
              <cell>3.9</cell>
              <cell>5.9</cell>
            </row>
            <row>
              <cell>LVC</cell>
              <cell>18.2</cell>
              <cell>29.3</cell>
              <cell>88.5</cell>
              <cell>88.2</cell>
            </row>
            <row>
              <cell>Idiom</cell>
              <cell>0.0</cell>
              <cell>2.4</cell>
              <cell>0.0</cell>
              <cell>0.0</cell>
            </row>
            <row>
              <cell>Para</cell>
              <cell>36.4</cell>
              <cell>24.3</cell>
              <cell>11.5</cell>
              <cell>23.5</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>4</id>
        <source>TableSeer</source>
        <caption>Table 4: False positive and false negative rate of one-to-many translations.</caption>
        <reference_text>None</reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>Trans. type</cell>
              <cell>Proportion</cell>
              <cell>MWE type   V Part</cell>
              <cell>Proportion    8.2%</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>MWEs</cell>
              <cell>57.5%</cell>
              <cell>V Prep</cell>
              <cell>51.8%</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>LVC</cell>
              <cell>32.4%</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>Idiom</cell>
              <cell>10.6%</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>24.4%</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>1.0%</cell>
            </row>
            <row>
              <cell>Noise</cell>
              <cell>17.1%</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Dimitra Anastasiou</author>
        </authors>
        <title>Identification of idioms by mt&#8217;s hybrid research system vs. three commercial system.</title>
        <publication>In Proceedings of the EAMT,</publication>
        <pages>12--20</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Timothy Baldwin</author>
          <author>Aline Villavicencio</author>
        </authors>
        <title>Extracting the unextractable: a case study on verb-particles.</title>
        <publication>In Proceedings of the COLING-02,</publication>
        <pages>1--7</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Colin Bannard</author>
          <author>Chris Callison-Burch</author>
        </authors>
        <title>Paraphrasing with bilingual parallel corpora.</title>
        <publication>In Proceedings of the 43rd Annual Meeting of the ACL,</publication>
        <pages>597--604</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Lea Cyrus</author>
        </authors>
        <title>Building a resource for studying translation shifts.</title>
        <publication>In Proceedings of the 5th LREC,</publication>
        <pages>1240--1245</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Helge Dyvik</author>
        </authors>
        <title>Translations as semantic mirrors. From parallel corpus to WordNet. Language and Computers,</title>
        <publication>None</publication>
        <pages>1--311</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Katrin Erk</author>
          <author>Sebastian Pado</author>
        </authors>
        <title>Paraphrase assessment in structured vector space: Exploring parameters and datasets.</title>
        <publication>In Proc. of the EACL GEMS Workshop,</publication>
        <pages>57--65</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Jo&#227;o de</author>
        </authors>
        <title>Almeida Varelas Gra&#231;a, Joana Paulo Pardal, Lu&#237;sa Coheur, and Diamantino Ant&#243;nio Caseiro.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Franz Josef Och</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>Statistical phrase-based translation.</title>
        <publication>In Proceedings of the NAACL &#8217;03,</publication>
        <pages>48--54</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Philipp Koehn</author>
        </authors>
        <title>Europarl: A parallel corpus for statistical machine translation.</title>
        <publication>In MT Summit</publication>
        <pages>79--86</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Joakim Nivre</author>
          <author>Johan Hall</author>
          <author>Jens Nilsson</author>
        </authors>
        <title>Maltparser: A data driven parser-generator for dependency parsing.</title>
        <publication>In Proc. of LREC-2006,</publication>
        <pages>2216--2219</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Franz Josef Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>A systematic comparison of various statistical alignment models.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Pavel Pecina</author>
        </authors>
        <title>A machine learning approach to multiword expression extraction.</title>
        <publication>In Proceedings of the LREC MWE 2008 Workshop,</publication>
        <pages>54--57</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Ivan A Sag</author>
          <author>Timothy Baldwin</author>
          <author>Francis Bond</author>
          <author>Ann Copestake</author>
        </authors>
        <title>Multiword expressions: A pain in the neck for NLP.</title>
        <publication>In Proc. of the CICLing-2002,</publication>
        <pages>1--15</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Frank Smadja</author>
          <author>Kathleen McKeown</author>
        </authors>
        <title>Translating collocations for use in bilingual lexicons.</title>
        <publication>In Proceedings of the HLT &#8217;94 workshop,</publication>
        <pages>152--156</pages>
        <date>1994</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Bego&#241;a Villada Moir&#243;n</author>
          <author>J&#246;rg Tiedemann</author>
        </authors>
        <title>Identifying idiomatic expressions using automatic wordalignment.</title>
        <publication>In Proc. of the EACL MWE 2006 Workshop,</publication>
        <pages>33--40</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>Dekai Wu</author>
        </authors>
        <title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1997</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Anastasiou, 2008</string>
        <sentence_id>42281</sentence_id>
        <char_offset>117</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Baldwin and Villavicencio, 2002</string>
        <sentence_id>42039</sentence_id>
        <char_offset>214</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>1</reference_id>
        <string>Baldwin and Villavicencio, 2002</string>
        <sentence_id>42084</sentence_id>
        <char_offset>76</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>Cyrus, 2006</string>
        <sentence_id>42115</sentence_id>
        <char_offset>89</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>4</reference_id>
        <string>Dyvik, 2004</string>
        <sentence_id>42025</sentence_id>
        <char_offset>211</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>4</reference_id>
        <string>Dyvik, 2004</string>
        <sentence_id>42289</sentence_id>
        <char_offset>100</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>5</reference_id>
        <string>Erk and Pado, 2009</string>
        <sentence_id>42287</sentence_id>
        <char_offset>174</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>7</reference_id>
        <string>Koehn et al., 2003</string>
        <sentence_id>42260</sentence_id>
        <char_offset>165</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>8</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>42031</sentence_id>
        <char_offset>92</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>9</reference_id>
        <string>Nivre et al., 2006</string>
        <sentence_id>42182</sentence_id>
        <char_offset>92</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>10</reference_id>
        <string>Och and Ney, 2003</string>
        <sentence_id>42067</sentence_id>
        <char_offset>127</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>10</reference_id>
        <string>Och and Ney, 2003</string>
        <sentence_id>42139</sentence_id>
        <char_offset>258</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>11</reference_id>
        <string>Pecina, 2008</string>
        <sentence_id>42038</sentence_id>
        <char_offset>211</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>12</reference_id>
        <string>Sag et al (2002)</string>
        <sentence_id>42090</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>13</reference_id>
        <string>Smadja and McKeown, 1994</string>
        <sentence_id>42207</sentence_id>
        <char_offset>116</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>13</reference_id>
        <string>Smadja and McKeown, 1994</string>
        <sentence_id>42209</sentence_id>
        <char_offset>196</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>13</reference_id>
        <string>Smadja and McKeown, 1994</string>
        <sentence_id>42216</sentence_id>
        <char_offset>68</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>13</reference_id>
        <string>Smadja and McKeown, 1994</string>
        <sentence_id>42281</sentence_id>
        <char_offset>91</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>14</reference_id>
        <string>Moir&#243;n and Tiedemann, 2006</string>
        <sentence_id>42039</sentence_id>
        <char_offset>280</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>14</reference_id>
        <string>Moir&#243;n and Tiedemann, 2006</string>
        <sentence_id>42282</sentence_id>
        <char_offset>12</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>15</reference_id>
        <string>Wu, 1997</string>
        <sentence_id>42279</sentence_id>
        <char_offset>16</char_offset>
      </citation>
    </citations>
  </content>
</document>
