<PAPER>
  <FILENO/>
  <TITLE>Phrase Training Based Adaptation for Statistical Machine Translation</TITLE>
  <AUTHORS>
    <AUTHOR>Saab Mansour</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-25234">We present a novel approach for translation model (TM) adaptation using phrase training.</A-S>
    <A-S ID="S-25235">The proposed adaptation procedure is initialized with a standard general-domain TM, which is then used to perform phrase training on a smaller in-domain set.</A-S>
    <A-S ID="S-25236">This way, we bias the probabilities of the general TM towards the in-domain distribution.</A-S>
    <A-S ID="S-25237">Experimental results on two different lectures translation tasks show significant improvements of the adapted systems over the general ones.</A-S>
    <A-S ID="S-25238">Additionally, we compare our results to mixture modeling, where we report gains when using the suggested phrase training adaptation method.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-25239">The task of domain-adaptation attempts to exploit data mainly drawn from one domain (e.g. news, parliamentary discussion) to maximize the performance on the test domain (e.g. lectures, web forums).</S>
        <S ID="S-25240">In this work, we focus on translation model (TM) adaptation.</S>
        <S ID="S-25241">A prominent approach in recent work is weighting at different levels of granularity.</S>
        <S ID="S-25242"><REF ID="R-00" RPTR="1">Foster and Kuhn (2007)</REF> perform weighting at the corpus level, where different corpora receive different weights and are then combined using mixture modeling.</S>
        <S ID="S-25243">A finer grained weighting is that of <REF ID="R-03" RPTR="5">Matsoukas et al. (2009)</REF>, who weight each sentence in the bitexts using features of meta-information and optimize a mapping from the feature vectors to weights using a translation quality measure.</S>
      </P>
      <P>
        <S ID="S-25244">In this work, we propose to perform TM adaptation using phrase training.</S>
        <S ID="S-25245">We start from a generaldomain phrase table and adapt the probabilities by training on an in-domain data.</S>
        <S ID="S-25246">Thus, we achieve direct phrase probabilities adaptation as opposed to weighting.</S>
        <S ID="S-25247"><REF ID="R-01" RPTR="2">Foster et al. (2010)</REF> perform weighting at the phrase level, assigning each phrase pair a weight according to its relevance to the test domain.</S>
        <S ID="S-25248">They compare phrase weighting to a &#8220;flat&#8221; model, where the weight directly approximates the phrase probability.</S>
        <S ID="S-25249">In their experiments, the weighting method performs better than the flat model, therefore, they conclude that retaining the original relative frequency probabilities of the TM is important for good performance.</S>
        <S ID="S-25250">The &#8220;flat&#8221; model of <REF ID="R-01" RPTR="3">Foster et al. (2010)</REF> is similar to our work.</S>
        <S ID="S-25251">We differ in the following points: (i) we use the same procedure to perform the phrase training based adaptation and the search thus avoiding inconsistencies between the two; (ii) we do not directly interpolate the original statistics with the new ones, but use a training procedure to manipulate the original statistics.</S>
        <S ID="S-25252">We perform experiments on the publicly available IWSLT TED task, on both Arabic-to-English and Germanto-English lectures translation tracks.</S>
        <S ID="S-25253">We compare our suggested phrase training adaptation method to a variety of baselines and show its effectiveness.</S>
        <S ID="S-25254">Finally, we experiment with mixture modeling based adaptation.</S>
        <S ID="S-25255">We compare mixture modeling to our adaptation method, and apply our method within a mixture modeling framework.</S>
      </P>
      <P>
        <S ID="S-25256">In Section 2, we present the phrase training method and explain how it is utilized for adaptation.</S>
        <S ID="S-25257">Experimental setup including corpora statistics and the SMT system are described in Section 3.</S>
        <S ID="S-25258">Section 4 summarizes the phrase training adaptation results ending with a comparison to mixture modeling.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Phrase Training</HEADER>
      <P>
        <S ID="S-25276">The standard phrase extraction procedure in SMT consists of two phases: (i) word-alignment training (e.g., IBM alignment models), (ii) heuristic phrase extraction and relative frequency based phrase translation probability estimation.</S>
        <S ID="S-25277">In this work, we utilize phrase training for the task of adaptation.</S>
        <S ID="S-25278">We use the forced alignment (FA) method (<REF ID="R-09" RPTR="11">Wuebker et al., 2010</REF>) to perform the phrase alignment training and probability estimation.</S>
        <S ID="S-25279">We perform phrase training by running a normal SMT decoder on the training data and constrain the translation to the given target instance.</S>
        <S ID="S-25280">Using n-best possible phrase segmentation for each training instance, the phrase probabilities are re-estimated over the output.</S>
        <S ID="S-25281">Leaving-one-out is used during the forced alignment procedure phase to avoid over-fitting (<REF ID="R-09" RPTR="12">Wuebker et al., 2010</REF>).</S>
      </P>
      <P>
        <S ID="S-25282">In the standard phrase training procedure, we are given a training set y, from which an initial heuristics-based phrase table p 0 y is generated.</S>
        <S ID="S-25283">FA training is then done over the training set y using the phrases and probabilities in p 0 y (possibly updated by the leaving-one-out method).</S>
        <S ID="S-25284">Finally, re-estimation of the phrase probabilities is done over the decoder output, generating the FA phrase table p 1 .</S>
        <S ID="S-25285">We explain next how to utilize FA training for adaptation.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>2.1 Adaptation</HEADER>
        <P>
          <S ID="S-25259">In this work, we utilize phrase training for the task of adaptation.</S>
          <S ID="S-25260">The main idea is to generate the initial phrase table required for FA using a general-domain training data y &#8242; , thus resulting in p 0 y &#8242;, and perform the FA training over y IN , the in-domain training data (instead of y &#8242; in the standard procedure).</S>
          <S ID="S-25261">This way, we bias the probabilities of p 0 y &#8242; towards the indomain distribution.</S>
          <S ID="S-25262">We denote this new procedure by Y&#8217;-FA-IN.</S>
          <S ID="S-25263">This differs from the standard IN-FA- IN by that we have more phrase pairs to use for FA.</S>
          <S ID="S-25264">Thus, we obtain phrase pairs relevant to IN in addition to &#8220;general&#8221; phrase pairs which were not extracted from IN, perhaps due to faulty word alignments.</S>
          <S ID="S-25265">The probabilities of the general phrase table will be tailored towards IN.</S>
          <S ID="S-25266">In practice, we usually have in-domain IN and other-domain OD data.</S>
          <S ID="S-25267">We denote by ALL the concatenation of IN and OD.</S>
          <S ID="S-25268">To adapt the ALL phrase table, we perform the FA procedure ALL-FA-IN.</S>
          <S ID="S-25269">We also utilize leaving-one-out to avoid over-fitting.</S>
        </P>
        <P>
          <S ID="S-25270">Another procedure we experimented with is adapting the OD phrase table using FA over IN, without leaving-one-out.</S>
          <S ID="S-25271">We denote it by OD-FA 0 - IN.</S>
          <S ID="S-25272">In this FA scenario, we do not use leaving-oneout as IN is not contained in OD, therefore, overfitting will not occur.</S>
          <S ID="S-25273">By this procedure, we train phrases from OD that are relevant for both OD and IN, while the probabilities will be tailored to IN.</S>
          <S ID="S-25274">In this case, we do not expect improvements over the IN based phrase table, but, improvements over OD and reduction in the phrase table size.</S>
          <S ID="S-25275">We compare our suggested FA based adaptation to the standard FA procedure.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Experimental Setup</HEADER>
      <P>
        <S ID="S-25312"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Training Corpora</HEADER>
        <P>
          <S ID="S-25286">To evaluate the introduced methods experimentally, we use the IWSLT 2011 TED Arabic-to-English and German-to-English translation tasks.</S>
          <S ID="S-25287">The IWSLT 2011 evaluation campaign focuses on the translation of TED talks, a collection of lectures on a variety of topics ranging from science to culture.</S>
          <S ID="S-25288">For Arabic-to-English, the bilingual data consists of roughly 100K sentences of in-domain TED talks data and 8M sentences of &#8220;other&#8221;-domain United Nations (UN) data.</S>
          <S ID="S-25289">For the German-to-English task, the data consists of 130K TED sentences and 2.1M sentences of &#8220;other&#8221;-domain data assembled from the news-commentary and the europarl corpora.</S>
          <S ID="S-25290">For language model training purposes, we use an additional 1.4 billion words (supplied as part of the campaign monolingual training data).</S>
        </P>
        <P>
          <S ID="S-25291">The bilingual training and test data for the Arabicto-English and German-to-English tasks are summarized in Table 1 1 .</S>
          <S ID="S-25292">The English data was tokenized and lowercased while the Arabic data was tokenized and segmented using MADA v3.1 (<REF ID="R-07" RPTR="9">Roth et al., 2008</REF>) with the ATB scheme.</S>
          <S ID="S-25293">The German source is decompounded (<REF ID="R-02" RPTR="4">Koehn and Knight, 2003</REF>) and part-of-speech-based long-range verb reordering rules (<REF ID="R-06" RPTR="8">Popovi&#263; and Ney, 2006</REF>) are applied.</S>
          <S ID="S-25294">From Table 1, we note that using the general data considerably reduces the number of out-of-</S>
        </P>
        <P>
          <S ID="S-25295">1 For a list of the IWSLT TED 2011 training corpora, see http://www.iwslt2011.org/doku.php?</S>
          <S ID="S-25296">id=06_evaluation</S>
        </P>
        <P>
          <S ID="S-25297">Set Sen Tok OOV/IN OOV/ALL</S>
        </P>
        <P>
          <S ID="S-25298">vocabulary (OOV) words.</S>
          <S ID="S-25299">This comes with the price of increasing the size of the training data by a factor of more than 20.</S>
          <S ID="S-25300">A simple concatenation of the corpora might mask the phrase probabilities obtained from the in-domain corpus, causing a deterioration in performance.</S>
          <S ID="S-25301">One way to avoid this contamination is by filtering the general corpus, but this discards phrase translations completely from the phrase model.</S>
          <S ID="S-25302">A more principled way is by adapting the phrase probabilities of the full system to the domain being tackled.</S>
          <S ID="S-25303">We perform this by phrase training the full phrase table over the in-domain training set.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Translation System</HEADER>
        <P>
          <S ID="S-25304">The baseline system is built using the open-source SMT toolkit Jane 2.0, which provides a state-ofthe-art phrase-based SMT system (<REF ID="R-10" RPTR="13">Wuebker et al., 2012</REF>a).</S>
          <S ID="S-25305">In addition to the phrase based decoder, Jane 2.0 implements the forced alignment procedure used in this work for the purpose of adaptation.</S>
          <S ID="S-25306">We use the standard set of models with phrase translation probabilities for source-to-target and target-tosource directions, smoothing with lexical weights, a word and phrase penalty, distance-based reordering and an n-gram target language model.</S>
          <S ID="S-25307">The SMT systems are tuned on the dev (dev2010) development set with minimum error rate training (<REF ID="R-04" RPTR="6">Och, 2003</REF>) using BLEU (<REF ID="R-05" RPTR="7">Papineni et al., 2002</REF>) accuracy measure as the optimization criterion.</S>
          <S ID="S-25308">We test the performance of our system on the test (tst2010) and eval (tst2011) sets using the BLEU and translation edit rate (TER) (<REF ID="R-08" RPTR="10">Snover et al., 2006</REF>) measures.</S>
          <S ID="S-25309">We use</S>
        </P>
        <P>
          <S ID="S-25310">TER as an additional measure to verify the consistency of our improvements and avoid over-tuning.</S>
          <S ID="S-25311">The Arabic-English results are case sensitive while the German-English results are case insensitive.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Results</HEADER>
      <P>
        <S ID="S-25326">For TM training, we define three different sets: indomain (IN) which is the TED corpus, other-domain (OD) which consists of the UN corpus for Arabic- English and a concatenation of news-commentary and europarl for German-English, and ALL which consists of the concatenation of IN and OD.</S>
        <S ID="S-25327">We experiment with the following extraction methods:</S>
      </P>
      <P>
        <S ID="S-25328">&#8226; Heuristics: standard phrase extraction using word-alignment training and heuristic phrase extraction over the word alignment.</S>
        <S ID="S-25329">The extraction is performed for the three different training data, IN, OD and ALL.</S>
      </P>
      <P>
        <S ID="S-25330">&#8226; FA standard: standard FA phrase training where the same training set is used for initial phrase table generation as well as the FA procedure.</S>
        <S ID="S-25331">We perform the training on the three different training sets and denote the resulting systems by IN-FA, OD-FA and ALL-FA.</S>
      </P>
      <P>
        <S ID="S-25332">&#8226; FA adaptation: FA based adaptation phrase training, where the initial table is generated from some general data and the FA training is performed on the IN data to achieve adaptation.</S>
        <S ID="S-25333">We perform two experiments, OD-FA 0 - IN without leaving-one-out and ALL-FA-IN with leaving-one-out.</S>
      </P>
      <P>
        <S ID="S-25334">The results of the various experiments over both Arabic-English and German-English tasks are summarized in Table 2.</S>
        <S ID="S-25335">The usefulness of the OD data differs between the Arabic-to-English and the German-to-English translation tasks.</S>
        <S ID="S-25336">For Arabic-to- English, the OD system is 2.5%-4.3% BLEU worse than the IN system, whereas for the German-to- English task the differences between IN and OD are smaller and range from 0.9% to 1.6% BLEU.</S>
        <S ID="S-25337">The</S>
      </P>
      <P>
        <S ID="S-25338">Phrase training System Rules dev test eval method number BLEU TER BLEU TER BLEU TER</S>
      </P>
      <P>
        <S ID="S-25339">Heuristics</S>
      </P>
      <P>
        <S ID="S-25340">FA standard</S>
      </P>
      <P>
        <S ID="S-25341">FA adaptation</S>
      </P>
      <P>
        <S ID="S-25342">Heuristics</S>
      </P>
      <P>
        <S ID="S-25343">FA standard</S>
      </P>
      <P>
        <S ID="S-25344">FA adaptation</S>
      </P>
      <P>
        <S ID="S-25345">inferior performance of the OD system can be related to noisy data or bigger discrepancy between the OD data domain distribution and the IN distribution.</S>
        <S ID="S-25346">The ALL system performs according to the usefulness of the OD training set, where for Arabicto-English we observe deterioration in performance for all test sets and up-to -0.9% BLEU on the test set.</S>
        <S ID="S-25347">On the other hand, for German-to-English, the ALL system is improving over IN where the biggest improvement is observed on the eval set with +0.9%</S>
      </P>
      <P>
        <S ID="S-25348">BLEU improvement.</S>
      </P>
      <P>
        <S ID="S-25349">The standard FA procedure achieves mixed results, where IN-FA deteriorates the results over the IN counterpart for Arabic-English, while improving for German-English.</S>
        <S ID="S-25350">ALL-FA performs comparably to the ALL system on both tasks, while reducing the phrase table size considerably.</S>
        <S ID="S-25351">The OD-FA system deteriorates the results in comparison to the OD system in most cases, which is expected as training over the OD set fits the phrase model on the OD domain, making it perform worse on IN.</S>
        <S ID="S-25352">(<REF ID="R-10" RPTR="14">Wuebker et al., 2012</REF>b) also report mixed results with FA training.</S>
      </P>
      <P>
        <S ID="S-25353">The FA adaptation results are summarized in the last block of the experiments.</S>
        <S ID="S-25354">The OD-FA 0 -IN improves over the OD system, which means that the training procedure was able to modify the OD probabilities to perform well on the IN data.</S>
        <S ID="S-25355">On the German-to-English task, the OD-FA 0 -IN performs comparably to the IN system, whereas for Arabicto-English OD-FA 0 -IN was able to close around half of the gap between OD and IN.</S>
      </P>
      <P>
        <S ID="S-25356">The FA adapted ALL system (ALL-FA-IN) performs best in our experiments, improving on both</S>
      </P>
      <P>
        <S ID="S-25357">BLEU and TER measures.</S>
        <S ID="S-25358">In comparison to the</S>
      </P>
      <P>
        <S ID="S-25359">best heuristics system (IN for Arabic-English and ALL for German-English), +0.4% BLEU and -0.6%</S>
      </P>
      <P>
        <S ID="S-25360">TER improvements are observed on the eval set for</S>
      </P>
      <P>
        <S ID="S-25361">Arabic-English.</S>
        <S ID="S-25362">For German-English, the biggest improvements are observed on TER with -0.8% on test and -0.5% on eval.</S>
        <S ID="S-25363">The results suggest that ALL- FA-IN is able to learn more useful phrases than the IN system and adjust the ALL phrase probabilities towards the in-domain distribution.</S>
      </P>
      <P>
        <S ID="S-25364">System dev test</S>
      </P>
      <P>
        <S ID="S-25365">BLEU TER BLEU TER</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Mixture Modeling</HEADER>
        <P>
          <S ID="S-25313">In this section, we compare our method to mixture modeling based adaptation, in addition to applying mixture modeling on top of our method.</S>
          <S ID="S-25314">We focus on linear interpolation (<REF ID="R-00" RPTR="0">Foster and Kuhn, 2007</REF>) of the in-domain (IN) and other-domain phrase tables, where we vary the latter between the heuristically extracted phrase table (OD) and the FA adapted one (OD-FA 0 -IN).</S>
          <S ID="S-25315">The interpolation weight is uniform for the interpolated phrase tables (0.5).</S>
          <S ID="S-25316">The results of mixture modeling are summarized in Table 3.</S>
          <S ID="S-25317">In this table, we include the best heuristics based system (Heuristics best ) from Table 2 as a reference system.</S>
          <S ID="S-25318">The results on the eval set are omitted as they show similar tendencies to the test set results.</S>
        </P>
        <P>
          <S ID="S-25319">Linear interpolation of IN and OD (IN,OD) is performing well in our experiments, with big improvements over the dev set, +1.0% BLEU for Arabic-to- English and +0.4% BLEU for German-to-English.</S>
          <S ID="S-25320">On the test set, we observe smaller improvements.</S>
          <S ID="S-25321">Interpolating IN with the phrase training adapted system OD-FA 0 -IN (IN,OD-FA 0 -IN) achieves additional gains over the IN,OD system, the biggest are observed on TER for German-to-English, with -0.4% and -0.5% improvements on the dev and test sets correspondingly.</S>
        </P>
        <P>
          <S ID="S-25322">Comparing heuristics based interpolation (IN,OD) to our best phrase training adapted system (ALL-FA-IN) shows mixed results.</S>
          <S ID="S-25323">For Arabic-to- English, the systems are comparable, while for the German-to-English test set, IN,OD is +0.2% BLEU better and +0.8% TER worse than ALL-FA-IN.</S>
          <S ID="S-25324">We hypothesize that for Arabic-to-English interpolation is important due to the larger size of the OD data, where it could reduce the masking of the IN training data by the much larger OD data.</S>
          <S ID="S-25325">Nevertheless, as mentioned previously, using phrase training adapted phrase table in a mixture setup consistently improves over using heuristically extracted tables.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Conclusions</HEADER>
      <P>
        <S ID="S-25366">In this work, we propose a phrase training procedure for adaptation.</S>
        <S ID="S-25367">The phrase training is implemented using the FA method.</S>
        <S ID="S-25368">First, we extract a standard phrase table using the whole available training data.</S>
        <S ID="S-25369">Using this table, we initialize the FA procedure and perform training on the in-domain set.</S>
        <S ID="S-25370">Experiments are done on the Arabic-to-English and German-to-English TED lectures translation tasks.</S>
        <S ID="S-25371">We show that the suggested procedure is improving over unadapted baselines.</S>
        <S ID="S-25372">On the Arabicto-English task, the FA adapted system is +0.9% BLEU better than the full unadapted counterpart on both test sets.</S>
        <S ID="S-25373">Unlike the Arabic-to-English setup, the German-to-English OD data is helpful and produces a strong unadapted baseline in concatenation with IN.</S>
        <S ID="S-25374">In this case, the FA adapted system achieves BLEU improvements mainly on the development set with +0.6% BLEU, on the test and eval sets, improvements of -0.8% and -0.6% TER are observed correspondingly.</S>
        <S ID="S-25375">As a side effect of the FA training process, the size of the adapted phrase table is less than 10% of the size of the full table.</S>
        <S ID="S-25376">Finally, we experimented with mixture modeling where improvements are observed over the unadapted baselines.</S>
        <S ID="S-25377">The results show that using our phrase training adapted OD table yields better performance than using the heuristically extracted OD in a mixture framework.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-25378">This material is based upon work supported by the DARPA BOLT project under Contract No.</S>
      <S ID="S-25379">HR0011- 12-C-0015.</S>
      <S ID="S-25380">Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>George Foster</RAUTHOR>
      <REFTITLE>Mixture-model adaptation for SMT.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>George Foster</RAUTHOR>
      <REFTITLE>Discriminative instance weighting for domain adaptation in statistical machine translation.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Empirical Methods for Compound Splitting. In</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>Spyros Matsoukas</RAUTHOR>
      <REFTITLE>Discriminative corpus weight estimation for machine translation.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Franz J Och</RAUTHOR>
      <REFTITLE>Minimum Error Rate Training in Statistical Machine Translation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Kishore Papineni</RAUTHOR>
      <REFTITLE>Bleu: a Method for Automatic Evaluation of Machine Translation.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>M Popovi&#263;</RAUTHOR>
      <REFTITLE>POS-based Word Reorderings for Statistical Machine Translation.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Ryan Roth</RAUTHOR>
      <REFTITLE>Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Matthew Snover</RAUTHOR>
      <REFTITLE>A Study of Translation Edit Rate with Targeted Human Annotation.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Joern Wuebker</RAUTHOR>
      <REFTITLE>Training phrase translation models with leaving-oneout.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Joern Wuebker</RAUTHOR>
      <REFTITLE>2: Open source phrase-based and hierarchical statistical machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
