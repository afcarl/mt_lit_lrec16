<document>
  <filename>W12-3132</filename>
  <authors>
    <author>Ond&#345;ej Du&#353;ek</author>
    <author>Zden&#283;k &#381;abokrtsk&#253;</author>
    <author>Martin Popel</author>
    <author>Martin Majli&#353;</author>
    <author>Michal Nov&#225;k</author>
  </authors>
  <title>Formemes in English-Czech Deep Syntactic MT &#8727;</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>One of the most notable recent improvements of the TectoMT English-to-Czech translation is a systematic and theoretically supported revision of formemes&#8212;the annotation of morpho-syntactic features of content words in deep dependency syntactic structures based on the Prague tectogrammatics theory. Our modifications aim at reducing data sparsity, increasing consistency across languages and widening the usage area of this markup. Formemes can be used not only in MT, but in various other NLP tasks.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>One of the most notable recent improvements of the TectoMT English-to-Czech translation is a systematic and theoretically supported revision of formemes&#8212;the annotation of morpho-syntactic features of content words in deep dependency syntactic structures based on the Prague tectogrammatics theory.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our modifications aim at reducing data sparsity, increasing consistency across languages and widening the usage area of this markup.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Formemes can be used not only in MT, but in various other NLP tasks.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>The cornerstone of the TectoMT tree-to-tree machine translation system is the deep-syntactic language representation following the Prague tectogrammatics theory (Sgall et al., 1986), and its application in the Prague Dependency Treebank (PDT) 2.0 1 (Haji&#269; et al., 2006), where each sentence is analyzed to a dependency tree whose nodes correspond to content words. Each node has a number of attributes, but the most important (and difficult) for the transfer phase are lemma&#8212;lexical information, and formeme&#8212;surface morpho-syntactic infor-
&#8727;
This research has been supported by the grants FP7-ICT-2009-4-247762 (FAUST), FP7-ICT-2009-4-249119 (Metanet), LH12093 (Kontakt II), DF12P01OVV022 (NAKI), 201/09/H057 (Czech Science Foundation), GAUK 116310, and SVV 265 314. This work has been using language resources developed and/or stored and/or distributed by the LINDAT-Clarin project of the Ministry of Education of the Czech Republic (project LM2010013). 1 http://ufal.mff.cuni.cz/pdt2.0
mation, including selected auxiliary words (Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006; &#381;abokrtsk&#253; et al., 2008).
This paper focuses on formemes&#8212;their definition and recent improvements of the annotation, which has been thoroughly revised in the course of preparation of the CzEng 1.0 parallel corpus (Bojar et al., 2012b), whose utilization in TectoMT along with the new formemes version has brought the greatest benefit to our English-Czech MT system in the recent year. However, the area of possible application of formemes is not limited to MT only or to the language pair used in our system; the underlying ideas are language-independent.
We summarize the development of morphosyntactic annotations related to formemes (Section 2), provide an overview of the whole TectoMT system (Section 3), then describe the formeme annotation (Section 4) and our recent improvements (Section 5), as well as experimental applications, including English-Czech MT (Section 6). The main asset of the formeme revision is a first systematic reorganization of the existing practical aid, providing it with a solid theoretical base, but still bearing its intended applications in mind.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The cornerstone of the TectoMT tree-to-tree machine translation system is the deep-syntactic language representation following the Prague tectogrammatics theory (Sgall et al., 1986), and its application in the Prague Dependency Treebank (PDT) 2.0 1 (Haji&#269; et al., 2006), where each sentence is analyzed to a dependency tree whose nodes correspond to content words.</text>
              <doc_id>3</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Each node has a number of attributes, but the most important (and difficult) for the transfer phase are lemma&#8212;lexical information, and formeme&#8212;surface morpho-syntactic infor-</text>
              <doc_id>4</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8727;</text>
              <doc_id>5</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This research has been supported by the grants FP7-ICT-2009-4-247762 (FAUST), FP7-ICT-2009-4-249119 (Metanet), LH12093 (Kontakt II), DF12P01OVV022 (NAKI), 201/09/H057 (Czech Science Foundation), GAUK 116310, and SVV 265 314.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This work has been using language resources developed and/or stored and/or distributed by the LINDAT-Clarin project of the Ministry of Education of the Czech Republic (project LM2010013).</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>1 http://ufal.mff.cuni.cz/pdt2.0</text>
              <doc_id>8</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>mation, including selected auxiliary words (Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006; &#381;abokrtsk&#253; et al., 2008).</text>
              <doc_id>9</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This paper focuses on formemes&#8212;their definition and recent improvements of the annotation, which has been thoroughly revised in the course of preparation of the CzEng 1.0 parallel corpus (Bojar et al., 2012b), whose utilization in TectoMT along with the new formemes version has brought the greatest benefit to our English-Czech MT system in the recent year.</text>
              <doc_id>10</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>However, the area of possible application of formemes is not limited to MT only or to the language pair used in our system; the underlying ideas are language-independent.</text>
              <doc_id>11</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We summarize the development of morphosyntactic annotations related to formemes (Section 2), provide an overview of the whole TectoMT system (Section 3), then describe the formeme annotation (Section 4) and our recent improvements (Section 5), as well as experimental applications, including English-Czech MT (Section 6).</text>
              <doc_id>12</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The main asset of the formeme revision is a first systematic reorganization of the existing practical aid, providing it with a solid theoretical base, but still bearing its intended applications in mind.</text>
              <doc_id>13</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Related Work</title>
        <text>Numerous theoretical approaches had been made to morpho-syntactic description, mainly within valency lexicons, starting probably with the work by Helbig and Schenkel (1969). Perhaps the best one for Czech is PDT-VALLEX (Haji&#269; et al., 2003), listing all possible subtrees corresponding to valency arguments (Ure&#353;ov&#225;, 2009). &#381;abokrtsk&#253; (2005) gives an overview of works in this field.
This kind of information has been most exploited in structural MT systems, employing semantic relations (Menezes and Richardson, 2001) or surface tree substructures (Quirk et al., 2005; Marcu et al., 2006). Formemes, originally developed for Natural Language Generation (NLG) (Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006), have been successfully applied to MT within the TectoMT system. Our revision of formeme annotation aims to improve the MT performance, keeping other possible applications in mind.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Numerous theoretical approaches had been made to morpho-syntactic description, mainly within valency lexicons, starting probably with the work by Helbig and Schenkel (1969).</text>
              <doc_id>14</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Perhaps the best one for Czech is PDT-VALLEX (Haji&#269; et al., 2003), listing all possible subtrees corresponding to valency arguments (Ure&#353;ov&#225;, 2009).</text>
              <doc_id>15</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>&#381;abokrtsk&#253; (2005) gives an overview of works in this field.</text>
              <doc_id>16</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This kind of information has been most exploited in structural MT systems, employing semantic relations (Menezes and Richardson, 2001) or surface tree substructures (Quirk et al., 2005; Marcu et al., 2006).</text>
              <doc_id>17</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Formemes, originally developed for Natural Language Generation (NLG) (Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006), have been successfully applied to MT within the TectoMT system.</text>
              <doc_id>18</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Our revision of formeme annotation aims to improve the MT performance, keeping other possible applications in mind.</text>
              <doc_id>19</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>3</index>
        <title>3 The TectoMT English-Czech Machine Translation System</title>
        <text>The TectoMT system is a structural machine translation system with deep transfer, first introduced by &#381;abokrtsk&#253; et al. (2008). It currently supports English-to-Czech translation. Its analysis stage follows the Prague tectogrammatics theory (Sgall, 1967; Sgall et al., 1986), proceeding over two layers of structural description, from shallow (analytical) to deep (tectogrammatical) (see Section 3.1).
The transfer phase of the system is based on Maximum Entropy context-sensitive translation models (Mare&#269;ek et al., 2010) and Hidden Tree Markov Models (&#381;abokrtsk&#253; and Popel, 2009). It is factorized into three subtasks: lemma, formeme and grammatemes translation (see Sections 3.2 and 3.3).
The subsequent generation phase consists of rulebased components that gradually change the deep target language representation into a shallow one, which is then converted to text (cf. Section 6.1).
The version of TectoMT submitted to WMT12 2 builds upon the WMT11 version. Several rule-based components were slightly refined. However, most of the effort was devoted to creating a better and bigger parallel treebank&#8212;CzEng 1.0 3 (Bojar et al., 2012b), and re-training the statistical components on this resource. Apart from bigger size and improved filtering, one of the main differences between CzEng 0.9 (Bojar and &#381;abokrtsk&#253;, 2009) (used in WMT11) and CzEng 1.0 (used in WMT12) is the revised annotation of formemes.
2 http://www.statmt.org/wmt12 3 http://ufal.mff.cuni.cz/czeng</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The TectoMT system is a structural machine translation system with deep transfer, first introduced by &#381;abokrtsk&#253; et al. (2008).</text>
              <doc_id>20</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It currently supports English-to-Czech translation.</text>
              <doc_id>21</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Its analysis stage follows the Prague tectogrammatics theory (Sgall, 1967; Sgall et al., 1986), proceeding over two layers of structural description, from shallow (analytical) to deep (tectogrammatical) (see Section 3.1).</text>
              <doc_id>22</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The transfer phase of the system is based on Maximum Entropy context-sensitive translation models (Mare&#269;ek et al., 2010) and Hidden Tree Markov Models (&#381;abokrtsk&#253; and Popel, 2009).</text>
              <doc_id>23</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It is factorized into three subtasks: lemma, formeme and grammatemes translation (see Sections 3.2 and 3.3).</text>
              <doc_id>24</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The subsequent generation phase consists of rulebased components that gradually change the deep target language representation into a shallow one, which is then converted to text (cf. Section 6.1).</text>
              <doc_id>25</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The version of TectoMT submitted to WMT12 2 builds upon the WMT11 version.</text>
              <doc_id>26</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Several rule-based components were slightly refined.</text>
              <doc_id>27</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>However, most of the effort was devoted to creating a better and bigger parallel treebank&#8212;CzEng 1.0 3 (Bojar et al., 2012b), and re-training the statistical components on this resource.</text>
              <doc_id>28</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Apart from bigger size and improved filtering, one of the main differences between CzEng 0.9 (Bojar and &#381;abokrtsk&#253;, 2009) (used in WMT11) and CzEng 1.0 (used in WMT12) is the revised annotation of formemes.</text>
              <doc_id>29</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2 http://www.statmt.org/wmt12 3 http://ufal.mff.cuni.cz/czeng</text>
              <doc_id>30</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Layers of structural analysis</title>
            <text>There are two distinct structural layers used in the TectoMT system:
&#8226; Analytical layer. A surface syntax layer, which includes all tokens of the sentence, organized into a labeled dependency tree. The labels correspond to surface syntax functions.
&#8226; Tectogrammatical layer. A deep syntax/semantic layer describing the linguistic meaning of the sentence. Its dependency trees include only content words as nodes, assigning to each of them a deep lemma (t-lemma), a semantic role label (functor), and other deep linguistic features (grammatemes), such as semantic partof-speech, person, tense or modality.
The analytical layer can be obtained using different dependency parsers (Popel et al., 2011); the tectogrammatical representation is then created by rulebased modules from the analytical trees.
In contrast to the original PDT annotation, the TectoMT tectogrammatical layer also includes formemes describing the surface morpho-syntactic realization of the nodes (cf. also Section 3.3).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>There are two distinct structural layers used in the TectoMT system:</text>
                  <doc_id>31</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Analytical layer.</text>
                  <doc_id>32</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A surface syntax layer, which includes all tokens of the sentence, organized into a labeled dependency tree.</text>
                  <doc_id>33</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The labels correspond to surface syntax functions.</text>
                  <doc_id>34</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Tectogrammatical layer.</text>
                  <doc_id>35</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A deep syntax/semantic layer describing the linguistic meaning of the sentence.</text>
                  <doc_id>36</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Its dependency trees include only content words as nodes, assigning to each of them a deep lemma (t-lemma), a semantic role label (functor), and other deep linguistic features (grammatemes), such as semantic partof-speech, person, tense or modality.</text>
                  <doc_id>37</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The analytical layer can be obtained using different dependency parsers (Popel et al., 2011); the tectogrammatical representation is then created by rulebased modules from the analytical trees.</text>
                  <doc_id>38</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In contrast to the original PDT annotation, the TectoMT tectogrammatical layer also includes formemes describing the surface morpho-syntactic realization of the nodes (cf. also Section 3.3).</text>
                  <doc_id>39</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Transfer: Translation Factorization and Symmetry</title>
            <text>Using the tectogrammatical representation in structural MT allows separating the problem of translating a sentence into relatively independent simpler subtasks: lemma, functors, and grammatemes translation (Bojar et al., 2009; &#381;abokrtsk&#253;, 2010). Since topology changes to deep syntax trees are rare in MT transfer, each of these three subtasks allows a virtually symmetric source-target one-to-one mapping, thus simplifying the initial n-to-m mapping of word phrases or surface subtrees. &#381;abokrtsk&#253; et al. (2008) obviated the need for transfer via functors (i.e. semantic role detection) by applying a formeme transfer instead. While formeme values are much simpler to obtain by automatic processing, this approach preserved the advantage of symmetric one-to-one value translation.
Moreover, translations of a given source morphosyntactic construction usually follow a limited number of patterns in the target language regardless of
their semantic functions, e.g. a finite clause will most often be translated as a finite clause.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Using the tectogrammatical representation in structural MT allows separating the problem of translating a sentence into relatively independent simpler subtasks: lemma, functors, and grammatemes translation (Bojar et al., 2009; &#381;abokrtsk&#253;, 2010).</text>
                  <doc_id>40</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Since topology changes to deep syntax trees are rare in MT transfer, each of these three subtasks allows a virtually symmetric source-target one-to-one mapping, thus simplifying the initial n-to-m mapping of word phrases or surface subtrees.</text>
                  <doc_id>41</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>&#381;abokrtsk&#253; et al. (2008) obviated the need for transfer via functors (i.e. semantic role detection) by applying a formeme transfer instead.</text>
                  <doc_id>42</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>While formeme values are much simpler to obtain by automatic processing, this approach preserved the advantage of symmetric one-to-one value translation.</text>
                  <doc_id>43</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Moreover, translations of a given source morphosyntactic construction usually follow a limited number of patterns in the target language regardless of</text>
                  <doc_id>44</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>their semantic functions, e.g. a finite clause will most often be translated as a finite clause.</text>
                  <doc_id>45</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Motivation for the Introduction of Formemes</title>
            <text>Surface-oriented formemes have been introduced into the semantics-oriented tectogrammatical layer, as it proves beneficial to combine the deep syntax trees, smaller in size and more consistent across languages, with the surface morphology and syntax to provide for a straightforward transition to the surface level (&#381;abokrtsk&#253;, 2010).
The three-fold factorization of the transfer phase (see Section 3.2) helps address the data sparsity issue faced by today&#8217;s MT systems. As the translation of lemmas and their morpho-syntactic forms is separated, combinations unseen in the training data may appear on the output.
To further reduce data sparsity, only minimal information needed to reconstruct the surface form is stored in formemes; morphological categories derivable from elsewhere, i.e. morphological agreement or grammatemes, are discarded.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Surface-oriented formemes have been introduced into the semantics-oriented tectogrammatical layer, as it proves beneficial to combine the deep syntax trees, smaller in size and more consistent across languages, with the surface morphology and syntax to provide for a straightforward transition to the surface level (&#381;abokrtsk&#253;, 2010).</text>
                  <doc_id>46</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The three-fold factorization of the transfer phase (see Section 3.2) helps address the data sparsity issue faced by today&#8217;s MT systems.</text>
                  <doc_id>47</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As the translation of lemmas and their morpho-syntactic forms is separated, combinations unseen in the training data may appear on the output.</text>
                  <doc_id>48</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To further reduce data sparsity, only minimal information needed to reconstruct the surface form is stored in formemes; morphological categories derivable from elsewhere, i.e. morphological agreement or grammatemes, are discarded.</text>
                  <doc_id>49</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 Czech and English Formemes in TectoMT</title>
        <text>A formeme is a concise description of relevant morpho-syntactic features of a node in a tectogrammatical tree (deep syntactic tree whose nodes usually correspond to content words). The general shape of revised Czech and English formemes, as implemented within the Treex 4 NLP framework (Popel and &#381;abokrtsk&#253;, 2010) for the TectoMT system, consists of three main parts:
1. Syntactic part-of-speech. 5 The number of syntactic parts-of-speech is very low, as only content words are used on the deep layer and the categories of pronouns and numerals have been divided under nouns and adjectives according to syntactic behavior (&#352;ev&#269;&#237;kov&#225;-Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006). The possible values are v for verbs, n for nouns, adj for adjectives, and adv for adverbs.
4 http://ufal.mff.cuni.cz/treex/,
https://metacpan.org/module/Treex 5 Cf. Section 5.2 for details.
2. Subordinate conjunction/preposition. Applies only to formemes of prepositional phrases and subordinate clauses introduced by a conjunction and contains the respective conjunction or preposition; e.g. if, on or in_case_of.
3. Form. This part represents the morphosyntactic form of the node in question and depends on the part-of-speech (see Table 1).
The two or three parts are concatenated into a human-readable string to facilitate usage in hand-written rules as well as statistical systems (&#381;abokrtsk&#253;, 2010), producing values such as v:inf, v:if+fin or n:into+X. Formeme values of nodes corresponding to uninflected words are atomic.
Formemes are detected by rule-based modules operating on deep and surface trees. Example deep syntax trees annotated with formemes are shown in Fig. 1. A listing of all possible formeme values is given in Table 1.
Verbal formemes remain quite consistent in both languages, except for the greater range of forms in English (Czech uses adjectives or nouns instead of gerunds and verbal attributes). Nominal formemes differ more significantly: Czech is a free-word order language with rich morphology, where declension is important to syntactic relations&#8212;case is therefore included in formemes. As English makes its syntactic relations visible rather with word-order than with morphology, English formemes indicate the syntactic position instead. The same holds for adjectival complements to verbs. Posession is expressed mostly using nouns in English and adjectives in Czech, which is also reflected in formemes.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>A formeme is a concise description of relevant morpho-syntactic features of a node in a tectogrammatical tree (deep syntactic tree whose nodes usually correspond to content words).</text>
              <doc_id>50</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The general shape of revised Czech and English formemes, as implemented within the Treex 4 NLP framework (Popel and &#381;abokrtsk&#253;, 2010) for the TectoMT system, consists of three main parts:</text>
              <doc_id>51</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1.</text>
              <doc_id>52</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Syntactic part-of-speech.</text>
              <doc_id>53</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>5 The number of syntactic parts-of-speech is very low, as only content words are used on the deep layer and the categories of pronouns and numerals have been divided under nouns and adjectives according to syntactic behavior (&#352;ev&#269;&#237;kov&#225;-Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006).</text>
              <doc_id>54</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The possible values are v for verbs, n for nouns, adj for adjectives, and adv for adverbs.</text>
              <doc_id>55</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>4 http://ufal.mff.cuni.cz/treex/,</text>
              <doc_id>56</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>https://metacpan.org/module/Treex 5 Cf. Section 5.2 for details.</text>
              <doc_id>57</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2.</text>
              <doc_id>58</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Subordinate conjunction/preposition.</text>
              <doc_id>59</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Applies only to formemes of prepositional phrases and subordinate clauses introduced by a conjunction and contains the respective conjunction or preposition; e.g. if, on or in_case_of.</text>
              <doc_id>60</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>3.</text>
              <doc_id>61</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Form.</text>
              <doc_id>62</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This part represents the morphosyntactic form of the node in question and depends on the part-of-speech (see Table 1).</text>
              <doc_id>63</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The two or three parts are concatenated into a human-readable string to facilitate usage in hand-written rules as well as statistical systems (&#381;abokrtsk&#253;, 2010), producing values such as v:inf, v:if+fin or n:into+X.</text>
              <doc_id>64</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Formeme values of nodes corresponding to uninflected words are atomic.</text>
              <doc_id>65</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Formemes are detected by rule-based modules operating on deep and surface trees.</text>
              <doc_id>66</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Example deep syntax trees annotated with formemes are shown in Fig.</text>
              <doc_id>67</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>1.</text>
              <doc_id>68</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>A listing of all possible formeme values is given in Table 1.</text>
              <doc_id>69</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Verbal formemes remain quite consistent in both languages, except for the greater range of forms in English (Czech uses adjectives or nouns instead of gerunds and verbal attributes).</text>
              <doc_id>70</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Nominal formemes differ more significantly: Czech is a free-word order language with rich morphology, where declension is important to syntactic relations&#8212;case is therefore included in formemes.</text>
              <doc_id>71</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>As English makes its syntactic relations visible rather with word-order than with morphology, English formemes indicate the syntactic position instead.</text>
              <doc_id>72</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The same holds for adjectival complements to verbs.</text>
              <doc_id>73</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Posession is expressed mostly using nouns in English and adjectives in Czech, which is also reflected in formemes.</text>
              <doc_id>74</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>5</index>
        <title>5 Recent Markup Improvements</title>
        <text>Our following markup innovations address several issues found in the previous version and aim to adapt the range of values more accurately to the intended applications.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Our following markup innovations address several issues found in the previous version and aim to adapt the range of values more accurately to the intended applications.</text>
              <doc_id>75</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>5.1 General Form Changes</title>
            <text>The relevant preposition and subordinate conjunction nodes had been selected based on their dependency labels; we use a simple part-of-speech tag filter instead in order to minimize the influence of parsing errors and capture more complex prepositions,
&#8727; I.e. infinitives as head of clauses, not infinitives as parts of compound verb forms with finite auxiliary verbs. &#8224; Numbers are traditionally used to mark morphological case in Czech; 1 stands for nominative, 2 for genitive etc. &#8225; Since many prepositions may govern multiple cases in Czech, the case number is necessary.
e.g. in case of. Our revision also allows combining prepositions with all English gerunds and infinitives, preventing a loss of important data.
We also use the lowercased surface form in the middle formeme part instead of lemmas to allow for a more straightforward surface form generation.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The relevant preposition and subordinate conjunction nodes had been selected based on their dependency labels; we use a simple part-of-speech tag filter instead in order to minimize the influence of parsing errors and capture more complex prepositions,</text>
                  <doc_id>76</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8727; I.e. infinitives as head of clauses, not infinitives as parts of compound verb forms with finite auxiliary verbs.</text>
                  <doc_id>77</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>&#8224; Numbers are traditionally used to mark morphological case in Czech; 1 stands for nominative, 2 for genitive etc. &#8225; Since many prepositions may govern multiple cases in Czech, the case number is necessary.</text>
                  <doc_id>78</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>e.g. in case of.</text>
                  <doc_id>79</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Our revision also allows combining prepositions with all English gerunds and infinitives, preventing a loss of important data.</text>
                  <doc_id>80</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We also use the lowercased surface form in the middle formeme part instead of lemmas to allow for a more straightforward surface form generation.</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>5.2 Introducing Syntactic Part-of-Speech</title>
            <text>Formemes originally contained the semantic part-ofspeech (sempos) (Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006) as their first part. We replaced it with a syntactic part-of-speech (syntpos), since it proved complicated to assign sempos reliably by a rule-based module and morpho-syntactic behavior is more relevant to formemes than semantics.
The syntpos is assigned in two steps:
1. A preliminary syntpos is selected, using our categorization based on the part-of-speech tag and lemma.
2. The final syntpos is selected according to the syntactic position of the node, addressing nominal usage of adjectives and cardinal numerals (see Sections 5.4 and 5.5).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Formemes originally contained the semantic part-ofspeech (sempos) (Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006) as their first part.</text>
                  <doc_id>82</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We replaced it with a syntactic part-of-speech (syntpos), since it proved complicated to assign sempos reliably by a rule-based module and morpho-syntactic behavior is more relevant to formemes than semantics.</text>
                  <doc_id>83</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The syntpos is assigned in two steps:</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1.</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A preliminary syntpos is selected, using our categorization based on the part-of-speech tag and lemma.</text>
                  <doc_id>86</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The final syntpos is selected according to the syntactic position of the node, addressing nominal usage of adjectives and cardinal numerals (see Sections 5.4 and 5.5).</text>
                  <doc_id>88</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>5.3 Capturing Czech Nominal Attributes</title>
            <text>Detecting the attributive usage of nouns is straightforward for English, where any noun depending directly on another noun is considered an attribute. In Czech, one needs to distinguish case-congruent attributes from others that have a fixed case. We aimed at assigning the n:attr formeme only in the former case and thus replaced the original method based on word order with a less error-prone one based on congruency and named entity recognition.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Detecting the attributive usage of nouns is straightforward for English, where any noun depending directly on another noun is considered an attribute.</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In Czech, one needs to distinguish case-congruent attributes from others that have a fixed case.</text>
                  <doc_id>90</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We aimed at assigning the n:attr formeme only in the former case and thus replaced the original method based on word order with a less error-prone one based on congruency and named entity recognition.</text>
                  <doc_id>91</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>5.4 Numerals: Distinguishing Usage and Correcting Czech Case</title>
            <text>The new formemes now distinguish adjectival and nominal usage of cardinal numerals (cf. also Section 5.2), e.g. the number in 5 potatoes is now assigned the adj:attr formeme, whereas Apollo 11 is given n:attr. The new situation is analogous in Czech, with nominal usages of numerals having their morphological case marked in formemes.
To reduce data sparsity in the new formemes version, we counter the inconsistent syntactic behavior of Czech cardinal numerals, where 1-4 behave like
The word ban&#225;n is in genitive (n:2), but would have an accusative (n:4) form if the numeral behaved like an adjective.
adjectives but other numerals behave like nouns and shift their semantically governing noun to the position of a genitive attribute. An example of this change is given in Fig. 2.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The new formemes now distinguish adjectival and nominal usage of cardinal numerals (cf. also Section 5.2), e.g. the number in 5 potatoes is now assigned the adj:attr formeme, whereas Apollo 11 is given n:attr.</text>
                  <doc_id>92</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The new situation is analogous in Czech, with nominal usages of numerals having their morphological case marked in formemes.</text>
                  <doc_id>93</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To reduce data sparsity in the new formemes version, we counter the inconsistent syntactic behavior of Czech cardinal numerals, where 1-4 behave like</text>
                  <doc_id>94</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The word ban&#225;n is in genitive (n:2), but would have an accusative (n:4) form if the numeral behaved like an adjective.</text>
                  <doc_id>95</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>adjectives but other numerals behave like nouns and shift their semantically governing noun to the position of a genitive attribute.</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>An example of this change is given in Fig.</text>
                  <doc_id>97</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>2.</text>
                  <doc_id>98</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>4</index>
            <title>5.5 Adjectives: Nominal Usage and Case</title>
            <text>The new formemes address the usage of adjectives in the syntactic position of nouns (cf. Section 5.2), which occurs only rarely, thus preventing sparse values, namely in these syntactic positions:
&#8226; The subject. We replaced the originally assigned adj:compl value, which was impossible to tell from adjectival objects, with the formeme a noun would have in the same position, e.g. in the sentence Many of them were late, the subject many is assigned n:subj. &#8226; Prepositional phrases. Syntactic behavior of adjectives is identical to nouns here; we thus assign them the formeme values a noun would receive in the same position, e.g. n:of+X instead of adj:of+X in He is one of the best at school.
In Czech, we detect nominal usage of adjectives in verbal direct objects as well, employing largecoverage valency lexicons (Lopatkov&#225; et al., 2008; Haji&#269; et al., 2003). Instead of assigning the compl value in Czech, our formemes revision includes the case of adjectival complements, which depends on the valency of the respective verb.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The new formemes address the usage of adjectives in the syntactic position of nouns (cf. Section 5.2), which occurs only rarely, thus preventing sparse values, namely in these syntactic positions:</text>
                  <doc_id>99</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; The subject.</text>
                  <doc_id>100</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We replaced the originally assigned adj:compl value, which was impossible to tell from adjectival objects, with the formeme a noun would have in the same position, e.g. in the sentence Many of them were late, the subject many is assigned n:subj.</text>
                  <doc_id>101</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>&#8226; Prepositional phrases.</text>
                  <doc_id>102</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Syntactic behavior of adjectives is identical to nouns here; we thus assign them the formeme values a noun would receive in the same position, e.g. n:of+X instead of adj:of+X in He is one of the best at school.</text>
                  <doc_id>103</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Czech, we detect nominal usage of adjectives in verbal direct objects as well, employing largecoverage valency lexicons (Lopatkov&#225; et al., 2008; Haji&#269; et al., 2003).</text>
                  <doc_id>104</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Instead of assigning the compl value in Czech, our formemes revision includes the case of adjectival complements, which depends on the valency of the respective verb.</text>
                  <doc_id>105</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>5</index>
            <title>5.6 Mutual Information Across Languages</title>
            <text>The changes described above have been motivated not only by theoretical linguistic description of the languages in question, but also by the intended usage within the TectoMT translation system. Instead
of retraining the translation model after each change, we devised a simpler and faster estimate to measure the asset of our innovations: using Mutual Information (MI) (Manning and Sch&#252;tze, 1999, p. 66) of formemes in Czech and English trees.
We expect that an inter-language MI increase will lead to lower noise in formeme-to-formeme translation dictionary (Bojar et al., 2009, cf. Section 3.2), thus achieving higher MT output quality. Using the analysis pipeline from CzEng1.0, we measured the inter-language MI on sentences from the Prague Czech-English Dependency Treebank (PCEDT) 2.0 (Bojar et al., 2012a). The overall results show an MI increase from 1.598 to 1.687 (Bojar et al., 2012b). Several proposed markup changes have been discarded as they led to an inter-language MI drop; e.g. removing the v:rc relative clause formeme or merging the v:attr and adj:attr values in English.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The changes described above have been motivated not only by theoretical linguistic description of the languages in question, but also by the intended usage within the TectoMT translation system.</text>
                  <doc_id>106</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Instead</text>
                  <doc_id>107</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of retraining the translation model after each change, we devised a simpler and faster estimate to measure the asset of our innovations: using Mutual Information (MI) (Manning and Sch&#252;tze, 1999, p.</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>66) of formemes in Czech and English trees.</text>
                  <doc_id>109</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We expect that an inter-language MI increase will lead to lower noise in formeme-to-formeme translation dictionary (Bojar et al., 2009, cf. Section 3.2), thus achieving higher MT output quality.</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Using the analysis pipeline from CzEng1.0, we measured the inter-language MI on sentences from the Prague Czech-English Dependency Treebank (PCEDT) 2.0 (Bojar et al., 2012a).</text>
                  <doc_id>111</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The overall results show an MI increase from 1.598 to 1.687 (Bojar et al., 2012b).</text>
                  <doc_id>112</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Several proposed markup changes have been discarded as they led to an inter-language MI drop; e.g. removing the v:rc relative clause formeme or merging the v:attr and adj:attr values in English.</text>
                  <doc_id>113</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>6</index>
        <title>6 Experimental Usage</title>
        <text>We list here our experiments with the newly developed annotation: an NLG experiment aimed at assessing the impact of formemes on the synthesis phase of the TectoMT system, and the usage in the English-Czech MT as a whole.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We list here our experiments with the newly developed annotation: an NLG experiment aimed at assessing the impact of formemes on the synthesis phase of the TectoMT system, and the usage in the English-Czech MT as a whole.</text>
              <doc_id>114</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>6.1 Czech Synthesis</title>
            <text>The synthesis phase of the TectoMT system relies heavily on the information included in formemes, as its rule-based blocks use solely formemes and grammar rules to gradually change a deep tree node into a surface subtree.
To directly measure the suitability of our changes for the synthesis stage of the TectoMT system, we used a Czech-to-Czech round trip&#8212;deep analysis of Czech PDT 2.0 development set sentences using the CzEng 1.0 pipeline (Bojar et al., 2012b), followed directly by the synthesis part of the TectoMT system. The results were evaluated using the BLEU metric (Papineni et al., 2002) with the original sentences as reference; they indicate a higher suitability of the new formemes for deep Czech synthesis (see Table 2).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The synthesis phase of the TectoMT system relies heavily on the information included in formemes, as its rule-based blocks use solely formemes and grammar rules to gradually change a deep tree node into a surface subtree.</text>
                  <doc_id>115</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To directly measure the suitability of our changes for the synthesis stage of the TectoMT system, we used a Czech-to-Czech round trip&#8212;deep analysis of Czech PDT 2.0 development set sentences using the CzEng 1.0 pipeline (Bojar et al., 2012b), followed directly by the synthesis part of the TectoMT system.</text>
                  <doc_id>116</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results were evaluated using the BLEU metric (Papineni et al., 2002) with the original sentences as reference; they indicate a higher suitability of the new formemes for deep Czech synthesis (see Table 2).</text>
                  <doc_id>117</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>6.2 English-Czech Machine Translation</title>
            <text>To measure the influence of the presented formeme revision on the translation quality, we compared
two translation scenarios&#8212;one using the original formemes and the second using the revised formemes in the formeme-to-formeme translation model. Due to time reasons, we were able to train both translation models only on 1/2 of the CzEng 1.0 training data.
The results in Table 3 demonstrate a slight 6 BLEU gain when using the revised formemes version. The gain is expected to be greater if several rule-based modules of the transfer phase are adapted to the revisions.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>To measure the influence of the presented formeme revision on the translation quality, we compared</text>
                  <doc_id>118</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>two translation scenarios&#8212;one using the original formemes and the second using the revised formemes in the formeme-to-formeme translation model.</text>
                  <doc_id>119</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Due to time reasons, we were able to train both translation models only on 1/2 of the CzEng 1.0 training data.</text>
                  <doc_id>120</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The results in Table 3 demonstrate a slight 6 BLEU gain when using the revised formemes version.</text>
                  <doc_id>121</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The gain is expected to be greater if several rule-based modules of the transfer phase are adapted to the revisions.</text>
                  <doc_id>122</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>7</index>
        <title>7 Conclusion and Further Work</title>
        <text>We have presented a systematic and theoretically supported revision of a surface morpho-syntactic markup within a deep dependency annotation scenario, designed to facilitate the TectoMT transfer phase. Our first practical experiments proved the merits of our innovations in the tasks of Czech synthesis and deep structural MT as a whole. We have also experimented with formemes in the functor assignment (semantic role labelling) task and gained moderate improvements (ca. 1-1.5% accuracy). In future, we intend to tune the rule-based parts of our MT transfer for the new version of formemes and examine further possibilities of data sparsity reduction (e.g. by merging synonymous formemes). We are also planning to create formeme annotation modules for further languages to widen the range of language pairs used in the TectoMT system. 6 Significant at 90% level using pairwise bootstrap resampling test (Koehn, 2004).</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We have presented a systematic and theoretically supported revision of a surface morpho-syntactic markup within a deep dependency annotation scenario, designed to facilitate the TectoMT transfer phase.</text>
              <doc_id>123</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our first practical experiments proved the merits of our innovations in the tasks of Czech synthesis and deep structural MT as a whole.</text>
              <doc_id>124</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We have also experimented with formemes in the functor assignment (semantic role labelling) task and gained moderate improvements (ca.</text>
              <doc_id>125</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>1-1.5% accuracy).</text>
              <doc_id>126</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In future, we intend to tune the rule-based parts of our MT transfer for the new version of formemes and examine further possibilities of data sparsity reduction (e.g. by merging synonymous formemes).</text>
              <doc_id>127</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We are also planning to create formeme annotation modules for further languages to widen the range of language pairs used in the TectoMT system.</text>
              <doc_id>128</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>6 Significant at 90% level using pairwise bootstrap resampling test (Koehn, 2004).</text>
              <doc_id>129</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: A listing of all possible formeme values, indicating their usage in Czech, English or both languages. &#8220;P+&#8221; denotes the (lowercased) surface form of a preposition or a subordinate conjunction. Round brackets denote optional parts, square brackets denote a set of alternatives.</caption>
        <reference_text></reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>Formeme</cell>
              <cell>Language</cell>
              <cell>Definition</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>v:(P+)fin</cell>
              <cell>both</cell>
              <cell>Verbs as heads of finite clauses</cell>
            </row>
            <row>
              <cell>v:rc</cell>
              <cell>both</cell>
              <cell>Verbs as heads of relative clauses</cell>
            </row>
            <row>
              <cell>v:(P+)inf</cell>
              <cell>both</cell>
              <cell>Infinitive clauses; typically with the particle to in English &#8727;</cell>
            </row>
            <row>
              <cell>v:(P+)ger</cell>
              <cell>EN</cell>
              <cell>Gerunds, e.g. I like reading (v:ger), but I am tired of arguing (v:of+ger).</cell>
            </row>
            <row>
              <cell>v:attr</cell>
              <cell>EN</cell>
              <cell>Present or past participles (i.e. -ing or -ed forms) in the attributive syntactic
position, e.g. Striking (v:attr) teachers hate bored (v:attr) students.</cell>
            </row>
            <row>
              <cell>n:[1..7]</cell>
              <cell>CS</cell>
              <cell>Bare nouns; the numbers indicate morphological case &#8224;</cell>
            </row>
            <row>
              <cell>n:X</cell>
              <cell>CS</cell>
              <cell>Bare nouns that cannot be inflected</cell>
            </row>
            <row>
              <cell>n:subj</cell>
              <cell>EN</cell>
              <cell>Nouns in the subject position (i.e. in front of the main verb of the clause)</cell>
            </row>
            <row>
              <cell>n:obj</cell>
              <cell>EN</cell>
              <cell>Nouns in the object position (i.e. following the verb with no preposition)</cell>
            </row>
            <row>
              <cell>n:obj1, n:obj2</cell>
              <cell>EN</cell>
              <cell>Nouns in the object position; distinguishing the two objects of ditransitive
verbs (e.g. give, consider)</cell>
            </row>
            <row>
              <cell>n:adv</cell>
              <cell>EN</cell>
              <cell>Nouns in an adverbial position, e.g. The sales went up by 1 % last month</cell>
            </row>
            <row>
              <cell>n:P+X</cell>
              <cell>EN</cell>
              <cell>Prepositional phrases</cell>
            </row>
            <row>
              <cell>n:P+[1..7]</cell>
              <cell>CS</cell>
              <cell>Prepositional phrases; the preposition surface form is combined with the required
case &#8225;</cell>
            </row>
            <row>
              <cell>n:attr</cell>
              <cell>both</cell>
              <cell>Nominal attributes, e.g. insurance company or president Smith in English
and prezident Smith in Czech</cell>
            </row>
            <row>
              <cell>n:poss</cell>
              <cell>EN</cell>
              <cell>English possessive pronouns and nouns with the &#8217;s suffix</cell>
            </row>
            <row>
              <cell>adj:attr</cell>
              <cell>both</cell>
              <cell>Adjectival attributes (Czech inflection forms need not be stored thanks to
congruency with the parent noun)</cell>
            </row>
            <row>
              <cell>adj:compl</cell>
              <cell>EN</cell>
              <cell>Direct adjectival complements to verbs</cell>
            </row>
            <row>
              <cell>adj:[1..7]</cell>
              <cell>CS</cell>
              <cell>Direct adjectival complements to verbs (morphological case must be stored
in Czech, as it is determined by valency)</cell>
            </row>
            <row>
              <cell>adj:poss</cell>
              <cell>CS</cell>
              <cell>Czech possesive adjectives and pronouns; a counterpart to English n:poss</cell>
            </row>
            <row>
              <cell>adv</cell>
              <cell>both</cell>
              <cell>Adverbs (not inflected, can take no prepositions etc.)</cell>
            </row>
            <row>
              <cell>x</cell>
              <cell>both</cell>
              <cell>Coordinating conjunctions, other uninflected words</cell>
            </row>
            <row>
              <cell>drop</cell>
              <cell>both</cell>
              <cell>Deep tree nodes which do not appear on the surface (e.g. pro-drop pronouns)</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TET</source>
        <caption>Table 2: A comparison of formeme versions in Czech-to- Czech round trip.</caption>
        <reference_text></reference_text>
        <page_num>5</page_num>
        <head>
          <rows>
            <row>
              <cell>Version</cell>
              <cell>BLEU</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Original formemes</cell>
              <cell>0.6818</cell>
            </row>
            <row>
              <cell>Revised formemes</cell>
              <cell>0.7092</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TableSeer</source>
        <caption>Table 2: A comparison of formeme versions in Czech-to- Czech round trip.#@#@Table 3: A comparison of formeme versions in Englishto-Czech TectoMT translation on the WMT12 test set.</caption>
        <reference_text>None</reference_text>
        <page_num>6</page_num>
        <head>
          <rows>
            <row>
              <cell>Version</cell>
              <cell>BLEU</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Original formemes</cell>
              <cell>0.1190</cell>
            </row>
            <row>
              <cell>Revised formemes</cell>
              <cell>0.1199</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>O Bojar</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>CzEng 0.9: Large Parallel Treebank with Rich Annotation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>O Bojar</author>
          <author>D Mare&#269;ek</author>
          <author>V Nov&#225;k</author>
          <author>M Popel</author>
          <author>J Pt&#225;&#269;ek</author>
          <author>J Rou&#353;</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>English-Czech MT in</title>
        <publication>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</publication>
        <pages>125--129</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>O Bojar</author>
          <author>J Haji&#269;</author>
          <author>E Haji&#269;ov&#225;</author>
          <author>J Panevov&#225;</author>
          <author>P Sgall</author>
          <author>S Cinkov&#225;</author>
          <author>E Fu&#269;&#237;kov&#225;</author>
          <author>M Mikulov&#225;</author>
          <author>P Pajas</author>
          <author>J Popelka</author>
          <author>J Semeck&#253;</author>
          <author>J &#352;indlerov&#225;</author>
          <author>J &#352;t&#283;p&#225;nek</author>
          <author>J Toman</author>
          <author>Z Ure&#353;ov&#225;</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>3</id>
        <authors/>
        <title>Announcing Prague Czech-English Dependency Treebank 2.0.</title>
        <publication>In Proceedings of LREC 2012,</publication>
        <pages>None</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>O Bojar</author>
          <author>Z &#381;abokrtsk&#253;</author>
          <author>O Du&#353;ek</author>
          <author>P Galu&#353;&#269;&#225;kov&#225;</author>
          <author>M Majli&#353;</author>
          <author>D Mare&#269;ek</author>
          <author>J Mar&#353;&#237;k</author>
          <author>M Nov&#225;k</author>
          <author>M Popel</author>
          <author>A Tamchyna</author>
        </authors>
        <title>ELRA, European Language Resources Association. In print.</title>
        <publication>2012b. The Joy of Parallelism with CzEng 1.0. In Proceedings of LREC 2012,</publication>
        <pages>None</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>J Haji&#269;</author>
          <author>J Panevov&#225;</author>
          <author>Z Ure&#353;ov&#225;</author>
          <author>A B&#233;mov&#225;</author>
          <author>V Kol&#225;rov&#225;</author>
          <author>P Pajas</author>
        </authors>
        <title>PDT-VALLEX: Creating a large-coverage valency lexicon for treebank annotation.</title>
        <publication>In Proceedings of The Second Workshop on Treebanks and Linguistic Theories,</publication>
        <pages>57--68</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>J Haji&#269;</author>
          <author>J Panevov&#225;</author>
          <author>E Haji&#269;ov&#225;</author>
          <author>P Sgall</author>
          <author>P Pajas</author>
          <author>J &#352;t&#283;p&#225;nek</author>
          <author>J Havelka</author>
          <author>M Mikulov&#225;</author>
          <author>Z &#381;abokrtsk&#253;</author>
          <author>M &#352;ev&#269;&#237;kov&#225;-Raz&#237;mov&#225;</author>
        </authors>
        <title>None</title>
        <publication>Prague Dependency Treebank 2.0. CD-ROM LDC2006T01, LDC,</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>G Helbig</author>
          <author>W Schenkel</author>
        </authors>
        <title>None</title>
        <publication>W&#246;rterbuch zur Valenz und Distribution deutscher Verben. VEB Bibliographisches Institut,</publication>
        <pages>None</pages>
        <date>1969</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>P Koehn</author>
        </authors>
        <title>Statistical Significance Tests for Machine Translation Evaluation.</title>
        <publication>In Proceedings of EMNLP 2004,</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>M Lopatkov&#225;</author>
          <author>Z &#381;abokrtsk&#253;</author>
          <author>V Kettnerov&#225;</author>
          <author>K Skwarska</author>
        </authors>
        <title>Valen&#269;n&#237; slovn&#237;k &#269;esk&#253;ch sloves.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>C D Manning</author>
          <author>H Sch&#252;tze</author>
        </authors>
        <title>Foundations of statistical natural language processing.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1999</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>D Marcu</author>
          <author>W Wang</author>
          <author>A Echihabi</author>
          <author>K Knight</author>
        </authors>
        <title>SPMT: Statistical machine translation with syntactified target language phrases.</title>
        <publication>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>44--52</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>D Mare&#269;ek</author>
          <author>M Popel</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Maximum entropy translation model in dependency-based MT framework.</title>
        <publication>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and Metrics (MATR),</publication>
        <pages>201--206</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>A Menezes</author>
          <author>S D Richardson</author>
        </authors>
        <title>A best-first alignment algorithm for automatic extraction of transfer mappings from bilingual corpora.</title>
        <publication>In Proceedings of the workshop on Data-driven methods in machine translation - Volume 14, DMMT &#8217;01,</publication>
        <pages>1--8</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>K Papineni</author>
          <author>S Roukos</author>
          <author>T Ward</author>
          <author>W J Zhu</author>
        </authors>
        <title>BLEU: a method for automatic evaluation of machine translation.</title>
        <publication>In Proceedings of the 40th annual meeting on association for computational linguistics,</publication>
        <pages>311--318</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>M Popel</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>None</title>
        <publication>TectoMT: modular NLP framework. Advances in Natural Language Processing,</publication>
        <pages>293--304</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>M Popel</author>
          <author>D Mare&#269;ek</author>
          <author>N Green</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Influence of parser choice on dependency-based MT.</title>
        <publication>Proceedings of the Sixth Workshop on Statistical Machine Translation,</publication>
        <pages>433--439</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>J Pt&#225;&#269;ek</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Synthesis of Czech sentences from tectogrammatical trees.</title>
        <publication>In Text, Speech and Dialogue,</publication>
        <pages>221--228</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>C Quirk</author>
          <author>A Menezes</author>
          <author>C Cherry</author>
        </authors>
        <title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
        <publication>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</publication>
        <pages>271--279</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>M Raz&#237;mov&#225;</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Annotation of grammatemes in the Prague Dependency Treebank 2.0.</title>
        <publication>In Proceedings of the LREC 2006 Workshop on Annotation Science,</publication>
        <pages>12--19</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>M &#352;ev&#269;&#237;kov&#225;-Raz&#237;mov&#225;</author>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Systematic parameterized description of pro-forms in the Prague Dependency Treebank 2.0.</title>
        <publication>Proceedings of the Fifth Workshop on Treebanks and Linguistic Theories (TLT),</publication>
        <pages>175--186</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>P Sgall</author>
          <author>E Haji&#269;ov&#225;</author>
          <author>J Panevov&#225;</author>
          <author>J Mey</author>
        </authors>
        <title>The meaning of the sentence in its semantic and pragmatic aspects.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1986</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>P Sgall</author>
        </authors>
        <title>Generativn&#237; popis jazyka a &#269;esk&#225; deklinace.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1967</date>
      </reference>
      <reference>
        <id>23</id>
        <authors>
          <author>Z Ure&#353;ov&#225;</author>
        </authors>
        <title>Building the PDT-VALLEX valency lexicon.</title>
        <publication>In On-line proceedings of the fifth Corpus Linguistics</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>24</id>
        <authors>
          <author>J Pt&#225;&#269;ek &#381;abokrtsk&#253;</author>
          <author>P Pajas</author>
        </authors>
        <title>TectoMT: highly modular MT system with tectogrammatics used as transfer layer.</title>
        <publication>In Proceedings of the Third Workshop on Statistical Machine Translation, StatMT &#8217;08,</publication>
        <pages>167--170</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>25</id>
        <authors>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>Valency Lexicon of Czech Verbs.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>26</id>
        <authors>
          <author>Z &#381;abokrtsk&#253;</author>
        </authors>
        <title>From Treebanking to Machine Translation. Habilitation thesis,</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>27</id>
        <authors>
          <author>Z &#381;abokrtsk&#253;</author>
          <author>M Popel</author>
        </authors>
        <title>Hidden Markov Tree Model in Dependency-based Machine Translation.</title>
        <publication>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</publication>
        <pages>145--148</pages>
        <date>2009</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Bojar and &#381;abokrtsk&#253;, 2009</string>
        <sentence_id>7062</sentence_id>
        <char_offset>94</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Bojar et al., 2009</string>
        <sentence_id>7043</sentence_id>
        <char_offset>207</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>1</reference_id>
        <string>Bojar et al., 2009</string>
        <sentence_id>7123</sentence_id>
        <char_offset>116</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7024</sentence_id>
        <char_offset>188</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7061</sentence_id>
        <char_offset>103</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7124</sentence_id>
        <char_offset>153</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7125</sentence_id>
        <char_offset>61</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7129</sentence_id>
        <char_offset>221</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>5</reference_id>
        <string>Haji&#269; et al., 2003</string>
        <sentence_id>7029</sentence_id>
        <char_offset>46</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>5</reference_id>
        <string>Haji&#269; et al., 2003</string>
        <sentence_id>7117</sentence_id>
        <char_offset>148</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>6</reference_id>
        <string>Haji&#269; et al., 2006</string>
        <sentence_id>7017</sentence_id>
        <char_offset>250</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>7</reference_id>
        <string>Helbig and Schenkel (1969)</string>
        <sentence_id>7028</sentence_id>
        <char_offset>146</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>9</reference_id>
        <string>Lopatkov&#225; et al., 2008</string>
        <sentence_id>7117</sentence_id>
        <char_offset>124</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>10</reference_id>
        <string>Manning and Sch&#252;tze, 1999</string>
        <sentence_id>7121</sentence_id>
        <char_offset>168</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>11</reference_id>
        <string>Marcu et al., 2006</string>
        <sentence_id>7031</sentence_id>
        <char_offset>186</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>12</reference_id>
        <string>Mare&#269;ek et al., 2010</string>
        <sentence_id>7056</sentence_id>
        <char_offset>99</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>13</reference_id>
        <string>Menezes and Richardson, 2001</string>
        <sentence_id>7031</sentence_id>
        <char_offset>105</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>14</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>7130</sentence_id>
        <char_offset>50</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>15</reference_id>
        <string>Popel and &#381;abokrtsk&#253;, 2010</string>
        <sentence_id>7065</sentence_id>
        <char_offset>106</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>16</reference_id>
        <string>Popel et al., 2011</string>
        <sentence_id>7041</sentence_id>
        <char_offset>73</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>17</reference_id>
        <string>Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006</string>
        <sentence_id>7023</sentence_id>
        <char_offset>44</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>17</reference_id>
        <string>Pt&#225;&#269;ek and &#381;abokrtsk&#253;, 2006</string>
        <sentence_id>7032</sentence_id>
        <char_offset>70</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>18</reference_id>
        <string>Quirk et al., 2005</string>
        <sentence_id>7031</sentence_id>
        <char_offset>166</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>19</reference_id>
        <string>Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006</string>
        <sentence_id>7068</sentence_id>
        <char_offset>236</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>19</reference_id>
        <string>Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006</string>
        <sentence_id>7095</sentence_id>
        <char_offset>67</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>20</reference_id>
        <string>&#352;ev&#269;&#237;kov&#225;-Raz&#237;mov&#225; and &#381;abokrtsk&#253;, 2006</string>
        <sentence_id>7068</sentence_id>
        <char_offset>226</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>21</reference_id>
        <string>Sgall et al., 1986</string>
        <sentence_id>7017</sentence_id>
        <char_offset>162</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>21</reference_id>
        <string>Sgall et al., 1986</string>
        <sentence_id>7055</sentence_id>
        <char_offset>75</char_offset>
      </citation>
      <citation>
        <id>28</id>
        <reference_id>22</reference_id>
        <string>Sgall, 1967</string>
        <sentence_id>7055</sentence_id>
        <char_offset>62</char_offset>
      </citation>
      <citation>
        <id>29</id>
        <reference_id>23</reference_id>
        <string>Ure&#353;ov&#225;, 2009</string>
        <sentence_id>7029</sentence_id>
        <char_offset>133</char_offset>
      </citation>
      <citation>
        <id>30</id>
        <reference_id>25</reference_id>
        <string>&#381;abokrtsk&#253; (2005)</string>
        <sentence_id>7030</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>31</id>
        <reference_id>26</reference_id>
        <string>&#381;abokrtsk&#253;, 2010</string>
        <sentence_id>7043</sentence_id>
        <char_offset>227</char_offset>
      </citation>
      <citation>
        <id>32</id>
        <reference_id>26</reference_id>
        <string>&#381;abokrtsk&#253;, 2010</string>
        <sentence_id>7049</sentence_id>
        <char_offset>316</char_offset>
      </citation>
      <citation>
        <id>33</id>
        <reference_id>26</reference_id>
        <string>&#381;abokrtsk&#253;, 2010</string>
        <sentence_id>7065</sentence_id>
        <char_offset>116</char_offset>
      </citation>
      <citation>
        <id>34</id>
        <reference_id>26</reference_id>
        <string>&#381;abokrtsk&#253;, 2010</string>
        <sentence_id>7078</sentence_id>
        <char_offset>143</char_offset>
      </citation>
      <citation>
        <id>35</id>
        <reference_id>27</reference_id>
        <string>&#381;abokrtsk&#253; and Popel, 2009</string>
        <sentence_id>7056</sentence_id>
        <char_offset>152</char_offset>
      </citation>
    </citations>
  </content>
</document>
