<PAPER>
  <FILENO/>
  <TITLE>Combining Multi-Engine Translations with Moses</TITLE>
  <AUTHORS/>
  <ABSTRACT>
    <A-S ID="S-40637">We present a simple method for generating translations with the Moses toolkit (<REF ID="R-06" RPTR="12">Koehn et al., 2007</REF>) from existing hypotheses produced by other translation engines.</A-S>
    <A-S ID="S-40638">As the structures underlying these translation engines are not known, an evaluationbased strategy is applied to select systems for combination.</A-S>
    <A-S ID="S-40639">The experiments show promising improvements in terms of BLEU.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-40640">With the wealth of machine translation systems available nowadays (many of them online and for free), it makes increasing sense to investigate clever ways of combining them.</S>
        <S ID="S-40641">Obviously, the main objective lies in finding out how to integrate the respective advantages of different approaches: Statistical machine translation (SMT) and rulebased machine translation (RBMT) systems often have complementary characteristics.</S>
        <S ID="S-40642">Previous work on building hybrid systems includes, among others, approaches using reranking, regeneration with an SMT decoder (<REF ID="R-02" RPTR="3">Eisele et al., 2008</REF>; <REF ID="R-01" RPTR="1">Chen et al., 2007</REF>), and confusion networks (<REF ID="R-08" RPTR="16">Matusov et al., 2006</REF>; <REF ID="R-12" RPTR="20">Rosti et al., 2007</REF>; <REF ID="R-04" RPTR="10">He et al., 2008</REF>).</S>
        <S ID="S-40643">The approach by (<REF ID="R-02" RPTR="4">Eisele et al., 2008</REF>) aimed specifically at filling lexical gaps in an SMT system with information from a number of RBMT systems.</S>
        <S ID="S-40644">The output of the RBMT engines was word-aligned with the input, yielding a total of seven phrase tables which where simply concatenated to expand the phrase table constructed from the training corpus.</S>
        <S ID="S-40645">This approach differs from the confusion network approaches mainly in that the final hypotheses do not necessarily follow any of the input translations as the skeleton.</S>
        <S ID="S-40646">On the other hand, it emphasizes that the additional translations should be produced by RBMT systems with lexicons that cannot be learned from the data.</S>
      </P>
      <P>
        <S ID="S-40647">The present work continues on the same track as the paper mentioned above but implements a number of important changes, most prominently a relaxation of the restrictions on the number and type of input systems.</S>
        <S ID="S-40648">These differences are described in more detail in Section 2.</S>
        <S ID="S-40649">Section 3 explains the implementation of our system and Section 4 its application in a number of experiments.</S>
        <S ID="S-40650">Finally, Section 5 concludes this paper with a summary and some thoughts on future work.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Integrating Multiple Systems of Unknown Type and Quality</HEADER>
      <P>
        <S ID="S-40651">When comparing (<REF ID="R-02" RPTR="5">Eisele et al., 2008</REF>) to the present work, our proposal is more general in a way that the requirement for knowledge about the systems is minimum.</S>
        <S ID="S-40652">The types and the identities of the participated systems are assumed unknown.</S>
        <S ID="S-40653">Accordingly, we are not able to restrict ourselves to a certain class of systems as (<REF ID="R-02" RPTR="6">Eisele et al., 2008</REF>) did.</S>
        <S ID="S-40654">We rely on a standard phrase-based SMT framework to extract the valuable pieces from the system outputs.</S>
        <S ID="S-40655">These extracted segments are also used to improve an existing SMT system that we have access to.</S>
      </P>
      <P>
        <S ID="S-40656">While (<REF ID="R-02" RPTR="7">Eisele et al., 2008</REF>) included translations from all of a fixed number of RBMT systems and added one feature to the translation model for each system, integrating all given system outputs in this way in our case could expand the search space tremendously.</S>
        <S ID="S-40657">Meanwhile, we cannot rely on the assumption that all candidate systems actually have the potential to improve our baseline.</S>
        <S ID="S-40658">This implies the need for a first step of system selection where the best candidate systems are identified and a limited number of them is chosen to be included in the combination.</S>
        <S ID="S-40659">Our approach would not work without a small set of tuning data being available so that we can evaluate the systems for later selection and adjust the weights of our systems.</S>
        <S ID="S-40660">Such tuning data is included in this year&#8217;s</S>
      </P>
      <P>
        <S ID="S-40661">task.</S>
      </P>
      <P>
        <S ID="S-40662">In this paper, we use the Moses decoder to construct translations from the given system outputs.</S>
        <S ID="S-40663">We mainly propose two slightly different ways: One is to construct translation models solely from the given translations and the other is to extend an existing translation model with these additional translations.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Implementation</HEADER>
      <P>
        <S ID="S-40717">Despite the fact that the output of current MT systems is usually not comparable in quality to human translations, the machine-generated translations are nevertheless &#8220;parallel&#8221; to the input so that it is straightforward to construct a translation model from data of this kind.</S>
        <S ID="S-40718">This is the spirit behind our method for combining multiple translations.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Direct combination</HEADER>
        <P>
          <S ID="S-40664">Clearly, for the same source sentence, we expect to have different translations from different translation systems, just like we would expect from human translators.</S>
          <S ID="S-40665">Also, every system may have its own advantages.</S>
          <S ID="S-40666">We break these translations into smaller units and hope to be able to select the best ones and form them into a better translation.</S>
          <S ID="S-40667">One single translation of a few thousand sentences is normally inadequate for building a reliable general-purpose SMT system (data sparseness problem).</S>
          <S ID="S-40668">However, in the system combination task, this is no longer an issue as the system only needs to translate sentences within the data set.</S>
          <S ID="S-40669">When more translation engines are available,</S>
        </P>
        <P>
          <S ID="S-40670">the size of this set becomes larger.</S>
          <S ID="S-40671">Hence, we collect translations from all available systems and pair them with the corresponding input text, thus forming a medium-sized &#8220;hypothesis&#8221; corpus.</S>
          <S ID="S-40672">Our system starts processing this corpus with a standard phrase-based SMT setup, using the Moses toolkit (<REF ID="R-06" RPTR="13">Koehn et al., 2007</REF>).</S>
          <S ID="S-40673">The hypothesis corpus is first tokenized and lowercased.</S>
          <S ID="S-40674">Then, we run GIZA++ (<REF ID="R-09" RPTR="17">Och and Ney, 2003</REF>) on the corpus to obtain word alignments in both directions.</S>
          <S ID="S-40675">The phrases are extracted from the intersection of the alignments with the &#8220;grow&#8221; heuristics.</S>
          <S ID="S-40676">In addition, we also generate a reordering model with the default configuration as included in the Moses toolkit.</S>
          <S ID="S-40677">This &#8220;hypothesis&#8221; translation model can already be used by the</S>
        </P>
        <P>
          <S ID="S-40678">Moses decoder together with a language model to perform translations over the corresponding sentence set.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Integration into existing SMT system</HEADER>
        <P>
          <S ID="S-40679">Sometimes, the goal of system combination is not only to produce a translation but also to improve one of the systems.</S>
          <S ID="S-40680">In this paper, we aim at incorporating the additional system outputs to improve an out-of-domain SMT system trained on the Europarl corpus (<REF ID="R-07" RPTR="14">Koehn, 2005</REF>).</S>
          <S ID="S-40681">Our hope is that the additional translation hypotheses could bring in new phrases or, more generally, new information that was not contained in the Europarl model.</S>
          <S ID="S-40682">In order to facilitate comparisons, we use in-domain LMs for all setups.</S>
        </P>
        <P>
          <S ID="S-40683">We investigate two alternative ways of integrating the additional phrases into the existing SMT system: One is to take the hypothesis translation model described in Section 3.1, the other is to construct system-specific models constructed with only translations from one system at a time.</S>
        </P>
        <P>
          <S ID="S-40684">Although the Moses decoder is able to work with two phrase tables at once (<REF ID="R-05" RPTR="11">Koehn and Schroeder, 2007</REF>), it is difficult to use this method when there is more than one additional model.</S>
          <S ID="S-40685">The method requires tuning on at least six more features, which expands the search space for the translation task unnecessarily.</S>
          <S ID="S-40686">We instead integrate the translation models from multiple sources by extending the phrase table.</S>
          <S ID="S-40687">In contrast to the prior approach presented in (<REF ID="R-01" RPTR="2">Chen et al., 2007</REF>) and (<REF ID="R-02" RPTR="8">Eisele et al., 2008</REF>) which concatenates the phrase tables and adds new features as system markers, our extension method avoids duplicate entries in the final combined table.</S>
          <S ID="S-40688">Given a set of hypothesis translation models (derived from an arbitrary number of system outputs) and an original large translation model to be improved, we first sort the models by quality (see Section 3.3), always assigning the highest priority to the original model.</S>
          <S ID="S-40689">The additional phrase tables are appended to the large model in sorted order such that only phrase pairs that were never seen before are included.</S>
          <S ID="S-40690">Lastly, we add new features (in the form of additional columns in the phrase table) to the translation model to indicate each pair&#8217;s origin.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 System evaluation</HEADER>
        <P>
          <S ID="S-40691">Since both the system translations and the reference translations are available for the tuning</S>
        </P>
        <P>
          <S ID="S-40692">set, we first compare each output to the reference translation using BLEU (<REF ID="R-11" RPTR="19">Papineni et al., 2001</REF>) and METEOR (<REF ID="R-00" RPTR="0">Banerjee and Lavie, 2005</REF>) and a combined scoring scheme provided by the ULC toolkit (<REF ID="R-03" RPTR="9">Gimenez and Marquez, 2008</REF>).</S>
          <S ID="S-40693">In our experiments, we selected a subset of 5 systems for the combination, in most cases, based on BLEU.</S>
        </P>
        <P>
          <S ID="S-40694">On the other hand, some systems may be designed in a way that they deliver interesting unique translation segments.</S>
          <S ID="S-40695">Therefore, we also measure the similarity among system outputs as shown in Table 2 in a given collection by calculating average similarity scores across every pair of outputs.</S>
        </P>
        <P>
          <S ID="S-40696">The range of BLEU scores cannot indicate the similarity of the systems.</S>
          <S ID="S-40697">The direction with the most systems submitted is Spanish-English but their respective performances are very close to each other.</S>
          <S ID="S-40698">As for the selected subset, the English- French systems have the most similar performance in terms of BLEU scores.</S>
          <S ID="S-40699">The French-English translations have the largest range in BLEU but the similarity in this group is not the lowest.</S>
        </P>
        <P>
          <S ID="S-40700">Ideally, we should select systems with highest quality scores and lowest similarity scores.</S>
          <S ID="S-40701">For German-English, we selected the three with the highest METEOR scores and another two with high METEOR scores but low similarity scores to the first three.</S>
          <S ID="S-40702">For the other language directions, we chose five systems from different institutions with the highest scores.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.4 Language models</HEADER>
        <P>
          <S ID="S-40703">We use a standard n-gram language model for each target language using the monolingual training data provided in the translation task.</S>
          <S ID="S-40704">These LMs are thus specific to the same domain as the input texts.</S>
          <S ID="S-40705">Moreover, we also generate &#8220;hypothesis&#8221; LMs solely based on the given system outputs, that is, LMs that model how the candidate systems convey information in the target language.</S>
          <S ID="S-40706">These LMs do not require any additional training data.</S>
          <S ID="S-40707">Therefore, we do not require any training data other than the given system outputs by using the &#8220;hypothesis&#8221; language model and the &#8220;hypothesis&#8221; translation model.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.5 Tuning</HEADER>
        <P>
          <S ID="S-40708">After building the models, it is essential to tune the SMT system to optimize the feature weights.</S>
          <S ID="S-40709">We use Minimal Error Rate Training (<REF ID="R-10" RPTR="18">Och, 2003</REF>) to maximize BLEU on the complete development data.</S>
          <S ID="S-40710">Unlike the standard tuning procedure, we do not tune the final system directly.</S>
          <S ID="S-40711">Instead, we obtain the weights using models built from the tuning portion of the system outputs.</S>
        </P>
        <P>
          <S ID="S-40712">For each combination variant, we first train models on the provided outputs corresponding to the tuning set.</S>
          <S ID="S-40713">This system, called the tuning system, is also tuned on the tuning set.</S>
          <S ID="S-40714">The initial weights of any additional features not included in the standard setting are set to 0.</S>
          <S ID="S-40715">We then adapt the weights to the system built with translations corresponding to the test set.</S>
          <S ID="S-40716">The procedure and the settings for building this system must be identical to that of the tuning system.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Experiments</HEADER>
      <P>
        <S ID="S-40742">The purpose of this exercise is to understand the nature of the system combination task in practice.</S>
        <S ID="S-40743">Therefore, we restrict ourselves to the training data and system translations provided by the shared task.</S>
        <S ID="S-40744">The types of the systems that produced the translations are assumed to be unknown.</S>
        <S ID="S-40745">We report results for six translation directions between four languages.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Data and baseline</HEADER>
        <P>
          <S ID="S-40719">We build an SMT system from release v4 of the Europarl corpus (<REF ID="R-07" RPTR="15">Koehn, 2005</REF>), following a standard routine using the Moses toolkit.</S>
          <S ID="S-40720">The system also includes 5-gram language models trained on in-domain corpora of the respective target languages using SRILM (Stolcke, 2002).</S>
          <S ID="S-40721">The systems in this paper, including the baseline, are all tuned on the same 501-sentence tuning set.</S>
          <S ID="S-40722">Note also that the provided n-best outputs are excluded in our experiments.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Results</HEADER>
        <P>
          <S ID="S-40723">The experiments include three different setups for direct system combination, involving only hypothesis translation models.</S>
          <S ID="S-40724">System S 0 , the baseline for this group, uses a hypothesis translation model built with all available system translations and a hypothesis LM (also from the machine-generated outputs).</S>
          <S ID="S-40725">S 1 differs from S 0 in that the LM in S 1 is generated from a large news corpus.</S>
          <S ID="S-40726">S 2 consists of translation models built with only the five selected systems.</S>
          <S ID="S-40727">The BLEU scores of these systems are shown in Table 3.</S>
        </P>
        <P>
          <S ID="S-40728">When all outputs are included, the combined system can always produce translations better than most of the systems.</S>
          <S ID="S-40729">When only a hypothesis LM is used, the BLEU scores are always higher than the average BLEU scores of the outputs.</S>
          <S ID="S-40730">It even outperforms the top system for English-French.</S>
          <S ID="S-40731">This simple setup (S 0 ) is certainly a feasible solution when no additional data is available and no system evaluation is possible.</S>
          <S ID="S-40732">This approach appears to be more effective on typically difficult language pairs that involve German.</S>
        </P>
        <P>
          <S ID="S-40733">As for the systems with normal language models, neither of the systems ensure better translations.</S>
          <S ID="S-40734">The translation quality is not completely determined by the number of included translations and their quality.</S>
          <S ID="S-40735">On the other hand, the output set with higher diversity (Table 2) usually leads to better combination results.</S>
          <S ID="S-40736">This observation is consistent with the results from the system integration experiments shown in Table 4.</S>
        </P>
        <P>
          <S ID="S-40737">There are two variants in our experiments on system integration.</S>
          <S ID="S-40738">All in Table 4 represents the system that integrates the complete hypothesis translation model with the Europarl model, while Top 5 refers to the system that incorporates the five system-specific models separately.</S>
          <S ID="S-40739">Both setups result in an improvement over the baseline Europarlbased SMT system.</S>
          <S ID="S-40740">BLEU scores increase by up to 4.25 points.</S>
          <S ID="S-40741">The integrated SMT system sometimes produces translations better than the best system (7 out of 12 cases).</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Conclusion</HEADER>
      <P>
        <S ID="S-40746">This work uses the Moses toolkit to combine translations from multiple engines in a simple way.</S>
        <S ID="S-40747">The experiments on six translation directions show interesting results: The final translations are always better than the majority of the given systems, while the combination performs better than the best system in half the cases.</S>
        <S ID="S-40748">A similar approach was applied to improve an existing SMT system which was built in a domain different from the test task.</S>
        <S ID="S-40749">We achieved improvements in all cases.</S>
        <S ID="S-40750">There are many possible future directions to continue this work.</S>
        <S ID="S-40751">As we have shown, the quality of the combined system is more related to the diversity of the involved systems than to the number of the systems or their quality.</S>
        <S ID="S-40752">Hand-picked systems lead to better combinations than those selected by BLEU scores.</S>
        <S ID="S-40753">It would be interesting to develop a more comprehensive system selection strategy.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-40754">This work was supported by the EuroMatrix project (IST-034291) which is funded by the European Community under the Sixth Framework Programme for Research and Technological Development.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>Satanjeev Banerjee</RAUTHOR>
      <REFTITLE>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Yu Chen</RAUTHOR>
      <REFTITLE>Multi-engine machine translation with an open-source SMT decoder.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Andreas Eisele</RAUTHOR>
      <REFTITLE>Using Moses to integrate multiple rule-based machine translation engines into a hybrid system.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>Jesus Gimenez</RAUTHOR>
      <REFTITLE>A smorgasbord of features for automatic MT evaluation.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Xiaodong He</RAUTHOR>
      <REFTITLE>Indirect-HMMbased hypothesis alignment for combining outputs from machine translation systems.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Experiments in domain adaptation for statistical machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Europarl: A Parallel Corpus for Statistical Machine Translation.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Evgeny Matusov</RAUTHOR>
      <REFTITLE>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Franz Josef Och</RAUTHOR>
      <REFTITLE>A systematic comparison of various statistical alignment models.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Franz Josef Och</RAUTHOR>
      <REFTITLE>Minimum error rate training in statistical machine translation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Kishore Papineni</RAUTHOR>
      <REFTITLE>BLEU: a method for automatic evaluation of machine translation.</REFTITLE>
      <DATE>2001</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Antti-Veikko I Rosti</RAUTHOR>
      <REFTITLE>Improved word-level system combination for machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
