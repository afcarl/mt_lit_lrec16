<document>
  <filename>W11-2022</filename>
  <authors>
    <author>Thomas Meyer</author>
    <author>Andrei Popescu-Belis</author>
    <author>Sandrine Zufferey</author>
  </authors>
  <title>Multilingual Annotation and Disambiguation of Discourse Connectives for Machine Translation</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>Many discourse connectives can signal several types of relations between sentences. Their automatic disambiguation, i.e. the labeling of the correct sense of each occurrence, is important for discourse parsing, but could also be helpful to machine translation. We describe new approaches for improving the accuracy of manual annotation of three discourse connectives (two English, one French) by using parallel corpora. An appropriate set of labels for each connective can be found using information from their translations. Our results for automatic disambiguation are state-of-the-art, at up to 85% accuracy using surface features. Using feature analysis, contextual features are shown to be useful across languages and connectives.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Many discourse connectives can signal several types of relations between sentences.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Their automatic disambiguation, i.e. the labeling of the correct sense of each occurrence, is important for discourse parsing, but could also be helpful to machine translation.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We describe new approaches for improving the accuracy of manual annotation of three discourse connectives (two English, one French) by using parallel corpora.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>An appropriate set of labels for each connective can be found using information from their translations.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Our results for automatic disambiguation are state-of-the-art, at up to 85% accuracy using surface features.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Using feature analysis, contextual features are shown to be useful across languages and connectives.</text>
              <doc_id>5</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>Discourse connectives are generally considered as indicators of discourse structure, relating two sentences of a written or spoken text, and making explicit the rhetorical or coherence relation between them. Leaving aside the cases when connectives are only implicit, the presence of a connective does not unambiguously signal a specific discourse relation. In fact, many connectives can indicate several types of relations between sentences, i.e. they have several possible &#8220;senses&#8221; in context.
This paper studies the manual and automated disambiguation of three ambiguous connectives in two languages: alors que in French, since and while in English. We will show how the multilingual perspective helps to improve the accuracy of annotation, and how it helps to find appropriate labels for automated processing and MT. Results from automatic annotation experiments, which are close to the state of the art, as well as feature analysis, help to assess the usefulness of the proposed labels.
The paper is organized as follows. Section 2 explains the motivation of our experiments, and offers a wider perspective on our research goals, illustrating them with examples of translation problems which arise from ambiguous discourse connectives. Current resources and methods for discourse annotation are discussed in Section 3. Section 4 analyzes our experiments in manual annotation and in particular the influence of the set of labels on the reliability of annotation. The automatic disambiguation experiments, the features used, the results and the analysis of features are described in Section 5. Section 6 concludes the paper and outlines future work.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Discourse connectives are generally considered as indicators of discourse structure, relating two sentences of a written or spoken text, and making explicit the rhetorical or coherence relation between them.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Leaving aside the cases when connectives are only implicit, the presence of a connective does not unambiguously signal a specific discourse relation.</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In fact, many connectives can indicate several types of relations between sentences, i.e. they have several possible &#8220;senses&#8221; in context.</text>
              <doc_id>8</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This paper studies the manual and automated disambiguation of three ambiguous connectives in two languages: alors que in French, since and while in English.</text>
              <doc_id>9</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We will show how the multilingual perspective helps to improve the accuracy of annotation, and how it helps to find appropriate labels for automated processing and MT.</text>
              <doc_id>10</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Results from automatic annotation experiments, which are close to the state of the art, as well as feature analysis, help to assess the usefulness of the proposed labels.</text>
              <doc_id>11</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The paper is organized as follows.</text>
              <doc_id>12</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 2 explains the motivation of our experiments, and offers a wider perspective on our research goals, illustrating them with examples of translation problems which arise from ambiguous discourse connectives.</text>
              <doc_id>13</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Current resources and methods for discourse annotation are discussed in Section 3.</text>
              <doc_id>14</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Section 4 analyzes our experiments in manual annotation and in particular the influence of the set of labels on the reliability of annotation.</text>
              <doc_id>15</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>The automatic disambiguation experiments, the features used, the results and the analysis of features are described in Section 5.</text>
              <doc_id>16</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Section 6 concludes the paper and outlines future work.</text>
              <doc_id>17</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Explicit Connectives and their Translation</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>18</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Three Multi-functional Connectives</title>
            <text>Discourse connectives form a functional category of lexical items that are used to mark coherence relations such as Cause or Contrast between units of discourse. Along with other function words, many connectives appear among the most frequent words, as shown for instance by counts (Cartoni et al., 2011) over the Europarl corpus (Koehn, 2005). The Penn Discourse Treebank (Prasad et al., 2008) (see Section 3.1 below) includes around 100 connective types, but the exact number varies across studies,
depending on the discourse theory used to classify them. Among these types, Pitler et al.(2008) have shown that most of them are unambiguous and easy to identify, but others, especially temporal ones, often signal multiple senses depending on their context.
Following the terminology of Petukhova and Bunt (2009, Section 2), we are interested here in &#8220;sequential&#8221; multi-functionality, i.e. the fact that the same connective can signal different relations in different contexts. We do not deal with &#8220;simultaneous&#8221; multi-functionality, i.e. the possibility for a single occurrence to signal several relations, which has been less frequently studied for connectives (see Petukhova and Bunt (2009) for the discourse usage of and). We identified the two English connectives while and since, along with the French connective alors que, as being particularly problematic because they are highly multi-functional, i.e. they can signal multiple senses. For alors que, a French database of connectives (LexConn (Roze et al., 2010), see Section 3 below) contains examples of sentences where alors que expresses either a Background or a Contrast relation. For the English connective since, Miltsakaki et al. (2005) identified three possible meanings: Temporal, Causal, and simultaneously Temporal/Causal. For while, even more senses are observed: Comparison, Contrast, Concession, and Opposition. In fact, in the Penn Discourse Treebank, the connective while is annotated with more than twenty different senses.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Discourse connectives form a functional category of lexical items that are used to mark coherence relations such as Cause or Contrast between units of discourse.</text>
                  <doc_id>19</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Along with other function words, many connectives appear among the most frequent words, as shown for instance by counts (Cartoni et al., 2011) over the Europarl corpus (Koehn, 2005).</text>
                  <doc_id>20</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The Penn Discourse Treebank (Prasad et al., 2008) (see Section 3.1 below) includes around 100 connective types, but the exact number varies across studies,</text>
                  <doc_id>21</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>depending on the discourse theory used to classify them.</text>
                  <doc_id>22</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Among these types, Pitler et al.(2008) have shown that most of them are unambiguous and easy to identify, but others, especially temporal ones, often signal multiple senses depending on their context.</text>
                  <doc_id>23</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Following the terminology of Petukhova and Bunt (2009, Section 2), we are interested here in &#8220;sequential&#8221; multi-functionality, i.e. the fact that the same connective can signal different relations in different contexts.</text>
                  <doc_id>24</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We do not deal with &#8220;simultaneous&#8221; multi-functionality, i.e. the possibility for a single occurrence to signal several relations, which has been less frequently studied for connectives (see Petukhova and Bunt (2009) for the discourse usage of and).</text>
                  <doc_id>25</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We identified the two English connectives while and since, along with the French connective alors que, as being particularly problematic because they are highly multi-functional, i.e. they can signal multiple senses.</text>
                  <doc_id>26</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>For alors que, a French database of connectives (LexConn (Roze et al., 2010), see Section 3 below) contains examples of sentences where alors que expresses either a Background or a Contrast relation.</text>
                  <doc_id>27</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For the English connective since, Miltsakaki et al. (2005) identified three possible meanings: Temporal, Causal, and simultaneously Temporal/Causal.</text>
                  <doc_id>28</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>For while, even more senses are observed: Comparison, Contrast, Concession, and Opposition.</text>
                  <doc_id>29</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>In fact, in the Penn Discourse Treebank, the connective while is annotated with more than twenty different senses.</text>
                  <doc_id>30</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Wider Research Objectives</title>
            <text>Our long-term goal is to identify automatically the senses of connectives for an application to machine translation (MT). Going beyond the labels provided by discourse theories, the goal is thus to find the most appropriate labels in a new multilingual, empirical approach that makes use of parallel corpora to annotate and then learn the various senses of connectives. The disambiguation of such connectives in a source text is crucial for its translation, because each sense may be translated by a different connective and/or syntactical construct in the target language. More specifically, we hypothesize that correctly labeled connectives are easier to learn and to translate by statistical MT systems than unlabeled ones. To support this hypothesis, we set up an experiment (Meyer, 2011) in which we constrained the translation of the three senses of the discourse connective while that were previously annotated as Temporal, Contrast and Concession. The system was forced to use predefined French translations known to be correct, by directly modifying the phrase table of the trained MT system. This modification noticeably helped to improve translation quality and rose the
BLEU score by 0.8 for a preliminary test set of 20
sentences.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Our long-term goal is to identify automatically the senses of connectives for an application to machine translation (MT).</text>
                  <doc_id>31</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Going beyond the labels provided by discourse theories, the goal is thus to find the most appropriate labels in a new multilingual, empirical approach that makes use of parallel corpora to annotate and then learn the various senses of connectives.</text>
                  <doc_id>32</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The disambiguation of such connectives in a source text is crucial for its translation, because each sense may be translated by a different connective and/or syntactical construct in the target language.</text>
                  <doc_id>33</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>More specifically, we hypothesize that correctly labeled connectives are easier to learn and to translate by statistical MT systems than unlabeled ones.</text>
                  <doc_id>34</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>To support this hypothesis, we set up an experiment (Meyer, 2011) in which we constrained the translation of the three senses of the discourse connective while that were previously annotated as Temporal, Contrast and Concession.</text>
                  <doc_id>35</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>The system was forced to use predefined French translations known to be correct, by directly modifying the phrase table of the trained MT system.</text>
                  <doc_id>36</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>This modification noticeably helped to improve translation quality and rose the</text>
                  <doc_id>37</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU score by 0.8 for a preliminary test set of 20</text>
                  <doc_id>38</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>sentences.</text>
                  <doc_id>39</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>2.3 Illustration of Mistranslations</title>
            <text>Among the connectives that we plan to process in order to improve MT, the three connectives we focus on in this paper are frequent, ambiguous and therefore difficult to translate correctly by MT systems, as illustrated in the following examples.
A first reason why machine translation of connectives can be difficult is that there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown in the reference translation of the first example in Table 1, taken from the Europarl corpus (Koehn, 2005).
EN It is also important that we should not leave these indicators floating in the air while congratulating ourselves on the fact that we have produced them.
FR Il est &#233;galement important de ne pas laisser ces indicateurs flotter, en nous f&#233;licitant de les avoir instaur&#233;s.
EN Finally, and in conclusion, Mr President, with the expiry of the ECSC Treaty, the regulations will have to be reviewed since [causal] I think that the aid system will have to continue beyond 2002 . . .
FR *Enfin, et en conclusion, Monsieur le pr&#233;sident, &#224; l&#8217;expiration du trait&#233; ceca, la r&#233;glementation devra &#234;tre revu depuis que [temporal] je pense que le syst&#232;me d&#8217;aides devront continuer au-del&#224; de 2002 . . .
FR Oui, bien entendu, sauf que le d&#233;veloppement ne se n&#233;gocie pas, alors que [contrast] le commerce, lui, se n&#233;gocie.
EN *Yes, of course, but development cannot be negotiated, so [causal] that trade can.
EN Between 1998 and 1999, loyalists assaulted and shot 123 people, while [contrast] republicans assaulted and shot 93 people.
FR *Entre 1998 et 1999, les loyalistes ont attaqu&#233; et abattu 123 personnes, &#966; 93 pour les r&#233;publicains.
When an ambiguous connective is explicitly translated by another connective, the incorrect rendering of its sense can lead to erroneous translations, as in the second and third examples in Table 1, which are translated by the Moses SMT decoder (Koehn et al., 2007) trained on the Europarl corpus. The reference translation for the second example uses the French connective car with a correct causal sense, instead of the wrong depuis que generated by SMT, which expresses a temporal relation. In the third example, the French connective alors que, in its contrastive usage, is wrongly translated into the English connective so, which has a causal meaning (the reference translation uses whereas to express contrast). It may even occur that the system fails to translate a connective at all, as in the fourth example where the discourse information provided by while, namely a Contrast relation, is lost in the French translation, which is hardly coherent any longer.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Among the connectives that we plan to process in order to improve MT, the three connectives we focus on in this paper are frequent, ambiguous and therefore difficult to translate correctly by MT systems, as illustrated in the following examples.</text>
                  <doc_id>40</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A first reason why machine translation of connectives can be difficult is that there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown in the reference translation of the first example in Table 1, taken from the Europarl corpus (Koehn, 2005).</text>
                  <doc_id>41</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>EN It is also important that we should not leave these indicators floating in the air while congratulating ourselves on the fact that we have produced them.</text>
                  <doc_id>42</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FR Il est &#233;galement important de ne pas laisser ces indicateurs flotter, en nous f&#233;licitant de les avoir instaur&#233;s.</text>
                  <doc_id>43</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>EN Finally, and in conclusion, Mr President, with the expiry of the ECSC Treaty, the regulations will have to be reviewed since [causal] I think that the aid system will have to continue beyond 2002 .</text>
                  <doc_id>44</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>.</text>
                  <doc_id>45</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>.</text>
                  <doc_id>46</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FR *Enfin, et en conclusion, Monsieur le pr&#233;sident, &#224; l&#8217;expiration du trait&#233; ceca, la r&#233;glementation devra &#234;tre revu depuis que [temporal] je pense que le syst&#232;me d&#8217;aides devront continuer au-del&#224; de 2002 .</text>
                  <doc_id>47</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>.</text>
                  <doc_id>48</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>.</text>
                  <doc_id>49</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FR Oui, bien entendu, sauf que le d&#233;veloppement ne se n&#233;gocie pas, alors que [contrast] le commerce, lui, se n&#233;gocie.</text>
                  <doc_id>50</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>EN *Yes, of course, but development cannot be negotiated, so [causal] that trade can.</text>
                  <doc_id>51</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>EN Between 1998 and 1999, loyalists assaulted and shot 123 people, while [contrast] republicans assaulted and shot 93 people.</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FR *Entre 1998 et 1999, les loyalistes ont attaqu&#233; et abattu 123 personnes, &#966; 93 pour les r&#233;publicains.</text>
                  <doc_id>53</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>When an ambiguous connective is explicitly translated by another connective, the incorrect rendering of its sense can lead to erroneous translations, as in the second and third examples in Table 1, which are translated by the Moses SMT decoder (Koehn et al., 2007) trained on the Europarl corpus.</text>
                  <doc_id>54</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The reference translation for the second example uses the French connective car with a correct causal sense, instead of the wrong depuis que generated by SMT, which expresses a temporal relation.</text>
                  <doc_id>55</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In the third example, the French connective alors que, in its contrastive usage, is wrongly translated into the English connective so, which has a causal meaning (the reference translation uses whereas to express contrast).</text>
                  <doc_id>56</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>It may even occur that the system fails to translate a connective at all, as in the fourth example where the discourse information provided by while, namely a Contrast relation, is lost in the French translation, which is hardly coherent any longer.</text>
                  <doc_id>57</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Related Work</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>58</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Annotated Resources</title>
            <text>One of the very few available discourse annotated corpora is the Penn Discourse Treebank (PDTB) in English (Prasad et al., 2008). For this resource, one hundred types of explicit discourse connectives were manually annotated, as well as implicit relations not signaled by a connective. The sense hierarchy used for annotation consists of three levels, from four toplevel senses (Temporal, Contingency, Comparison, and Expansion), to 16 subsenses on the second level, and 23 further ones on the third level. The annotators were allowed to assign more than one sense to each occurrence, so 129 simple or complex labels are observed, over more than 18,000 explicit connectives. For French, the ANNODIS project (P&#233;ry- Woodley et al., 2009) will provide annotation of discourse on an original corpus. Resources for Czech are also becoming available (Zik&#225;nov&#225; et al., 2010).
For German, a lexicon of discourse markers named DiMLex exists since the 1990s (Stede and Umbach, 1998). An equivalent, more recent database for French is the LexConn lexicon of connectives (Roze et al., 2010) containing a list of 328 explicit connectives. For each of them, LexConn indicates and exemplifies the possible senses, chosen from a list of 30 labels inspired from Rhetorical Structure Theory (Mann and Thompson, 1988).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>One of the very few available discourse annotated corpora is the Penn Discourse Treebank (PDTB) in English (Prasad et al., 2008).</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For this resource, one hundred types of explicit discourse connectives were manually annotated, as well as implicit relations not signaled by a connective.</text>
                  <doc_id>60</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The sense hierarchy used for annotation consists of three levels, from four toplevel senses (Temporal, Contingency, Comparison, and Expansion), to 16 subsenses on the second level, and 23 further ones on the third level.</text>
                  <doc_id>61</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The annotators were allowed to assign more than one sense to each occurrence, so 129 simple or complex labels are observed, over more than 18,000 explicit connectives.</text>
                  <doc_id>62</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For French, the ANNODIS project (P&#233;ry- Woodley et al., 2009) will provide annotation of discourse on an original corpus.</text>
                  <doc_id>63</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Resources for Czech are also becoming available (Zik&#225;nov&#225; et al., 2010).</text>
                  <doc_id>64</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For German, a lexicon of discourse markers named DiMLex exists since the 1990s (Stede and Umbach, 1998).</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>An equivalent, more recent database for French is the LexConn lexicon of connectives (Roze et al., 2010) containing a list of 328 explicit connectives.</text>
                  <doc_id>66</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For each of them, LexConn indicates and exemplifies the possible senses, chosen from a list of 30 labels inspired from Rhetorical Structure Theory (Mann and Thompson, 1988).</text>
                  <doc_id>67</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Automatic Disambiguation of Connectives</title>
            <text>The release of the PDTB had quite an impact on automatic disambiguation experiments. The stateof-the-art for recognizing all types of explicit connectives in English is therefore already high, at 97% accuracy for disambiguating discourse vs. nondiscourse uses (Lin et al., 2010) and 94% for disambiguating the four main senses from the PDTB hierarchy (Pitler and Nenkova, 2009). Lin et al. (2010) recently built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38.18% for senses on the second level of the PDTB hierarchy. Other important contributions to automatic discourse connective classification and feature analysis has been provided by Wellner et al. (2006) and Elwell and Baldrige (2008). Fewer studies focus on the detailed analysis of specific discourse connectives. In Section 5.3, we will compare our results to Miltsakaki et al. (2005) who report classification results for the connectives since, while and when. In their study, as in the present one, the goal is to disambiguate senses from the second level of the PDTB hierarchy, a level which, as we will show, is appropriate for the translation of these connectives as well.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The release of the PDTB had quite an impact on automatic disambiguation experiments.</text>
                  <doc_id>68</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The stateof-the-art for recognizing all types of explicit connectives in English is therefore already high, at 97% accuracy for disambiguating discourse vs. nondiscourse uses (Lin et al., 2010) and 94% for disambiguating the four main senses from the PDTB hierarchy (Pitler and Nenkova, 2009).</text>
                  <doc_id>69</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Lin et al. (2010) recently built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38.18% for senses on the second level of the PDTB hierarchy.</text>
                  <doc_id>70</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Other important contributions to automatic discourse connective classification and feature analysis has been provided by Wellner et al. (2006) and Elwell and Baldrige (2008).</text>
                  <doc_id>71</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Fewer studies focus on the detailed analysis of specific discourse connectives.</text>
                  <doc_id>72</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>In Section 5.3, we will compare our results to Miltsakaki et al. (2005) who report classification results for the connectives since, while and when.</text>
                  <doc_id>73</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>In their study, as in the present one, the goal is to disambiguate senses from the second level of the PDTB hierarchy, a level which, as we will show, is appropriate for the translation of these connectives as well.</text>
                  <doc_id>74</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 Connective Annotation in Parallel Corpora</title>
        <text>The resources mentioned above are either monolingual only (PDTB, LexConn) and/or not yet publicly available (ANNODIS, DiMLex). Moreover, our overall goal is related to multilingualism and translation, as explained in Section 2.2 above. Therefore, we performed manual annotation of connectives in a multilingual, aligned resource: the Europarl corpus (Koehn, 2005). We extracted from Europarl two subcorpora for each translation direction, EN/FR and FR/EN, to take into account the varying distribution of connectives in translated vs. original language, as explained in Cartoni et al. (2011).
As the full PDTB hierarchy seemed too finegrained given current capabilities for automatic labeling and the needs for translating connectives, we defined a simplified set of labels for the senses of connectives, by considering their usefulness and
granularity with respect to translation, focusing on those that may lead to different connectives or syntactical constructs in the target language.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The resources mentioned above are either monolingual only (PDTB, LexConn) and/or not yet publicly available (ANNODIS, DiMLex).</text>
              <doc_id>75</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Moreover, our overall goal is related to multilingualism and translation, as explained in Section 2.2 above.</text>
              <doc_id>76</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Therefore, we performed manual annotation of connectives in a multilingual, aligned resource: the Europarl corpus (Koehn, 2005).</text>
              <doc_id>77</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We extracted from Europarl two subcorpora for each translation direction, EN/FR and FR/EN, to take into account the varying distribution of connectives in translated vs. original language, as explained in Cartoni et al. (2011).</text>
              <doc_id>78</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>As the full PDTB hierarchy seemed too finegrained given current capabilities for automatic labeling and the needs for translating connectives, we defined a simplified set of labels for the senses of connectives, by considering their usefulness and</text>
              <doc_id>79</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>granularity with respect to translation, focusing on those that may lead to different connectives or syntactical constructs in the target language.</text>
              <doc_id>80</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 Method</title>
            <text>There are two major ways to annotate explicit discourse connectives. The first approach is to label each occurrence of a connective with a label for its sense, similar to the PDTB or LexConn hierarchies of senses. However, as shown among others by Zikanova et al. (2010), this is a difficult and timeconsuming task even when the annotators are trained over a long period of time. This is confirmed by the rather low kappa scores resulting from the manual sense annotations as can be seen for each connective in detail below.
The second approach to annotation, which is the one put forward in this paper, is based on translation spotting. In a first step, human annotators work on bilingual sentence pairs, and annotate the translation of each connective in the target language. The translations are either a target language connective (signaling in principle the same sense(s) as the source one), or a reformulation, or a construct with no connective at all. In a second step of the annotation, all translations of a connective are manually clustered by the experimenters to derive sense labels, by grouping together similar translations.
As demonstrated in the following subsections, for the three connectives under study, the second approach to connective annotation not only facilitates the annotation task, but also helps to derive the appropriate level of granularity for the sense labels.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>There are two major ways to annotate explicit discourse connectives.</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The first approach is to label each occurrence of a connective with a label for its sense, similar to the PDTB or LexConn hierarchies of senses.</text>
                  <doc_id>82</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, as shown among others by Zikanova et al. (2010), this is a difficult and timeconsuming task even when the annotators are trained over a long period of time.</text>
                  <doc_id>83</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This is confirmed by the rather low kappa scores resulting from the manual sense annotations as can be seen for each connective in detail below.</text>
                  <doc_id>84</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The second approach to annotation, which is the one put forward in this paper, is based on translation spotting.</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In a first step, human annotators work on bilingual sentence pairs, and annotate the translation of each connective in the target language.</text>
                  <doc_id>86</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The translations are either a target language connective (signaling in principle the same sense(s) as the source one), or a reformulation, or a construct with no connective at all.</text>
                  <doc_id>87</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In a second step of the annotation, all translations of a connective are manually clustered by the experimenters to derive sense labels, by grouping together similar translations.</text>
                  <doc_id>88</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As demonstrated in the following subsections, for the three connectives under study, the second approach to connective annotation not only facilitates the annotation task, but also helps to derive the appropriate level of granularity for the sense labels.</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Annotation of alors que</title>
            <text>This first manual annotation involved two experienced annotators who annotated alors que in 423 original French sentences. The two main senses identified for alors que are Background (labeled B) Contrast (labeled C), as in the LexConn database. Annotators were also allowed to use the J label if they did not know which label to assign, and a D label for discarded sentences &#8211; due to a nonconnective use of the two words which could not be filtered out automatically (e.g. Alors, que fera-t-on? ). The annotators found 20 sentences labeled with D, which were removed from the data. 15 sentences were labeled with J by one annotator (but none by both), and it was decided to assign to them the label (either B or C) provided by the other annotator.
The inter-annotator agreement on the B vs. C labels was quite low, showing the difficulty of the task: kappa reached 0.43, quite below the 0.7 mark often considered as indicating reliability. The following example from Europarl illustrates the difficulty of choosing between B and C. In particular, the reference translation into English also uses an ambiguous connective, namely while.
FR La monnaie unique va entrer en vigueur au milieu de la tourmente financi&#232;re, alors que de nombreux compl&#233;ments, logiques, mais que les &#201;tats ne semblaient pas avoir pr&#233;vus, n&#8217;ont pas encore &#233;t&#233; apport&#233;s.
EN The single currency is going to come into force in the midst of financial turmoil, while a great many additional factors which were only to be expected, but which the states do not seem to have anticipated, have not been taken into consideration.
Two methods were applied to deal with diverging manual annotations. To prepare the datasets for the automated disambiguation experiments, one solution (named A1, see Table 2) is to use the doublesense label B/C for sentences labeled differently by annotators (B vs. C). This label reflects the difficulty of manual annotation and preserves the ambiguity which might be genuinely present in each occurrence. The relevance of the B/C label is also supported by results from automatic labeling in Section 5.3 below.
For comparison purposes, a second dataset named A2 was derived from translation spotting on the same French sentences aligned to English ones, as explained in Section 4.1. Alors que appeared to be mainly translated by the following English equivalents and constructs: although, whereas, while, whilst, when, at a time when. Through this operation, inter-annotator disagreement can sometimes be solved: when the translation is a clearly contrastive English connective (whereas or although), then the C label was assigned instead of B/C. Conversely, when the English translation was still ambiguous (while, whilst, or when), the experimenters made a decision in favor of either B or C by re-examining source and target sentences.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>This first manual annotation involved two experienced annotators who annotated alors que in 423 original French sentences.</text>
                  <doc_id>90</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The two main senses identified for alors que are Background (labeled B) Contrast (labeled C), as in the LexConn database.</text>
                  <doc_id>91</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Annotators were also allowed to use the J label if they did not know which label to assign, and a D label for discarded sentences &#8211; due to a nonconnective use of the two words which could not be filtered out automatically (e.g. Alors, que fera-t-on?</text>
                  <doc_id>92</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>).</text>
                  <doc_id>93</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The annotators found 20 sentences labeled with D, which were removed from the data.</text>
                  <doc_id>94</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>15 sentences were labeled with J by one annotator (but none by both), and it was decided to assign to them the label (either B or C) provided by the other annotator.</text>
                  <doc_id>95</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The inter-annotator agreement on the B vs. C labels was quite low, showing the difficulty of the task: kappa reached 0.43, quite below the 0.7 mark often considered as indicating reliability.</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The following example from Europarl illustrates the difficulty of choosing between B and C.</text>
                  <doc_id>97</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In particular, the reference translation into English also uses an ambiguous connective, namely while.</text>
                  <doc_id>98</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FR La monnaie unique va entrer en vigueur au milieu de la tourmente financi&#232;re, alors que de nombreux compl&#233;ments, logiques, mais que les &#201;tats ne semblaient pas avoir pr&#233;vus, n&#8217;ont pas encore &#233;t&#233; apport&#233;s.</text>
                  <doc_id>99</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>EN The single currency is going to come into force in the midst of financial turmoil, while a great many additional factors which were only to be expected, but which the states do not seem to have anticipated, have not been taken into consideration.</text>
                  <doc_id>100</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Two methods were applied to deal with diverging manual annotations.</text>
                  <doc_id>101</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To prepare the datasets for the automated disambiguation experiments, one solution (named A1, see Table 2) is to use the doublesense label B/C for sentences labeled differently by annotators (B vs. C).</text>
                  <doc_id>102</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This label reflects the difficulty of manual annotation and preserves the ambiguity which might be genuinely present in each occurrence.</text>
                  <doc_id>103</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The relevance of the B/C label is also supported by results from automatic labeling in Section 5.3 below.</text>
                  <doc_id>104</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For comparison purposes, a second dataset named A2 was derived from translation spotting on the same French sentences aligned to English ones, as explained in Section 4.1.</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Alors que appeared to be mainly translated by the following English equivalents and constructs: although, whereas, while, whilst, when, at a time when.</text>
                  <doc_id>106</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Through this operation, inter-annotator disagreement can sometimes be solved: when the translation is a clearly contrastive English connective (whereas or although), then the C label was assigned instead of B/C.</text>
                  <doc_id>107</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Conversely, when the English translation was still ambiguous (while, whilst, or when), the experimenters made a decision in favor of either B or C by re-examining source and target sentences.</text>
                  <doc_id>108</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>4.3 Annotation of since</title>
            <text>For since, 30 sentences were annotated by four experimenters in a preliminary round, with a kappa
score of 0.77, indicating good agreement. Then, each half of the entire dataset (727 sentences) was annotated by another person with three possible sense labels: T for Temporal, C for Causal and T/C for a simultaneously Temporal/Causal meaning. Two datasets were again derived from this manual annotation. To study the effects of a supplementary label, we kept the label T/C for dataset B1, but condensed it under label C in dataset B2, as shown in Table 2.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>For since, 30 sentences were annotated by four experimenters in a preliminary round, with a kappa</text>
                  <doc_id>109</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>score of 0.77, indicating good agreement.</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Then, each half of the entire dataset (727 sentences) was annotated by another person with three possible sense labels: T for Temporal, C for Causal and T/C for a simultaneously Temporal/Causal meaning.</text>
                  <doc_id>111</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Two datasets were again derived from this manual annotation.</text>
                  <doc_id>112</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To study the effects of a supplementary label, we kept the label T/C for dataset B1, but condensed it under label C in dataset B2, as shown in Table 2.</text>
                  <doc_id>113</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>4.4 Annotation of while</title>
            <text>The English connective while is highly ambiguous. In the PDTB, occurrences of while are annotated with no less than 21 possible senses, ranging from Conjunction to Contrast, Concession, or Synchrony.
We performed a pilot annotation of 30 sentences containing while with five different experimenters, resulting in a quite low inter-annotator agreement, &#954; = 0.56. We therefore decided to perform a translation spotting task only, with two experienced annotators fluent in English and French. The observed translations into French confirm the ambiguity of while, as they include several connectives and constructs, quite evenly distributed in terms of frequency: alors que, gerundive reformulations, other reformulations, si, tandis que, m&#234;me si, bien que, etc. The translations were manually clustered to derive senses for while, in an empirical manner. For example, alors que signals Temporal/Contrast, which is also true for tandis que. Similarly, m&#234;me si and bien que are clustered under the label Concession, and so forth. The translation spotting shows that at least Contrast, Concession, and several temporal senses are necessary to account for a correct translation. These distinctions are comparable to the semantic granularity of the second PDTB hierarchy level.
To generate training sets for automated classification out of a total of 500 sentences, we discarded 201 sentences labeled by annotators with G (gerundive constructions), P (reformulations) or Z (no translation at all) &#8211; these cases could be reconsidered in further work, as they represent valid translation problems. For the remaining 299 sentences, we created the following six labels by clustering the spotted translations: T/C (Temporal/Contrast), T/PUNCT (Temporal/Punctual), T/DUR (Temporal/Duration), T/CAUSAL (Temporal/Causal), CONC (Concession) and C (Contrast). These were used to tag the remaining 299 sentences, forming dataset C1. A second dataset (C2) with fewer senses was obtained from C1 by merging T/C to C (Contrast only) and all T/x to T (Temporal only).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The English connective while is highly ambiguous.</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In the PDTB, occurrences of while are annotated with no less than 21 possible senses, ranging from Conjunction to Contrast, Concession, or Synchrony.</text>
                  <doc_id>115</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We performed a pilot annotation of 30 sentences containing while with five different experimenters, resulting in a quite low inter-annotator agreement, &#954; = 0.56.</text>
                  <doc_id>116</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We therefore decided to perform a translation spotting task only, with two experienced annotators fluent in English and French.</text>
                  <doc_id>117</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The observed translations into French confirm the ambiguity of while, as they include several connectives and constructs, quite evenly distributed in terms of frequency: alors que, gerundive reformulations, other reformulations, si, tandis que, m&#234;me si, bien que, etc.</text>
                  <doc_id>118</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The translations were manually clustered to derive senses for while, in an empirical manner.</text>
                  <doc_id>119</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For example, alors que signals Temporal/Contrast, which is also true for tandis que.</text>
                  <doc_id>120</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Similarly, m&#234;me si and bien que are clustered under the label Concession, and so forth.</text>
                  <doc_id>121</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The translation spotting shows that at least Contrast, Concession, and several temporal senses are necessary to account for a correct translation.</text>
                  <doc_id>122</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>These distinctions are comparable to the semantic granularity of the second PDTB hierarchy level.</text>
                  <doc_id>123</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To generate training sets for automated classification out of a total of 500 sentences, we discarded 201 sentences labeled by annotators with G (gerundive constructions), P (reformulations) or Z (no translation at all) &#8211; these cases could be reconsidered in further work, as they represent valid translation problems.</text>
                  <doc_id>124</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For the remaining 299 sentences, we created the following six labels by clustering the spotted translations: T/C (Temporal/Contrast), T/PUNCT (Temporal/Punctual), T/DUR (Temporal/Duration), T/CAUSAL (Temporal/Causal), CONC (Concession) and C (Contrast).</text>
                  <doc_id>125</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>These were used to tag the remaining 299 sentences, forming dataset C1.</text>
                  <doc_id>126</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>A second dataset (C2) with fewer senses was obtained from C1 by merging T/C to C (Contrast only) and all T/x to T (Temporal only).</text>
                  <doc_id>127</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Disambiguation Experiments</title>
        <text>The features for connective classification, the results obtained and a detailed feature analysis are discussed in this section. We show that an automated disambiguation system can be used to determine the most appropriate set of labels, and thus to corroborate the selection we made using translation spotting.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The features for connective classification, the results obtained and a detailed feature analysis are discussed in this section.</text>
              <doc_id>128</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We show that an automated disambiguation system can be used to determine the most appropriate set of labels, and thus to corroborate the selection we made using translation spotting.</text>
              <doc_id>129</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>5.1 Features</title>
            <text>For feature extraction, all the datasets described in Section 4 were processed as follows. The English texts were parsed and POS-tagged by Charniak and Johnson&#8217;s (2005) reranking parser. The French texts were POS-tagged with the MElt tagger (Denis and Sagot, 2009) and parsed with MaltParser (Nivre, 2003). As the English parser provides constituency trees, and the parser for French generates dependency trees, the features are slightly different in the two languages. The other features below were extracted using elementary pre-processing of the sentences.
For English sentences, we used the following features: the sentence-initial character of the connec-
tive (yes/no); the POS tag of the first verb in the sentence; the type of first auxiliary verb in the sentence (if any); the word preceding the connective; the word following the connective; the POS tag of the first verb following the connective; the type of the first auxiliary verb after the connective (if any). For French sentences, the features were the following: the sentence-initial character of the connective (yes/no); the dependency tag of the connective; the first verb in the sentence; its dependency tag; the word preceding the connective; its POS tag; its dependency tag; the word following the connective; its POS tag; its dependency tag; the first verb after the connective; its dependency tag. The cased connective word forms from the corpus were not lower-cased, thus keeping the implicit indication of the sentence-initial character of the occurrence, i.e. whether it starts a sentence or not. The output of the POS taggers was used for neighboring words, but not for the connectives, which almost always received the same tag. Charniak&#8217;s parser for English provides POS tags which differentiate the verb tenses, such as VBD (past), VBG (gerund), and so on. These were considered for the verb directly preceding and the one directly following the connective. Tense was believed to be potentially relevant because since and while can have temporal meanings. The occurrence of auxiliary verbs (be, have, do, or need) may give additional indications about temporal relations in the sentence. We therefore used the types of auxiliary verbs as features, including the elementary conjugations, represented for to be as: be present, be past, be part, be inf, be gerund &#8211; and similarly for the other auxiliary verbs, as in (Miltsakaki et al., 2005).
As shown by Lin et al. (2010), duVerle and Prendinger (2009) or Wellner et al. (2006), the context of a connective is very important. We therefore extracted the words preceding and following each connective, the verbs and the first and the last word of the sentences. These may include numbers, sometimes indicating a numerical comparison, time expressions, or antonyms, which could indicate contrastive relations, such as rise vs. fall (e.g. It is interesting to see the fundamental stock pickers scream &#8221;foul&#8221; on program trading when the markets decline, while hailing the great values still abounding as the markets rise.).
For French, we likewise extracted the words immediately preceding and following each connective, supplemented by their POS tags. In contrast to constituents, dependency structures contain information about the grammatical function of each word (heads) and link the dependents belonging to the same head. However, as the dependency parser provides no differentiated verb tags, we extracted the verb word forms themselves and added their dependency tags. The same applies to the connective itself, and preceding and following words and their dependency tags.
The dependency tag of the non-connectives varies between subj (subject), det (determiner), mod (modifier) and obj (object). The first verb in the sentence often belongs to the root dependency while the verb following the connective most often belongs to the obj dependency. For alors que, the most frequent dependency tags were mod mod and mod obj, indicating the connective&#8217;s main function as a modifier of its argument.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>For feature extraction, all the datasets described in Section 4 were processed as follows.</text>
                  <doc_id>130</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The English texts were parsed and POS-tagged by Charniak and Johnson&#8217;s (2005) reranking parser.</text>
                  <doc_id>131</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The French texts were POS-tagged with the MElt tagger (Denis and Sagot, 2009) and parsed with MaltParser (Nivre, 2003).</text>
                  <doc_id>132</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>As the English parser provides constituency trees, and the parser for French generates dependency trees, the features are slightly different in the two languages.</text>
                  <doc_id>133</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The other features below were extracted using elementary pre-processing of the sentences.</text>
                  <doc_id>134</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For English sentences, we used the following features: the sentence-initial character of the connec-</text>
                  <doc_id>135</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>tive (yes/no); the POS tag of the first verb in the sentence; the type of first auxiliary verb in the sentence (if any); the word preceding the connective; the word following the connective; the POS tag of the first verb following the connective; the type of the first auxiliary verb after the connective (if any).</text>
                  <doc_id>136</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For French sentences, the features were the following: the sentence-initial character of the connective (yes/no); the dependency tag of the connective; the first verb in the sentence; its dependency tag; the word preceding the connective; its POS tag; its dependency tag; the word following the connective; its POS tag; its dependency tag; the first verb after the connective; its dependency tag.</text>
                  <doc_id>137</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The cased connective word forms from the corpus were not lower-cased, thus keeping the implicit indication of the sentence-initial character of the occurrence, i.e. whether it starts a sentence or not.</text>
                  <doc_id>138</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The output of the POS taggers was used for neighboring words, but not for the connectives, which almost always received the same tag.</text>
                  <doc_id>139</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Charniak&#8217;s parser for English provides POS tags which differentiate the verb tenses, such as VBD (past), VBG (gerund), and so on.</text>
                  <doc_id>140</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>These were considered for the verb directly preceding and the one directly following the connective.</text>
                  <doc_id>141</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>Tense was believed to be potentially relevant because since and while can have temporal meanings.</text>
                  <doc_id>142</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>The occurrence of auxiliary verbs (be, have, do, or need) may give additional indications about temporal relations in the sentence.</text>
                  <doc_id>143</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>We therefore used the types of auxiliary verbs as features, including the elementary conjugations, represented for to be as: be present, be past, be part, be inf, be gerund &#8211; and similarly for the other auxiliary verbs, as in (Miltsakaki et al., 2005).</text>
                  <doc_id>144</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As shown by Lin et al. (2010), duVerle and Prendinger (2009) or Wellner et al. (2006), the context of a connective is very important.</text>
                  <doc_id>145</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We therefore extracted the words preceding and following each connective, the verbs and the first and the last word of the sentences.</text>
                  <doc_id>146</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>These may include numbers, sometimes indicating a numerical comparison, time expressions, or antonyms, which could indicate contrastive relations, such as rise vs. fall (e.g. It is interesting to see the fundamental stock pickers scream &#8221;foul&#8221; on program trading when the markets decline, while hailing the great values still abounding as the markets rise.</text>
                  <doc_id>147</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>).</text>
                  <doc_id>148</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For French, we likewise extracted the words immediately preceding and following each connective, supplemented by their POS tags.</text>
                  <doc_id>149</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In contrast to constituents, dependency structures contain information about the grammatical function of each word (heads) and link the dependents belonging to the same head.</text>
                  <doc_id>150</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, as the dependency parser provides no differentiated verb tags, we extracted the verb word forms themselves and added their dependency tags.</text>
                  <doc_id>151</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The same applies to the connective itself, and preceding and following words and their dependency tags.</text>
                  <doc_id>152</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The dependency tag of the non-connectives varies between subj (subject), det (determiner), mod (modifier) and obj (object).</text>
                  <doc_id>153</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The first verb in the sentence often belongs to the root dependency while the verb following the connective most often belongs to the obj dependency.</text>
                  <doc_id>154</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For alors que, the most frequent dependency tags were mod mod and mod obj, indicating the connective&#8217;s main function as a modifier of its argument.</text>
                  <doc_id>155</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>5.2 Experimental Setting</title>
            <text>Our classification experiments made use of the WEKA machine learning toolkit (Hall et al., 2009) to run and compare several classification algorithms: Random Forest (sets of decision trees), Naive Bayes, and Support Vector Machine. The results are reported with 10-fold cross validation on the entire data for each connective, using all features.
Table 3 lists for each method &#8211; including the majority classifier as a baseline &#8211; the percentage of correctly classified instances (or accuracy, noted Acc.), and the kappa values. Significance above the baseline is computed using paired t-tests at 95% confidence. When a score is significantly above the baseline, it is shown in italics in Table 3. The best scores for each dataset, across classifiers, are indicated in boldface. When these scores were not significantly above the baseline, at least they were never significantly below either.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Our classification experiments made use of the WEKA machine learning toolkit (Hall et al., 2009) to run and compare several classification algorithms: Random Forest (sets of decision trees), Naive Bayes, and Support Vector Machine.</text>
                  <doc_id>156</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results are reported with 10-fold cross validation on the entire data for each connective, using all features.</text>
                  <doc_id>157</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 3 lists for each method &#8211; including the majority classifier as a baseline &#8211; the percentage of correctly classified instances (or accuracy, noted Acc.</text>
                  <doc_id>158</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>), and the kappa values.</text>
                  <doc_id>159</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Significance above the baseline is computed using paired t-tests at 95% confidence.</text>
                  <doc_id>160</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>When a score is significantly above the baseline, it is shown in italics in Table 3.</text>
                  <doc_id>161</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The best scores for each dataset, across classifiers, are indicated in boldface.</text>
                  <doc_id>162</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>When these scores were not significantly above the baseline, at least they were never significantly below either.</text>
                  <doc_id>163</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>5.3 Results and Discussion</title>
            <text>Overall, the SVM classifier performed best, which may be due to the large number of textual features (3 for EN data and 5 for FR data), as SVMs are known to handle them well (Joachims, 1998; du-
T/CAUSAL, CONC, C
C2 while T, C, CONC 43.5 60.5 0.3 59.9 0.3 60.9 0.3
Verle and Prendinger, 2009). The maximum accuracy for alors que is 55.7%, for since it is 85.7%, and for while it is 60.9%. While close to other reported values, there is still potential for improvement in the future.
The analysis of results for each data sets leads to observations that are specific to each connective. The high improvement of over the baseline for A1, as opposed to no improvement for A2, confirms the usefulness of the double-sense B/C label for alors que, showing that in this case the three-way classification is probably better adapted to the linguistic properties of alors que than a two-way classification. Indeed, alors que, just as its frequently spotted translation while, is linguistically ambiguous in some contexts (see for instance the example in Section 4.2), in which the temporal and the contrastive meaning are likely to co-exist. In the case of A2, where the labels were forced to B or C only, automatic classifiers do not significantly outperform the baseline. While more elaborate features might help, these low scores can be related to the difficulties of human annotators (Section 4.2), and make a strong case against using a two-label schema for alors que.
The features used so far lead to high scores for since in datasets B1 and B2. The results are comparable to those from Miltsakaki et al. (2005), who used similar features and labels, though with a Maximum Entropy classifier. Moreover, they provide results for individual connectives, and not, as most of the related work for the PDTB, on the whole set of ca. 100 discourse connective types. However, Miltsakaki et al. (2005) used their own datasets for each connective, which are different from the PDTB, because the PDTB was not available at that time. Our SVM classifier outperforms considerably the Maximum Entropy classifier on the three-way classification task (with T, C, T/C), with an accuracy of 85.4% vs. 75.5%, obtained however on different datasets. For the two-way classification (T, C), again on different datasets, our accuracy of 85.7% is slightly lower than the 89.5% given in Miltsakaki et al. (2005). 1
For while, when comparing C1 to C2, it appears that reducing the number of labels from six to three increases accuracy by 8-10%. This is probably due to the small number of training instances for the labels T/PUNCT and T/DUR in C1 for example. However, even for the larger set of labels, the scores are significantly above baseline (52.2% vs. 44.8%), which indicates that such a classifier might still be useful as input to an MT system, possibly improved thanks to a larger training set. The performance obtained by Miltsakaki et al. (2005) on while is markedly better than ours, with an accuracy of 71.8% compared to ours of 60.9% with three labels.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Overall, the SVM classifier performed best, which may be due to the large number of textual features (3 for EN data and 5 for FR data), as SVMs are known to handle them well (Joachims, 1998; du-</text>
                  <doc_id>164</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>T/CAUSAL, CONC, C</text>
                  <doc_id>165</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>C2 while T, C, CONC 43.5 60.5 0.3 59.9 0.3 60.9 0.3</text>
                  <doc_id>166</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Verle and Prendinger, 2009).</text>
                  <doc_id>167</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The maximum accuracy for alors que is 55.7%, for since it is 85.7%, and for while it is 60.9%.</text>
                  <doc_id>168</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>While close to other reported values, there is still potential for improvement in the future.</text>
                  <doc_id>169</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The analysis of results for each data sets leads to observations that are specific to each connective.</text>
                  <doc_id>170</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The high improvement of over the baseline for A1, as opposed to no improvement for A2, confirms the usefulness of the double-sense B/C label for alors que, showing that in this case the three-way classification is probably better adapted to the linguistic properties of alors que than a two-way classification.</text>
                  <doc_id>171</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Indeed, alors que, just as its frequently spotted translation while, is linguistically ambiguous in some contexts (see for instance the example in Section 4.2), in which the temporal and the contrastive meaning are likely to co-exist.</text>
                  <doc_id>172</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In the case of A2, where the labels were forced to B or C only, automatic classifiers do not significantly outperform the baseline.</text>
                  <doc_id>173</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>While more elaborate features might help, these low scores can be related to the difficulties of human annotators (Section 4.2), and make a strong case against using a two-label schema for alors que.</text>
                  <doc_id>174</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The features used so far lead to high scores for since in datasets B1 and B2.</text>
                  <doc_id>175</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results are comparable to those from Miltsakaki et al. (2005), who used similar features and labels, though with a Maximum Entropy classifier.</text>
                  <doc_id>176</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Moreover, they provide results for individual connectives, and not, as most of the related work for the PDTB, on the whole set of ca.</text>
                  <doc_id>177</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>100 discourse connective types.</text>
                  <doc_id>178</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>However, Miltsakaki et al. (2005) used their own datasets for each connective, which are different from the PDTB, because the PDTB was not available at that time.</text>
                  <doc_id>179</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Our SVM classifier outperforms considerably the Maximum Entropy classifier on the three-way classification task (with T, C, T/C), with an accuracy of 85.4% vs. 75.5%, obtained however on different datasets.</text>
                  <doc_id>180</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>For the two-way classification (T, C), again on different datasets, our accuracy of 85.7% is slightly lower than the 89.5% given in Miltsakaki et al. (2005).</text>
                  <doc_id>181</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>1</text>
                  <doc_id>182</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For while, when comparing C1 to C2, it appears that reducing the number of labels from six to three increases accuracy by 8-10%.</text>
                  <doc_id>183</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This is probably due to the small number of training instances for the labels T/PUNCT and T/DUR in C1 for example.</text>
                  <doc_id>184</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, even for the larger set of labels, the scores are significantly above baseline (52.2% vs. 44.8%), which indicates that such a classifier might still be useful as input to an MT system, possibly improved thanks to a larger training set.</text>
                  <doc_id>185</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The performance obtained by Miltsakaki et al. (2005) on while is markedly better than ours, with an accuracy of 71.8% compared to ours of 60.9% with three labels.</text>
                  <doc_id>186</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>5.4 Feature Analysis</title>
            <text>The relevance of features can be measured using WEKA by computing the information gain (IG) brought by each feature to the classification task,
1 In another experiment (Meyer, 2011), we also applied our
classifiers to the PDTB data, with less features however. The results were in the same range as those from Miltsakaki et al. (2005), i.e. 75.3% accuracy for since and 59.6% for while.
i.e. the reduction in entropy with respect to desired classes (Hall et al., 2009) &#8211; the higher the IG, the more relevant the feature. Features can be ranked by decreasing IG, as shown in Tables 4, 5 and 6, in which ranks were averaged over the first and the second data set in each series.
The tables show that across all three connectives and the two languages, the contextual features are always in the first positions, thus confirming the importance of the context of a connective. Following these are verbal features, which are, for these connectives, of importance because the temporal meanings are additionally established by verbal tenses. POS and dependency features seem the least help-
ful for disambiguation.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The relevance of features can be measured using WEKA by computing the information gain (IG) brought by each feature to the classification task,</text>
                  <doc_id>187</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1 In another experiment (Meyer, 2011), we also applied our</text>
                  <doc_id>188</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>classifiers to the PDTB data, with less features however.</text>
                  <doc_id>189</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results were in the same range as those from Miltsakaki et al. (2005), i.e. 75.3% accuracy for since and 59.6% for while.</text>
                  <doc_id>190</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>i.e. the reduction in entropy with respect to desired classes (Hall et al., 2009) &#8211; the higher the IG, the more relevant the feature.</text>
                  <doc_id>191</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Features can be ranked by decreasing IG, as shown in Tables 4, 5 and 6, in which ranks were averaged over the first and the second data set in each series.</text>
                  <doc_id>192</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The tables show that across all three connectives and the two languages, the contextual features are always in the first positions, thus confirming the importance of the context of a connective.</text>
                  <doc_id>193</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Following these are verbal features, which are, for these connectives, of importance because the temporal meanings are additionally established by verbal tenses.</text>
                  <doc_id>194</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>POS and dependency features seem the least help-</text>
                  <doc_id>195</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>ful for disambiguation.</text>
                  <doc_id>196</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>6</index>
        <title>6 Conclusion and Future Work</title>
        <text>We have described a translation-oriented approach to the manual and automatic annotation of discourse connectives, with the goal of identifying their senses automatically, prior to machine translation. The manual annotation of the senses of connectives has been enhanced through parallel corpora and translation spotting. This has lead to tag sets that improved both inter-annotator agreement and automatic labeling, which reached state-of-the-art scores. The analysis of relevant features has shown the utility of contextual information. To improve over these initial results, we will use more semantic information, such as relations found in WordNet between words in the neighborhood of connectives &#8211; e.g. word similarity measures and semantic relations such as antonymy. To generate more training instances of the labels found, manual annotation will continue in order to see whether the senses found through translation spotting can improve automatic disambiguation of many more connectives. The annotation of a large parallel corpus will then help to train disambiguation tools along with statistical MT systems that use their output.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We have described a translation-oriented approach to the manual and automatic annotation of discourse connectives, with the goal of identifying their senses automatically, prior to machine translation.</text>
              <doc_id>197</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The manual annotation of the senses of connectives has been enhanced through parallel corpora and translation spotting.</text>
              <doc_id>198</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This has lead to tag sets that improved both inter-annotator agreement and automatic labeling, which reached state-of-the-art scores.</text>
              <doc_id>199</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The analysis of relevant features has shown the utility of contextual information.</text>
              <doc_id>200</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>To improve over these initial results, we will use more semantic information, such as relations found in WordNet between words in the neighborhood of connectives &#8211; e.g. word similarity measures and semantic relations such as antonymy.</text>
              <doc_id>201</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>To generate more training instances of the labels found, manual annotation will continue in order to see whether the senses found through translation spotting can improve automatic disambiguation of many more connectives.</text>
              <doc_id>202</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>The annotation of a large parallel corpus will then help to train disambiguation tools along with statistical MT systems that use their output.</text>
              <doc_id>203</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>7</index>
        <title>Acknowledgments</title>
        <text>We are grateful for the funding of this work by the Swiss National Science Foundation (SNSF) under the COMTIS Sinergia Project, n. CRSI22 127510 (see www.idiap.ch/comtis/).
References
Bruno Cartoni, Sandrine Zufferey, Thomas Meyer, and Andrei Popescu-Belis. 2011. How comparable are parallel corpora? Measuring the distribution of general vocabulary and connectives. In Proceedings of 4th Workshop on Building and Using Comparable Corpora, Portland, OR. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL 2005 (43rd Annual Meeting of the ACL), pages 173&#8211;180, Ann Arbor, MI.
Pascal Denis and Beno&#238;t Sagot. 2009. Coupling an annotated corpus and a morphosyntactic lexicon for stateof-the-art POS tagging with less human effort. In Proceedings of PACLIC 2009 (23rd Pacific Asia Conference on Language, Information and Computation), pages 110&#8211;119, Hong Kong, China. David duVerle and Helmut Prendinger. 2009. A novel
discourse parser based on support vector machine classification. In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP), pages 665&#8211;673, Singapore. Robert Elwell and Jason Baldridge. 2008. Discourse
connective argument identification with connective specific rankers. In Proceedings of ICSC 2008 (2nd IEEE International Conference on Semantic Computing), pages 198&#8211;205, Santa Clara, CA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: An update. ACM SIGKDD Explorations Newsletter, 11:10&#8211;18. Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of ECML 1998 (10th European Conference on Machine Learning), pages 137&#8211; 142, Chemnitz, Germany.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL 2007 (45th Annual Meeting of the ACL), Demonstration Session, pages 177&#8211;180, Prague, Czech Republic. Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of MT Summit X, pages 79&#8211;86, Phuket, Thailand.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2010. A PDTB-styled end-to-end discourse parser. Technical Report TRB8/10, School of Computing, National University of Singapore, Singapore.
William C. Mann and Sandra A. Thompson. 1988. Rhetorical Structure Theory: towards a functional theory of text organization. Text, 8(3):243&#8211;281. Thomas Meyer. 2011. Disambiguating temporalcontrastive discourse connectives for machine translation. In Proceedings of ACL-HLT 2011 (49th Annual Meeting of the ACL: Human Language Technologies), Student Session, Portland, OR. Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Aravind Joshi, and Bonnie Webber. 2005. Experiments on sense annotations and sense disambiguation of discourse connectives. In Proceedings of the TLT 2005 (4th Workshop on Treebanks and Linguistic Theories), Barcelona, Spain. Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of IWPT 2008 (8th International Workshop on Parsing Technologies), pages 149&#8211;160, Tokyo, Japan. Marie-Paule P&#233;ry-Woodley, Nicholas Asher, Patrice
Enjalbert, Farah Benamara, Myriam Bras, C&#233;cile Fabre, St&#233;phane Ferrari, Lydia-Mai Ho-Dac, Anne Le Draoulec, Yann Mathet, Philippe Muller, Laurent Pr&#233;vot, Josette Rebeyrolle, Ludovic Tanguy, Marianne Vergez-Couret, Laure Vieu, and Antoine Widl&#246;cher. 2009. Annodis: une approche outill&#233;e de l&#8217;annotation
de structures discursives. In Proceedings of TALN 2009 (16&#232;me Conf&#233;rence sur le Traitement Automatique des Langues Naturelles), Paris, France. Volha Petukhova and Harry Bunt. 2009. Towards a multidimensional semantics of discourse markers in spoken dialogue. In Proceedings of IWCS-8 (8th International Conference on Computational Semantics), pages 157&#8211;168, Tilburg, The Netherlands. Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text. In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP), Short Papers, pages 13&#8211;16, Singapore. Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani
Nenkova, Alan Lee, and Aravind Joshi. 2008. Easily identifiable discourse relations. In Proceedings of Coling 2008 (22nd International Conference on Computational Linguistics), Companion Volume: Posters, pages 87&#8211;90, Manchester, UK. Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of LREC 2008 (6th International Conference on Language Resources and Evaluation), pages 2961&#8211;2968, Marrakech, Morocco. Charlotte Roze, Laurence Danlos, and Phillippe Muller.
2010. LEXCONN: a French lexicon of discourse connectives. In Proceedings of MAD 2010 (Multidis-
ciplinary Approaches to Discourse), pages 114&#8211;125,
Moissac, France. Manfred Stede and Carla Umbach. 1998. DiMLex: a lexicon of discourse markers for text generation and understanding. In Proceedings of ACL 1998 (36th Annual Meeting of the ACL), pages 1238&#8211;1242, Montreal, Canada. Ben Wellner, James Pustejovsky, Catherine Havasi,
Roser Sauri, and Anna Rumshisky. 2006. Classification of discourse coherence relations: An exploratory study using multiple knowledge sources. In Proceedings of 7th SIGDIAL Workshop on Discourse and Dialogue, pages 117&#8211;125, Sydney, Australia. S&#225;rka Zik&#225;nov&#225;, Lucie Mladov&#225;, Ji&#345;&#237; M&#237;rovsk&#253;, and Pavlina J&#237;nov&#225;. 2010. Typical cases of annotators&#8217; disagreement in discourse annotations in Prague Dependency Treebank. In Proceedings of LREC 2010 (7th International Conference on Language Resources and Evaluation), pages 2002&#8211;2006, Valletta, Malta.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We are grateful for the funding of this work by the Swiss National Science Foundation (SNSF) under the COMTIS Sinergia Project, n. CRSI22 127510 (see www.idiap.ch/comtis/).</text>
              <doc_id>204</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>References</text>
              <doc_id>205</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Bruno Cartoni, Sandrine Zufferey, Thomas Meyer, and Andrei Popescu-Belis.</text>
              <doc_id>206</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2011.</text>
              <doc_id>207</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>How comparable are parallel corpora?</text>
              <doc_id>208</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Measuring the distribution of general vocabulary and connectives.</text>
              <doc_id>209</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of 4th Workshop on Building and Using Comparable Corpora, Portland, OR.</text>
              <doc_id>210</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Eugene Charniak and Mark Johnson.</text>
              <doc_id>211</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>2005.</text>
              <doc_id>212</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Coarse-tofine n-best parsing and maxent discriminative reranking.</text>
              <doc_id>213</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL 2005 (43rd Annual Meeting of the ACL), pages 173&#8211;180, Ann Arbor, MI.</text>
              <doc_id>214</doc_id>
              <sec_id>8</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Pascal Denis and Beno&#238;t Sagot.</text>
              <doc_id>215</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>216</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Coupling an annotated corpus and a morphosyntactic lexicon for stateof-the-art POS tagging with less human effort.</text>
              <doc_id>217</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of PACLIC 2009 (23rd Pacific Asia Conference on Language, Information and Computation), pages 110&#8211;119, Hong Kong, China.</text>
              <doc_id>218</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>David duVerle and Helmut Prendinger.</text>
              <doc_id>219</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>220</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>A novel</text>
              <doc_id>221</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>discourse parser based on support vector machine classification.</text>
              <doc_id>222</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP), pages 665&#8211;673, Singapore.</text>
              <doc_id>223</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Robert Elwell and Jason Baldridge.</text>
              <doc_id>224</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>2008.</text>
              <doc_id>225</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Discourse</text>
              <doc_id>226</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>connective argument identification with connective specific rankers.</text>
              <doc_id>227</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ICSC 2008 (2nd IEEE International Conference on Semantic Computing), pages 198&#8211;205, Santa Clara, CA.</text>
              <doc_id>228</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten.</text>
              <doc_id>229</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>230</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The WEKA data mining software: An update.</text>
              <doc_id>231</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>ACM SIGKDD Explorations Newsletter, 11:10&#8211;18.</text>
              <doc_id>232</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Thorsten Joachims.</text>
              <doc_id>233</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>1998.</text>
              <doc_id>234</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Text categorization with support vector machines: Learning with many relevant features.</text>
              <doc_id>235</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ECML 1998 (10th European Conference on Machine Learning), pages 137&#8211; 142, Chemnitz, Germany.</text>
              <doc_id>236</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs.</text>
              <doc_id>237</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2007.</text>
              <doc_id>238</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Moses: Open source toolkit for statistical machine translation.</text>
              <doc_id>239</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL 2007 (45th Annual Meeting of the ACL), Demonstration Session, pages 177&#8211;180, Prague, Czech Republic.</text>
              <doc_id>240</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Philipp Koehn.</text>
              <doc_id>241</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>2005.</text>
              <doc_id>242</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Europarl: A parallel corpus for</text>
              <doc_id>243</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>statistical machine translation.</text>
              <doc_id>244</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of MT Summit X, pages 79&#8211;86, Phuket, Thailand.</text>
              <doc_id>245</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan.</text>
              <doc_id>246</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2010.</text>
              <doc_id>247</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A PDTB-styled end-to-end discourse parser.</text>
              <doc_id>248</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Technical Report TRB8/10, School of Computing, National University of Singapore, Singapore.</text>
              <doc_id>249</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>William C. Mann and Sandra A. Thompson.</text>
              <doc_id>250</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>1988.</text>
              <doc_id>251</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Rhetorical Structure Theory: towards a functional theory of text organization.</text>
              <doc_id>252</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Text, 8(3):243&#8211;281.</text>
              <doc_id>253</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Thomas Meyer.</text>
              <doc_id>254</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>2011.</text>
              <doc_id>255</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Disambiguating temporalcontrastive discourse connectives for machine translation.</text>
              <doc_id>256</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL-HLT 2011 (49th Annual Meeting of the ACL: Human Language Technologies), Student Session, Portland, OR.</text>
              <doc_id>257</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Aravind Joshi, and Bonnie Webber.</text>
              <doc_id>258</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>2005.</text>
              <doc_id>259</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>Experiments on sense annotations and sense disambiguation of discourse connectives.</text>
              <doc_id>260</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of the TLT 2005 (4th Workshop on Treebanks and Linguistic Theories), Barcelona, Spain.</text>
              <doc_id>261</doc_id>
              <sec_id>11</sec_id>
            </sentence>
            <sentence>
              <text>Joakim Nivre.</text>
              <doc_id>262</doc_id>
              <sec_id>12</sec_id>
            </sentence>
            <sentence>
              <text>2003.</text>
              <doc_id>263</doc_id>
              <sec_id>13</sec_id>
            </sentence>
            <sentence>
              <text>An efficient algorithm for projective dependency parsing.</text>
              <doc_id>264</doc_id>
              <sec_id>14</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of IWPT 2008 (8th International Workshop on Parsing Technologies), pages 149&#8211;160, Tokyo, Japan.</text>
              <doc_id>265</doc_id>
              <sec_id>15</sec_id>
            </sentence>
            <sentence>
              <text>Marie-Paule P&#233;ry-Woodley, Nicholas Asher, Patrice</text>
              <doc_id>266</doc_id>
              <sec_id>16</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Enjalbert, Farah Benamara, Myriam Bras, C&#233;cile Fabre, St&#233;phane Ferrari, Lydia-Mai Ho-Dac, Anne Le Draoulec, Yann Mathet, Philippe Muller, Laurent Pr&#233;vot, Josette Rebeyrolle, Ludovic Tanguy, Marianne Vergez-Couret, Laure Vieu, and Antoine Widl&#246;cher.</text>
              <doc_id>267</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>268</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Annodis: une approche outill&#233;e de l&#8217;annotation</text>
              <doc_id>269</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>de structures discursives.</text>
              <doc_id>270</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of TALN 2009 (16&#232;me Conf&#233;rence sur le Traitement Automatique des Langues Naturelles), Paris, France.</text>
              <doc_id>271</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Volha Petukhova and Harry Bunt.</text>
              <doc_id>272</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>273</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Towards a multidimensional semantics of discourse markers in spoken dialogue.</text>
              <doc_id>274</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of IWCS-8 (8th International Conference on Computational Semantics), pages 157&#8211;168, Tilburg, The Netherlands.</text>
              <doc_id>275</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Emily Pitler and Ani Nenkova.</text>
              <doc_id>276</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>2009.</text>
              <doc_id>277</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Using syntax to</text>
              <doc_id>278</doc_id>
              <sec_id>8</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>disambiguate explicit discourse connectives in text.</text>
              <doc_id>279</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP), Short Papers, pages 13&#8211;16, Singapore.</text>
              <doc_id>280</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Emily Pitler, Mridhula Raghupathy, Hena Mehta, Ani</text>
              <doc_id>281</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Nenkova, Alan Lee, and Aravind Joshi.</text>
              <doc_id>282</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2008.</text>
              <doc_id>283</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Easily identifiable discourse relations.</text>
              <doc_id>284</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of Coling 2008 (22nd International Conference on Computational Linguistics), Companion Volume: Posters, pages 87&#8211;90, Manchester, UK.</text>
              <doc_id>285</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber.</text>
              <doc_id>286</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>2008.</text>
              <doc_id>287</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>The Penn Discourse Treebank 2.0.</text>
              <doc_id>288</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of LREC 2008 (6th International Conference on Language Resources and Evaluation), pages 2961&#8211;2968, Marrakech, Morocco.</text>
              <doc_id>289</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Charlotte Roze, Laurence Danlos, and Phillippe Muller.</text>
              <doc_id>290</doc_id>
              <sec_id>8</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2010.</text>
              <doc_id>291</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>LEXCONN: a French lexicon of discourse connectives.</text>
              <doc_id>292</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of MAD 2010 (Multidis-</text>
              <doc_id>293</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>ciplinary Approaches to Discourse), pages 114&#8211;125,</text>
              <doc_id>294</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Moissac, France.</text>
              <doc_id>295</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Manfred Stede and Carla Umbach.</text>
              <doc_id>296</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>1998.</text>
              <doc_id>297</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>DiMLex: a lexicon of discourse markers for text generation and understanding.</text>
              <doc_id>298</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of ACL 1998 (36th Annual Meeting of the ACL), pages 1238&#8211;1242, Montreal, Canada.</text>
              <doc_id>299</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Ben Wellner, James Pustejovsky, Catherine Havasi,</text>
              <doc_id>300</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Roser Sauri, and Anna Rumshisky.</text>
              <doc_id>301</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2006.</text>
              <doc_id>302</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Classification of discourse coherence relations: An exploratory study using multiple knowledge sources.</text>
              <doc_id>303</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of 7th SIGDIAL Workshop on Discourse and Dialogue, pages 117&#8211;125, Sydney, Australia.</text>
              <doc_id>304</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>S&#225;rka Zik&#225;nov&#225;, Lucie Mladov&#225;, Ji&#345;&#237; M&#237;rovsk&#253;, and Pavlina J&#237;nov&#225;.</text>
              <doc_id>305</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>2010.</text>
              <doc_id>306</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Typical cases of annotators&#8217; disagreement in discourse annotations in Prague Dependency Treebank.</text>
              <doc_id>307</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>In Proceedings of LREC 2010 (7th International Conference on Language Resources and Evaluation), pages 2002&#8211;2006, Valletta, Malta.</text>
              <doc_id>308</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TableSeer</source>
        <caption>Table 1: Translation examples from Europarl. Discourse connectives, their translations, and their senses are indi- cated in bold. The first example is a reference transla- tion from EN into FR, while the others are wrong transla- tions generated by MT (EN/FR and respectively FR/EN), hence marked with an asterisk.</caption>
        <reference_text>In PAGE 2: ...3 Illustration of Mistranslations Among the connectives that we plan to process in or- der to improve MT, the three connectives we focus on in this paper are frequent, ambiguous and there- fore difficult to translate correctly by MT systems, as illustrated in the following examples. A first reason why machine translation of connec- tives can be difficult is that there may be no direct lexical correspondence for the explicit source lan- guage connective in the target language, as shown in the reference translation of the first example in  Table1 , taken from the Europarl corpus (Koehn, 2005). EN It is also important that we should not leave these indica- tors floating in the air while congratulating ourselves on the fact that we have produced them....  In PAGE 3: ...an ambiguous connective is explicitly translated by another connective, the incorrect ren- dering of its sense can lead to erroneous translations, as in the second and third examples in  Table1 , which are translated by the Moses SMT decoder (Koehn et al., 2007) trained on the Europarl corpus....</reference_text>
        <page_num>2</page_num>
        <head>
          <rows>
            <row>
              <cell>None</cell>
              <cell>people.</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>FR</cell>
              <cell>e et abattu *Entre 1998 et 1999, les loyalistes ont attaqu?</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>epublicains. 123 personnes, ? 93 pour les r?</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TET</source>
        <caption>Table 2: The six datasets resulting from the manual annotation of the three connectives, with total number of sentences, possible labels and their number of occurrences. The explanations of the labels are given in Sections 4.2 through 4.4.</caption>
        <reference_text></reference_text>
        <page_num>4</page_num>
        <head>
          <rows>
            <row>
              <cell>ID</cell>
              <cell>Connective</cell>
              <cell>Sent.</cell>
              <cell>Labels (nb. of occ.)</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>A1</cell>
              <cell>alors que</cell>
              <cell>403</cell>
              <cell>B (92), C (191), B/C (120)</cell>
            </row>
            <row>
              <cell>A2</cell>
              <cell>alors que</cell>
              <cell>403</cell>
              <cell>B (126), C (277)</cell>
            </row>
            <row>
              <cell>B1</cell>
              <cell>since</cell>
              <cell>727</cell>
              <cell>T (375), C (341), T/C (11)</cell>
            </row>
            <row>
              <cell>B2</cell>
              <cell>since</cell>
              <cell>727</cell>
              <cell>T (375), C (352)</cell>
            </row>
            <row>
              <cell>C1</cell>
              <cell>while</cell>
              <cell>299</cell>
              <cell>T/C (92), CONC (134), C (43)
T/CAUSAL (19), T/DUR (7)
T/PUNCT (4)</cell>
            </row>
            <row>
              <cell>C2</cell>
              <cell>while</cell>
              <cell>299</cell>
              <cell>T (30), C (135), CONC (134)</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TableSeer</source>
        <caption>Table 3: Disambiguation scores for three connectives (number of occurrences in the training sets), with two sets of labels each, for various classification algorithms. Accuracy (Acc.) is in percentage (%), and kappa is zero for the baseline method (majority class). The best scores for each data set are in boldface, and scores significantly above the baseline (95% t-test) are in italics.</caption>
        <reference_text>In PAGE 6: ... The results are re- ported with 10-fold cross validation on the entire data for each connective, using all features.  Table3  lists for each method ? including the ma- jority classifier as a baseline ? the percentage of cor- rectly classified instances (or accuracy, noted Acc.), and the kappa values....  In PAGE 6: ... Significance above the base- line is computed using paired t-tests at 95% confi- dence. When a score is significantly above the base- line, it is shown in italics in  Table3 . The best scores for each dataset, across classifiers, are indicated in boldface....</reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>ID</cell>
              <cell>Connective</cell>
              <cell>#</cell>
              <cell>Labels</cell>
              <cell>Baseline</cell>
              <cell>R. Forest</cell>
              <cell>N. Bayes</cell>
              <cell>SVM</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell></cell>
              <cell></cell>
              <cell>Acc.</cell>
              <cell>Acc.</cell>
              <cell>&#954;</cell>
              <cell>Acc.</cell>
              <cell>&#954;</cell>
              <cell>Acc.</cell>
              <cell>&#954;</cell>
            </row>
            <row>
              <cell>A1</cell>
              <cell>alors que</cell>
              <cell>403</cell>
              <cell>B, C, B/C</cell>
              <cell>46.9</cell>
              <cell>53.1</cell>
              <cell>0.2</cell>
              <cell>55.7</cell>
              <cell>0.3</cell>
              <cell>54.2</cell>
              <cell>0.3</cell>
            </row>
            <row>
              <cell>A2</cell>
              <cell>alors que</cell>
              <cell></cell>
              <cell>B, C</cell>
              <cell>68.7</cell>
              <cell>69.2</cell>
              <cell>0.1</cell>
              <cell>68.3</cell>
              <cell>0.2</cell>
              <cell>64.7</cell>
              <cell>0.1</cell>
            </row>
            <row>
              <cell>B1</cell>
              <cell>since</cell>
              <cell>727</cell>
              <cell>T, C, T/C</cell>
              <cell>51.6</cell>
              <cell>79.8</cell>
              <cell>0.6</cell>
              <cell>82.3</cell>
              <cell>0.7</cell>
              <cell>85.4</cell>
              <cell>0.7</cell>
            </row>
            <row>
              <cell>B2</cell>
              <cell>since</cell>
              <cell></cell>
              <cell>T, C</cell>
              <cell>51.6</cell>
              <cell>80.7</cell>
              <cell>0.6</cell>
              <cell>84.0</cell>
              <cell>0.7</cell>
              <cell>85.7</cell>
              <cell>0.7</cell>
            </row>
            <row>
              <cell>C1</cell>
              <cell>while</cell>
              <cell>299</cell>
              <cell>T/C,</cell>
              <cell>T/PUNCT,</cell>
              <cell>T/DUR,</cell>
              <cell>44.8</cell>
              <cell>43.2</cell>
              <cell>0.1</cell>
              <cell>49.9</cell>
              <cell>0.2</cell>
              <cell>52.2</cell>
              <cell>0.2</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>4</id>
        <source>TET</source>
        <caption>Table 4: Information gain (IG) of features for French connective alors que, ordered by decreasing average ranking (R) in experiments A1 and A2. Features 1&#8211;4 are considerably more relevant than the following ones.</caption>
        <reference_text></reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>R</cell>
              <cell>Feature</cell>
              <cell>IG</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>A1</cell>
              <cell>A2</cell>
            </row>
            <row>
              <cell>1</cell>
              <cell>preceding word</cell>
              <cell>1.12</cell>
              <cell>0.64</cell>
            </row>
            <row>
              <cell>2</cell>
              <cell>following verb</cell>
              <cell>0.81</cell>
              <cell>0.51</cell>
            </row>
            <row>
              <cell>3</cell>
              <cell>first verb</cell>
              <cell>0.74</cell>
              <cell>0.42</cell>
            </row>
            <row>
              <cell>4</cell>
              <cell>following word</cell>
              <cell>0.68</cell>
              <cell>0.23</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>preceding word&#8217;s POS tag</cell>
              <cell>0.15</cell>
              <cell>0.05</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>first verb&#8217;s dep. tag</cell>
              <cell>0.14</cell>
              <cell>0.06</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>following word&#8217;s POS tag</cell>
              <cell>0.19</cell>
              <cell>0.03</cell>
            </row>
            <row>
              <cell>8</cell>
              <cell>preceding word&#8217;s dep. tag</cell>
              <cell>0.10</cell>
              <cell>0.03</cell>
            </row>
            <row>
              <cell>8</cell>
              <cell>connective&#8217;s dep. tag</cell>
              <cell>0.09</cell>
              <cell>0.04</cell>
            </row>
            <row>
              <cell>10</cell>
              <cell>following word&#8217;s dep. tag</cell>
              <cell>0.13</cell>
              <cell>0.013</cell>
            </row>
            <row>
              <cell>10</cell>
              <cell>following verb&#8217;s dep. tag</cell>
              <cell>0.04</cell>
              <cell>0.03</cell>
            </row>
            <row>
              <cell>12</cell>
              <cell>sentence initial</cell>
              <cell>0.05</cell>
              <cell>0.001</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>5</id>
        <source>TableSeer</source>
        <caption>Table 4: Information gain (IG) of features for French con- nective alors que, ordered by decreasing average ranking (R) in experiments A1 and A2. Features 1?4 are consid- erably more relevant than the following ones.#@#@Table 5: Information gain (IG) of features for EN connective since, ordered by decreasing average ranking (R) in experiments B1 and B2.</caption>
        <reference_text>None</reference_text>
        <page_num>8</page_num>
        <head>
          <rows>
            <row>
              <cell>R</cell>
              <cell>Feature</cell>
              <cell>IG</cell>
              <cell>IG</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>B1</cell>
              <cell>B2</cell>
            </row>
            <row>
              <cell>1</cell>
              <cell>preceding word</cell>
              <cell>0.83</cell>
              <cell>0.75</cell>
            </row>
            <row>
              <cell>2</cell>
              <cell>following word</cell>
              <cell>0.56</cell>
              <cell>0.52</cell>
            </row>
            <row>
              <cell>3</cell>
              <cell>following verb?s POS tag#@#@following verb&#8217;s POS tag</cell>
              <cell>0.24</cell>
              <cell>0.21</cell>
            </row>
            <row>
              <cell>4</cell>
              <cell>type of following aux. verb</cell>
              <cell>0.13</cell>
              <cell>0.12</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>type of first aux. verb</cell>
              <cell>0.11</cell>
              <cell>0.11</cell>
            </row>
            <row>
              <cell>6</cell>
              <cell>first verb?s POS tag#@#@first verb&#8217;s POS tag</cell>
              <cell>0.02</cell>
              <cell>0.01</cell>
            </row>
            <row>
              <cell>7</cell>
              <cell>sentence initial</cell>
              <cell>0.00</cell>
              <cell>0.00</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>6</id>
        <source>TableSeer</source>
        <caption>Table 6: Information gain (IG) of features for EN connective while, ordered by decreasing average ranking (R) in experiments C1 and C2. The first two features are considerably more relevant than the remaining ones.</caption>
        <reference_text>None</reference_text>
        <page_num>8</page_num>
        <head>
          <rows>
            <row>
              <cell>R</cell>
              <cell>Feature</cell>
              <cell>IG</cell>
              <cell>IG</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>C1</cell>
              <cell>C2</cell>
            </row>
            <row>
              <cell>1</cell>
              <cell>preceding word</cell>
              <cell>1.02</cell>
              <cell>0.65</cell>
            </row>
            <row>
              <cell>2</cell>
              <cell>following word</cell>
              <cell>0.83</cell>
              <cell>0.55</cell>
            </row>
            <row>
              <cell>3</cell>
              <cell>type of first aux. verb</cell>
              <cell>0.12</cell>
              <cell>0.07</cell>
            </row>
            <row>
              <cell>4</cell>
              <cell>following verb?s POS tag#@#@following verb&#8217;s POS tag</cell>
              <cell>0.16</cell>
              <cell>0.04</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>first verb?s POS tag#@#@first verb&#8217;s POS tag</cell>
              <cell>0.07</cell>
              <cell>0.09</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>type of following aux. verb</cell>
              <cell>0.12</cell>
              <cell>0.05</cell>
            </row>
            <row>
              <cell>7</cell>
              <cell>sentence initial</cell>
              <cell>0.08</cell>
              <cell>0.07</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Bruno Cartoni</author>
          <author>Sandrine Zufferey</author>
          <author>Thomas Meyer</author>
          <author>Andrei Popescu-Belis</author>
        </authors>
        <title>How comparable are parallel corpora? Measuring the distribution of general vocabulary and connectives.</title>
        <publication>In Proceedings of 4th Workshop on Building and Using Comparable Corpora,</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Eugene Charniak</author>
          <author>Mark Johnson</author>
        </authors>
        <title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
        <publication>In Proceedings of ACL 2005 (43rd Annual Meeting of the ACL),</publication>
        <pages>173--180</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Pascal Denis</author>
          <author>Beno&#238;t Sagot</author>
        </authors>
        <title>Coupling an annotated corpus and a morphosyntactic lexicon for stateof-the-art POS tagging with less human effort.</title>
        <publication>In Proceedings of PACLIC 2009 (23rd Pacific Asia Conference on Language, Information and Computation),</publication>
        <pages>110--119</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>David duVerle</author>
          <author>Helmut Prendinger</author>
        </authors>
        <title>A novel discourse parser based on support vector machine classification.</title>
        <publication>In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP),</publication>
        <pages>665--673</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Robert Elwell</author>
          <author>Jason Baldridge</author>
        </authors>
        <title>Discourse connective argument identification with connective specific rankers.</title>
        <publication>In Proceedings of ICSC 2008 (2nd IEEE International Conference on Semantic Computing),</publication>
        <pages>198--205</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Mark Hall</author>
          <author>Eibe Frank</author>
          <author>Geoffrey Holmes</author>
          <author>Bernhard Pfahringer</author>
          <author>Peter Reutemann</author>
          <author>Ian H Witten</author>
        </authors>
        <title>The WEKA data mining software: An update.</title>
        <publication>None</publication>
        <pages>11--10</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Thorsten Joachims</author>
        </authors>
        <title>Text categorization with support vector machines: Learning with many relevant features.</title>
        <publication>In Proceedings of ECML 1998 (10th European Conference on Machine Learning),</publication>
        <pages>137--142</pages>
        <date>1998</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Hieu Hoang</author>
          <author>Alexandra Birch</author>
          <author>Chris Callison-Burch</author>
          <author>Marcello Federico</author>
          <author>Nicola Bertoldi</author>
          <author>Brooke Cowan</author>
          <author>Wade Shen</author>
          <author>Christine Moran</author>
          <author>Richard Zens</author>
        </authors>
        <title>Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs.</title>
        <publication>In Proceedings of ACL 2007 (45th Annual Meeting of the ACL), Demonstration Session,</publication>
        <pages>177--180</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Philipp Koehn</author>
        </authors>
        <title>Europarl: A parallel corpus for statistical machine translation.</title>
        <publication>In Proceedings of MT Summit X,</publication>
        <pages>79--86</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Ziheng Lin</author>
          <author>Hwee Tou Ng</author>
          <author>Min-Yen Kan</author>
        </authors>
        <title>A PDTB-styled end-to-end discourse parser.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>William C Mann</author>
          <author>Sandra A Thompson</author>
        </authors>
        <title>Rhetorical Structure Theory: towards a functional theory of text organization.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1988</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Thomas Meyer</author>
        </authors>
        <title>Disambiguating temporalcontrastive discourse connectives for machine translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>12</id>
        <authors/>
        <title>None</title>
        <publication>In Proceedings of ACL-HLT 2011 (49th Annual Meeting of the ACL: Human Language Technologies),</publication>
        <pages>None</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Eleni Miltsakaki</author>
          <author>Nikhil Dinesh</author>
          <author>Rashmi Prasad</author>
          <author>Aravind Joshi</author>
          <author>Bonnie Webber</author>
        </authors>
        <title>Experiments on sense annotations and sense disambiguation of discourse connectives.</title>
        <publication>In Proceedings of the TLT 2005 (4th Workshop on Treebanks and Linguistic Theories),</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Joakim Nivre</author>
        </authors>
        <title>An efficient algorithm for projective dependency parsing.</title>
        <publication>In Proceedings of IWPT 2008 (8th International Workshop on Parsing Technologies),</publication>
        <pages>149--160</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>Marie-Paule P&#233;ry-Woodley</author>
          <author>Nicholas Asher</author>
          <author>Patrice Enjalbert</author>
          <author>Farah Benamara</author>
          <author>Myriam Bras</author>
        </authors>
        <title>C&#233;cile Fabre, St&#233;phane Ferrari, Lydia-Mai Ho-Dac, Anne Le Draoulec, Yann Mathet, Philippe Muller, Laurent Pr&#233;vot, Josette Rebeyrolle, Ludovic Tanguy, Marianne Vergez-Couret, Laure Vieu, and Antoine Widl&#246;cher.</title>
        <publication>In Proceedings of TALN 2009 (16&#232;me Conf&#233;rence sur le Traitement Automatique des Langues Naturelles),</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Volha Petukhova</author>
          <author>Harry Bunt</author>
        </authors>
        <title>Towards a multidimensional semantics of discourse markers in spoken dialogue.</title>
        <publication>In Proceedings of IWCS-8 (8th International Conference on Computational Semantics),</publication>
        <pages>157--168</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Emily Pitler</author>
          <author>Ani Nenkova</author>
        </authors>
        <title>Using syntax to disambiguate explicit discourse connectives in text.</title>
        <publication>In Proceedings of ACL-IJCNLP 2009 (47th Annual Meeting of the ACL and 4th International Joint Conference on NLP of the AFNLP), Short Papers,</publication>
        <pages>13--16</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Emily Pitler</author>
          <author>Mridhula Raghupathy</author>
          <author>Hena Mehta</author>
          <author>Ani Nenkova</author>
          <author>Alan Lee</author>
          <author>Aravind Joshi</author>
        </authors>
        <title>Easily identifiable discourse relations.</title>
        <publication>In Proceedings of Coling 2008 (22nd International Conference on Computational Linguistics), Companion Volume: Posters,</publication>
        <pages>87--90</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>Rashmi Prasad</author>
          <author>Nikhil Dinesh</author>
          <author>Alan Lee</author>
          <author>Eleni Miltsakaki</author>
          <author>Livio Robaldo</author>
          <author>Aravind Joshi</author>
          <author>Bonnie Webber</author>
        </authors>
        <title>The Penn Discourse Treebank 2.0.</title>
        <publication>In Proceedings of LREC 2008 (6th International Conference on Language Resources and Evaluation),</publication>
        <pages>2961--2968</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>Charlotte Roze</author>
          <author>Laurence Danlos</author>
          <author>Phillippe Muller</author>
        </authors>
        <title>LEXCONN: a French lexicon of discourse connectives.</title>
        <publication>In Proceedings of MAD 2010 (Multidis202 Approaches to Discourse),</publication>
        <pages>114--125</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>Manfred Stede</author>
          <author>Carla Umbach</author>
        </authors>
        <title>DiMLex: a lexicon of discourse markers for text generation and understanding.</title>
        <publication>In Proceedings of ACL 1998 (36th Annual Meeting of the ACL),</publication>
        <pages>1238--1242</pages>
        <date>1998</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>Ben Wellner</author>
          <author>James Pustejovsky</author>
          <author>Catherine Havasi</author>
          <author>Roser Sauri</author>
          <author>Anna Rumshisky</author>
        </authors>
        <title>Classification of discourse coherence relations: An exploratory study using multiple knowledge sources.</title>
        <publication>In Proceedings of 7th SIGDIAL Workshop on Discourse and Dialogue,</publication>
        <pages>117--125</pages>
        <date>2006</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Cartoni et al., 2011</string>
        <sentence_id>46059</sentence_id>
        <char_offset>121</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>0</reference_id>
        <string>Cartoni et al. (2011)</string>
        <sentence_id>46165</sentence_id>
        <char_offset>205</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>2</reference_id>
        <string>Denis and Sagot, 2009</string>
        <sentence_id>46170</sentence_id>
        <char_offset>55</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>duVerle and Prendinger (2009)</string>
        <sentence_id>46183</sentence_id>
        <char_offset>31</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>5</reference_id>
        <string>Hall et al., 2009</string>
        <sentence_id>46194</sentence_id>
        <char_offset>78</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>5</reference_id>
        <string>Hall et al., 2009</string>
        <sentence_id>46229</sentence_id>
        <char_offset>63</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>6</reference_id>
        <string>Joachims, 1998</string>
        <sentence_id>46202</sentence_id>
        <char_offset>175</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>7</reference_id>
        <string>Koehn et al., 2007</string>
        <sentence_id>46093</sentence_id>
        <char_offset>245</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>8</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>46059</sentence_id>
        <char_offset>169</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>8</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>46080</sentence_id>
        <char_offset>296</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>8</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>46164</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>9</reference_id>
        <string>Lin et al., 2010</string>
        <sentence_id>46108</sentence_id>
        <char_offset>176</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>9</reference_id>
        <string>Lin et al. (2010)</string>
        <sentence_id>46109</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>9</reference_id>
        <string>Lin et al. (2010)</string>
        <sentence_id>46183</sentence_id>
        <char_offset>12</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>10</reference_id>
        <string>Mann and Thompson, 1988</string>
        <sentence_id>46106</sentence_id>
        <char_offset>148</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>11</reference_id>
        <string>Meyer, 2011</string>
        <sentence_id>46074</sentence_id>
        <char_offset>53</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>11</reference_id>
        <string>Meyer, 2011</string>
        <sentence_id>46226</sentence_id>
        <char_offset>25</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46067</sentence_id>
        <char_offset>34</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46112</sentence_id>
        <char_offset>47</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46214</sentence_id>
        <char_offset>41</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46217</sentence_id>
        <char_offset>9</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46219</sentence_id>
        <char_offset>132</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46224</sentence_id>
        <char_offset>28</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al. (2005)</string>
        <sentence_id>46228</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>13</reference_id>
        <string>Miltsakaki et al., 2005</string>
        <sentence_id>46182</sentence_id>
        <char_offset>227</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>14</reference_id>
        <string>Nivre, 2003</string>
        <sentence_id>46170</sentence_id>
        <char_offset>106</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>16</reference_id>
        <string>Petukhova and Bunt (2009</string>
        <sentence_id>46063</sentence_id>
        <char_offset>29</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>16</reference_id>
        <string>Petukhova and Bunt (2009</string>
        <sentence_id>46064</sentence_id>
        <char_offset>190</char_offset>
      </citation>
      <citation>
        <id>28</id>
        <reference_id>17</reference_id>
        <string>Pitler and Nenkova, 2009</string>
        <sentence_id>46108</sentence_id>
        <char_offset>267</char_offset>
      </citation>
      <citation>
        <id>29</id>
        <reference_id>19</reference_id>
        <string>Prasad et al., 2008</string>
        <sentence_id>46060</sentence_id>
        <char_offset>29</char_offset>
      </citation>
      <citation>
        <id>30</id>
        <reference_id>19</reference_id>
        <string>Prasad et al., 2008</string>
        <sentence_id>46098</sentence_id>
        <char_offset>108</char_offset>
      </citation>
      <citation>
        <id>31</id>
        <reference_id>20</reference_id>
        <string>Roze et al., 2010</string>
        <sentence_id>46066</sentence_id>
        <char_offset>58</char_offset>
      </citation>
      <citation>
        <id>32</id>
        <reference_id>20</reference_id>
        <string>Roze et al., 2010</string>
        <sentence_id>46105</sentence_id>
        <char_offset>86</char_offset>
      </citation>
      <citation>
        <id>33</id>
        <reference_id>21</reference_id>
        <string>Stede and Umbach, 1998</string>
        <sentence_id>46104</sentence_id>
        <char_offset>80</char_offset>
      </citation>
      <citation>
        <id>34</id>
        <reference_id>22</reference_id>
        <string>Wellner et al. (2006)</string>
        <sentence_id>46110</sentence_id>
        <char_offset>121</char_offset>
      </citation>
      <citation>
        <id>35</id>
        <reference_id>22</reference_id>
        <string>Wellner et al. (2006)</string>
        <sentence_id>46183</sentence_id>
        <char_offset>64</char_offset>
      </citation>
    </citations>
  </content>
</document>
