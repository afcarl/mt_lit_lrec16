<document>
  <filename>D09-1108</filename>
  <authors/>
  <title>Fast Translation Rule Matching for Syntax-based Statistical Machine Translation</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>In a linguistically-motivated syntax-based translation system, the entire translation process is normally carried out in two steps, translation rule matching and target sentence decoding using the matched rules. Both steps are very timeconsuming due to the tremendous number of translation rules, the exhaustive search in translation rule matching and the complex nature of the translation task itself. In this paper, we propose a hyper-tree-based fast algorithm for translation rule matching. Experimental results on the NIST MT-2003 Chinese-English translation task show that our algorithm is at least 19 times faster in rule matching and is able to help to save 57% of overall translation time over previous methods when using large fragment translation rules.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In a linguistically-motivated syntax-based translation system, the entire translation process is normally carried out in two steps, translation rule matching and target sentence decoding using the matched rules.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Both steps are very timeconsuming due to the tremendous number of translation rules, the exhaustive search in translation rule matching and the complex nature of the translation task itself.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In this paper, we propose a hyper-tree-based fast algorithm for translation rule matching.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Experimental results on the NIST MT-2003 Chinese-English translation task show that our algorithm is at least 19 times faster in rule matching and is able to help to save 57% of overall translation time over previous methods when using large fragment translation rules.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation (SMT) (Galley et al., 2004; Liu et al., 2006, 2007; Zhang et al., 2007, 2008a; Mi et al., 2008; Mi and Huang 2008; Zhang et al., 2009). It translates a source sentence to its target one in two steps by using structured translation rules. In the first step, which is called translation rule matching step, all the applicable 1 translation rules are extracted from the entire rule set by matching the source parse tree/forest. The second step is to decode the source sentence into its target one using the extracted translation rules. Both of the two steps are very time-consuming due to the exponential number of translation rules and the complex nature of machine translation as
1 Given a source structure (either a parse tree or a parse
forest), a translation rule is applicable if and only if the left hand side of the translation rule exactly matches a tree fragment of the given source structure.
an NP-hard search problem (Knight, 1999). In the SMT research community, the second step has been well studied and many methods have been proposed to speed up the decoding process, such as node-based or span-based beam search with different pruning strategies (Liu et al., 2006; Zhang et al., 2008a, 2008b) and cube pruning (Huang and Chiang, 2007; Mi et al., 2008). However, the first step attracts less attention. The previous solution to this problem is to do exhaustive searching with heuristics on each tree/forest node or on each source span. This solution becomes computationally infeasible when it is applied to packed forests with loose pruning threshold or rule sets with large tree fragments of large rule height and width. This not only overloads the translation process but also compromises the translation performance since as shown in our experiments the large tree fragment rules are also very useful.
To solve the above issue, in this paper, we propose a hyper-tree-based fast algorithm for translation rule matching. Our solution includes two steps. In the first step, all the translation rules are re-organized using our proposed hyper-tree structure, which is a compact representation of the entire translation rule set, in order to make the common parts of translation rules shared as much as possible. This enables the common parts of different translation rules to be visited only once in rule matching. Please note that the first step can be easily done off-line very fast. As a result, it does not consume real translation time. In the second step, we design a recursive algorithm to traverse the hyper-tree structure and the input source forest in a top-down manner to do the rule matching between them. As we will show later, the hyper-tree structure and the recursive algorithm significantly improve the speed of the rule matching and the entire translation process compared with previous methods.
With the proposed algorithm, we are able to carry out experiments with very loose pruning
thresholds and larger tree fragment rules efficiently. Experimental results on the NIST MT- 2003 Chinese-English translation task shows that our algorithm is 19 times faster in rule matching and is able to save 57% of overall translation time over previous methods when using large fragment translation rules with height up to 5. It also shows that the larger rules with height of up to 5 significantly outperforms the rules with height of up to 3 by around 1 BLEU score.
The rest of this paper is organized as follows. Section 2 introduces the syntax-based translation system that we are working on. Section 3 reviews the previous work. Section 4 explains our solution while section 5 reports the experimental results. Section 6 concludes the paper.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Recently linguistically-motivated syntax-based translation method has achieved great success in statistical machine translation (SMT) (Galley et al., 2004; Liu et al., 2006, 2007; Zhang et al., 2007, 2008a; Mi et al., 2008; Mi and Huang 2008; Zhang et al., 2009).</text>
              <doc_id>4</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It translates a source sentence to its target one in two steps by using structured translation rules.</text>
              <doc_id>5</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In the first step, which is called translation rule matching step, all the applicable 1 translation rules are extracted from the entire rule set by matching the source parse tree/forest.</text>
              <doc_id>6</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The second step is to decode the source sentence into its target one using the extracted translation rules.</text>
              <doc_id>7</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Both of the two steps are very time-consuming due to the exponential number of translation rules and the complex nature of machine translation as</text>
              <doc_id>8</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1 Given a source structure (either a parse tree or a parse</text>
              <doc_id>9</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>forest), a translation rule is applicable if and only if the left hand side of the translation rule exactly matches a tree fragment of the given source structure.</text>
              <doc_id>10</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>an NP-hard search problem (Knight, 1999).</text>
              <doc_id>11</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In the SMT research community, the second step has been well studied and many methods have been proposed to speed up the decoding process, such as node-based or span-based beam search with different pruning strategies (Liu et al., 2006; Zhang et al., 2008a, 2008b) and cube pruning (Huang and Chiang, 2007; Mi et al., 2008).</text>
              <doc_id>12</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>However, the first step attracts less attention.</text>
              <doc_id>13</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The previous solution to this problem is to do exhaustive searching with heuristics on each tree/forest node or on each source span.</text>
              <doc_id>14</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>This solution becomes computationally infeasible when it is applied to packed forests with loose pruning threshold or rule sets with large tree fragments of large rule height and width.</text>
              <doc_id>15</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>This not only overloads the translation process but also compromises the translation performance since as shown in our experiments the large tree fragment rules are also very useful.</text>
              <doc_id>16</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>To solve the above issue, in this paper, we propose a hyper-tree-based fast algorithm for translation rule matching.</text>
              <doc_id>17</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our solution includes two steps.</text>
              <doc_id>18</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In the first step, all the translation rules are re-organized using our proposed hyper-tree structure, which is a compact representation of the entire translation rule set, in order to make the common parts of translation rules shared as much as possible.</text>
              <doc_id>19</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>This enables the common parts of different translation rules to be visited only once in rule matching.</text>
              <doc_id>20</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Please note that the first step can be easily done off-line very fast.</text>
              <doc_id>21</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>As a result, it does not consume real translation time.</text>
              <doc_id>22</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>In the second step, we design a recursive algorithm to traverse the hyper-tree structure and the input source forest in a top-down manner to do the rule matching between them.</text>
              <doc_id>23</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>As we will show later, the hyper-tree structure and the recursive algorithm significantly improve the speed of the rule matching and the entire translation process compared with previous methods.</text>
              <doc_id>24</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>With the proposed algorithm, we are able to carry out experiments with very loose pruning</text>
              <doc_id>25</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>thresholds and larger tree fragment rules efficiently.</text>
              <doc_id>26</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Experimental results on the NIST MT- 2003 Chinese-English translation task shows that our algorithm is 19 times faster in rule matching and is able to save 57% of overall translation time over previous methods when using large fragment translation rules with height up to 5.</text>
              <doc_id>27</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>It also shows that the larger rules with height of up to 5 significantly outperforms the rules with height of up to 3 by around 1 BLEU score.</text>
              <doc_id>28</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The rest of this paper is organized as follows.</text>
              <doc_id>29</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 2 introduces the syntax-based translation system that we are working on.</text>
              <doc_id>30</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Section 3 reviews the previous work.</text>
              <doc_id>31</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Section 4 explains our solution while section 5 reports the experimental results.</text>
              <doc_id>32</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Section 6 concludes the paper.</text>
              <doc_id>33</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Syntax-based Translation</title>
        <text>This section briefly introduces the forest/treebased tree-to-string translation model which serves as the translation platform in this paper.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This section briefly introduces the forest/treebased tree-to-string translation model which serves as the translation platform in this paper.</text>
              <doc_id>34</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Tree-to-string model</title>
            <text>The tree-to-string model (Galley et al. 2004; Liu et al. 2006) views the translation as a structure mapping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence. Fig. 1 illustrates this process. In real translation, the number of possible tree fragment segmentations for a given input tree is exponential in the number of tree nodes.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The tree-to-string model (Galley et al. 2004; Liu et al. 2006) views the translation as a structure mapping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence.</text>
                  <doc_id>35</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Fig.</text>
                  <doc_id>36</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>1 illustrates this process.</text>
                  <doc_id>37</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In real translation, the number of possible tree fragment segmentations for a given input tree is exponential in the number of tree nodes.</text>
                  <doc_id>38</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Forest-based translation</title>
            <text>To overcome parse error for SMT, Mi and Huang (2008) propose forest-based translation by using a packed forest instead of a single syntax tree as the translation input. A packed forest (Tomita 1987; Klein and Manning, 2001; Huang and Chiang, 2005) is a compact representation of many possible parse trees of a sentence, which can be formally described as a triple , where V is the set of non-terminal nodes, E is the set of hyper-edges and S is a sentence represented as an ordered word sequence. A hyper-edge in a packed forest is a group of edges in a tree which connects a father node to all its children nodes, representing a CFG-based parse rule. Fig. 2 is a packed forest incorporating two parse trees T1 and T2 of a sentence as shown in Fig. 3 and Fig. 4. Given a hyper-edge e, let h be its father node, then we say that e is attached to h.
A non-terminal node in a packed forest can be represented as &#8220;label [start, stop]&#8221;, where &#8220;label&#8221; is its syntax category and &#8220;[start, stop]&#8221; is the range of words it covers. For example, the node in Fig. 5 pointed by the dark arrow is labelled as &#8220;NP[3,4]&#8221;, where NP is its label and [3,4] means that it covers the span from the 3 rd word to the 4 th word. In forest-based translation, rule matching is much more complicated than the tree-based one.
XNA declaration is related to some regulation
Figure 1. A tree-to-string translation process. Figure 2. A packed forest
Zhang et al. (2009) reduce the tree sequence problem into tree problem by introducing virtual node and related forest conversion algorithms, so
the algorithm proposed in this paper is also applicable to the tree sequence-based models.
For example, if we want to extract useful rules for node NP[3,4] in Fig 5, we have to generate all the tree fragments rooted at node NP[3,4] as shown in Fig 6, and then query each fragment in the rule set. Let be a node in the packed forest,
represents the number of possible tree fragments rooted at node , then we have:
Figure 3. Tree 1 (T1)
Figure 4. Tree 2 (T2)</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>To overcome parse error for SMT, Mi and Huang (2008) propose forest-based translation by using a packed forest instead of a single syntax tree as the translation input.</text>
                  <doc_id>39</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A packed forest (Tomita 1987; Klein and Manning, 2001; Huang and Chiang, 2005) is a compact representation of many possible parse trees of a sentence, which can be formally described as a triple , where V is the set of non-terminal nodes, E is the set of hyper-edges and S is a sentence represented as an ordered word sequence.</text>
                  <doc_id>40</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A hyper-edge in a packed forest is a group of edges in a tree which connects a father node to all its children nodes, representing a CFG-based parse rule.</text>
                  <doc_id>41</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Fig.</text>
                  <doc_id>42</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>2 is a packed forest incorporating two parse trees T1 and T2 of a sentence as shown in Fig.</text>
                  <doc_id>43</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>3 and Fig.</text>
                  <doc_id>44</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>4.</text>
                  <doc_id>45</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>Given a hyper-edge e, let h be its father node, then we say that e is attached to h.</text>
                  <doc_id>46</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A non-terminal node in a packed forest can be represented as &#8220;label [start, stop]&#8221;, where &#8220;label&#8221; is its syntax category and &#8220;[start, stop]&#8221; is the range of words it covers.</text>
                  <doc_id>47</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For example, the node in Fig.</text>
                  <doc_id>48</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>5 pointed by the dark arrow is labelled as &#8220;NP[3,4]&#8221;, where NP is its label and [3,4] means that it covers the span from the 3 rd word to the 4 th word.</text>
                  <doc_id>49</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In forest-based translation, rule matching is much more complicated than the tree-based one.</text>
                  <doc_id>50</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>XNA declaration is related to some regulation</text>
                  <doc_id>51</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 1.</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A tree-to-string translation process.</text>
                  <doc_id>53</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Figure 2.</text>
                  <doc_id>54</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>A packed forest</text>
                  <doc_id>55</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Zhang et al. (2009) reduce the tree sequence problem into tree problem by introducing virtual node and related forest conversion algorithms, so</text>
                  <doc_id>56</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the algorithm proposed in this paper is also applicable to the tree sequence-based models.</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For example, if we want to extract useful rules for node NP[3,4] in Fig 5, we have to generate all the tree fragments rooted at node NP[3,4] as shown in Fig 6, and then query each fragment in the rule set.</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Let be a node in the packed forest,</text>
                  <doc_id>59</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>represents the number of possible tree fragments rooted at node , then we have:</text>
                  <doc_id>60</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 3.</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Tree 1 (T1)</text>
                  <doc_id>62</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 4.</text>
                  <doc_id>63</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Tree 2 (T2)</text>
                  <doc_id>64</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Matching Methods in Previous Work</title>
        <text>In this section, we discuss the two typical rule matching algorithms used in previous work.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this section, we discuss the two typical rule matching algorithms used in previous work.</text>
              <doc_id>65</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Exhaustive search by tree fragments</title>
            <text>This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al., 2008a).
Figure 5. Node NP[3,4] in packed forest
&#65533; &#65533;&#65533; &#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533; &#65533; &#65533; &#65533;&#65533; &#65533;&#65533;&#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533; &#65533;&#65533; &#65533; &#65533; &#65533;&#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;
&#65533;&#65533;&#65533;&#65533; &#65533;&#65533; &#65533;
The above equation shows that the number of tree fragments is exponential to the span size, the height and the number of hyper-edges it covers. In a real system, one can use heuristics, e.g. the maximum number of nodes and the maximum height of fragment, to limit the number of possible fragments. However, these heuristics are very subjective and hard to optimize. In addition, they may filter out some &#8220;good&#8221; fragments.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>This method generates all possible tree fragments rooted by each node in the source parse tree or forest, and then matches all the generated tree fragments against the source parts (left hand side) of translation rules to extract the useful rules (Zhang et al., 2008a).</text>
                  <doc_id>66</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 5.</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Node NP[3,4] in packed forest</text>
                  <doc_id>68</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533; &#65533;&#65533; &#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533; &#65533; &#65533; &#65533;&#65533; &#65533;&#65533;&#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533; &#65533;&#65533; &#65533; &#65533; &#65533;&#65533; &#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;&#65533;</text>
                  <doc_id>69</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;&#65533;&#65533;&#65533; &#65533;&#65533; &#65533;</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The above equation shows that the number of tree fragments is exponential to the span size, the height and the number of hyper-edges it covers.</text>
                  <doc_id>71</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In a real system, one can use heuristics, e.g. the maximum number of nodes and the maximum height of fragment, to limit the number of possible fragments.</text>
                  <doc_id>72</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, these heuristics are very subjective and hard to optimize.</text>
                  <doc_id>73</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In addition, they may filter out some &#8220;good&#8221; fragments.</text>
                  <doc_id>74</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Exhaustive search by rules</title>
            <text>This method does not generate any source tree fragments. Instead, it does top-down recursive matching from each node one-by-one with each translation rule in the rule set (Mi and Huang 2008).
For example, given a translation rule with its left hand side as shown in Fig. 7, the rule matching between the given rule and the node IP[1,4] in Fig. 2 can be done as follows.
1. Decompose the left hand side of the translation rule as shown in Fig. 7 into a sequence of hyper-edges in top-down, left-to-right order as follows:
IP =&gt; NP VP; NP =&gt; NP NP; NP =&gt; NN; NN =&gt; &#22768; &#26126;
&#65533;
Figure 6. Candidate fragments on NP[3,4]
Figure 7. The left hand side of a rule
2. Pattern match these hyper-edges(rule) oneby-one in top-down left-to-right order from node IP[1,4]. If there is a continuous path in the forest matching all of these hyper-edges in order, then we can say that the rule is useful and matchable
with the tree fragment covered by the continuous path. The following illustrates the matching steps:
1. Match hyper-edge &#8220;IP =&gt; NP VP&#8221; with node IP[1,4]. There are two hyper-edges in the forest matching it: &#8220;IP[1,4] =&gt; NP[1,1] VP[2,4]&#8221; and &#8220;IP[1,4] =&gt; NP[1,2] VP [3,4]&#8221;, which generates two candidate paths.
2. Since hyper-edge &#8220;NP =&gt; NP NP&#8221; fails to match NP[1,1], the path initiated with &#8220;IP[1,4] =&gt; NP[1,1] VP[2,4]&#8221; is pruned out.
3. Since there is a hyper-edge &#8220;NP[1,2] =&gt; NP[1,1] NP[2,2]&#8221; matching &#8220;NP =&gt; NP NP&#8221; on NP[1,2], then continue for further matching.
4. Since &#8220;NP=&gt;NN&#8221; on NP[2,2] matches &#8220;NP[2,2] =&gt; NN[2,2]&#8221;, then continue for further matching.
5. &#8220;NN=&gt; &#22768; &#26126; &#8221; on NN[2,2] matches &#8220;NN[2,2] =&gt; &#22768; &#26126; &#8221; and it is the last hyper-edge in the input rules. Finally, there is one continuous path successfully matching the left hand side of the input rule.
This method is able to avoid the exponential problem of the first method as described in the previous subsection. However, it has to do one-byone pattern matching for each rule on each node. When the rule set is very large (indeed it is very large in the forest-based model even with a small training set), it becomes very slow, and even much slower than the first method.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>This method does not generate any source tree fragments.</text>
                  <doc_id>75</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Instead, it does top-down recursive matching from each node one-by-one with each translation rule in the rule set (Mi and Huang 2008).</text>
                  <doc_id>76</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For example, given a translation rule with its left hand side as shown in Fig.</text>
                  <doc_id>77</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>7, the rule matching between the given rule and the node IP[1,4] in Fig.</text>
                  <doc_id>78</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>2 can be done as follows.</text>
                  <doc_id>79</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1.</text>
                  <doc_id>80</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Decompose the left hand side of the translation rule as shown in Fig.</text>
                  <doc_id>81</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>7 into a sequence of hyper-edges in top-down, left-to-right order as follows:</text>
                  <doc_id>82</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>IP =&gt; NP VP; NP =&gt; NP NP; NP =&gt; NN; NN =&gt; &#22768; &#26126;</text>
                  <doc_id>83</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 6.</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Candidate fragments on NP[3,4]</text>
                  <doc_id>86</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 7.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The left hand side of a rule</text>
                  <doc_id>88</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Pattern match these hyper-edges(rule) oneby-one in top-down left-to-right order from node IP[1,4].</text>
                  <doc_id>90</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>If there is a continuous path in the forest matching all of these hyper-edges in order, then we can say that the rule is useful and matchable</text>
                  <doc_id>91</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>with the tree fragment covered by the continuous path.</text>
                  <doc_id>92</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The following illustrates the matching steps:</text>
                  <doc_id>93</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1.</text>
                  <doc_id>94</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Match hyper-edge &#8220;IP =&gt; NP VP&#8221; with node IP[1,4].</text>
                  <doc_id>95</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>There are two hyper-edges in the forest matching it: &#8220;IP[1,4] =&gt; NP[1,1] VP[2,4]&#8221; and &#8220;IP[1,4] =&gt; NP[1,2] VP [3,4]&#8221;, which generates two candidate paths.</text>
                  <doc_id>96</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2.</text>
                  <doc_id>97</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Since hyper-edge &#8220;NP =&gt; NP NP&#8221; fails to match NP[1,1], the path initiated with &#8220;IP[1,4] =&gt; NP[1,1] VP[2,4]&#8221; is pruned out.</text>
                  <doc_id>98</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3.</text>
                  <doc_id>99</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Since there is a hyper-edge &#8220;NP[1,2] =&gt; NP[1,1] NP[2,2]&#8221; matching &#8220;NP =&gt; NP NP&#8221; on NP[1,2], then continue for further matching.</text>
                  <doc_id>100</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4.</text>
                  <doc_id>101</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Since &#8220;NP=&gt;NN&#8221; on NP[2,2] matches &#8220;NP[2,2] =&gt; NN[2,2]&#8221;, then continue for further matching.</text>
                  <doc_id>102</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>&#8220;NN=&gt; &#22768; &#26126; &#8221; on NN[2,2] matches &#8220;NN[2,2] =&gt; &#22768; &#26126; &#8221; and it is the last hyper-edge in the input rules.</text>
                  <doc_id>104</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Finally, there is one continuous path successfully matching the left hand side of the input rule.</text>
                  <doc_id>105</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>This method is able to avoid the exponential problem of the first method as described in the previous subsection.</text>
                  <doc_id>106</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, it has to do one-byone pattern matching for each rule on each node.</text>
                  <doc_id>107</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>When the rule set is very large (indeed it is very large in the forest-based model even with a small training set), it becomes very slow, and even much slower than the first method.</text>
                  <doc_id>108</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 The Proposed Hyper-tree-based Rule Matching Algorithm</title>
        <text>In this section, we first explain the motivation why we re-organize the translation rule sets, and then elaborate how to re-organize the translation rules using our proposed hyper-tree structure. Finally we discuss the top-down rule matching algorithm between forest and hyper-tree.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this section, we first explain the motivation why we re-organize the translation rule sets, and then elaborate how to re-organize the translation rules using our proposed hyper-tree structure.</text>
              <doc_id>109</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Finally we discuss the top-down rule matching algorithm between forest and hyper-tree.</text>
              <doc_id>110</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 Motivation</title>
            <text>Figure 8. Two rules&#8217; left hand side
Figure 9. Common part of the two rules&#8217; left hand sides in Figure 8
Fig. 9 shows the common part of the left hand sides of two translation rules as shown in Fig. 8. In previous rule matching algorithm, the common parts are matched as many times as they appear in the rule set, which reduces the rule matching speed significantly. This motivates us to propose the hyper-tree structure and the rule matching algorithm to make the common parts shared by multiple translation rules to be visited only once in the entire rule matching process.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Figure 8.</text>
                  <doc_id>111</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Two rules&#8217; left hand side</text>
                  <doc_id>112</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 9.</text>
                  <doc_id>113</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Common part of the two rules&#8217; left hand sides in Figure 8</text>
                  <doc_id>114</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Fig.</text>
                  <doc_id>115</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>9 shows the common part of the left hand sides of two translation rules as shown in Fig.</text>
                  <doc_id>116</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>8.</text>
                  <doc_id>117</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In previous rule matching algorithm, the common parts are matched as many times as they appear in the rule set, which reduces the rule matching speed significantly.</text>
                  <doc_id>118</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This motivates us to propose the hyper-tree structure and the rule matching algorithm to make the common parts shared by multiple translation rules to be visited only once in the entire rule matching process.</text>
                  <doc_id>119</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Hyper-node, hyper-path and hyper-tree</title>
            <text>A hyper-tree is a compact representation of a group of tree translation rules with common parts shared. It consists of a set of hyper-nodes with edges connecting different hyper-nodes into a big tree. A hyper-tree is constructed from the translation rule sets in two steps:
1) Convert each tree translation rule into a hyper-path; 2) Construct the hyper-tree by incrementally
adding each individual hyper-path into the hyper-tree.
A tree rule can be converted into a hyper-path without losing information. Fig. 10 demonstrates the conversion process:
1) We first fill the rule tree with virtual nodes to make all its leaves have the same depth to the root;
2) We then group all the nodes in the same tree level to form a single hyper-node, where we use a comma as a delimiter to separate the tree nodes with different father nodes;
3) A hyper-path is a set of hyper-nodes linked
in a top-down manner.
The commas and virtual nodes are introduced to help to recover the original tree from the hyperpath. Given a tree node in a hyper-node, if there are n commas before it, then its father node is the (n+1) th tree node in the father hyper-node. If we could find father node for each node in hypernodes, then it is straightforward to recover the original tree from the hyper-path by just adding the edges between original father and children nodes except the virtual node .
After converting each tree rule into a hyperpath, we can organize the entire rule set into a big hyper-tree as shown in Figure 11. The concept of hyper-path and hyper-tree could be viewed as an extension of the "prefix merging" ideas for CFG rules (Klein and Manning 2001).
rules for easy discussion. Indeed, we can easily represent all the complete translation rules (not only left hand side) in Fig. 11 by simply adding the corresponding rule target sides into each hyper-node as done by line 5 of Algorithm 1.
Any hyper-path from the root to any hypernode (not necessarily be a leaf of the hyper-tree) in a hyper-tree can represent a tree fragment. As a result, the hyper-tree in Fig. 11 can represent up to 6 candidate tree fragments. It is easy to understand that the maximum number of tree fragments that a hyper-tree can represent is equal to the number of hyper-nodes in it except the root. It is worth noting that a hyper-node in a hyper-tree without any target side rule attached means there is no translation rule corresponding to the tree fragment represented by the hyper-path from the root to the current hyper-node. The compact representation of the rule set by hyper-tree enables a fast algorithm to do translation rule matching.
Algorithm 1. Compile rule set into hyper-tree Input: rule set Output: hyper-tree
Figure 10. Convert tree to hyper-path
Figure 11. A hyper-tree example
Algorithm 1 shows how to organize the rule set into a big hyper-tree. The general process is that for each rule we convert it into a hyper-path and then add the hyper-path into a hyper-tree incrementally. However, there are many different hyper-trees generated given a big rule set. We then introduce a TOP label as the root node to link all the individual hyper-trees to a single big hypertree. Algorithm 2 shows the process of adding a hyper-path into a hyper-tree. Given a hyper-path, we do a top-down matching between the hypertree and the input hyper-path from root hypernode until a leaf hyper-node is reached or there is no matching hyper-node at some level found. Then we add the remaining unmatchable part of the input hyper-path as the descendants of the last matchable hyper-node.
Please note that in Fig. 10 and Fig. 11, we ignore the target side (right hand side) of translation
Algorithm 2. Add hyper-path into hyper-tree Input: hyper-path p and hyper-tree t Notation:
h: the height of hyper-path p p(i) : the hyper-node of ith level (top-down) of p TN: the hyper-node in hyper-tree Output: updated hyper-tree t
4.3 Translation rule matching between forest and hyper-tree
Given the source parse forest and the translation rules represented in the hyper-tree structure, here we present a fast matching algorithm to extract socalled useful translation rules from the entire rule set in a top-down manner for each node of the forest.
As shown in Algorithm 3, the general process of the matching algorithm is as follows:
Algorithm 3. Rule matching on one node Input: hyper-tree T, forest F, and node n Notation:
FP: a pair &lt;FNS, TN&gt;, FNS is the frontier nodes of matched tree fragment, TN is the hyper-tree node matching it
SFP: the queue of FP Output: Available rules on node n
Algorithm 4. PropagateNextLevel Input: Frontier node sequence FNS, hyper-tree node TN Notation: CT: a child node of TN
the number of node sequence (separated by comma, see Fig 11) in CT is equal to the number of node in TN. CT(i) : the ith node sequence in hyper-node CT FNS(i): the ith node in FNS TFNS: the temporary set of frontier node sequence RFNS: the result set of frontier node sequence FP: a pair of frontier node sequence
and hyper-tree node RFP: the result set of FP Output: RFP
1) For each node n of the source forest if no child node of TOP in hyper-tree has the same label with it, it means that no rule matches any tree fragments rooted at the node n (i.e., no useful rules to be used for the node n) (line 1-2)
2) Otherwise, we match the sub-forest starting from the node n against a sub-hyper-tree starting from the matchable child node of TOP layer by layer in a top-down manner. There may be many possible tree fragments rooted at node n and each of them may have multiple useful translation rules. In our implementation, we maintain a data structure of FP = &lt;FNS, TN&gt; to record the currently matched tree fragment of forest and its corresponding hyper-tree node in the rule set, where FNS is the frontier node set of the current tree fragment and TN is the hyper-tree node. The data structure FP is used to help extract useful translation rules and is also used for further matching of larger tree fragments. Finally, all the FPs for the node n are kept in a queue. During the search, the queue size is dynamically increased. The matching algorithm terminates when all the FPs have been visited (line 5-6 and Algorithm 4).
3) In the final queue, each element (FP) of the queue contains the frontier node sequence of the matched tree fragment and its corresponding hyper-tree node. If the target side of a rule in the hyper-tree node is not empty, we just output the frontier nodes of the matched tree fragment, its root node n and all the useful translation rules for later translation process.
Algorithm 4 describes the detailed process of how to propagate the matching process down to the next level. &lt;FNS, TN&gt; is the current level frontier node sequence and hyper-tree node. Given a child hyper-node CT of TN (line 1), we try to find the group of next level frontier node sequence to match it (line 2-18). As shown in Fig 11, a hyper-node consists of a sequence of node sequence with comma as delimiter. For the i th node sequence CT(i) in CT, If CT(i) is , that means FNS(i) is a leaf/frontier node in the matched tree fragment and thus no need to propagate to the next level (line 4-5). Otherwise, we try each hyperedge e of FNS(i) to see whether its children match CT(i), and put the children of the matched hyperedge into a temp set TFNS (line 7-9). If the temp set is empty, that means the current matching fails and no further expansion needs (line 10-12). Otherwise, we integrate current matched children into the final group of frontier node sequence (line 13- 16) by Descartes Product ( ). Finally, we construct all the &lt;FNS, TN&gt; pair for next level matching (line 17-18).
It would be interesting to study the time complexity of our Algorithm 3 and 4. Suppose the maximum number of children of each hyper-node in hyper-tree is N (line 1), the maximum number of node sequence in CT is M (line 2), the maximum number of hyper-edge in each node in packed forest is K (line 7), the maximum number of hyper-edge with same children representation in each node in packed forest is C (i.e. the maximum size of TFNS in line 16, and the maximum complexity of the Descartes Product in line 16
would be C M ), then the time complexity upperbound of Algorithm 4 is O(NM(K+C M )). For Algorithm 3, its time complexity is O(RNM(K+C M )), where R is the maximum number of tree fragment matched in each node.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>A hyper-tree is a compact representation of a group of tree translation rules with common parts shared.</text>
                  <doc_id>120</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>It consists of a set of hyper-nodes with edges connecting different hyper-nodes into a big tree.</text>
                  <doc_id>121</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A hyper-tree is constructed from the translation rule sets in two steps:</text>
                  <doc_id>122</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1) Convert each tree translation rule into a hyper-path; 2) Construct the hyper-tree by incrementally</text>
                  <doc_id>123</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>adding each individual hyper-path into the hyper-tree.</text>
                  <doc_id>124</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A tree rule can be converted into a hyper-path without losing information.</text>
                  <doc_id>125</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Fig.</text>
                  <doc_id>126</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>10 demonstrates the conversion process:</text>
                  <doc_id>127</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1) We first fill the rule tree with virtual nodes to make all its leaves have the same depth to the root;</text>
                  <doc_id>128</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2) We then group all the nodes in the same tree level to form a single hyper-node, where we use a comma as a delimiter to separate the tree nodes with different father nodes;</text>
                  <doc_id>129</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3) A hyper-path is a set of hyper-nodes linked</text>
                  <doc_id>130</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>in a top-down manner.</text>
                  <doc_id>131</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The commas and virtual nodes are introduced to help to recover the original tree from the hyperpath.</text>
                  <doc_id>132</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Given a tree node in a hyper-node, if there are n commas before it, then its father node is the (n+1) th tree node in the father hyper-node.</text>
                  <doc_id>133</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>If we could find father node for each node in hypernodes, then it is straightforward to recover the original tree from the hyper-path by just adding the edges between original father and children nodes except the virtual node .</text>
                  <doc_id>134</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>After converting each tree rule into a hyperpath, we can organize the entire rule set into a big hyper-tree as shown in Figure 11.</text>
                  <doc_id>135</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The concept of hyper-path and hyper-tree could be viewed as an extension of the "prefix merging" ideas for CFG rules (Klein and Manning 2001).</text>
                  <doc_id>136</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>rules for easy discussion.</text>
                  <doc_id>137</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Indeed, we can easily represent all the complete translation rules (not only left hand side) in Fig.</text>
                  <doc_id>138</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>11 by simply adding the corresponding rule target sides into each hyper-node as done by line 5 of Algorithm 1.</text>
                  <doc_id>139</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Any hyper-path from the root to any hypernode (not necessarily be a leaf of the hyper-tree) in a hyper-tree can represent a tree fragment.</text>
                  <doc_id>140</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As a result, the hyper-tree in Fig.</text>
                  <doc_id>141</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>11 can represent up to 6 candidate tree fragments.</text>
                  <doc_id>142</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>It is easy to understand that the maximum number of tree fragments that a hyper-tree can represent is equal to the number of hyper-nodes in it except the root.</text>
                  <doc_id>143</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>It is worth noting that a hyper-node in a hyper-tree without any target side rule attached means there is no translation rule corresponding to the tree fragment represented by the hyper-path from the root to the current hyper-node.</text>
                  <doc_id>144</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>The compact representation of the rule set by hyper-tree enables a fast algorithm to do translation rule matching.</text>
                  <doc_id>145</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 1.</text>
                  <doc_id>146</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Compile rule set into hyper-tree Input: rule set Output: hyper-tree</text>
                  <doc_id>147</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 10.</text>
                  <doc_id>148</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Convert tree to hyper-path</text>
                  <doc_id>149</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 11.</text>
                  <doc_id>150</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A hyper-tree example</text>
                  <doc_id>151</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 1 shows how to organize the rule set into a big hyper-tree.</text>
                  <doc_id>152</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The general process is that for each rule we convert it into a hyper-path and then add the hyper-path into a hyper-tree incrementally.</text>
                  <doc_id>153</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, there are many different hyper-trees generated given a big rule set.</text>
                  <doc_id>154</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We then introduce a TOP label as the root node to link all the individual hyper-trees to a single big hypertree.</text>
                  <doc_id>155</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Algorithm 2 shows the process of adding a hyper-path into a hyper-tree.</text>
                  <doc_id>156</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Given a hyper-path, we do a top-down matching between the hypertree and the input hyper-path from root hypernode until a leaf hyper-node is reached or there is no matching hyper-node at some level found.</text>
                  <doc_id>157</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>Then we add the remaining unmatchable part of the input hyper-path as the descendants of the last matchable hyper-node.</text>
                  <doc_id>158</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Please note that in Fig.</text>
                  <doc_id>159</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>10 and Fig.</text>
                  <doc_id>160</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>11, we ignore the target side (right hand side) of translation</text>
                  <doc_id>161</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 2.</text>
                  <doc_id>162</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Add hyper-path into hyper-tree Input: hyper-path p and hyper-tree t Notation:</text>
                  <doc_id>163</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>h: the height of hyper-path p p(i) : the hyper-node of ith level (top-down) of p TN: the hyper-node in hyper-tree Output: updated hyper-tree t</text>
                  <doc_id>164</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4.3 Translation rule matching between forest and hyper-tree</text>
                  <doc_id>165</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Given the source parse forest and the translation rules represented in the hyper-tree structure, here we present a fast matching algorithm to extract socalled useful translation rules from the entire rule set in a top-down manner for each node of the forest.</text>
                  <doc_id>166</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As shown in Algorithm 3, the general process of the matching algorithm is as follows:</text>
                  <doc_id>167</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 3.</text>
                  <doc_id>168</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Rule matching on one node Input: hyper-tree T, forest F, and node n Notation:</text>
                  <doc_id>169</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>FP: a pair &lt;FNS, TN&gt;, FNS is the frontier nodes of matched tree fragment, TN is the hyper-tree node matching it</text>
                  <doc_id>170</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>SFP: the queue of FP Output: Available rules on node n</text>
                  <doc_id>171</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 4.</text>
                  <doc_id>172</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>PropagateNextLevel Input: Frontier node sequence FNS, hyper-tree node TN Notation: CT: a child node of TN</text>
                  <doc_id>173</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the number of node sequence (separated by comma, see Fig 11) in CT is equal to the number of node in TN.</text>
                  <doc_id>174</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>CT(i) : the ith node sequence in hyper-node CT FNS(i): the ith node in FNS TFNS: the temporary set of frontier node sequence RFNS: the result set of frontier node sequence FP: a pair of frontier node sequence</text>
                  <doc_id>175</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>and hyper-tree node RFP: the result set of FP Output: RFP</text>
                  <doc_id>176</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1) For each node n of the source forest if no child node of TOP in hyper-tree has the same label with it, it means that no rule matches any tree fragments rooted at the node n (i.e., no useful rules to be used for the node n) (line 1-2)</text>
                  <doc_id>177</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2) Otherwise, we match the sub-forest starting from the node n against a sub-hyper-tree starting from the matchable child node of TOP layer by layer in a top-down manner.</text>
                  <doc_id>178</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>There may be many possible tree fragments rooted at node n and each of them may have multiple useful translation rules.</text>
                  <doc_id>179</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In our implementation, we maintain a data structure of FP = &lt;FNS, TN&gt; to record the currently matched tree fragment of forest and its corresponding hyper-tree node in the rule set, where FNS is the frontier node set of the current tree fragment and TN is the hyper-tree node.</text>
                  <doc_id>180</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The data structure FP is used to help extract useful translation rules and is also used for further matching of larger tree fragments.</text>
                  <doc_id>181</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Finally, all the FPs for the node n are kept in a queue.</text>
                  <doc_id>182</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>During the search, the queue size is dynamically increased.</text>
                  <doc_id>183</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The matching algorithm terminates when all the FPs have been visited (line 5-6 and Algorithm 4).</text>
                  <doc_id>184</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3) In the final queue, each element (FP) of the queue contains the frontier node sequence of the matched tree fragment and its corresponding hyper-tree node.</text>
                  <doc_id>185</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>If the target side of a rule in the hyper-tree node is not empty, we just output the frontier nodes of the matched tree fragment, its root node n and all the useful translation rules for later translation process.</text>
                  <doc_id>186</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Algorithm 4 describes the detailed process of how to propagate the matching process down to the next level.</text>
                  <doc_id>187</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>&lt;FNS, TN&gt; is the current level frontier node sequence and hyper-tree node.</text>
                  <doc_id>188</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Given a child hyper-node CT of TN (line 1), we try to find the group of next level frontier node sequence to match it (line 2-18).</text>
                  <doc_id>189</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>As shown in Fig 11, a hyper-node consists of a sequence of node sequence with comma as delimiter.</text>
                  <doc_id>190</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For the i th node sequence CT(i) in CT, If CT(i) is , that means FNS(i) is a leaf/frontier node in the matched tree fragment and thus no need to propagate to the next level (line 4-5).</text>
                  <doc_id>191</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Otherwise, we try each hyperedge e of FNS(i) to see whether its children match CT(i), and put the children of the matched hyperedge into a temp set TFNS (line 7-9).</text>
                  <doc_id>192</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>If the temp set is empty, that means the current matching fails and no further expansion needs (line 10-12).</text>
                  <doc_id>193</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>Otherwise, we integrate current matched children into the final group of frontier node sequence (line 13- 16) by Descartes Product ( ).</text>
                  <doc_id>194</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>Finally, we construct all the &lt;FNS, TN&gt; pair for next level matching (line 17-18).</text>
                  <doc_id>195</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>It would be interesting to study the time complexity of our Algorithm 3 and 4.</text>
                  <doc_id>196</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Suppose the maximum number of children of each hyper-node in hyper-tree is N (line 1), the maximum number of node sequence in CT is M (line 2), the maximum number of hyper-edge in each node in packed forest is K (line 7), the maximum number of hyper-edge with same children representation in each node in packed forest is C (i.e. the maximum size of TFNS in line 16, and the maximum complexity of the Descartes Product in line 16</text>
                  <doc_id>197</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>would be C M ), then the time complexity upperbound of Algorithm 4 is O(NM(K+C M )).</text>
                  <doc_id>198</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For Algorithm 3, its time complexity is O(RNM(K+C M )), where R is the maximum number of tree fragment matched in each node.</text>
                  <doc_id>199</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Experiment</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>200</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>5.1 Experimental settings</title>
            <text>We carry out experiment on Chinese-English NIST evaluation tasks. We use FBIS corpus (250K sentence pairs) as training data with the source side parsed by a modified Charniak parser (Charniak 2000) which can output a packed forest. The Charniak Parser is trained on CTB5, tuned on 301-325 portion, with F1 score of 80.85% on 271- 300 portion. We use GIZA++ (Och and Ney, 2003) to do m-to-n word-alignment and adopt heuristic &#8220;grow-diag-final-and&#8221; to do refinement. A 4-gram language model is trained on Gigaword 3 Xinhua portion by SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing. We use NIST 2002 as development set and NIST 2003 as test set. The feature weights are tuned by the modified Koehn&#8217;s MER (Och, 2003, Koehn, 2007) trainer. We use case-sensitive BLEU-4 (Papineni et al., 2002) to measure the quality of translation result. Zhang et al. 2004&#8217;s implementation is used to do significant test.
Following (Mi and Huang 2008), we use viterbi algorithm to prune the forest. Instead of using a static pruning threshold (Mi and Huang 2008), we set the threshold as the distance of the probabilities of the n th best tree and the 1 st best tree. It means the pruned forest is able to at least keep all the top n best trees. However, because of the sharing nature of the packed forest, it may still contain a large number of additional trees. Our statistic shows that when we set the threshold as the 100 th best tree, the average number of all possible trees in the forest is 1.2*10 5 after pruning.
In our experiments, we compare our algorithm with the two traditional algorithms as discussed in section 3. For the &#8220;Exhaustive search by tree&#8221; algorithm, we use a bottom-up dynamic programming algorithm to generate all the candidate tree fragments rooted at each node. For the &#8220;Exhaustive search by rule&#8221; algorithm, we group all rules with the same left hand side in order to remove the duplicated matching for the same left hand side rules. All these settings aim for fair comparison.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We carry out experiment on Chinese-English NIST evaluation tasks.</text>
                  <doc_id>201</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We use FBIS corpus (250K sentence pairs) as training data with the source side parsed by a modified Charniak parser (Charniak 2000) which can output a packed forest.</text>
                  <doc_id>202</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The Charniak Parser is trained on CTB5, tuned on 301-325 portion, with F1 score of 80.85% on 271- 300 portion.</text>
                  <doc_id>203</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We use GIZA++ (Och and Ney, 2003) to do m-to-n word-alignment and adopt heuristic &#8220;grow-diag-final-and&#8221; to do refinement.</text>
                  <doc_id>204</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>A 4-gram language model is trained on Gigaword 3 Xinhua portion by SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing.</text>
                  <doc_id>205</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>We use NIST 2002 as development set and NIST 2003 as test set.</text>
                  <doc_id>206</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The feature weights are tuned by the modified Koehn&#8217;s MER (Och, 2003, Koehn, 2007) trainer.</text>
                  <doc_id>207</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>We use case-sensitive BLEU-4 (Papineni et al., 2002) to measure the quality of translation result.</text>
                  <doc_id>208</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>Zhang et al. 2004&#8217;s implementation is used to do significant test.</text>
                  <doc_id>209</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Following (Mi and Huang 2008), we use viterbi algorithm to prune the forest.</text>
                  <doc_id>210</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Instead of using a static pruning threshold (Mi and Huang 2008), we set the threshold as the distance of the probabilities of the n th best tree and the 1 st best tree.</text>
                  <doc_id>211</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>It means the pruned forest is able to at least keep all the top n best trees.</text>
                  <doc_id>212</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>However, because of the sharing nature of the packed forest, it may still contain a large number of additional trees.</text>
                  <doc_id>213</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Our statistic shows that when we set the threshold as the 100 th best tree, the average number of all possible trees in the forest is 1.2*10 5 after pruning.</text>
                  <doc_id>214</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In our experiments, we compare our algorithm with the two traditional algorithms as discussed in section 3.</text>
                  <doc_id>215</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For the &#8220;Exhaustive search by tree&#8221; algorithm, we use a bottom-up dynamic programming algorithm to generate all the candidate tree fragments rooted at each node.</text>
                  <doc_id>216</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For the &#8220;Exhaustive search by rule&#8221; algorithm, we group all rules with the same left hand side in order to remove the duplicated matching for the same left hand side rules.</text>
                  <doc_id>217</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>All these settings aim for fair comparison.</text>
                  <doc_id>218</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>5.2 Accuracy, speed vs. rule heights</title>
            <text>We first compare the three algorithms&#8217; performance by setting the maximum rule height from 1
H
to 5. We set the forest pruning threshold to the 100 th best parse tree.
Table 1 compares the speed of the three algorithms. It clearly shows that the speed of both of the two traditional algorithms increases dramatically while the speed of our hyper-tree based algorithm is almost linear to the tree height. In the case of rule height of 5, the hyper-tree algorithm is at least 19 times (9.329/0.486) faster than the two traditional algorithms and saves 8.843(9.329 - 0.486) seconds in rule matching for each sentence on average, which contributes 57% (8.843/(9.329 + 6.21)) speed improvement to the overall translation.
Exhaustive by tree Rule Matching
Exhaustive by rule Hypertreebased
1 0.043 0.077 0.083 2.96
Table 1. Speed in seconds per sentence vs. rule height; &#8220;H&#8221; is rule height, &#8220;D&#8221; represents the decoding time after rule matching
Height BLEU 1 0.1646 2 0.2498 3 0.2824 4 0.2874 5 0.2925 Moses 0.2625
Table 2. BLEU vs. rule height
Table 2 reports the BLEU score with different rule heights, where Moses, a state-of-the-art phrase-based SMT system, serves as the baseline system. It shows the BLEU score consistently improves as the rule height increases. In addition, one can see that the rules with maximum height of 5 are able to outperform the rules with maximum height of 3 by 1 BLEU score (p&lt;0.05) and significantly outperforms Moses by 3 BLEU score (p&lt;0.01). To our knowledge, this is the first time to report the performance of rules up to height of 5 for forest-based translation model.
D
We also study the distribution of the rules used in the 1-best translation output. The results are shown in Table 3; we could see something interesting that is as the rule height increases, the total number of rules with that height decreases, while the percentage of partial-lexicalized increases dramatically. And one thing needs to note is the percentage of partial-lexicalized rules with height of 1 is 0, since there is no partial-lexicalized rule with height of 1 in the rule set (the father node of a word is a pos tag node).
H Total Rule Type Percentage (%)
F P U
1 9814 76.58 0 23.42
Table 3. statistics of rules used in the 1-best translation output, &#8220;F&#8221; means full-lexicalized, &#8220;P&#8221; means partial-lexicalized, &#8220;U&#8221; means unlexiclaizd.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We first compare the three algorithms&#8217; performance by setting the maximum rule height from 1</text>
                  <doc_id>219</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>H</text>
                  <doc_id>220</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>to 5.</text>
                  <doc_id>221</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We set the forest pruning threshold to the 100 th best parse tree.</text>
                  <doc_id>222</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 1 compares the speed of the three algorithms.</text>
                  <doc_id>223</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>It clearly shows that the speed of both of the two traditional algorithms increases dramatically while the speed of our hyper-tree based algorithm is almost linear to the tree height.</text>
                  <doc_id>224</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In the case of rule height of 5, the hyper-tree algorithm is at least 19 times (9.329/0.486) faster than the two traditional algorithms and saves 8.843(9.329 - 0.486) seconds in rule matching for each sentence on average, which contributes 57% (8.843/(9.329 + 6.21)) speed improvement to the overall translation.</text>
                  <doc_id>225</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Exhaustive by tree Rule Matching</text>
                  <doc_id>226</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Exhaustive by rule Hypertreebased</text>
                  <doc_id>227</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1 0.043 0.077 0.083 2.96</text>
                  <doc_id>228</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 1.</text>
                  <doc_id>229</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Speed in seconds per sentence vs. rule height; &#8220;H&#8221; is rule height, &#8220;D&#8221; represents the decoding time after rule matching</text>
                  <doc_id>230</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Height BLEU 1 0.1646 2 0.2498 3 0.2824 4 0.2874 5 0.2925 Moses 0.2625</text>
                  <doc_id>231</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 2.</text>
                  <doc_id>232</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>BLEU vs. rule height</text>
                  <doc_id>233</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 2 reports the BLEU score with different rule heights, where Moses, a state-of-the-art phrase-based SMT system, serves as the baseline system.</text>
                  <doc_id>234</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>It shows the BLEU score consistently improves as the rule height increases.</text>
                  <doc_id>235</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In addition, one can see that the rules with maximum height of 5 are able to outperform the rules with maximum height of 3 by 1 BLEU score (p&lt;0.05) and significantly outperforms Moses by 3 BLEU score (p&lt;0.01).</text>
                  <doc_id>236</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To our knowledge, this is the first time to report the performance of rules up to height of 5 for forest-based translation model.</text>
                  <doc_id>237</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>D</text>
                  <doc_id>238</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We also study the distribution of the rules used in the 1-best translation output.</text>
                  <doc_id>239</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results are shown in Table 3; we could see something interesting that is as the rule height increases, the total number of rules with that height decreases, while the percentage of partial-lexicalized increases dramatically.</text>
                  <doc_id>240</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>And one thing needs to note is the percentage of partial-lexicalized rules with height of 1 is 0, since there is no partial-lexicalized rule with height of 1 in the rule set (the father node of a word is a pos tag node).</text>
                  <doc_id>241</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>H Total Rule Type Percentage (%)</text>
                  <doc_id>242</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>F P U</text>
                  <doc_id>243</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1 9814 76.58 0 23.42</text>
                  <doc_id>244</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 3. statistics of rules used in the 1-best translation output, &#8220;F&#8221; means full-lexicalized, &#8220;P&#8221; means partial-lexicalized, &#8220;U&#8221; means unlexiclaizd.</text>
                  <doc_id>245</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>5.3 Speed vs. forest pruning threshold</title>
            <text>This section studies the impact of the forest pruning threshold on the rule matching speed when setting the maximum rule height to 5.
Threshold Exhaustive by tree Rule Matching
Exhaustive by rule Hypertreebased
Table 4. Speed in seconds per sentence vs. forest pruning threshold
In Table 4, we can see that our hyper-tree based algorithm is the fastest among the three algorithms in all pruning threshold settings and even 150 times faster than both of the two traditional algorithms with threshold of 500 th best. Table 5 shows the average number of parse trees embedded in a packed forest with different pruning thresholds per sentence. We can see that the number of trees increases exponentially when the pruning threshold increases linearly. When the threshold is 500 th best, the average number of trees per sentence is 1.49*10 9 . However, even in this extreme case, the hyper-tree based algorithm is still capable of completing rule matching within 1 second.
Table 5. Average number of trees in packed forest with different pruning threshold.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>This section studies the impact of the forest pruning threshold on the rule matching speed when setting the maximum rule height to 5.</text>
                  <doc_id>246</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Threshold Exhaustive by tree Rule Matching</text>
                  <doc_id>247</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Exhaustive by rule Hypertreebased</text>
                  <doc_id>248</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 4.</text>
                  <doc_id>249</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Speed in seconds per sentence vs. forest pruning threshold</text>
                  <doc_id>250</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Table 4, we can see that our hyper-tree based algorithm is the fastest among the three algorithms in all pruning threshold settings and even 150 times faster than both of the two traditional algorithms with threshold of 500 th best.</text>
                  <doc_id>251</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Table 5 shows the average number of parse trees embedded in a packed forest with different pruning thresholds per sentence.</text>
                  <doc_id>252</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We can see that the number of trees increases exponentially when the pruning threshold increases linearly.</text>
                  <doc_id>253</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>When the threshold is 500 th best, the average number of trees per sentence is 1.49*10 9 .</text>
                  <doc_id>254</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>However, even in this extreme case, the hyper-tree based algorithm is still capable of completing rule matching within 1 second.</text>
                  <doc_id>255</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 5.</text>
                  <doc_id>256</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Average number of trees in packed forest with different pruning threshold.</text>
                  <doc_id>257</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>5.4 Hyper-tree compression rate</title>
            <text>As we describe in section 4.2, theoretically the number of tree fragments that a hyper-tree can represent is equal to the number of hyper-nodes in it. However, in real rule set, there is no guarantee that each tree fragment in the hyper-tree has corresponding translation rules. To gain insights into how effective the compact representation of the hyper-tree and how many hyper-nodes without translation rules, we define the compression rate as follows.
Table 6 reports the different statistics on the rule sets with different maximum rule heights ranging from 1 to 5. The reported statistics are the number of rules, the number of unique left hand side (since there may be more than one rules having the same left hand side), the number of hypernodes and the compression rate.
Table 6. Statistics of rule set and hyper-tree. &#8220;H&#8221; is rule height, &#8220;n_rules&#8221; is the number of rules, &#8220;n_LHS&#8221; is the number of unique left hand side, &#8220;n_nodes&#8221; is the number of hyper-nodes in hypertree and &#8220;c_rate&#8221; is the compression rate.
Table 6 shows that in all the five cases, the compression rates of hyper-tree are all more than
98%. It means that almost all the tree fragments embedded in the hyper-tree have corresponding translation rules. As a result, we are able to use almost only one hyper-edge (i.e. only the frontier nodes of a tree fragment without any internal nodes) to represent all the rules with the same left hand side. This suggests that our hyper-tree is particularly effective in representing the tree translation rules compactly. It also shows that there are a lot of common parts among different translation rules.
All the experiments reported in this section convincingly demonstrate the effectiveness of our proposed hyper-tree representation of translation rules and the hyper-tree-based rule matching algorithm.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>As we describe in section 4.2, theoretically the number of tree fragments that a hyper-tree can represent is equal to the number of hyper-nodes in it.</text>
                  <doc_id>258</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, in real rule set, there is no guarantee that each tree fragment in the hyper-tree has corresponding translation rules.</text>
                  <doc_id>259</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>To gain insights into how effective the compact representation of the hyper-tree and how many hyper-nodes without translation rules, we define the compression rate as follows.</text>
                  <doc_id>260</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 6 reports the different statistics on the rule sets with different maximum rule heights ranging from 1 to 5.</text>
                  <doc_id>261</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The reported statistics are the number of rules, the number of unique left hand side (since there may be more than one rules having the same left hand side), the number of hypernodes and the compression rate.</text>
                  <doc_id>262</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 6.</text>
                  <doc_id>263</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Statistics of rule set and hyper-tree.</text>
                  <doc_id>264</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>&#8220;H&#8221; is rule height, &#8220;n_rules&#8221; is the number of rules, &#8220;n_LHS&#8221; is the number of unique left hand side, &#8220;n_nodes&#8221; is the number of hyper-nodes in hypertree and &#8220;c_rate&#8221; is the compression rate.</text>
                  <doc_id>265</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Table 6 shows that in all the five cases, the compression rates of hyper-tree are all more than</text>
                  <doc_id>266</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>98%.</text>
                  <doc_id>267</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>It means that almost all the tree fragments embedded in the hyper-tree have corresponding translation rules.</text>
                  <doc_id>268</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>As a result, we are able to use almost only one hyper-edge (i.e. only the frontier nodes of a tree fragment without any internal nodes) to represent all the rules with the same left hand side.</text>
                  <doc_id>269</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This suggests that our hyper-tree is particularly effective in representing the tree translation rules compactly.</text>
                  <doc_id>270</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>It also shows that there are a lot of common parts among different translation rules.</text>
                  <doc_id>271</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>All the experiments reported in this section convincingly demonstrate the effectiveness of our proposed hyper-tree representation of translation rules and the hyper-tree-based rule matching algorithm.</text>
                  <doc_id>272</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>6</index>
        <title>6 Conclusion</title>
        <text>In this paper 2, we propose the concept of hypertree for compact rule representation and a hypertree-based fast algorithm for translation rule matching in a forest-based translation system. We compare our algorithm with two previous widelyused rule matching algorithms. Experimental results on the NIST Chinese-English MT 2003 evaluation data set show the rules with maximum rule height of 5 outperform those with height 3 by 1.0 BLEU and outperform MOSES by 3.0 BLEU. In the same test cases, our algorithm is at least 19 times faster than the two traditional algorithms, and contributes 57% speed improvement to the overall translation. We also show that in a more challenging setting (forest containing 1.49*10 9 trees on average) our algorithm is 150 times faster than the two traditional algorithms. Finally, we show that the hyper-tree structure has more than 98% compression rate. It means the compact representation by the hyper-tree is very effective for translation rules.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this paper 2, we propose the concept of hypertree for compact rule representation and a hypertree-based fast algorithm for translation rule matching in a forest-based translation system.</text>
              <doc_id>273</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We compare our algorithm with two previous widelyused rule matching algorithms.</text>
              <doc_id>274</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Experimental results on the NIST Chinese-English MT 2003 evaluation data set show the rules with maximum rule height of 5 outperform those with height 3 by 1.0 BLEU and outperform MOSES by 3.0 BLEU.</text>
              <doc_id>275</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>In the same test cases, our algorithm is at least 19 times faster than the two traditional algorithms, and contributes 57% speed improvement to the overall translation.</text>
              <doc_id>276</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We also show that in a more challenging setting (forest containing 1.49*10 9 trees on average) our algorithm is 150 times faster than the two traditional algorithms.</text>
              <doc_id>277</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Finally, we show that the hyper-tree structure has more than 98% compression rate.</text>
              <doc_id>278</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>It means the compact representation by the hyper-tree is very effective for translation rules.</text>
              <doc_id>279</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TableSeer</source>
        <caption>Table 1. Speed in seconds per sentence vs. rule height; &#8220;H&#8221; is rule height, &#8220;D&#8221; represents the decoding time after rule matching</caption>
        <reference_text>In PAGE 7: ... We set the forest pruning threshold to the  100th best parse tree.    Table1  compares the speed of the three algo- rithms. It clearly shows that the speed of both of  the two traditional algorithms increases dramati- cally while the speed of our hyper-tree based algo- rithm is almost linear to the tree height....</reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>coding time after rule matching</cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Height BLEU</cell>
              <cell>Height BLEU</cell>
            </row>
            <row>
              <cell>1 0.1646</cell>
              <cell>1 0.1646</cell>
            </row>
            <row>
              <cell>2 0.2498</cell>
              <cell>2 0.2498</cell>
            </row>
            <row>
              <cell>3 0.2824</cell>
              <cell>3 0.2824</cell>
            </row>
            <row>
              <cell>4 0.2874</cell>
              <cell>4 0.2874</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>0.2925</cell>
            </row>
            <row>
              <cell>M</cell>
              <cell>o</cell>
              <cell>s</cell>
              <cell>e</cell>
              <cell>s</cell>
              <cell></cell>
              <cell>0</cell>
              <cell>.</cell>
              <cell>2</cell>
              <cell>6</cell>
              <cell>2</cell>
              <cell>5</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TET</source>
        <caption>Table 3. statistics of rules used in the 1-best translation output, &#8220;F&#8221; means full-lexicalized, &#8220;P&#8221; means partial-lexicalized, &#8220;U&#8221; means unlexiclaizd.</caption>
        <reference_text></reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>2</cell>
              <cell>5289</cell>
              <cell>44.99</cell>
              <cell>46.40</cell>
              <cell>8.60</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>3</cell>
              <cell>3925</cell>
              <cell>18.39</cell>
              <cell>77.25</cell>
              <cell>4.35</cell>
            </row>
            <row>
              <cell>4</cell>
              <cell>1810</cell>
              <cell>7.90</cell>
              <cell>87.68</cell>
              <cell>4.41</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>511</cell>
              <cell>6.46</cell>
              <cell>90.50</cell>
              <cell>3.04</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>4</id>
        <source>TET</source>
        <caption>Table 4. Speed in seconds per sentence vs. forest pruning threshold</caption>
        <reference_text></reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>1</cell>
              <cell>1.2</cell>
              <cell>23.66</cell>
              <cell>0.171</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>10</cell>
              <cell>3.1</cell>
              <cell>36.42</cell>
              <cell>0.234</cell>
            </row>
            <row>
              <cell>50</cell>
              <cell>5.7</cell>
              <cell>66.20</cell>
              <cell>0.405</cell>
            </row>
            <row>
              <cell>100</cell>
              <cell>9.3</cell>
              <cell>90.80</cell>
              <cell>0.486</cell>
            </row>
            <row>
              <cell>200</cell>
              <cell>27.3</cell>
              <cell>104.86</cell>
              <cell>0.598</cell>
            </row>
            <row>
              <cell>500</cell>
              <cell>133.6</cell>
              <cell>148.54</cell>
              <cell>0.873</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>5</id>
        <source>TET</source>
        <caption>Table 5. Average number of trees in packed forest with different pruning threshold.</caption>
        <reference_text></reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>Threshold</cell>
              <cell>Number of Trees</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>1</cell>
              <cell>1</cell>
            </row>
            <row>
              <cell>10</cell>
              <cell>32</cell>
            </row>
            <row>
              <cell>50</cell>
              <cell>5922</cell>
            </row>
            <row>
              <cell>100</cell>
              <cell>128860</cell>
            </row>
            <row>
              <cell>200</cell>
              <cell>2.75*10 6</cell>
            </row>
            <row>
              <cell>500</cell>
              <cell>1.49*10 9</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>6</id>
        <source>TET</source>
        <caption>Table 6. Statistics of rule set and hyper-tree. &#8220;H&#8221; is rule height, &#8220;n_rules&#8221; is the number of rules, &#8220;n_LHS&#8221; is the number of unique left hand side, &#8220;n_nodes&#8221; is the number of hyper-nodes in hypertree and &#8220;c_rate&#8221; is the compression rate.</caption>
        <reference_text></reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>H</cell>
              <cell>n_rules</cell>
              <cell>n_LHS</cell>
              <cell>n_nodes</cell>
              <cell>c_rate</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>1</cell>
              <cell>21588</cell>
              <cell>10779</cell>
              <cell>10779</cell>
              <cell>100%</cell>
            </row>
            <row>
              <cell>2</cell>
              <cell>141632</cell>
              <cell>51807</cell>
              <cell>51903</cell>
              <cell>99.8%</cell>
            </row>
            <row>
              <cell>3</cell>
              <cell>1.73*10 6</cell>
              <cell>491268</cell>
              <cell>494919</cell>
              <cell>99.2%</cell>
            </row>
            <row>
              <cell>4</cell>
              <cell>8.65*10 6</cell>
              <cell>2052731</cell>
              <cell>2083296</cell>
              <cell>98.5%</cell>
            </row>
            <row>
              <cell>5</cell>
              <cell>1.89*10 7</cell>
              <cell>3966742</cell>
              <cell>4043824</cell>
              <cell>98.1%</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Eugene Charniak</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2000</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Michel Galley</author>
          <author>Mark Hopkins</author>
          <author>Kevin Knight</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>What&#8217;s in a translation rule?</title>
        <publication>None</publication>
        <pages>04</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Liang Huang</author>
          <author>David Chiang</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Liang Huang</author>
          <author>David Chiang</author>
        </authors>
        <title>Forest rescoring: Faster decoding with integrated language models.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Christopher D Manning</author>
        </authors>
        <title>The corresponding authors of this paper are Hui Zhang (zhangh1982@gmail.com) and Min Zhang (mzhang@i2r.a-star.edu.sg) Dan Klein</title>
        <publication>None</publication>
        <pages>07--144</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Dan Klein</author>
          <author>Christopher D Manning</author>
        </authors>
        <title>Parsing with Treebank Grammars: Empirical Bounds, Theoretical Models, and the Structure of the Penn Treebank.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>ACL</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>338--345</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Kevin Knight</author>
        </authors>
        <title>Decoding Complexity in WordReplacement Translation Models.</title>
        <publication>None</publication>
        <pages>99--4005</pages>
        <date>1999</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Hieu Hoang</author>
          <author>Alexandra Birch</author>
          <author>Chris Callison-Burch</author>
          <author>Marcello Federico</author>
          <author>Nicola Bertoldi</author>
          <author>Brooke Cowan</author>
          <author>Wade Shen</author>
        </authors>
        <title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Yang Liu</author>
          <author>Qun Liu</author>
          <author>Shouxun Lin</author>
        </authors>
        <title>Tree-toString Alignment Template for Statistical Machine Translation.</title>
        <publication>None</publication>
        <pages>609--616</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Yang Liu</author>
          <author>Yun Huang</author>
          <author>Qun Liu</author>
          <author>Shouxun Lin</author>
        </authors>
        <title>Forest-to-String Statistical Translation Rules.</title>
        <publication>None</publication>
        <pages>704--711</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Haitao Mi</author>
          <author>Liang Huang</author>
          <author>Qun Liu</author>
        </authors>
        <title>Forestbased translation.</title>
        <publication>None</publication>
        <pages>08--192</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Haitao Mi</author>
          <author>Liang Huang</author>
        </authors>
        <title>Forest-based Translation Rule Extraction.</title>
        <publication>None</publication>
        <pages>206--214</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Franz Josef Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>A Systematic Comparison of Various Statistical Alignment Models.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Computational Linguistics</author>
        </authors>
        <title>Kishore Papineni, Salim Roukos, ToddWard and WeiJing Zhu.</title>
        <publication>None</publication>
        <pages>02--311</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>Andreas Stolcke</author>
        </authors>
        <title>SRILM - an extensible language modeling toolkit.</title>
        <publication>None</publication>
        <pages>02--901</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Masaru Tomita</author>
        </authors>
        <title>An Efficient AugmentedContext-Free Parsing Algorithm.</title>
        <publication>None</publication>
        <pages>31--46</pages>
        <date>1987</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Hui Zhang</author>
          <author>Min Zhang</author>
          <author>Haizhou Li</author>
        </authors>
        <title>Aiti Aw and Chew Lim Tan.</title>
        <publication>None</publication>
        <pages>09</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Min Zhang</author>
          <author>Hongfei Jiang</author>
        </authors>
        <title>Ai Ti Aw, Jun Sun, Sheng Li and Chew Lim Tan.</title>
        <publication>None</publication>
        <pages>535--542</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>Min Zhang</author>
        </authors>
        <title>Hongfei Jiang, Aiti Aw,</title>
        <publication>None</publication>
        <pages>559--567</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>Min Zhang</author>
          <author>Hongfei Jiang</author>
          <author>Haizhou Li</author>
        </authors>
        <title>Aiti Aw, Sheng Li.</title>
        <publication>2008b. Grammar Comparison Study for Translational Equivalence Modeling and Statistical Machine Translation. COLING-08.</publication>
        <pages>1097--1104</pages>
        <date>None</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Charniak 2000</string>
        <sentence_id>7110</sentence_id>
        <char_offset>117</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Galley et al. 2004</string>
        <sentence_id>6943</sentence_id>
        <char_offset>26</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>1</reference_id>
        <string>Galley et al., 2004</string>
        <sentence_id>6913</sentence_id>
        <char_offset>135</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>2</reference_id>
        <string>Huang and Chiang, 2005</string>
        <sentence_id>6948</sentence_id>
        <char_offset>55</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>3</reference_id>
        <string>Huang and Chiang, 2007</string>
        <sentence_id>6921</sentence_id>
        <char_offset>283</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>4</reference_id>
        <string>Manning, 2001</string>
        <sentence_id>6948</sentence_id>
        <char_offset>40</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>4</reference_id>
        <string>Manning 2001</string>
        <sentence_id>7043</sentence_id>
        <char_offset>128</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>5</reference_id>
        <string>Klein and Manning, 2001</string>
        <sentence_id>6948</sentence_id>
        <char_offset>30</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>5</reference_id>
        <string>Klein and Manning 2001</string>
        <sentence_id>7043</sentence_id>
        <char_offset>118</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>7</reference_id>
        <string>Knight, 1999</string>
        <sentence_id>6920</sentence_id>
        <char_offset>27</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>9</reference_id>
        <string>Liu et al. 2006</string>
        <sentence_id>6943</sentence_id>
        <char_offset>46</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>9</reference_id>
        <string>Liu et al., 2006</string>
        <sentence_id>6913</sentence_id>
        <char_offset>156</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>9</reference_id>
        <string>Liu et al., 2006</string>
        <sentence_id>6921</sentence_id>
        <char_offset>219</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>11</reference_id>
        <string>Mi et al., 2008</string>
        <sentence_id>6913</sentence_id>
        <char_offset>207</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>11</reference_id>
        <string>Mi et al., 2008</string>
        <sentence_id>6921</sentence_id>
        <char_offset>307</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>12</reference_id>
        <string>Mi and Huang (2008)</string>
        <sentence_id>6947</sentence_id>
        <char_offset>33</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>12</reference_id>
        <string>Mi and Huang 2008</string>
        <sentence_id>6913</sentence_id>
        <char_offset>224</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>12</reference_id>
        <string>Mi and Huang 2008</string>
        <sentence_id>6984</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>12</reference_id>
        <string>Mi and Huang 2008</string>
        <sentence_id>7118</sentence_id>
        <char_offset>11</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>12</reference_id>
        <string>Mi and Huang 2008</string>
        <sentence_id>7119</sentence_id>
        <char_offset>45</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>13</reference_id>
        <string>Och and Ney, 2003</string>
        <sentence_id>7112</sentence_id>
        <char_offset>15</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>15</reference_id>
        <string>Stolcke, 2002</string>
        <sentence_id>7113</sentence_id>
        <char_offset>82</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>16</reference_id>
        <string>Tomita 1987</string>
        <sentence_id>6948</sentence_id>
        <char_offset>17</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>17</reference_id>
        <string>Zhang et al., 2009</string>
        <sentence_id>6913</sentence_id>
        <char_offset>243</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>17</reference_id>
        <string>Zhang et al. (2009)</string>
        <sentence_id>6964</sentence_id>
        <char_offset>0</char_offset>
      </citation>
    </citations>
  </content>
</document>
