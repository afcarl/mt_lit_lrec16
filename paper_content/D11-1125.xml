<document>
  <filename>D11-1125</filename>
  <authors>
    <author>Mark Hopkins</author>
  </authors>
  <title>Tuning as Ranking</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999). Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PRO&#8217;s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999).</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We establish PRO&#8217;s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features. This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation.
Several researchers have attempted to address this weakness. Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus. The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Haji&#269; et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT. 1
Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs.
Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful that many would-be enhancements to the
1 The remainder either did not specify their tuning method
(though a number of these used the Moses toolkit (Koehn et al., 2007), which uses MERT for tuning) or, in one case, set weights by hand.
state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets.
We describe tuning in abstract and somewhat formal terms in Section 2, describe the MERT algorithm in the context of those terms and illustrate its scalability issues via a synthetic experiment in Section 3, introduce our pairwise ranking optimization method in Section 4, present numerous large-scale MT experiments to validate our claims in Section 5, discuss some related work in Section 6, and conclude in Section 7.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system.</text>
              <doc_id>5</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features.</text>
              <doc_id>6</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation.</text>
              <doc_id>7</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Several researchers have attempted to address this weakness.</text>
              <doc_id>8</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus.</text>
              <doc_id>9</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009).</text>
              <doc_id>10</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>However, the technique is complex and architecturally quite different from MERT.</text>
              <doc_id>11</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Tellingly, in the entire proceedings of ACL 2010 (Haji&#269; et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.</text>
              <doc_id>12</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>1</text>
              <doc_id>13</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces.</text>
              <doc_id>14</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations.</text>
              <doc_id>15</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs.</text>
              <doc_id>16</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Of primary concern to us is the ease of adoption of our proposed technique.</text>
              <doc_id>17</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software.</text>
              <doc_id>18</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation.</text>
              <doc_id>19</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Mindful that many would-be enhancements to the</text>
              <doc_id>20</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1 The remainder either did not specify their tuning method</text>
              <doc_id>21</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(though a number of these used the Moses toolkit (Koehn et al., 2007), which uses MERT for tuning) or, in one case, set weights by hand.</text>
              <doc_id>22</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets.</text>
              <doc_id>23</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We describe tuning in abstract and somewhat formal terms in Section 2, describe the MERT algorithm in the context of those terms and illustrate its scalability issues via a synthetic experiment in Section 3, introduce our pairwise ranking optimization method in Section 4, present numerous large-scale MT experiments to validate our claims in Section 5, discuss some related work in Section 6, and conclude in Section 7.</text>
              <doc_id>24</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Tuning</title>
        <text>In Figure 1, we show an example candidate space, defined as a tuple &#12296;&#8710;, I, J, f, e, x&#12297; where:
&#8226; &#8710; is a positive integer referred to as the dimensionality of the space
&#8226; I is a (possibly infinite) set of positive integers, referred to as sentence indices
&#8226; J maps each sentence index to a (possibly infinite) set of positive integers, referred to as candidate indices
&#8226; f maps each sentence index to a sentence from the source language
&#8226; e maps each pair &#12296;i, j&#12297; &#8712; I &#215; J(i) to the j th target-language candidate translation of source sentence f(i)
&#8226; x maps each pair &#12296;i, j&#12297; &#8712; I &#215; J(i) to a &#8710;-dimension feature vector representation of e(i, j)
The example candidate space has two source sentences, three candidate translations for each source sentence, and feature vectors of dimension 2. It is an example of a finite candidate space, defined as a candidate space for which I is finite and J maps each index of I to a finite set.
A policy of candidate space &#12296;&#8710;, I, J, f, e, x&#12297; is a function that maps each member i &#8712; I to a member of J(i). A policy corresponds to a choice of one candidate translation for each source sentence. For the example in Figure 1, policy p 1 = {1 &#8614;&#8594; 2, 2 &#8614;&#8594; 3} corresponds to the choice of &#8220;he does not go&#8221; for the first source sentence and &#8220;I do not go&#8221; for the second source sentence. Obviously some policies are better than others. Policy p 2 = {1 &#8614;&#8594; 3, 2 &#8614;&#8594; 1} corresponds to the inferior translations &#8220;she not go&#8221; and &#8220;I go not.&#8221;
We assume the MT system distinguishes between policies using a scoring function for candidate translations of the form h w (i, j) = w &#183; x(i, j), where w is a weight vector of the same dimension as feature vector x(i, j). This scoring function extends to a policy p by summing the cost of each of the policy&#8217;s candidate translations: H w (p) = &#8721; i&#8712;I h w(i, p(i)). As can be seen in Figure 1, using w = [&#8722;2, 1], H w (p 1 ) = 9 and H w (p 2 ) = &#8722;8.
The goal of tuning is to learn a weight vector w such that H w (p) assigns a high score to good policies, and a low score to bad policies. 2 To do so, we need information about which policies are good and which are bad. This information is provided by a &#8220;gold&#8221; scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a).
We want to find a weight vector w such that H w behaves &#8220;similarly&#8221; to G on a candidate space s. We assume a loss function l s (H w , G) which returns the real-valued loss of using scoring function H w when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In Figure 1, we show an example candidate space, defined as a tuple &#12296;&#8710;, I, J, f, e, x&#12297; where:</text>
              <doc_id>25</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; &#8710; is a positive integer referred to as the dimensionality of the space</text>
              <doc_id>26</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; I is a (possibly infinite) set of positive integers, referred to as sentence indices</text>
              <doc_id>27</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; J maps each sentence index to a (possibly infinite) set of positive integers, referred to as candidate indices</text>
              <doc_id>28</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; f maps each sentence index to a sentence from the source language</text>
              <doc_id>29</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; e maps each pair &#12296;i, j&#12297; &#8712; I &#215; J(i) to the j th target-language candidate translation of source sentence f(i)</text>
              <doc_id>30</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#8226; x maps each pair &#12296;i, j&#12297; &#8712; I &#215; J(i) to a &#8710;-dimension feature vector representation of e(i, j)</text>
              <doc_id>31</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The example candidate space has two source sentences, three candidate translations for each source sentence, and feature vectors of dimension 2.</text>
              <doc_id>32</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It is an example of a finite candidate space, defined as a candidate space for which I is finite and J maps each index of I to a finite set.</text>
              <doc_id>33</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>A policy of candidate space &#12296;&#8710;, I, J, f, e, x&#12297; is a function that maps each member i &#8712; I to a member of J(i).</text>
              <doc_id>34</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>A policy corresponds to a choice of one candidate translation for each source sentence.</text>
              <doc_id>35</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>For the example in Figure 1, policy p 1 = {1 &#8614;&#8594; 2, 2 &#8614;&#8594; 3} corresponds to the choice of &#8220;he does not go&#8221; for the first source sentence and &#8220;I do not go&#8221; for the second source sentence.</text>
              <doc_id>36</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Obviously some policies are better than others.</text>
              <doc_id>37</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Policy p 2 = {1 &#8614;&#8594; 3, 2 &#8614;&#8594; 1} corresponds to the inferior translations &#8220;she not go&#8221; and &#8220;I go not.&#8221;</text>
              <doc_id>38</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We assume the MT system distinguishes between policies using a scoring function for candidate translations of the form h w (i, j) = w &#183; x(i, j), where w is a weight vector of the same dimension as feature vector x(i, j).</text>
              <doc_id>39</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This scoring function extends to a policy p by summing the cost of each of the policy&#8217;s candidate translations: H w (p) = &#8721; i&#8712;I h w(i, p(i)).</text>
              <doc_id>40</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>As can be seen in Figure 1, using w = [&#8722;2, 1], H w (p 1 ) = 9 and H w (p 2 ) = &#8722;8.</text>
              <doc_id>41</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The goal of tuning is to learn a weight vector w such that H w (p) assigns a high score to good policies, and a low score to bad policies.</text>
              <doc_id>42</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>2 To do so, we need information about which policies are good and which are bad.</text>
              <doc_id>43</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This information is provided by a &#8220;gold&#8221; scoring function G that maps each policy to a real-valued score.</text>
              <doc_id>44</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a).</text>
              <doc_id>45</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We want to find a weight vector w such that H w behaves &#8220;similarly&#8221; to G on a candidate space s.</text>
              <doc_id>46</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We assume a loss function l s (H w , G) which returns the real-valued loss of using scoring function H w when the gold scoring function is G and the candidate space is s.</text>
              <doc_id>47</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss.</text>
              <doc_id>48</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>3</index>
        <title>3 MERT</title>
        <text>In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset of source sentences 3 and a finite subset of candidate translations as well. The classic tuning architecture used in the dominant MERT approach (Och, 2003) forms the translation subset and learns weight vector w via
2 Without loss of generality, we assume that a higher score
indicates a better translation. 3 See Section 5.2 for the tune sets used in this paper&#8217;s experiments.
Algorithm TUNE(s, G):
1: initialize pool: let s &#8242; = &#12296;&#8710;, I &#8242; , J &#8242; , f, e, x&#12297;,
where I &#8242; &#8838; I and J &#8242; = &#8709;
2: for the desired number of iterations do
3: candidate generation: choose index pairs
(i, j); for each, add j to J &#8242; (i)
4: optimization: find vector w that minimizes
l s &#8242;(H w , G)
5: return w
a feedback loop consisting of two phases. Figure 2 shows the pseudocode. During candidate generation, candidate translations are selected from a base candidate space s and added to a finite candidate space s &#8242; called the candidate pool. During optimization, the weight vector w is optimized to minimize loss l s &#8242;(H w , G).
For its candidate generation phase, MERT generates the k-best candidate translations for each source sentence according to h w , where w is the weight vector from the previous optimization phase (or an arbitrary weight vector for the first iteration).
For its optimization phase, MERT defines the loss function as follows:
l s (H w , G) = max
p
G(p) &#8722; G(arg max H w (p))
p
In other words, it prefers weight vectors w such that the gold function G scores H w &#8217;s best policy as highly as possible (if H w &#8217;s best policy is the same as G&#8217;s best policy, then there is zero loss). Typically the optimization phase is implemented using Och&#8217;s line optimization algorithm (2003).
MERT has proven itself effective at tuning candidate spaces with low dimensionality. However, it is often claimed that MERT does not scale well with dimensionality. To test this claim, we devised the following synthetic data experiment:
1. We created a gold scoring function G that is also a linear function of the same form as H w , i.e., G(p) = H w &#8727;(p) for some gold weight vector w &#8727; . Under this assumption, the role of the optimization phase reduces to learning back the gold weight vector w &#8727; .
2. We generated a &#8710;-dimensionality candidate pool with 500 source &#8220;sentences&#8221; and 100 candidate &#8220;translations&#8221; per sentence. We created the corresponding feature vectors by drawing &#8710; random real numbers uniformly from the interval [0, 500].
3. We ran MERT&#8217;s line optimization on this synthetic candidate pool and compared the learned weight vector w to the gold weight vector w &#8727; using cosine similarity.
We used line optimization in the standard way, by generating 20 random starting weight vectors and hill-climbing on each independently until no further progress is made, then choosing the final weight vector that minimizes loss. We tried various dimensionalities from 10 to 1000. We repeated each setting three times, generating different random data each time. The results in Figure 3 indicate that as the dimensionality of the problem increases MERT rapidly loses the ability to learn w &#8727; . Note that this synthetic problem is considerably easier than a real MT scenario, where the data is noisy and interdependent, and the gold scoring function is nonlinear. If
MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence.</text>
              <doc_id>49</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In practice, tuning optimizes over a finite subset of source sentences 3 and a finite subset of candidate translations as well.</text>
              <doc_id>50</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The classic tuning architecture used in the dominant MERT approach (Och, 2003) forms the translation subset and learns weight vector w via</text>
              <doc_id>51</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2 Without loss of generality, we assume that a higher score</text>
              <doc_id>52</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>indicates a better translation.</text>
              <doc_id>53</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>3 See Section 5.2 for the tune sets used in this paper&#8217;s experiments.</text>
              <doc_id>54</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Algorithm TUNE(s, G):</text>
              <doc_id>55</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1: initialize pool: let s &#8242; = &#12296;&#8710;, I &#8242; , J &#8242; , f, e, x&#12297;,</text>
              <doc_id>56</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>where I &#8242; &#8838; I and J &#8242; = &#8709;</text>
              <doc_id>57</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2: for the desired number of iterations do</text>
              <doc_id>58</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>3: candidate generation: choose index pairs</text>
              <doc_id>59</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>(i, j); for each, add j to J &#8242; (i)</text>
              <doc_id>60</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>4: optimization: find vector w that minimizes</text>
              <doc_id>61</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>l s &#8242;(H w , G)</text>
              <doc_id>62</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>5: return w</text>
              <doc_id>63</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>a feedback loop consisting of two phases.</text>
              <doc_id>64</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Figure 2 shows the pseudocode.</text>
              <doc_id>65</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>During candidate generation, candidate translations are selected from a base candidate space s and added to a finite candidate space s &#8242; called the candidate pool.</text>
              <doc_id>66</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>During optimization, the weight vector w is optimized to minimize loss l s &#8242;(H w , G).</text>
              <doc_id>67</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>For its candidate generation phase, MERT generates the k-best candidate translations for each source sentence according to h w , where w is the weight vector from the previous optimization phase (or an arbitrary weight vector for the first iteration).</text>
              <doc_id>68</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>For its optimization phase, MERT defines the loss function as follows:</text>
              <doc_id>69</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>l s (H w , G) = max</text>
              <doc_id>70</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>p</text>
              <doc_id>71</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>G(p) &#8722; G(arg max H w (p))</text>
              <doc_id>72</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>p</text>
              <doc_id>73</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In other words, it prefers weight vectors w such that the gold function G scores H w &#8217;s best policy as highly as possible (if H w &#8217;s best policy is the same as G&#8217;s best policy, then there is zero loss).</text>
              <doc_id>74</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Typically the optimization phase is implemented using Och&#8217;s line optimization algorithm (2003).</text>
              <doc_id>75</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>MERT has proven itself effective at tuning candidate spaces with low dimensionality.</text>
              <doc_id>76</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>However, it is often claimed that MERT does not scale well with dimensionality.</text>
              <doc_id>77</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>To test this claim, we devised the following synthetic data experiment:</text>
              <doc_id>78</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1.</text>
              <doc_id>79</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We created a gold scoring function G that is also a linear function of the same form as H w , i.e., G(p) = H w &#8727;(p) for some gold weight vector w &#8727; .</text>
              <doc_id>80</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Under this assumption, the role of the optimization phase reduces to learning back the gold weight vector w &#8727; .</text>
              <doc_id>81</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2.</text>
              <doc_id>82</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We generated a &#8710;-dimensionality candidate pool with 500 source &#8220;sentences&#8221; and 100 candidate &#8220;translations&#8221; per sentence.</text>
              <doc_id>83</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We created the corresponding feature vectors by drawing &#8710; random real numbers uniformly from the interval [0, 500].</text>
              <doc_id>84</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>3.</text>
              <doc_id>85</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We ran MERT&#8217;s line optimization on this synthetic candidate pool and compared the learned weight vector w to the gold weight vector w &#8727; using cosine similarity.</text>
              <doc_id>86</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We used line optimization in the standard way, by generating 20 random starting weight vectors and hill-climbing on each independently until no further progress is made, then choosing the final weight vector that minimizes loss.</text>
              <doc_id>87</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We tried various dimensionalities from 10 to 1000.</text>
              <doc_id>88</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We repeated each setting three times, generating different random data each time.</text>
              <doc_id>89</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The results in Figure 3 indicate that as the dimensionality of the problem increases MERT rapidly loses the ability to learn w &#8727; .</text>
              <doc_id>90</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Note that this synthetic problem is considerably easier than a real MT scenario, where the data is noisy and interdependent, and the gold scoring function is nonlinear.</text>
              <doc_id>91</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>If</text>
              <doc_id>92</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario.</text>
              <doc_id>93</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>4</index>
        <title>4 Optimization via Pairwise Ranking</title>
        <text>We would like to modify MERT so that it scales well to high-dimensionality candidate spaces. The most prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT.
With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the established MERT tuning architecture. Instead, we focus on the optimization phase.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We would like to modify MERT so that it scales well to high-dimensionality candidate spaces.</text>
              <doc_id>94</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The most prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009).</text>
              <doc_id>95</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted.</text>
              <doc_id>96</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Our goal is to achieve the same performance with minimal modification to MERT.</text>
              <doc_id>97</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both.</text>
              <doc_id>98</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the established MERT tuning architecture.</text>
              <doc_id>99</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Instead, we focus on the optimization phase.</text>
              <doc_id>100</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 Basic Approach</title>
            <text>While intuitive, the MERT optimization module focuses attention on H w &#8217;s best policy, and not on its overall prowess at ranking policies. We will create an optimization module that directly addresses H w &#8217;s ability to rank policies in the hope that this more holistic approach will generalize better to unseen data.
Assume that the gold scoring function G decomposes in the following way:
G(p) = &#8721; i&#8712;I g(i, p(i)) (1)
where g(i, j) is a local scoring function that scores the single candidate translation e(i, j). We show an example g in Figure 1. For an arbitrary pair of candidate translations e(i, j) and e(i, j &#8242; ), the local gold function g tells us which is the better translation. Note that this induces a ranking on the candidate translations for each source sentence.
We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered. Specifically, for candidate translation pair e(i, j) and e(i, j &#8242; ), we want: g(i, j) &gt; g(i, j &#8242; ) &#8660; h w (i, j) &gt; h w (i, j &#8242; ). We can re-express this condition: g(i, j) &gt; g(i, j &#8242; ) &#8660; h w (i, j) &gt; h w (i, j &#8242; )
&#8660; h w (i, j) &#8722; h w (i, j &#8242; ) &gt; 0
&#8660; w &#183; x(i, j) &#8722; w &#183; x(i, j &#8242; ) &gt; 0
&#8660; w &#183; (x(i, j) &#8722; x(i, j &#8242; )) &gt; 0
Thus optimization reduces to a classic binary classification problem. We create a labeled training instance for this problem by computing difference vector x(i, j) &#8722; x(i, j &#8242; ), and labeling it as a positive or negative instance based on whether, respectively, the first or second vector is superior according to gold function g. To ensure balance, we consider both possible difference vectors from a pair. For example, given the candidate space of Figure 1, since g(1, 1) &gt; g(1, 3), we would add ([&#8722;4, 3], +) and ([4, &#8722;3], &#8722;) to our training set. We can then feed this training data directly to any off-the-shelf classification tool that returns a linear classifier, in order to obtain a weight vector w that optimizes the above condition. This weight vector can then be used directly by the MT system in the subsequent candidate generation phase. The exact loss function l s &#8242;(H w , G) optimized depends on the choice of classifier. 4 Typical approaches to pairwise ranking enumerate all difference vectors as training data. For tuning however, this means O(|I| &#8727; Jmax) 2 vectors, where J max is the cardinality of the largest J(i). Since I and J max commonly range in the thousands, a full enumeration would produce billions of feature vectors. Out of tractability considerations, we sample from the space of difference vectors, using the sampler template in Figure 4. For each source sentence i, the sampler generates &#915; candidate translation pairs &#12296;j, j &#8242; &#12297;, and accepts each pair with probability &#945; i (|g(i, j) &#8722; g(i, j &#8242; )|). Among the accepted pairs, it keeps the &#926; with greatest g differential, and adds their difference vectors to the training data. 5
4 See (Chen et al., 2009) for a brief survey. 5 The intuition for biasing toward high score differential is
Cosine similarity of learned parameter weights
0.8
0.6
0.4
0.2
Synthetic parameter learning of MERT and PRO
PRO Noisy PRO
MERT Noisy MERT
0 0 200 400 600 800 1000 Dimensionality</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>While intuitive, the MERT optimization module focuses attention on H w &#8217;s best policy, and not on its overall prowess at ranking policies.</text>
                  <doc_id>101</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We will create an optimization module that directly addresses H w &#8217;s ability to rank policies in the hope that this more holistic approach will generalize better to unseen data.</text>
                  <doc_id>102</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Assume that the gold scoring function G decomposes in the following way:</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>G(p) = &#8721; i&#8712;I g(i, p(i)) (1)</text>
                  <doc_id>104</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where g(i, j) is a local scoring function that scores the single candidate translation e(i, j).</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We show an example g in Figure 1.</text>
                  <doc_id>106</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For an arbitrary pair of candidate translations e(i, j) and e(i, j &#8242; ), the local gold function g tells us which is the better translation.</text>
                  <doc_id>107</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Note that this induces a ranking on the candidate translations for each source sentence.</text>
                  <doc_id>108</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007).</text>
                  <doc_id>109</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered.</text>
                  <doc_id>110</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Specifically, for candidate translation pair e(i, j) and e(i, j &#8242; ), we want: g(i, j) &gt; g(i, j &#8242; ) &#8660; h w (i, j) &gt; h w (i, j &#8242; ).</text>
                  <doc_id>111</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We can re-express this condition: g(i, j) &gt; g(i, j &#8242; ) &#8660; h w (i, j) &gt; h w (i, j &#8242; )</text>
                  <doc_id>112</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8660; h w (i, j) &#8722; h w (i, j &#8242; ) &gt; 0</text>
                  <doc_id>113</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8660; w &#183; x(i, j) &#8722; w &#183; x(i, j &#8242; ) &gt; 0</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8660; w &#183; (x(i, j) &#8722; x(i, j &#8242; )) &gt; 0</text>
                  <doc_id>115</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Thus optimization reduces to a classic binary classification problem.</text>
                  <doc_id>116</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We create a labeled training instance for this problem by computing difference vector x(i, j) &#8722; x(i, j &#8242; ), and labeling it as a positive or negative instance based on whether, respectively, the first or second vector is superior according to gold function g. To ensure balance, we consider both possible difference vectors from a pair.</text>
                  <doc_id>117</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For example, given the candidate space of Figure 1, since g(1, 1) &gt; g(1, 3), we would add ([&#8722;4, 3], +) and ([4, &#8722;3], &#8722;) to our training set.</text>
                  <doc_id>118</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We can then feed this training data directly to any off-the-shelf classification tool that returns a linear classifier, in order to obtain a weight vector w that optimizes the above condition.</text>
                  <doc_id>119</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This weight vector can then be used directly by the MT system in the subsequent candidate generation phase.</text>
                  <doc_id>120</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>The exact loss function l s &#8242;(H w , G) optimized depends on the choice of classifier.</text>
                  <doc_id>121</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>4 Typical approaches to pairwise ranking enumerate all difference vectors as training data.</text>
                  <doc_id>122</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>For tuning however, this means O(|I| &#8727; Jmax) 2 vectors, where J max is the cardinality of the largest J(i).</text>
                  <doc_id>123</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>Since I and J max commonly range in the thousands, a full enumeration would produce billions of feature vectors.</text>
                  <doc_id>124</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>Out of tractability considerations, we sample from the space of difference vectors, using the sampler template in Figure 4.</text>
                  <doc_id>125</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>For each source sentence i, the sampler generates &#915; candidate translation pairs &#12296;j, j &#8242; &#12297;, and accepts each pair with probability &#945; i (|g(i, j) &#8722; g(i, j &#8242; )|).</text>
                  <doc_id>126</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
                <sentence>
                  <text>Among the accepted pairs, it keeps the &#926; with greatest g differential, and adds their difference vectors to the training data.</text>
                  <doc_id>127</doc_id>
                  <sec_id>11</sec_id>
                </sentence>
                <sentence>
                  <text>5</text>
                  <doc_id>128</doc_id>
                  <sec_id>12</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4 See (Chen et al., 2009) for a brief survey.</text>
                  <doc_id>129</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>5 The intuition for biasing toward high score differential is</text>
                  <doc_id>130</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Cosine similarity of learned parameter weights</text>
                  <doc_id>131</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.8</text>
                  <doc_id>132</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.6</text>
                  <doc_id>133</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.4</text>
                  <doc_id>134</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.2</text>
                  <doc_id>135</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Synthetic parameter learning of MERT and PRO</text>
                  <doc_id>136</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>PRO Noisy PRO</text>
                  <doc_id>137</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>MERT Noisy MERT</text>
                  <doc_id>138</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0 0 200 400 600 800 1000 Dimensionality</text>
                  <doc_id>139</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Scalability</title>
            <text>We repeated the scalability study from Section 3, now using our pairwise ranking optimization (hereafter, PRO) approach. Throughout all experiments with PRO we choose &#915; = 5000, &#926; = 50, and the following step function &#945; for each &#945; i : 6 {
0 if n &lt; 0.05 &#945;(n) = 1 otherwise
We used MegaM (Daum&#233; III, 2004) as a binary classifier in our contrasting synthetic experiment and ran it &#8220;out of the box,&#8221; i.e., with all default settings for binary classification. 7 Figure 3 shows that PRO is able to learn w &#8727; nearly perfectly at all dimensionalities from 10 to 1000.
As noted previously, though, this is a rather simple task. To encourage a disconnect between g and h w and make the synthetic scenario look more like MT reality, we repeated the synthetic experiments
that our primary goal is to ensure good translations are preferred to bad translations, and not to tease apart small differences. 6 We obtained these parameters by trial-and-error experimentation on a single MT system (Urdu-English SBMT), then held them fixed throughout our experiments. We obtained similar results using &#915; = &#926; = 100, and for each &#945; i, a logistic sigmoid function centered at the mean g differential of candidate translation pairs for the i th source sentence. This alternative approach has the advantage of being agnostic about which gold scoring function is used. 7 With the sampling settings previously described and
MegaM as our classifier we were able to optimize two to three times faster than with MERT&#8217;s line optimization.
but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, also in Figure 3 (the lines labeled &#8220;Noisy&#8221;), show that the pairwise ranking approach is less successful than before at learning w &#8727; at high dimensionality, but still greatly outperforms MERT.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We repeated the scalability study from Section 3, now using our pairwise ranking optimization (hereafter, PRO) approach.</text>
                  <doc_id>140</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Throughout all experiments with PRO we choose &#915; = 5000, &#926; = 50, and the following step function &#945; for each &#945; i : 6 {</text>
                  <doc_id>141</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0 if n &lt; 0.05 &#945;(n) = 1 otherwise</text>
                  <doc_id>142</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We used MegaM (Daum&#233; III, 2004) as a binary classifier in our contrasting synthetic experiment and ran it &#8220;out of the box,&#8221; i.e., with all default settings for binary classification.</text>
                  <doc_id>143</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>7 Figure 3 shows that PRO is able to learn w &#8727; nearly perfectly at all dimensionalities from 10 to 1000.</text>
                  <doc_id>144</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>As noted previously, though, this is a rather simple task.</text>
                  <doc_id>145</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To encourage a disconnect between g and h w and make the synthetic scenario look more like MT reality, we repeated the synthetic experiments</text>
                  <doc_id>146</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>that our primary goal is to ensure good translations are preferred to bad translations, and not to tease apart small differences.</text>
                  <doc_id>147</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>6 We obtained these parameters by trial-and-error experimentation on a single MT system (Urdu-English SBMT), then held them fixed throughout our experiments.</text>
                  <doc_id>148</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We obtained similar results using &#915; = &#926; = 100, and for each &#945; i, a logistic sigmoid function centered at the mean g differential of candidate translation pairs for the i th source sentence.</text>
                  <doc_id>149</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This alternative approach has the advantage of being agnostic about which gold scoring function is used.</text>
                  <doc_id>150</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>7 With the sampling settings previously described and</text>
                  <doc_id>151</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>MegaM as our classifier we were able to optimize two to three times faster than with MERT&#8217;s line optimization.</text>
                  <doc_id>152</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500.</text>
                  <doc_id>153</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The results of the noisy synthetic experiments, also in Figure 3 (the lines labeled &#8220;Noisy&#8221;), show that the pairwise ranking approach is less successful than before at learning w &#8727; at high dimensionality, but still greatly outperforms MERT.</text>
                  <doc_id>154</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>4.3 Discussion</title>
            <text>The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1). An advantage of MERT is that it can directly optimize for non-decomposable scoring functions like BLEU. In our experiments, we use the BLEU+1 approximation to BLEU (Liang et al., 2006) to determine class labels. We will nevertheless use BLEU to evaluate the trained systems.
BLEU. For every choice of system, language pair, and feature set, PRO performs comparably with the other methods.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors.</text>
                  <doc_id>155</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture.</text>
                  <doc_id>156</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations.</text>
                  <doc_id>157</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1).</text>
                  <doc_id>158</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>An advantage of MERT is that it can directly optimize for non-decomposable scoring functions like BLEU.</text>
                  <doc_id>159</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>In our experiments, we use the BLEU+1 approximation to BLEU (Liang et al., 2006) to determine class labels.</text>
                  <doc_id>160</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>We will nevertheless use BLEU to evaluate the trained systems.</text>
                  <doc_id>161</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU.</text>
                  <doc_id>162</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For every choice of system, language pair, and feature set, PRO performs comparably with the other methods.</text>
                  <doc_id>163</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Experiments</title>
        <text>We now turn to real machine translation conditions to validate our thesis: We can cleanly replace MERT&#8217;s line optimization with pairwise ranking optimization and immediately realize the benefits of high-dimension tuning. We now detail the three language pairs, two feature scenarios, and two MT models used for our experiments. For each language pair and each MT model we used MERT, MIRA, and PRO to tune with a standard set of baseline features, and used the latter two methods to tune with an extended set of features. 8 At the end of every experiment we used the final feature weights to decode a held-out test set and evaluated it with case-sensitive
BLEU. The results are in Table 1.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We now turn to real machine translation conditions to validate our thesis: We can cleanly replace MERT&#8217;s line optimization with pairwise ranking optimization and immediately realize the benefits of high-dimension tuning.</text>
              <doc_id>164</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We now detail the three language pairs, two feature scenarios, and two MT models used for our experiments.</text>
              <doc_id>165</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>For each language pair and each MT model we used MERT, MIRA, and PRO to tune with a standard set of baseline features, and used the latter two methods to tune with an extended set of features.</text>
              <doc_id>166</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>8 At the end of every experiment we used the final feature weights to decode a held-out test set and evaluated it with case-sensitive</text>
              <doc_id>167</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>BLEU.</text>
              <doc_id>168</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The results are in Table 1.</text>
              <doc_id>169</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>5.1 Systems</title>
            <text>We used two systems, each based on a different MT model. Our syntax-based system (hereafter, SBMT) follows the model of Galley et al. (2004). Our
8 MERT could not run to a satisfactory completion in any
extended feature scenario; as implied in the synthetic data experiment of Section 3, the algorithm makes poor choices for its weights and this leads to low-quality k-best lists and dismal performance, near 0 BLEU in every iteration.
phrase-based system (hereafter, PBMT) follows the model of Och and Ney (2004). In both systems we learn alignments with GIZA++ (Och and Ney, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We used two systems, each based on a different MT model.</text>
                  <doc_id>170</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Our syntax-based system (hereafter, SBMT) follows the model of Galley et al. (2004).</text>
                  <doc_id>171</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Our</text>
                  <doc_id>172</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>8 MERT could not run to a satisfactory completion in any</text>
                  <doc_id>173</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>extended feature scenario; as implied in the synthetic data experiment of Section 3, the algorithm makes poor choices for its weights and this leads to low-quality k-best lists and dismal performance, near 0 BLEU in every iteration.</text>
                  <doc_id>174</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>phrase-based system (hereafter, PBMT) follows the model of Och and Ney (2004).</text>
                  <doc_id>175</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In both systems we learn alignments with GIZA++ (Och and Ney, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method.</text>
                  <doc_id>176</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>5.2 Data</title>
            <text>Table 2 notes the sizes of the datasets used in our experiments. All tune and test data have four English reference sets for the purposes of scoring.
5.2.1 Urdu-English
The training data for Urdu-English is that made available in the constrained track in the NIST 2009 MT evaluation. This includes many lexicon entries and other single-word data, which accounts for the large number of lines relative to word count. The NIST 2008 evaluation set, which contains newswire and web data, is split into two parts; we used roughly half each for tune and test. We trained a 5-gram English language model on the English side of the training data.
5.2.2 Arabic-English
The training data for Arabic English is that made available in the constrained track in the NIST 2008 MT evaluation. The tune set, which contains only newswire data, is a mix from NIST MT evaluation sets from 2003&#8211;2006 and from GALE development data. The test set, which contains both web and newswire data, is the evaluation set from the NIST 2008 MT evaluation. We trained a 4-gram English language model on the English side of the training data.
5.2.3 Chinese-English
For Chinese-English we used 173M words of training data from GALE 2008. For SBMT we used a 32M word subset for extracting rules and building a language model, but used the entire training data for alignments, and for all PBMT training. The tune and test sets both contain web and newswire data. The tune set is selected from NIST MT evaluation sets from 2003&#8211;2006. The test set is the evaluation set from the NIST 2008 MT evaluation. We trained a 3-gram English language model on the English side of the training data.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Table 2 notes the sizes of the datasets used in our experiments.</text>
                  <doc_id>177</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>All tune and test data have four English reference sets for the purposes of scoring.</text>
                  <doc_id>178</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.2.1 Urdu-English</text>
                  <doc_id>179</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The training data for Urdu-English is that made available in the constrained track in the NIST 2009 MT evaluation.</text>
                  <doc_id>180</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This includes many lexicon entries and other single-word data, which accounts for the large number of lines relative to word count.</text>
                  <doc_id>181</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The NIST 2008 evaluation set, which contains newswire and web data, is split into two parts; we used roughly half each for tune and test.</text>
                  <doc_id>182</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We trained a 5-gram English language model on the English side of the training data.</text>
                  <doc_id>183</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.2.2 Arabic-English</text>
                  <doc_id>184</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The training data for Arabic English is that made available in the constrained track in the NIST 2008 MT evaluation.</text>
                  <doc_id>185</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The tune set, which contains only newswire data, is a mix from NIST MT evaluation sets from 2003&#8211;2006 and from GALE development data.</text>
                  <doc_id>186</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The test set, which contains both web and newswire data, is the evaluation set from the NIST 2008 MT evaluation.</text>
                  <doc_id>187</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We trained a 4-gram English language model on the English side of the training data.</text>
                  <doc_id>188</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.2.3 Chinese-English</text>
                  <doc_id>189</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For Chinese-English we used 173M words of training data from GALE 2008.</text>
                  <doc_id>190</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For SBMT we used a 32M word subset for extracting rules and building a language model, but used the entire training data for alignments, and for all PBMT training.</text>
                  <doc_id>191</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The tune and test sets both contain web and newswire data.</text>
                  <doc_id>192</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The tune set is selected from NIST MT evaluation sets from 2003&#8211;2006.</text>
                  <doc_id>193</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The test set is the evaluation set from the NIST 2008 MT evaluation.</text>
                  <doc_id>194</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>We trained a 3-gram English language model on the English side of the training data.</text>
                  <doc_id>195</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>5.3 Features</title>
            <text>For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features. Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007). We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b). We used the following feature classes in SBMT and PBMT extended scenarios:
&#8226; Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1)
&#8226; Target word insertion features 9
We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1): 10
&#8226; Rule overlap features
&#8226; Node count features
9 For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word. 10 The parser used for Arabic-English had a different nonterminal set than that used for the other two SBMT systems, accounting for the wide disparity in feature count for these feature classes.
We used the following feature classes in PBMT extended scenarios only:
&#8226; Unigram word pair features for the 80 most frequent words in both languages plus tokens for unaligned and all other words (cf. Watanabe et al. (2007), Section 3.2.1) 11
&#8226; Source, target, and joint phrase length features from 1 to 7, e.g. &#8220;tgt=4&#8221;, &#8220;src=2&#8221;, and &#8220;src/tgt=2,4&#8221;
The feature classes and number of features used within those classes for each language pair are summarized in Table 3.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features.</text>
                  <doc_id>196</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007).</text>
                  <doc_id>197</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b).</text>
                  <doc_id>198</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We used the following feature classes in SBMT and PBMT extended scenarios:</text>
                  <doc_id>199</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1)</text>
                  <doc_id>200</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Target word insertion features 9</text>
                  <doc_id>201</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1): 10</text>
                  <doc_id>202</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Rule overlap features</text>
                  <doc_id>203</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Node count features</text>
                  <doc_id>204</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>9 For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word.</text>
                  <doc_id>205</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>10 The parser used for Arabic-English had a different nonterminal set than that used for the other two SBMT systems, accounting for the wide disparity in feature count for these feature classes.</text>
                  <doc_id>206</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We used the following feature classes in PBMT extended scenarios only:</text>
                  <doc_id>207</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Unigram word pair features for the 80 most frequent words in both languages plus tokens for unaligned and all other words (cf. Watanabe et al. (2007), Section 3.2.1) 11</text>
                  <doc_id>208</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; Source, target, and joint phrase length features from 1 to 7, e.g. &#8220;tgt=4&#8221;, &#8220;src=2&#8221;, and &#8220;src/tgt=2,4&#8221;</text>
                  <doc_id>209</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The feature classes and number of features used within those classes for each language pair are summarized in Table 3.</text>
                  <doc_id>210</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>5.4 Tuning settings</title>
            <text>Each of the three approaches we compare in this study has various details associated with it that may prove useful to those wishing to reproduce our results. We list choices made for the various tuning methods here, and note that all our decisions were made in keeping with best practices for each algorithm.
5.4.1 MERT
We used David Chiang&#8217;s CMERT implementation of MERT that is available with the Moses system (Koehn et al., 2007). We ran MERT for up to 30 iterations, using k = 1500, and stopping early when
11 This constitutes 6,723 features in principle (82 2 &#8722; 1 since
&#8220;unaligned-unaligned&#8221; is not considered) but in practice far fewer co-occurrences were seen. Table 3 shows the number of actual unigram word pair features observed in data.
the accumulated k-best list does not change in an iteration. In every tuning iteration we ran MERT once with weights initialized to the last iteration&#8217;s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set. The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002).
5.4.2 MIRA
We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009) 12 but instead of using the 10-best of each of the best h w , h w +g, and h w -g, we use the 30-best according to h w . 13 We use the same sentence-level
BLEU calculated in the context of previous 1-best
translations as Chiang et al. (2008b; 2009). We ran MIRA for 30 iterations.
5.4.3 PRO
We used the MegaM classifier and sampled as described in Section 4.2. As previously noted, we used
BLEU+1 (Liang et al., 2006) for g. MegaM was easy
to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results
12 and acknowledge the use of David Chiang&#8217;s code 13 This is a more realistic scenario for would-be implementers
of MIRA, as obtaining the so-called &#8220;hope&#8221; and &#8220;fear&#8221; translations from the lattice or forest is significantly more complicated than simply obtaining a k-best list. Other tests comparing these methods have shown between 0.1 to 0.3 BLEU drop using 30- best h w on Chinese-English (Wang, 2011).
using the support vector machine module of WEKA (Hall et al., 2009) as well as the Stanford classifier (Manning and Klein, 2003). We ran for up to 30 iterations and used the same k and stopping criterion as was used for MERT, though variability of sampling precluded list convergence.
While MERT and MIRA use each iteration&#8217;s final weights as a starting point for hill-climbing the next iteration, the pairwise ranking approach has no explicit tie to previous iterations. To incorporate such stability into our process we interpolated the weights w &#8242; learned by the classifier in iteration t with those from iteration t &#8722; 1 by a factor of &#936;, such that w t = &#936; &#183; w &#8242; + (1 &#8722; &#936;) &#183; w t&#8722;1 . We found &#936; = 0.1 gave good performance across the board.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Each of the three approaches we compare in this study has various details associated with it that may prove useful to those wishing to reproduce our results.</text>
                  <doc_id>211</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We list choices made for the various tuning methods here, and note that all our decisions were made in keeping with best practices for each algorithm.</text>
                  <doc_id>212</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.4.1 MERT</text>
                  <doc_id>213</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We used David Chiang&#8217;s CMERT implementation of MERT that is available with the Moses system (Koehn et al., 2007).</text>
                  <doc_id>214</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We ran MERT for up to 30 iterations, using k = 1500, and stopping early when</text>
                  <doc_id>215</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>11 This constitutes 6,723 features in principle (82 2 &#8722; 1 since</text>
                  <doc_id>216</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8220;unaligned-unaligned&#8221; is not considered) but in practice far fewer co-occurrences were seen.</text>
                  <doc_id>217</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Table 3 shows the number of actual unigram word pair features observed in data.</text>
                  <doc_id>218</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the accumulated k-best list does not change in an iteration.</text>
                  <doc_id>219</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In every tuning iteration we ran MERT once with weights initialized to the last iteration&#8217;s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set.</text>
                  <doc_id>220</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002).</text>
                  <doc_id>221</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.4.2 MIRA</text>
                  <doc_id>222</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009) 12 but instead of using the 10-best of each of the best h w , h w +g, and h w -g, we use the 30-best according to h w .</text>
                  <doc_id>223</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>13 We use the same sentence-level</text>
                  <doc_id>224</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU calculated in the context of previous 1-best</text>
                  <doc_id>225</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>translations as Chiang et al. (2008b; 2009).</text>
                  <doc_id>226</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We ran MIRA for 30 iterations.</text>
                  <doc_id>227</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>5.4.3 PRO</text>
                  <doc_id>228</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We used the MegaM classifier and sampled as described in Section 4.2.</text>
                  <doc_id>229</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>As previously noted, we used</text>
                  <doc_id>230</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU+1 (Liang et al., 2006) for g. MegaM was easy</text>
                  <doc_id>231</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results</text>
                  <doc_id>232</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>12 and acknowledge the use of David Chiang&#8217;s code 13 This is a more realistic scenario for would-be implementers</text>
                  <doc_id>233</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of MIRA, as obtaining the so-called &#8220;hope&#8221; and &#8220;fear&#8221; translations from the lattice or forest is significantly more complicated than simply obtaining a k-best list.</text>
                  <doc_id>234</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Other tests comparing these methods have shown between 0.1 to 0.3 BLEU drop using 30- best h w on Chinese-English (Wang, 2011).</text>
                  <doc_id>235</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>using the support vector machine module of WEKA (Hall et al., 2009) as well as the Stanford classifier (Manning and Klein, 2003).</text>
                  <doc_id>236</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We ran for up to 30 iterations and used the same k and stopping criterion as was used for MERT, though variability of sampling precluded list convergence.</text>
                  <doc_id>237</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>While MERT and MIRA use each iteration&#8217;s final weights as a starting point for hill-climbing the next iteration, the pairwise ranking approach has no explicit tie to previous iterations.</text>
                  <doc_id>238</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To incorporate such stability into our process we interpolated the weights w &#8242; learned by the classifier in iteration t with those from iteration t &#8722; 1 by a factor of &#936;, such that w t = &#936; &#183; w &#8242; + (1 &#8722; &#936;) &#183; w t&#8722;1 .</text>
                  <doc_id>239</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We found &#936; = 0.1 gave good performance across the board.</text>
                  <doc_id>240</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>4</index>
            <title>5.5 Discussion</title>
            <text>We implore the reader to avoid the natural tendency to compare results using baseline vs. extended features or between PBMT and SBMT on the same language pair. Such discussions are indeed interesting, and could lead to improvements in feature engineering or sartorial choices due to the outcome of wagers (Goodale, 2008), but they distract from our thesis. As can be seen in Table 1, for each of the 12 choices of system, language pair, and feature set, the PRO method performed nearly the same as or better than MIRA and MERT on test data.
In Figure 5 we show the tune and test BLEU using the weights learned at every iteration for each Urdu-English SBMT experiment. Typical of the rest of the experiments, we can clearly see that PRO appears to proceed more monotonically than the other methods. We quantified PRO&#8217;s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration. The tune and test BLEU at each iteration is depicted in Figure 6. The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We implore the reader to avoid the natural tendency to compare results using baseline vs. extended features or between PBMT and SBMT on the same language pair.</text>
                  <doc_id>241</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Such discussions are indeed interesting, and could lead to improvements in feature engineering or sartorial choices due to the outcome of wagers (Goodale, 2008), but they distract from our thesis.</text>
                  <doc_id>242</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>As can be seen in Table 1, for each of the 12 choices of system, language pair, and feature set, the PRO method performed nearly the same as or better than MIRA and MERT on test data.</text>
                  <doc_id>243</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Figure 5 we show the tune and test BLEU using the weights learned at every iteration for each Urdu-English SBMT experiment.</text>
                  <doc_id>244</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Typical of the rest of the experiments, we can clearly see that PRO appears to proceed more monotonically than the other methods.</text>
                  <doc_id>245</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We quantified PRO&#8217;s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration.</text>
                  <doc_id>246</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The tune and test BLEU at each iteration is depicted in Figure 6.</text>
                  <doc_id>247</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05.</text>
                  <doc_id>248</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>6</index>
        <title>6 Related Work</title>
        <text>Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of
same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT.</text>
              <doc_id>249</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Tillmann and Zhang (2005) used a customized form of</text>
              <doc_id>250</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>same Urdu-English PBMT baseline feature experiment.</text>
              <doc_id>251</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>PRO is more stable than MERT.</text>
              <doc_id>252</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>multi-class stochastic gradient descent to learn feature weights for an MT model.</text>
              <doc_id>253</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations.</text>
              <doc_id>254</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data.</text>
              <doc_id>255</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model.</text>
              <doc_id>256</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts.</text>
              <doc_id>257</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>7</index>
        <title>7 Conclusion</title>
        <text>We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement. We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable. It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement.</text>
              <doc_id>258</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable.</text>
              <doc_id>259</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research.</text>
              <doc_id>260</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>8</index>
        <title>Acknowledgments</title>
        <text>Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance. Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.</text>
              <doc_id>261</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Thanks also to the anonymous reviewers, especially the reviewer who implemented PRO during the review period and replicated our results.</text>
              <doc_id>262</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TableSeer</source>
        <caption>Table 1: Machine translation performance for the experiments listed in this paper. Scores are case-sensitive IBM BLEU. For every choice of system, language pair, and feature set, PRO performs comparably with the other methods.</caption>
        <reference_text>In PAGE 9: ... Such discussions are indeed interesting, and could lead to improvements in feature engineer- ing or sartorial choices due to the outcome of wagers (Goodale, 2008), but they distract from our thesis. As can be seen in  Table1 , for each of the 12 choices of system, language pair, and feature set, the PRO method performed nearly the same as or better than MIRA and MERT on test data. In Figure 5 we show the tune and test BLEU us- ing the weights learned at every iteration for each Urdu-English SBMT experiment....</reference_text>
        <page_num>6</page_num>
        <head>
          <rows>
            <row>
              <cell>None</cell>
              <cell>PBMT</cell>
              <cell>PBMT</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>SBMT</cell>
              <cell>SBMT</cell>
              <cell>None</cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Language</cell>
              <cell>Experiment</cell>
              <cell>Experiment</cell>
              <cell>BLEU</cell>
              <cell>BLEU</cell>
              <cell>Language</cell>
              <cell>Experiment</cell>
              <cell>Experiment</cell>
              <cell>BLEU</cell>
              <cell>BLEU</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>feats</cell>
              <cell>method</cell>
              <cell>tune</cell>
              <cell>test</cell>
              <cell>None</cell>
              <cell>feats</cell>
              <cell>method</cell>
              <cell>tune</cell>
              <cell>test</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>20.5</cell>
              <cell>17.7</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>23.4</cell>
              <cell>21.4</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>20.5</cell>
              <cell>17.9</cell>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>23.6</cell>
              <cell>22.3</cell>
            </row>
            <row>
              <cell>Urdu-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>20.4</cell>
              <cell>18.2</cell>
              <cell>Urdu-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>23.4</cell>
              <cell>22.2</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>21.8</cell>
              <cell>17.8</cell>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>25.2</cell>
              <cell>22.8</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>21.6</cell>
              <cell>18.1</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>24.2</cell>
              <cell>22.8</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>46.8</cell>
              <cell>41.2</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>44.7</cell>
              <cell>39.0</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>47.0</cell>
              <cell>41.1</cell>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>44.6</cell>
              <cell>39.0</cell>
            </row>
            <row>
              <cell>Arabic-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>46.9</cell>
              <cell>41.1</cell>
              <cell>Arabic-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>44.5</cell>
              <cell>39.0</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>47.5</cell>
              <cell>41.7</cell>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>45.8</cell>
              <cell>39.8</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>48.5</cell>
              <cell>41.9</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>45.9</cell>
              <cell>40.3</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>23.8</cell>
              <cell>22.2</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>MERT</cell>
              <cell>25.5</cell>
              <cell>22.7</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>24.1</cell>
              <cell>22.5</cell>
              <cell>None</cell>
              <cell>base</cell>
              <cell>MIRA</cell>
              <cell>25.4</cell>
              <cell>22.9</cell>
            </row>
            <row>
              <cell>Chinese-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>23.8</cell>
              <cell>22.5</cell>
              <cell>Chinese-English</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>25.5</cell>
              <cell>22.9</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>24.8</cell>
              <cell>22.6</cell>
              <cell>None</cell>
              <cell>ext</cell>
              <cell>MIRA</cell>
              <cell>26.0</cell>
              <cell>23.3</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>24.9</cell>
              <cell>22.7</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>PRO</cell>
              <cell>25.6</cell>
              <cell>23.5</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TET</source>
        <caption>Table 2: Data sizes for the experiments reported in this paper (English words shown).</caption>
        <reference_text></reference_text>
        <page_num>5</page_num>
        <head>
          <rows>
            <row>
              <cell>Data</cell>
              <cell>U-E</cell>
              <cell>A-E</cell>
              <cell>C-E</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Train</cell>
              <cell>lines 515K 6.5M 7.9M
words 2.2M 175M 173M</cell>
            </row>
            <row>
              <cell>Tune</cell>
              <cell>lines 923 1994 1615
words 16K 65K 42K</cell>
            </row>
            <row>
              <cell>Test</cell>
              <cell>lines 938 1357 1357
words 18K 47K 37K</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TableSeer</source>
        <caption>Table 3: Summary of features used in experiments in this paper.</caption>
        <reference_text>In PAGE 8: ...Koehn et al., 2007). We ran MERT for up to 30 it- erations, using k = 1500, and stopping early when 11This constitutes 6,723 features in principle (822 ? 1 since  unaligned-unaligned  is not considered) but in practice far fewer co-occurrences were seen.  Table3  shows the number of actual unigram word pair features observed in data. the accumulated k-best list does not change in an it- eration....</reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>None</cell>
              <cell>None</cell>
              <cell>Urdu-English</cell>
              <cell>Urdu-English</cell>
              <cell>None</cell>
              <cell>None</cell>
              <cell>Arabic-English</cell>
              <cell>Arabic-English</cell>
              <cell>None</cell>
              <cell>Chinese-English</cell>
              <cell>Chinese-English</cell>
              <cell>Chinese-English</cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Class</cell>
              <cell>PBMT</cell>
              <cell>PBMT</cell>
              <cell>SBMT</cell>
              <cell>SBMT</cell>
              <cell>PBMT</cell>
              <cell>PBMT</cell>
              <cell>SBMT</cell>
              <cell>SBMT</cell>
              <cell>PBMT</cell>
              <cell>PBMT</cell>
              <cell>SBMT</cell>
              <cell>SBMT</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>base</cell>
              <cell>ext</cell>
              <cell>base</cell>
              <cell>ext</cell>
              <cell>base</cell>
              <cell>ext</cell>
              <cell>base</cell>
              <cell>ext</cell>
              <cell>base</cell>
              <cell>ext</cell>
              <cell>base</cell>
              <cell>ext</cell>
            </row>
            <row>
              <cell>baseline</cell>
              <cell>15</cell>
              <cell>15</cell>
              <cell>19</cell>
              <cell>19</cell>
              <cell>15</cell>
              <cell>15</cell>
              <cell>19</cell>
              <cell>19</cell>
              <cell>15</cell>
              <cell>15</cell>
              <cell>19</cell>
              <cell>19</cell>
            </row>
            <row>
              <cell>target word</cell>
              <cell>?</cell>
              <cell>51</cell>
              <cell>?</cell>
              <cell>50</cell>
              <cell>?</cell>
              <cell>51</cell>
              <cell>?</cell>
              <cell>50</cell>
              <cell>?</cell>
              <cell>51</cell>
              <cell>?</cell>
              <cell>299</cell>
            </row>
            <row>
              <cell>discount</cell>
              <cell>?</cell>
              <cell>11</cell>
              <cell>?</cell>
              <cell>11</cell>
              <cell>?</cell>
              <cell>11</cell>
              <cell>?</cell>
              <cell>10</cell>
              <cell>?</cell>
              <cell>11</cell>
              <cell>?</cell>
              <cell>10</cell>
            </row>
            <row>
              <cell>node count</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>99</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>138</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>96</cell>
            </row>
            <row>
              <cell>rule overlap</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>98</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>136</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>93</cell>
            </row>
            <row>
              <cell>word pair</cell>
              <cell>?</cell>
              <cell>2110</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>6193</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>1688</cell>
              <cell>?</cell>
              <cell>?</cell>
            </row>
            <row>
              <cell>phrase length</cell>
              <cell>?</cell>
              <cell>63</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>63</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>?</cell>
              <cell>63</cell>
              <cell>?</cell>
              <cell>?</cell>
            </row>
            <row>
              <cell>total</cell>
              <cell>15</cell>
              <cell>2250</cell>
              <cell>19</cell>
              <cell>277</cell>
              <cell>15</cell>
              <cell>6333</cell>
              <cell>18</cell>
              <cell>352</cell>
              <cell>15</cell>
              <cell>1828</cell>
              <cell>19</cell>
              <cell>517</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Chris Burges</author>
          <author>Tal Shaked</author>
          <author>Erin Renshaw</author>
          <author>Ari Lazier</author>
          <author>Matt Deeds</author>
          <author>Nicole Hamilton</author>
          <author>Greg Hullender</author>
        </authors>
        <title>Learning to rank using gradient descent.</title>
        <publication>In Proceedings of the 22nd International Conference on Machine Learning, ICML &#8217;05,</publication>
        <pages>89--96</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Zhe Cao</author>
          <author>Tao Qin</author>
          <author>Tie-Yan Liu</author>
          <author>Ming-Feng Tsai</author>
          <author>Hang Li</author>
        </authors>
        <title>Learning to rank: From pairwise approach to listwise approach.</title>
        <publication>In Proceedings of the 24th International Conference on Machine Learning,</publication>
        <pages>129--136</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Samidh Chatterjee</author>
          <author>Nicola Cancedda</author>
        </authors>
        <title>Minimum error rate training by sampling the translation lattice.</title>
        <publication>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>606--615</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Wei Chen</author>
          <author>Tie-Yan Liu</author>
          <author>Yanyan Lan</author>
          <author>Zhi-Ming Ma</author>
          <author>Hang Li</author>
        </authors>
        <title>Ranking measures and loss functions in learning to rank. In</title>
        <publication>Advances in Neural Information Processing Systems 22,</publication>
        <pages>315--323</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>David Chiang</author>
        </authors>
        <title>Steve DeNeefe, Yee Seng Chan, and Hwee Tou Ng. 2008a. Decomposability of translation metrics for improved evaluation and efficient algorithms.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>5</id>
        <authors/>
        <title>None</title>
        <publication>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>610--619</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>David Chiang</author>
          <author>Yuval Marton</author>
          <author>Philip Resnik</author>
        </authors>
        <title>Online large-margin training of syntactic and structural translation features.</title>
        <publication>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>224--233</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>David Chiang</author>
          <author>Kevin Knight</author>
          <author>Wei Wang</author>
        </authors>
        <title>11,001 new features for statistical machine translation.</title>
        <publication>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</publication>
        <pages>218--226</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>David Chiang</author>
        </authors>
        <title>Learning to translate with source and target syntax.</title>
        <publication>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>1443--1452</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Brooke Cowan</author>
          <author>Ivona Ku&#728;cerov&#225;</author>
          <author>Michael Collins</author>
        </authors>
        <title>A discriminative model for tree-to-tree translation.</title>
        <publication>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>232--241</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Koby Crammer</author>
          <author>Yoram Singer</author>
        </authors>
        <title>Ultraconservative online algorithms for multiclass problems.</title>
        <publication>None</publication>
        <pages>3--951</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Hal Daum&#233;</author>
        </authors>
        <title>Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.name/ megam/,</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Yoav Freund</author>
          <author>Raj Iyer</author>
          <author>Robert E Schapire</author>
          <author>Yoram Singer</author>
        </authors>
        <title>An efficient boosting algorithm for combining preferences.</title>
        <publication>None</publication>
        <pages>4--933</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Michel Galley</author>
          <author>Mark Hopkins</author>
          <author>Kevin Knight</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>What&#8217;s in a translation rule?</title>
        <publication>In HLTNAACL 2004: Main Proceedings,</publication>
        <pages>273--280</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Gloria Goodale</author>
        </authors>
        <title>Language Weaver: fast in translation.</title>
        <publication>The Christian Science Monitor, October 1. http://www.csmonitor.com/ Innovation/Tech-Culture/2008/1001/</publication>
        <pages>language-weaver-fast-in-translation.</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>15</id>
        <authors/>
        <title>None</title>
        <publication>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,</publication>
        <pages>None</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Mark Hall</author>
          <author>Eibe Frank</author>
          <author>Geoffrey Holmes</author>
          <author>Bernhard Pfahringer</author>
          <author>Peter Reutemann</author>
          <author>Ian H Witten</author>
        </authors>
        <title>The WEKA data mining software: An update.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Ralf Herbrich</author>
          <author>Thore Graepel</author>
          <author>Klaus Obermayer</author>
        </authors>
        <title>Support vector learning for ordinal regression.</title>
        <publication>In Proceedings of the 1999 International Conference on Artificial Neural Networks,</publication>
        <pages>97--102</pages>
        <date>1999</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Abraham Ittycheriah</author>
          <author>Salim Roukos</author>
        </authors>
        <title>A maximum entropy word aligner for Arabic-English machine translation.</title>
        <publication>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>89--96</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Hieu Hoang</author>
          <author>Alexandra Birch</author>
          <author>Chris Callison-Burch</author>
          <author>Marcello Federico</author>
          <author>Nicola Bertoldi</author>
          <author>Brooke Cowan</author>
          <author>Wade Shen</author>
          <author>Christine Moran</author>
          <author>Richard Zens</author>
          <author>Chris Dyer</author>
          <author>Ondrej Bojar</author>
          <author>Alexandra Constantin</author>
          <author>Evan Herbst</author>
        </authors>
        <title>Moses: Open source toolkit for statistical machine translation.</title>
        <publication>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</publication>
        <pages>177--1361</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>Shankar Kumar</author>
          <author>Wolfgang Macherey</author>
          <author>Chris Dyer</author>
          <author>Franz Och</author>
        </authors>
        <title>Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices.</title>
        <publication>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</publication>
        <pages>163--171</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>Alon Lavie</author>
          <author>Michael J Denkowski</author>
        </authors>
        <title>The METEOR metric for automatic evaluation of machine translation.</title>
        <publication>None</publication>
        <pages>23--2</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>Percy Liang</author>
          <author>Alexandre Bouchard-C&#244;t&#233;</author>
          <author>Dan Klein</author>
          <author>Ben Taskar</author>
        </authors>
        <title>An end-to-end discriminative approach to machine translation.</title>
        <publication>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>761--768</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>23</id>
        <authors>
          <author>Wolfgang Macherey</author>
          <author>Franz Josef Och</author>
          <author>Ignacio Thayer</author>
          <author>Jakob Uszkoreit</author>
        </authors>
        <title>Lattice-based minimum error rate training for statistical machine translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>24</id>
        <authors/>
        <title>Association for Computational Linguistics.</title>
        <publication>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>725--734</pages>
        <date>None</date>
      </reference>
      <reference>
        <id>25</id>
        <authors>
          <author>Christopher Manning</author>
          <author>Dan Klein</author>
        </authors>
        <title>Optimization, maxent models, and conditional estimation without magic.</title>
        <publication>Tutorial at HLT-NAACL 2003 and ACL</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>26</id>
        <authors>
          <author>I Dan Melamed</author>
          <author>Ryan Green</author>
          <author>Joseph P Turian</author>
        </authors>
        <title>Precision and recall of machine translation.</title>
        <publication>In Companion Volume of the Proceedings of HLT-NAACL</publication>
        <pages>61--63</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>27</id>
        <authors>
          <author>Franz Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>Improved statistical alignment models.</title>
        <publication>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>440--447</pages>
        <date>2000</date>
      </reference>
      <reference>
        <id>28</id>
        <authors>
          <author>Franz Josef Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>Discriminative training and maximum entropy models for statistical machine translation.</title>
        <publication>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>295--302</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>29</id>
        <authors>
          <author>Franz Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>The alignment template approach to statistical machine translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>30</id>
        <authors>
          <author>Franz Och</author>
        </authors>
        <title>Minimum error rate training in statistical machine translation.</title>
        <publication>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>160--167</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>31</id>
        <authors>
          <author>Kishore Papineni</author>
          <author>Salim Roukos</author>
          <author>Todd Ward</author>
          <author>WeiJing Zhu</author>
        </authors>
        <title>BLEU: a method for automatic evaluation of machine translation.</title>
        <publication>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</publication>
        <pages>311--318</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>32</id>
        <authors>
          <author>Benjamin Roth</author>
          <author>Andrew McCallum</author>
          <author>Marc Dymetman</author>
          <author>Nicola Cancedda</author>
        </authors>
        <title>Machine translation using overlapping alignments and samplerank.</title>
        <publication>In Proceedings of Association for Machine Translation in the Americas,</publication>
        <pages>None</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>33</id>
        <authors>
          <author>Libin Shen</author>
          <author>Anoop Sarkar</author>
          <author>Franz Josef Och</author>
        </authors>
        <title>Discriminative reranking for machine translation.</title>
        <publication>HLT-NAACL 2004: Main Proceedings,</publication>
        <pages>177--184</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>34</id>
        <authors>
          <author>Matthew Snover</author>
          <author>Bonnie Dorr</author>
          <author>Richard Schwartz</author>
          <author>Linnea Micciulla</author>
          <author>John Makhoul</author>
        </authors>
        <title>A study of translation edit rate with targeted human annotation.</title>
        <publication>In Proceedings of Association for Machine Translation in the Americas,</publication>
        <pages>223--231</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>35</id>
        <authors>
          <author>Christoph Tillmann</author>
          <author>Tong Zhang</author>
        </authors>
        <title>A localized prediction model for statistical machine translation.</title>
        <publication>In Proceedings of the 43rd Annual Meeting of the ACL,</publication>
        <pages>557--564</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>36</id>
        <authors>
          <author>Wei Wang</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>37</id>
        <authors>
          <author>Taro Watanabe</author>
          <author>Jun Suzuki</author>
          <author>Hajime Tsukada</author>
          <author>Hideki Isozaki</author>
        </authors>
        <title>NTT statistical machine translation for IWSLT</title>
        <publication>In Proceedings of IWSLT</publication>
        <pages>95--102</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>38</id>
        <authors>
          <author>Taro Watanabe</author>
          <author>Jun Suzuki</author>
          <author>Hajime Tsukada</author>
          <author>Hideki Isozaki</author>
        </authors>
        <title>Online large-margin training for statistical machine translation.</title>
        <publication>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</publication>
        <pages>764--773</pages>
        <date>2007</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Burges et al., 2005</string>
        <sentence_id>11063</sentence_id>
        <char_offset>102</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>0</reference_id>
        <string>Burges et al., 2005</string>
        <sentence_id>11149</sentence_id>
        <char_offset>88</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>1</reference_id>
        <string>Cao et al., 2007</string>
        <sentence_id>11063</sentence_id>
        <char_offset>123</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>1</reference_id>
        <string>Cao et al., 2007</string>
        <sentence_id>11149</sentence_id>
        <char_offset>109</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>2</reference_id>
        <string>Chatterjee and Cancedda, 2010</string>
        <sentence_id>11209</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>3</reference_id>
        <string>Chen et al., 2009</string>
        <sentence_id>11062</sentence_id>
        <char_offset>37</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>3</reference_id>
        <string>Chen et al., 2009</string>
        <sentence_id>11169</sentence_id>
        <char_offset>7</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>6</reference_id>
        <string>Chiang et al. (2008</string>
        <sentence_id>11056</sentence_id>
        <char_offset>37</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>6</reference_id>
        <string>Chiang et al. (2008</string>
        <sentence_id>11205</sentence_id>
        <char_offset>167</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>6</reference_id>
        <string>Chiang et al. (2008</string>
        <sentence_id>11239</sentence_id>
        <char_offset>84</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>6</reference_id>
        <string>Chiang et al. (2008</string>
        <sentence_id>11267</sentence_id>
        <char_offset>16</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>6</reference_id>
        <string>Chiang et al., 2008</string>
        <sentence_id>11049</sentence_id>
        <char_offset>118</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>6</reference_id>
        <string>Chiang et al., 2008</string>
        <sentence_id>11092</sentence_id>
        <char_offset>178</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>6</reference_id>
        <string>Chiang et al., 2008</string>
        <sentence_id>11209</sentence_id>
        <char_offset>93</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>6</reference_id>
        <string>Chiang et al., 2008</string>
        <sentence_id>11195</sentence_id>
        <char_offset>121</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>7</reference_id>
        <string>Chiang et al. (2009)</string>
        <sentence_id>11241</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>7</reference_id>
        <string>Chiang et al. (2009)</string>
        <sentence_id>11243</sentence_id>
        <char_offset>75</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>7</reference_id>
        <string>Chiang et al. (2009)</string>
        <sentence_id>11264</sentence_id>
        <char_offset>87</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>8</reference_id>
        <string>Chiang, 2010</string>
        <sentence_id>11059</sentence_id>
        <char_offset>155</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>10</reference_id>
        <string>Crammer and Singer, 2003</string>
        <sentence_id>11056</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>12</reference_id>
        <string>Freund et al., 2003</string>
        <sentence_id>11063</sentence_id>
        <char_offset>81</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>12</reference_id>
        <string>Freund et al., 2003</string>
        <sentence_id>11149</sentence_id>
        <char_offset>67</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>13</reference_id>
        <string>Galley et al. (2004)</string>
        <sentence_id>11212</sentence_id>
        <char_offset>63</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>14</reference_id>
        <string>Goodale, 2008</string>
        <sentence_id>11283</sentence_id>
        <char_offset>146</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>15</reference_id>
        <string>(2010)</string>
        <sentence_id>11195</sentence_id>
        <char_offset>175</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>16</reference_id>
        <string>Hall et al., 2009</string>
        <sentence_id>11277</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>17</reference_id>
        <string>Herbrich et al., 1999</string>
        <sentence_id>11047</sentence_id>
        <char_offset>146</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>17</reference_id>
        <string>Herbrich et al., 1999</string>
        <sentence_id>11063</sentence_id>
        <char_offset>58</char_offset>
      </citation>
      <citation>
        <id>28</id>
        <reference_id>17</reference_id>
        <string>Herbrich et al., 1999</string>
        <sentence_id>11149</sentence_id>
        <char_offset>44</char_offset>
      </citation>
      <citation>
        <id>29</id>
        <reference_id>18</reference_id>
        <string>Ittycheriah and Roukos (2005)</string>
        <sentence_id>11302</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>30</id>
        <reference_id>19</reference_id>
        <string>Koehn et al., 2007</string>
        <sentence_id>11069</sentence_id>
        <char_offset>50</char_offset>
      </citation>
      <citation>
        <id>31</id>
        <reference_id>19</reference_id>
        <string>Koehn et al., 2007</string>
        <sentence_id>11255</sentence_id>
        <char_offset>93</char_offset>
      </citation>
      <citation>
        <id>32</id>
        <reference_id>20</reference_id>
        <string>Kumar et al., 2009</string>
        <sentence_id>11304</sentence_id>
        <char_offset>70</char_offset>
      </citation>
      <citation>
        <id>33</id>
        <reference_id>21</reference_id>
        <string>Lavie and Denkowski, 2009</string>
        <sentence_id>11092</sentence_id>
        <char_offset>108</char_offset>
      </citation>
      <citation>
        <id>34</id>
        <reference_id>22</reference_id>
        <string>Liang et al., 2006</string>
        <sentence_id>11200</sentence_id>
        <char_offset>61</char_offset>
      </citation>
      <citation>
        <id>35</id>
        <reference_id>22</reference_id>
        <string>Liang et al., 2006</string>
        <sentence_id>11272</sentence_id>
        <char_offset>8</char_offset>
      </citation>
      <citation>
        <id>36</id>
        <reference_id>23</reference_id>
        <string>Macherey et al., 2008</string>
        <sentence_id>11209</sentence_id>
        <char_offset>70</char_offset>
      </citation>
      <citation>
        <id>37</id>
        <reference_id>23</reference_id>
        <string>Macherey et al., 2008</string>
        <sentence_id>11304</sentence_id>
        <char_offset>47</char_offset>
      </citation>
      <citation>
        <id>38</id>
        <reference_id>25</reference_id>
        <string>Manning and Klein, 2003</string>
        <sentence_id>11277</sentence_id>
        <char_offset>104</char_offset>
      </citation>
      <citation>
        <id>39</id>
        <reference_id>26</reference_id>
        <string>Melamed et al., 2003</string>
        <sentence_id>11092</sentence_id>
        <char_offset>135</char_offset>
      </citation>
      <citation>
        <id>40</id>
        <reference_id>27</reference_id>
        <string>Och and Ney, 2000</string>
        <sentence_id>11217</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>41</id>
        <reference_id>28</reference_id>
        <string>Och and Ney (2002)</string>
        <sentence_id>11301</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>42</id>
        <reference_id>29</reference_id>
        <string>Och and Ney (2004)</string>
        <sentence_id>11216</sentence_id>
        <char_offset>59</char_offset>
      </citation>
      <citation>
        <id>43</id>
        <reference_id>30</reference_id>
        <string>Och, 2003</string>
        <sentence_id>11048</sentence_id>
        <char_offset>35</char_offset>
      </citation>
      <citation>
        <id>44</id>
        <reference_id>30</reference_id>
        <string>Och, 2003</string>
        <sentence_id>11052</sentence_id>
        <char_offset>20</char_offset>
      </citation>
      <citation>
        <id>45</id>
        <reference_id>30</reference_id>
        <string>Och, 2003</string>
        <sentence_id>11098</sentence_id>
        <char_offset>68</char_offset>
      </citation>
      <citation>
        <id>46</id>
        <reference_id>31</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>11092</sentence_id>
        <char_offset>38</char_offset>
      </citation>
      <citation>
        <id>47</id>
        <reference_id>31</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>11262</sentence_id>
        <char_offset>57</char_offset>
      </citation>
      <citation>
        <id>48</id>
        <reference_id>32</reference_id>
        <string>Roth et al. (2010)</string>
        <sentence_id>11195</sentence_id>
        <char_offset>163</char_offset>
      </citation>
      <citation>
        <id>49</id>
        <reference_id>33</reference_id>
        <string>Shen et al., 2004</string>
        <sentence_id>11296</sentence_id>
        <char_offset>15</char_offset>
      </citation>
      <citation>
        <id>50</id>
        <reference_id>34</reference_id>
        <string>Snover et al., 2006</string>
        <sentence_id>11092</sentence_id>
        <char_offset>157</char_offset>
      </citation>
      <citation>
        <id>51</id>
        <reference_id>35</reference_id>
        <string>Tillmann and Zhang (2005)</string>
        <sentence_id>11297</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>52</id>
        <reference_id>36</reference_id>
        <string>Wang, 2011</string>
        <sentence_id>11276</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>53</id>
        <reference_id>37</reference_id>
        <string>Watanabe et al., 2006</string>
        <sentence_id>11296</sentence_id>
        <char_offset>54</char_offset>
      </citation>
      <citation>
        <id>54</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al. (2007)</string>
        <sentence_id>11056</sentence_id>
        <char_offset>10</char_offset>
      </citation>
      <citation>
        <id>55</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al. (2007)</string>
        <sentence_id>11205</sentence_id>
        <char_offset>140</char_offset>
      </citation>
      <citation>
        <id>56</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al. (2007)</string>
        <sentence_id>11238</sentence_id>
        <char_offset>98</char_offset>
      </citation>
      <citation>
        <id>57</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al. (2007)</string>
        <sentence_id>11249</sentence_id>
        <char_offset>129</char_offset>
      </citation>
      <citation>
        <id>58</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al., 2007</string>
        <sentence_id>11049</sentence_id>
        <char_offset>95</char_offset>
      </citation>
      <citation>
        <id>59</id>
        <reference_id>38</reference_id>
        <string>Watanabe et al., 2007</string>
        <sentence_id>11195</sentence_id>
        <char_offset>98</char_offset>
      </citation>
    </citations>
  </content>
</document>
