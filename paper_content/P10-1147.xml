<document>
  <filename>P10-1147</filename>
  <authors>
    <author>John DeNero</author>
  </authors>
  <title>Discriminative Modeling of Extraction Sets for Machine Translation</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair. Our model scores extraction sets: nested collections of all the overlapping phrase pairs consistent with an underlying word alignment. Extraction set models provide two principle advantages over word-factored alignment models. First, we can incorporate features on phrase pairs, in addition to word links. Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations. Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our model scores extraction sets: nested collections of all the overlapping phrase pairs consistent with an underlying word alignment.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Extraction set models provide two principle advantages over word-factored alignment models.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>First, we can incorporate features on phrase pairs, in addition to word links.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.</text>
              <doc_id>5</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>In the last decade, the field of statistical machine translation has shifted from generating sentences word by word to systems that recycle whole fragments of training examples, expressed as translation rules. This general paradigm was first pursued using contiguous phrases (Och et al., 1999; Koehn et al., 2003), and has since been generalized to a wide variety of hierarchical and syntactic formalisms. The training stage of statistical systems focuses primarily on discovering translation rules in parallel corpora. Most systems discover translation rules via a two-stage pipeline: a parallel corpus is aligned at the word level, and then a second procedure extracts fragment-level rules from word-aligned sentence pairs. This paper offers a model-based alternative to phrasal rule extraction, which merges this two-stage pipeline into a single step. We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair. Our model predicts extraction sets: combinatorial objects that include the set of all overlapping phrasal translation rules consistent with an underlying word-level alignment. This approach provides additional discriminative power relative to word aligners because extraction sets are scored based on the phrasal rules they contain in addition to word-to-word alignment links. Moreover, the structure of our model directly reflects the purpose of alignment models in general, which is to discover translation rules. We address several challenges to training and applying an extraction set model. First, we would like to leverage existing word-level alignment resources. To do so, we define a deterministic mapping from word alignments to extraction sets, inspired by existing extraction procedures. In our mapping, possible alignment links have a precise interpretation that dictates what phrasal translation rules can be extracted from a sentence pair. This mapping allows us to train with existing annotated data sets and use the predictions from word-level aligners as features in our extraction set model. Second, our model solves a structured prediction problem, and the choice of loss function during training affects model performance. We optimize for a phrase-level F-measure in order to focus learning on the task of predicting phrasal rules rather than word alignment links.
Third, our discriminative approach requires that we perform inference in the space of extraction sets. Our model does not factor over disjoint wordto-word links or minimal phrase pairs, and so existing inference procedures do not directly apply. However, we show that the dynamic program for a block ITG aligner can be augmented to score extraction sets that are indexed by underlying ITG word alignments (Wu, 1997). We also describe a
&#65533;&#65533; [past] st] &#963;(f j )
&#65533; o]
&#65533; ar]
&#65533;]
[two]
[year]
[in]
[after]
[dinner]
[after]
[I]
[sleep]
&#963;(e i )
[past tense]
&#963;(e i )
&#963;(f j )
On February 15 2010 On February 15 2010
2010&#65533;2010&#65533;
2&#65533;
15&#65533;
coarse-to-fine inference approach that allows us to scale our method to long sentences.
Our extraction set model outperforms both unsupervised and supervised word aligners at predicting word alignments and extraction sets. We also demonstrate that extraction sets are useful for end-to-end machine translation. Our model improves translation quality relative to state-of-theart Chinese-to-English baselines across two publicly available systems, providing total BLEU improvements of 1.2 in Moses, a phrase-based system, and 1.4 in a Joshua, a hierarchical system (Koehn et al., 2007; Li et al., 2009)</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In the last decade, the field of statistical machine translation has shifted from generating sentences word by word to systems that recycle whole fragments of training examples, expressed as translation rules.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This general paradigm was first pursued using contiguous phrases (Och et al., 1999; Koehn et al., 2003), and has since been generalized to a wide variety of hierarchical and syntactic formalisms.</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The training stage of statistical systems focuses primarily on discovering translation rules in parallel corpora.</text>
              <doc_id>8</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Most systems discover translation rules via a two-stage pipeline: a parallel corpus is aligned at the word level, and then a second procedure extracts fragment-level rules from word-aligned sentence pairs.</text>
              <doc_id>9</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>This paper offers a model-based alternative to phrasal rule extraction, which merges this two-stage pipeline into a single step.</text>
              <doc_id>10</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair.</text>
              <doc_id>11</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Our model predicts extraction sets: combinatorial objects that include the set of all overlapping phrasal translation rules consistent with an underlying word-level alignment.</text>
              <doc_id>12</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>This approach provides additional discriminative power relative to word aligners because extraction sets are scored based on the phrasal rules they contain in addition to word-to-word alignment links.</text>
              <doc_id>13</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Moreover, the structure of our model directly reflects the purpose of alignment models in general, which is to discover translation rules.</text>
              <doc_id>14</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>We address several challenges to training and applying an extraction set model.</text>
              <doc_id>15</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>First, we would like to leverage existing word-level alignment resources.</text>
              <doc_id>16</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>To do so, we define a deterministic mapping from word alignments to extraction sets, inspired by existing extraction procedures.</text>
              <doc_id>17</doc_id>
              <sec_id>11</sec_id>
            </sentence>
            <sentence>
              <text>In our mapping, possible alignment links have a precise interpretation that dictates what phrasal translation rules can be extracted from a sentence pair.</text>
              <doc_id>18</doc_id>
              <sec_id>12</sec_id>
            </sentence>
            <sentence>
              <text>This mapping allows us to train with existing annotated data sets and use the predictions from word-level aligners as features in our extraction set model.</text>
              <doc_id>19</doc_id>
              <sec_id>13</sec_id>
            </sentence>
            <sentence>
              <text>Second, our model solves a structured prediction problem, and the choice of loss function during training affects model performance.</text>
              <doc_id>20</doc_id>
              <sec_id>14</sec_id>
            </sentence>
            <sentence>
              <text>We optimize for a phrase-level F-measure in order to focus learning on the task of predicting phrasal rules rather than word alignment links.</text>
              <doc_id>21</doc_id>
              <sec_id>15</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Third, our discriminative approach requires that we perform inference in the space of extraction sets.</text>
              <doc_id>22</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our model does not factor over disjoint wordto-word links or minimal phrase pairs, and so existing inference procedures do not directly apply.</text>
              <doc_id>23</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>However, we show that the dynamic program for a block ITG aligner can be augmented to score extraction sets that are indexed by underlying ITG word alignments (Wu, 1997).</text>
              <doc_id>24</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We also describe a</text>
              <doc_id>25</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533;&#65533; [past] st] &#963;(f j )</text>
              <doc_id>26</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533; o]</text>
              <doc_id>27</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533; ar]</text>
              <doc_id>28</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533;]</text>
              <doc_id>29</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[two]</text>
              <doc_id>30</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[year]</text>
              <doc_id>31</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[in]</text>
              <doc_id>32</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[after]</text>
              <doc_id>33</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[dinner]</text>
              <doc_id>34</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[after]</text>
              <doc_id>35</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[I]</text>
              <doc_id>36</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[sleep]</text>
              <doc_id>37</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#963;(e i )</text>
              <doc_id>38</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>[past tense]</text>
              <doc_id>39</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#963;(e i )</text>
              <doc_id>40</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#963;(f j )</text>
              <doc_id>41</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>On February 15 2010 On February 15 2010</text>
              <doc_id>42</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2010&#65533;2010&#65533;</text>
              <doc_id>43</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2&#65533;</text>
              <doc_id>44</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>15&#65533;</text>
              <doc_id>45</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>coarse-to-fine inference approach that allows us to scale our method to long sentences.</text>
              <doc_id>46</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our extraction set model outperforms both unsupervised and supervised word aligners at predicting word alignments and extraction sets.</text>
              <doc_id>47</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We also demonstrate that extraction sets are useful for end-to-end machine translation.</text>
              <doc_id>48</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Our model improves translation quality relative to state-of-theart Chinese-to-English baselines across two publicly available systems, providing total BLEU improvements of 1.2 in Moses, a phrase-based system, and 1.4 in a Joshua, a hierarchical system (Koehn et al., 2007; Li et al., 2009)</text>
              <doc_id>49</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Extraction Set Models</title>
        <text>2&#65533;
15&#65533;
The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>2&#65533;</text>
              <doc_id>50</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>15&#65533;</text>
              <doc_id>51</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules.</text>
              <doc_id>52</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Word-level alignments are generated as a byproduct of inference.</text>
              <doc_id>53</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We first specify the relationship between word alignments and extraction sets, then define our model.</text>
              <doc_id>54</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Extraction Sets from Word Alignments</title>
            <text>Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc. In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based.
Given a sentence pair (e, f), phrasal rule extraction defines a mapping from a set of word-to-word
Type (a) 1: Type Language-specific 1: Language-specific function function words omitted words omitted in the other in the language other language
&#65533; [go over] Distribution over &#65533; [go over] Distribution over possible possible link types link types
&#65533;&#65533; &#65533;&#65533; [Earth] [Earth]
over the Earth 65% over the Earth 65%
Type 2: Type Role-equivalent
2: Role-equivalent pairs that word pairs
are not that lexical
are equivalents not lexical equivalents
was discovered was discovered
&#65533; [passive marker] &#65533; [passive marker]
&#65533;&#65533; [discover] &#65533;&#65533; [discover]
31% 31%
(b) &#963;(e 1 )
of the possible alignment links in our data set. &#963;(f 2 ) 2010&#65533; 2&#65533;
&#963;(f alignment 2 ) links A = {(i, j)} to an extraction set 15&#65533; 2&#65533;
of bispans R n (A) = {[g, h) &#8660; [k, l)}, where each bispan links target span [g, h) to source span
15&#65533;
[k, l). 1 The maximum On February phrase length 15 2010 n ensures that max(h &#8722; g, l &#8722; k) &#8804; n.
We canOndescribe Februarythis 15 mapping 2010 PDT via word-tophrase projections, as illustrated in Figure 1. Let word e i project to the phrasal span &#963;(e i ), where [ ) &#963;(e i ) = min j , max j + 1 (1)
j&#8712;J i j&#8712;J i
J i = {j : (i, j) &#8712; A}
and likewise each word f j projects to a span of e. Then, R n (A) includes a bispan [g, h) &#8660; [k, l) iff
&#963;(e i ) &#8838; [k, l) &#8704;i &#8712; [g, h)
&#963;(f j ) &#8838; [g, h) &#8704;j &#8712; [k, l)
That is, every word in one of the phrasal spans must project within the other. This mapping is deterministic, and so we can interpret a word-level alignment A as also specifying the phrasal rules that should be extracted from a sentence pair.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc.</text>
                  <doc_id>55</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based.</text>
                  <doc_id>56</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Given a sentence pair (e, f), phrasal rule extraction defines a mapping from a set of word-to-word</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Type (a) 1: Type Language-specific 1: Language-specific function function words omitted words omitted in the other in the language other language</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533; [go over] Distribution over &#65533; [go over] Distribution over possible possible link types link types</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;&#65533; &#65533;&#65533; [Earth] [Earth]</text>
                  <doc_id>60</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>over the Earth 65% over the Earth 65%</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Type 2: Type Role-equivalent</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>2: Role-equivalent pairs that word pairs</text>
                  <doc_id>63</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>are not that lexical</text>
                  <doc_id>64</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>are equivalents not lexical equivalents</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>was discovered was discovered</text>
                  <doc_id>66</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533; [passive marker] &#65533; [passive marker]</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;&#65533; [discover] &#65533;&#65533; [discover]</text>
                  <doc_id>68</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>31% 31%</text>
                  <doc_id>69</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(b) &#963;(e 1 )</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of the possible alignment links in our data set.</text>
                  <doc_id>71</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>&#963;(f 2 ) 2010&#65533; 2&#65533;</text>
                  <doc_id>72</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#963;(f alignment 2 ) links A = {(i, j)} to an extraction set 15&#65533; 2&#65533;</text>
                  <doc_id>73</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of bispans R n (A) = {[g, h) &#8660; [k, l)}, where each bispan links target span [g, h) to source span</text>
                  <doc_id>74</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>15&#65533;</text>
                  <doc_id>75</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>[k, l).</text>
                  <doc_id>76</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>1 The maximum On February phrase length 15 2010 n ensures that max(h &#8722; g, l &#8722; k) &#8804; n.</text>
                  <doc_id>77</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We canOndescribe Februarythis 15 mapping 2010 PDT via word-tophrase projections, as illustrated in Figure 1.</text>
                  <doc_id>78</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Let word e i project to the phrasal span &#963;(e i ), where [ ) &#963;(e i ) = min j , max j + 1 (1)</text>
                  <doc_id>79</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>j&#8712;J i j&#8712;J i</text>
                  <doc_id>80</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>J i = {j : (i, j) &#8712; A}</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>and likewise each word f j projects to a span of e. Then, R n (A) includes a bispan [g, h) &#8660; [k, l) iff</text>
                  <doc_id>82</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#963;(e i ) &#8838; [k, l) &#8704;i &#8712; [g, h)</text>
                  <doc_id>83</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#963;(f j ) &#8838; [g, h) &#8704;j &#8712; [k, l)</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>That is, every word in one of the phrasal spans must project within the other.</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This mapping is deterministic, and so we can interpret a word-level alignment A as also specifying the phrasal rules that should be extracted from a sentence pair.</text>
                  <doc_id>86</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Possible and Null Alignment Links</title>
            <text>We have not yet accounted for two special cases in annotated corpora: possible alignments and null alignments. To analyze these annotations, we consider a particular data set: a hand-aligned portion 1 We use the fencepost indexing scheme used commonly for parsing. Words are 0-indexed. Spans are inclusive on the lower bound and exclusive on the upper bound. For example, the span [0, 2) includes the first two words of a sentence.
of the NIST MT02 Chinese-to-English test set, which has been used in previous alignment experiments (Ayan et al., 2005; DeNero and Klein, 2007; Haghighi et al., 2009). Possible links account for 22% of all alignment links in these data, and we found that most of these links fall into two categories. First, possible links are used to align function words that have no equivalent in the other language, but colocate with aligned content words, such as English determiners. Second, they are used to mark pairs of words or short phrases that are not lexical equivalents, but which play equivalent roles in each sentence. Figure 2 shows examples of these two use cases, along with their corpus frequencies. 2 On the other hand, null alignments are used sparingly in our annotated data. More than 90% of words participate in some alignment link. The unaligned words typically express content in one sentence that is absent in its translation. Figure 3 illustrates how we interpret possible and null links in our projection. Possible links are typically not included in extraction procedures because most aligners predict only sure links. However, we see a natural interpretation for possible links in rule extraction: they license phrasal rules that both include and exclude them. We exclude null alignments from extracted phrases because they often indicate a mismatch in content. We achieve these effects by redefining the projection operator &#963;. Let A (s) be the subset of A that are sure links, then let the index set J i used for projection &#963; in Equation 1 be
Here, J i is a set of integers, and &#963;(e i ) for null aligned e i will be [&#8722;1, |f |+ 1) by Equation 1. Of course, the characteristics of our aligned corpus may not hold for other annotated corpora or other language pairs. However, we hope that the overall effectiveness of our modeling approach will influence future annotation efforts to build corpora that are consistent with this interpretation.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We have not yet accounted for two special cases in annotated corpora: possible alignments and null alignments.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To analyze these annotations, we consider a particular data set: a hand-aligned portion 1 We use the fencepost indexing scheme used commonly for parsing.</text>
                  <doc_id>88</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Words are 0-indexed.</text>
                  <doc_id>89</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Spans are inclusive on the lower bound and exclusive on the upper bound.</text>
                  <doc_id>90</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For example, the span [0, 2) includes the first two words of a sentence.</text>
                  <doc_id>91</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of the NIST MT02 Chinese-to-English test set, which has been used in previous alignment experiments (Ayan et al., 2005; DeNero and Klein, 2007; Haghighi et al., 2009).</text>
                  <doc_id>92</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Possible links account for 22% of all alignment links in these data, and we found that most of these links fall into two categories.</text>
                  <doc_id>93</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>First, possible links are used to align function words that have no equivalent in the other language, but colocate with aligned content words, such as English determiners.</text>
                  <doc_id>94</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Second, they are used to mark pairs of words or short phrases that are not lexical equivalents, but which play equivalent roles in each sentence.</text>
                  <doc_id>95</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Figure 2 shows examples of these two use cases, along with their corpus frequencies.</text>
                  <doc_id>96</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>2 On the other hand, null alignments are used sparingly in our annotated data.</text>
                  <doc_id>97</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>More than 90% of words participate in some alignment link.</text>
                  <doc_id>98</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>The unaligned words typically express content in one sentence that is absent in its translation.</text>
                  <doc_id>99</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>Figure 3 illustrates how we interpret possible and null links in our projection.</text>
                  <doc_id>100</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>Possible links are typically not included in extraction procedures because most aligners predict only sure links.</text>
                  <doc_id>101</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>However, we see a natural interpretation for possible links in rule extraction: they license phrasal rules that both include and exclude them.</text>
                  <doc_id>102</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
                <sentence>
                  <text>We exclude null alignments from extracted phrases because they often indicate a mismatch in content.</text>
                  <doc_id>103</doc_id>
                  <sec_id>11</sec_id>
                </sentence>
                <sentence>
                  <text>We achieve these effects by redefining the projection operator &#963;. Let A (s) be the subset of A that are sure links, then let the index set J i used for projection &#963; in Equation 1 be</text>
                  <doc_id>104</doc_id>
                  <sec_id>12</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Here, J i is a set of integers, and &#963;(e i ) for null aligned e i will be [&#8722;1, |f |+ 1) by Equation 1.</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Of course, the characteristics of our aligned corpus may not hold for other annotated corpora or other language pairs.</text>
                  <doc_id>106</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>However, we hope that the overall effectiveness of our modeling approach will influence future annotation efforts to build corpora that are consistent with this interpretation.</text>
                  <doc_id>107</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>2.3 A Linear Model of Extraction Sets</title>
            <text>We now define a linear model that scores extraction sets. We restrict our model to score only co-
projection of otherwise unaligned words, which in turn license overlapping phrases. In this example, &#963;(f 2 ) = [1, 2) does not include the possible link at (1, 0) because of the sure link at (1, 1), but &#963;(e 1 ) = [1, 2) does use the possible link because it would otherwise be unaligned. The word &#8220;PDT&#8221; is null aligned, and so its projection &#963;(e 4 ) = [&#8722;1, 4) extends beyond the bounds of the sentence, excluding &#8220;PDT&#8221; from all phrase pairs. herent extraction sets R n (A), those that are licensed by an underlying word alignment A with sure alignments A (s) &#8838; A. Conditioned on a sentence pair (e, f) and maximum phrase length n, we score extraction sets via a feature vector
&#966; b (g, h, k, l) Because the projection operator R n (&#183;) is a deterministic function, we can abbreviate &#966;(A (s) , R n (A)) as &#966;(A) without loss of information, although we emphasize that A is a set of sure and possible alignments, and &#966;(A) does not decompose as a sum of vectors on individual word-level alignment links. Our model is parameterized by a weight vector &#952;, which scores an extraction set R n (A) as &#952; &#183; &#966;(A). To further limit the space of extraction sets we are willing to consider, we restrict A to block inverse transduction grammar (ITG) alignments, a space that allows many-to-many alignments through phrasal terminal productions, but otherwise enforces at-most-one-to-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008). The ITG constraint
of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009). In summary, our model scores all R n (A) for A &#8712; ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We now define a linear model that scores extraction sets.</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We restrict our model to score only co-</text>
                  <doc_id>109</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>projection of otherwise unaligned words, which in turn license overlapping phrases.</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In this example, &#963;(f 2 ) = [1, 2) does not include the possible link at (1, 0) because of the sure link at (1, 1), but &#963;(e 1 ) = [1, 2) does use the possible link because it would otherwise be unaligned.</text>
                  <doc_id>111</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The word &#8220;PDT&#8221; is null aligned, and so its projection &#963;(e 4 ) = [&#8722;1, 4) extends beyond the bounds of the sentence, excluding &#8220;PDT&#8221; from all phrase pairs.</text>
                  <doc_id>112</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>herent extraction sets R n (A), those that are licensed by an underlying word alignment A with sure alignments A (s) &#8838; A.</text>
                  <doc_id>113</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Conditioned on a sentence pair (e, f) and maximum phrase length n, we score extraction sets via a feature vector</text>
                  <doc_id>114</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#966; b (g, h, k, l) Because the projection operator R n (&#183;) is a deterministic function, we can abbreviate &#966;(A (s) , R n (A)) as &#966;(A) without loss of information, although we emphasize that A is a set of sure and possible alignments, and &#966;(A) does not decompose as a sum of vectors on individual word-level alignment links.</text>
                  <doc_id>115</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Our model is parameterized by a weight vector &#952;, which scores an extraction set R n (A) as &#952; &#183; &#966;(A).</text>
                  <doc_id>116</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>To further limit the space of extraction sets we are willing to consider, we restrict A to block inverse transduction grammar (ITG) alignments, a space that allows many-to-many alignments through phrasal terminal productions, but otherwise enforces at-most-one-to-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008).</text>
                  <doc_id>117</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The ITG constraint</text>
                  <doc_id>118</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model.</text>
                  <doc_id>119</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links.</text>
                  <doc_id>120</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008).</text>
                  <doc_id>121</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009).</text>
                  <doc_id>122</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>In summary, our model scores all R n (A) for A &#8712; ITG(e, f) where A can include block terminals of size up to n.</text>
                  <doc_id>123</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>In our experiments, n = 3.</text>
                  <doc_id>124</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4.</text>
                  <doc_id>125</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Model Estimation</title>
        <text>We estimate the weights &#952; of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)&#8212;a large-margin, perceptron-style, online learning algorithm. MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al., 2009) and translation models (Chiang et al., 2008). For each training example, MIRA requires that we find the alignment A m corresponding to the highest scoring extraction set R n (A m ) under the current model, A m = arg max A&#8712;ITG(e,f) &#952; &#183; &#966;(A) (2) Section 4 describes our approach to solving this search problem for model inference. MIRA updates away from R n (A m ) and toward a gold extraction set R n (A g ). Some handannotated alignments are outside of the block ITG Inference &#963;(f details 2 ) appear in Section 4.3.
where &#964; is the minimal On step February size that 15 will 2010 ensurePDT we prefer A g to A m by a margin greater than the loss L(A m ; A g ), capped at some maximum update size C to provide regularization. We use C = 0.01 in experiments. The step size is a closed form function of the loss and feature vectors: &#964; =
We train the model for 30 iterations over the training set, shuffling the order each time, and we average the weight vectors observed after each iteration to estimate our final model.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We estimate the weights &#952; of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)&#8212;a large-margin, perceptron-style, online learning algorithm.</text>
              <doc_id>126</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al., 2009) and translation models (Chiang et al., 2008).</text>
              <doc_id>127</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>For each training example, MIRA requires that we find the alignment A m corresponding to the highest scoring extraction set R n (A m ) under the current model, A m = arg max A&#8712;ITG(e,f) &#952; &#183; &#966;(A) (2) Section 4 describes our approach to solving this search problem for model inference.</text>
              <doc_id>128</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>MIRA updates away from R n (A m ) and toward a gold extraction set R n (A g ).</text>
              <doc_id>129</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Some handannotated alignments are outside of the block ITG Inference &#963;(f details 2 ) appear in Section 4.3.</text>
              <doc_id>130</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>where &#964; is the minimal On step February size that 15 will 2010 ensurePDT we prefer A g to A m by a margin greater than the loss L(A m ; A g ), capped at some maximum update size C to provide regularization.</text>
              <doc_id>131</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We use C = 0.01 in experiments.</text>
              <doc_id>132</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The step size is a closed form function of the loss and feature vectors: &#964; =</text>
              <doc_id>133</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We train the model for 30 iterations over the training set, shuffling the order each time, and we average the weight vectors observed after each iteration to estimate our final model.</text>
              <doc_id>134</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Extraction Set Loss Function</title>
            <text></text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text></text>
                  <doc_id>135</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Features on Extraction Sets</title>
            <text>The discriminative power of our model is driven by the features on sure word alignment links &#966; a (i, j) and bispans &#966; b (g, h, k, l). In both cases, the most important features come from the predictions of unsupervised models trained on large parallel corpora, which provide frequency and cooccurrence information.
To score word-to-word links, we use the posterior predictions of a jointly trained HMM alignment model (Liang et al., 2006). The remaining features include a dictionary feature, an identical word feature, an absolute position distortion feature, and features for numbers and punctuation.
To score phrasal translation rules in an extraction set, we use a mixture of feature types. Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003). To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and score bispans using the resulting features. We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al. (2009). We include indicators for the number of words and Chinese characters in rules. One useful indicator feature exploits the fact that capitalized terms in English tend to align to Chinese words with three or more characters. On 1-by-n or n-by-1 phrasal rules, we include indicator features of fertility for common words. 3 We also include monolingual phrase features that expose useful information to the model. For instance, English bigrams beginning with &#8220;the&#8221; are often extractable phrases. English trigrams with a hyphen as the second word are typically extractable, meaning that the first and third words align to consecutive Chinese words. When any conjugation of the word &#8220;to be&#8221; is followed by a verb, indicating passive voice or progressive tense, the two words tend to align together. Our feature set also includes bias features on phrasal rules and links, which control the number of null-aligned words and number of rules licensed. In total, our final model includes 4,249 individual features, dominated by various instantiations of lexical templates.
3 Limiting lexicalized features to common words helps
prevent overfitting.
or
In the past two years
&#65533;&#65533; [past]</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The discriminative power of our model is driven by the features on sure word alignment links &#966; a (i, j) and bispans &#966; b (g, h, k, l).</text>
                  <doc_id>136</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In both cases, the most important features come from the predictions of unsupervised models trained on large parallel corpora, which provide frequency and cooccurrence information.</text>
                  <doc_id>137</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To score word-to-word links, we use the posterior predictions of a jointly trained HMM alignment model (Liang et al., 2006).</text>
                  <doc_id>138</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The remaining features include a dictionary feature, an identical word feature, an absolute position distortion feature, and features for numbers and punctuation.</text>
                  <doc_id>139</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>To score phrasal translation rules in an extraction set, we use a mixture of feature types.</text>
                  <doc_id>140</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003).</text>
                  <doc_id>141</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and score bispans using the resulting features.</text>
                  <doc_id>142</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al. (2009).</text>
                  <doc_id>143</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We include indicators for the number of words and Chinese characters in rules.</text>
                  <doc_id>144</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>One useful indicator feature exploits the fact that capitalized terms in English tend to align to Chinese words with three or more characters.</text>
                  <doc_id>145</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>On 1-by-n or n-by-1 phrasal rules, we include indicator features of fertility for common words.</text>
                  <doc_id>146</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>3 We also include monolingual phrase features that expose useful information to the model.</text>
                  <doc_id>147</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>For instance, English bigrams beginning with &#8220;the&#8221; are often extractable phrases.</text>
                  <doc_id>148</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>English trigrams with a hyphen as the second word are typically extractable, meaning that the first and third words align to consecutive Chinese words.</text>
                  <doc_id>149</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
                <sentence>
                  <text>When any conjugation of the word &#8220;to be&#8221; is followed by a verb, indicating passive voice or progressive tense, the two words tend to align together.</text>
                  <doc_id>150</doc_id>
                  <sec_id>10</sec_id>
                </sentence>
                <sentence>
                  <text>Our feature set also includes bias features on phrasal rules and links, which control the number of null-aligned words and number of rules licensed.</text>
                  <doc_id>151</doc_id>
                  <sec_id>11</sec_id>
                </sentence>
                <sentence>
                  <text>In total, our final model includes 4,249 individual features, dominated by various instantiations of lexical templates.</text>
                  <doc_id>152</doc_id>
                  <sec_id>12</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>3 Limiting lexicalized features to common words helps</text>
                  <doc_id>153</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>prevent overfitting.</text>
                  <doc_id>154</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>or</text>
                  <doc_id>155</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In the past two years</text>
                  <doc_id>156</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;&#65533; [past]</text>
                  <doc_id>157</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 Model Inference</title>
        <text>l
Equation 2 asks for the highest scoring extraction set under our model, R n (A m ), which we also require at test time. Although we have restricted A m &#8712; ITG(e, f), our extraction set model does not
&#65533; [after]
factor over ITG productions, and so the dynamic program for a vanilla block ITG will not suffice to
k =2 &#65533;&#65533; [dinner]
find R n (A m ). To see this, consider the extraction set in Figure 5. An ITG decomposition of the &#65533; un-[afterderlying alignment imposes a hierarchical bracketing onl =4 each sentence, and some bispan in the &#65533; ex-[Itraction set for this alignment will cross any such bracketing. Hence, g =1the score of h =3 some licensed &#65533; bis-[sleeppan will be non-local to the ITG decomposition.
&#65533; [past tense]</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>l</text>
              <doc_id>158</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Equation 2 asks for the highest scoring extraction set under our model, R n (A m ), which we also require at test time.</text>
              <doc_id>159</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Although we have restricted A m &#8712; ITG(e, f), our extraction set model does not</text>
              <doc_id>160</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533; [after]</text>
              <doc_id>161</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>factor over ITG productions, and so the dynamic program for a vanilla block ITG will not suffice to</text>
              <doc_id>162</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>k =2 &#65533;&#65533; [dinner]</text>
              <doc_id>163</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>find R n (A m ).</text>
              <doc_id>164</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>To see this, consider the extraction set in Figure 5.</text>
              <doc_id>165</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>An ITG decomposition of the &#65533; un-[afterderlying alignment imposes a hierarchical bracketing onl =4 each sentence, and some bispan in the &#65533; ex-[Itraction set for this alignment will cross any such bracketing.</text>
              <doc_id>166</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Hence, g =1the score of h =3 some licensed &#65533; bis-[sleeppan will be non-local to the ITG decomposition.</text>
              <doc_id>167</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>&#65533; [past tense]</text>
              <doc_id>168</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 A Dynamic Program for Extraction Sets</title>
            <text>After dinner I slept
If we treat the maximum phrase length n as a fixed constant, then we can define a dynamic program to search the space of extraction sets. An ITG derivation for some alignment A decomposes into two sub-derivations for A L and A R . 4 The model score of A, which scores extraction set R n (A), decomposes over A L and A R , along with any phrasal bispans licensed by adjoining A L and A R .
&#65533;
&#65533;
&#65533;
[two]
[year]
[in]
&#952; &#183; &#966;(A) = &#952; &#183; &#966;(A L ) + &#952; &#183; &#966;(A R ) + I(A L , A R )
where I(A L , A R ) is &#952; &#183; &#8721; &#966;(g, h, k, l) summed over licensed bispans [g, h) &#8660; [k, l) that overlap the boundary between A L and A R . 5
4 We abuse notation in conflating an alignment A with its
derivation. All derivations of the same alignment receive the same score, and we only compute the max, not the sum. 5 We focus on the case of adjoining two aligned bispans.
Our algorithm easily extends to include null alignments, but we focus on the non-null setting for simplicity.
&#963;(e i )
&#963;(f j )
&#65533;
[in] On February 15 2010
In the past two years
k
l
g h
bispans. The state must encode whether a sure link orders search states from small to large, where we appears in each edge column or row, but the &#65533;spe-[after] cific location of edge links is not required. words contained within it. For each size, we main- define the size of a bispan as the total number of
l =4 &#65533; [I] tain a separate agenda. Only when the agenda for
size k is exhausted does the parser proceed to process the agenda for size k + 1. In order tog compute =1 I(A h L , A
=3 R ), we need &#65533; certain information about the alignment configura- [sleep]
tions of A L and A R where they adjoin at a corner. We also employ coarse-to-fine search to speed &#65533; (past) The state must represent (a) the specific alignment links in the nAfter &#8722; 1 deep dinner corner I of each sleptA, and (b) whether any sure alignments appear in the rows or columns extending from those corners. 6 With this information, we can infer the bispans licensed by adjoining A L and A R , as in Figure 6.
Applying our score recurrence yields a polynomial-time dynamic program. This dynamic program is an instance of ITG bitext parsing, where the grammar uses symbols to encode the alignment contexts described above. This context-as-symbol augmentation of the grammar is similar in character to augmenting symbols with lexical items to score language models during hierarchical decoding (Chiang, 2007).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>After dinner I slept</text>
                  <doc_id>169</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>If we treat the maximum phrase length n as a fixed constant, then we can define a dynamic program to search the space of extraction sets.</text>
                  <doc_id>170</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>An ITG derivation for some alignment A decomposes into two sub-derivations for A L and A R .</text>
                  <doc_id>171</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>4 The model score of A, which scores extraction set R n (A), decomposes over A L and A R , along with any phrasal bispans licensed by adjoining A L and A R .</text>
                  <doc_id>172</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;</text>
                  <doc_id>173</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;</text>
                  <doc_id>174</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;</text>
                  <doc_id>175</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>[two]</text>
                  <doc_id>176</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>[year]</text>
                  <doc_id>177</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>[in]</text>
                  <doc_id>178</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#952; &#183; &#966;(A) = &#952; &#183; &#966;(A L ) + &#952; &#183; &#966;(A R ) + I(A L , A R )</text>
                  <doc_id>179</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where I(A L , A R ) is &#952; &#183; &#8721; &#966;(g, h, k, l) summed over licensed bispans [g, h) &#8660; [k, l) that overlap the boundary between A L and A R .</text>
                  <doc_id>180</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>5</text>
                  <doc_id>181</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4 We abuse notation in conflating an alignment A with its</text>
                  <doc_id>182</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>derivation.</text>
                  <doc_id>183</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>All derivations of the same alignment receive the same score, and we only compute the max, not the sum.</text>
                  <doc_id>184</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>5 We focus on the case of adjoining two aligned bispans.</text>
                  <doc_id>185</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Our algorithm easily extends to include null alignments, but we focus on the non-null setting for simplicity.</text>
                  <doc_id>186</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#963;(e i )</text>
                  <doc_id>187</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#963;(f j )</text>
                  <doc_id>188</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#65533;</text>
                  <doc_id>189</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>[in] On February 15 2010</text>
                  <doc_id>190</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In the past two years</text>
                  <doc_id>191</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>k</text>
                  <doc_id>192</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>l</text>
                  <doc_id>193</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>g h</text>
                  <doc_id>194</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>bispans.</text>
                  <doc_id>195</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The state must encode whether a sure link orders search states from small to large, where we appears in each edge column or row, but the &#65533;spe-[after] cific location of edge links is not required.</text>
                  <doc_id>196</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>words contained within it.</text>
                  <doc_id>197</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>For each size, we main- define the size of a bispan as the total number of</text>
                  <doc_id>198</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>l =4 &#65533; [I] tain a separate agenda.</text>
                  <doc_id>199</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Only when the agenda for</text>
                  <doc_id>200</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>size k is exhausted does the parser proceed to process the agenda for size k + 1.</text>
                  <doc_id>201</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In order tog compute =1 I(A h L , A</text>
                  <doc_id>202</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>=3 R ), we need &#65533; certain information about the alignment configura- [sleep]</text>
                  <doc_id>203</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>tions of A L and A R where they adjoin at a corner.</text>
                  <doc_id>204</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We also employ coarse-to-fine search to speed &#65533; (past) The state must represent (a) the specific alignment links in the nAfter &#8722; 1 deep dinner corner I of each sleptA, and (b) whether any sure alignments appear in the rows or columns extending from those corners.</text>
                  <doc_id>205</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>6 With this information, we can infer the bispans licensed by adjoining A L and A R , as in Figure 6.</text>
                  <doc_id>206</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Applying our score recurrence yields a polynomial-time dynamic program.</text>
                  <doc_id>207</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This dynamic program is an instance of ITG bitext parsing, where the grammar uses symbols to encode the alignment contexts described above.</text>
                  <doc_id>208</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This context-as-symbol augmentation of the grammar is similar in character to augmenting symbols with lexical items to score language models during hierarchical decoding (Chiang, 2007).</text>
                  <doc_id>209</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Coarse-to-Fine Inference and Pruning</title>
            <text>Exhaustive inference under an ITG requires O(k 6 ) time in sentence length k, and is prohibitively slow when there is no sparsity in the grammar. Maintaining the context necessary to score non-local bispans further increases running time. That is, ITG inference is organized around search states associated with a grammar symbol and a bispan; augmenting grammar symbols also augments this state space. To parse quickly, we prune away search states using predictions from the more efficient HMM
6 The number of configuration states does not depend on
the size of A because corners have fixed size, and because the position of links within rows or columns is not needed.
alignment model (Ney and Vogel, 1996). We discard all states corresponding to bispans that are incompatible with 3 or more alignment links under an intersected HMM&#8212;a proven approach to pruning the space of ITG alignments (Zhang and Gildea, 2006; Haghighi et al., 2009). Pruning in this way reduces the search space dramatically, but only rarely prohibits correct alignments. The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for
up inference (Charniak and Caraballo, 1998). In the coarse pass, we search over the space of ITG alignments, but score only features on alignment links and bispans that are local to terminal blocks. This simplification eliminates the need to augment grammar symbols, and so we can exhaustively explore the (pruned) space. We then compute outside scores for bispans under a max-sum semiring (Goodman, 1996). In the fine pass with the full extraction set model, we impose a maximum size of 10,000 for each agenda. We order states on agendas by the sum of their inside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when the results are falling off the agenda beams. Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Exhaustive inference under an ITG requires O(k 6 ) time in sentence length k, and is prohibitively slow when there is no sparsity in the grammar.</text>
                  <doc_id>210</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Maintaining the context necessary to score non-local bispans further increases running time.</text>
                  <doc_id>211</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>That is, ITG inference is organized around search states associated with a grammar symbol and a bispan; augmenting grammar symbols also augments this state space.</text>
                  <doc_id>212</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To parse quickly, we prune away search states using predictions from the more efficient HMM</text>
                  <doc_id>213</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>6 The number of configuration states does not depend on</text>
                  <doc_id>214</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the size of A because corners have fixed size, and because the position of links within rows or columns is not needed.</text>
                  <doc_id>215</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>alignment model (Ney and Vogel, 1996).</text>
                  <doc_id>216</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We discard all states corresponding to bispans that are incompatible with 3 or more alignment links under an intersected HMM&#8212;a proven approach to pruning the space of ITG alignments (Zhang and Gildea, 2006; Haghighi et al., 2009).</text>
                  <doc_id>217</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Pruning in this way reduces the search space dramatically, but only rarely prohibits correct alignments.</text>
                  <doc_id>218</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for</text>
                  <doc_id>219</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>up inference (Charniak and Caraballo, 1998).</text>
                  <doc_id>220</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In the coarse pass, we search over the space of ITG alignments, but score only features on alignment links and bispans that are local to terminal blocks.</text>
                  <doc_id>221</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This simplification eliminates the need to augment grammar symbols, and so we can exhaustively explore the (pruned) space.</text>
                  <doc_id>222</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We then compute outside scores for bispans under a max-sum semiring (Goodman, 1996).</text>
                  <doc_id>223</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>In the fine pass with the full extraction set model, we impose a maximum size of 10,000 for each agenda.</text>
                  <doc_id>224</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>We order states on agendas by the sum of their inside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size.</text>
                  <doc_id>225</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states.</text>
                  <doc_id>226</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>For each corner and size combination, built states are maintained in sorted order according to their inside score.</text>
                  <doc_id>227</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>This ordering allows us to stop combining states early when the results are falling off the agenda beams.</text>
                  <doc_id>228</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
                <sentence>
                  <text>Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007).</text>
                  <doc_id>229</doc_id>
                  <sec_id>9</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>4.3 Finding Pseudo-Gold ITG Alignments</title>
            <text>Equation 3 asks for the block ITG alignment A g that is closest to a reference alignment A t , which may not lie in ITG(e,f). We search for
uses an admissible heuristic for bispans that counts the number of gold links outside of [k, l) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. A g using A* bitext parsing (Klein and Manning, 2003). Search states, which correspond to bispans [g, h) &#8660; [k, l), are scored by the number of errors within the bispan plus the number of (i, j) &#8712; A t such that j &#8712; [k, l) but i /&#8712; [g, h) (recall errors). As an admissible heuristic for the future cost of a bispan [g, h) &#8660; [k, l), we count the number of (i, j) &#8712; A t such that i &#8712; [g, h) but j /&#8712; [k, l), as depicted in Figure 7. These links will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Equation 3 asks for the block ITG alignment A g that is closest to a reference alignment A t , which may not lie in ITG(e,f).</text>
                  <doc_id>230</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We search for</text>
                  <doc_id>231</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>uses an admissible heuristic for bispans that counts the number of gold links outside of [k, l) but within [g, h).</text>
                  <doc_id>232</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan.</text>
                  <doc_id>233</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A g using A* bitext parsing (Klein and Manning, 2003).</text>
                  <doc_id>234</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Search states, which correspond to bispans [g, h) &#8660; [k, l), are scored by the number of errors within the bispan plus the number of (i, j) &#8712; A t such that j &#8712; [k, l) but i /&#8712; [g, h) (recall errors).</text>
                  <doc_id>235</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>As an admissible heuristic for the future cost of a bispan [g, h) &#8660; [k, l), we count the number of (i, j) &#8712; A t such that i &#8712; [g, h) but j /&#8712; [k, l), as depicted in Figure 7.</text>
                  <doc_id>236</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>These links will become recall errors eventually.</text>
                  <doc_id>237</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible.</text>
                  <doc_id>238</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Relationship to Previous Work</title>
        <text>Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K&#228;&#228;ri&#228;inen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and focuses on translation model estimation, while we focus on alignment and translate using standard relative frequency estimators. Deng and Zhou (2009) present an alignment combination technique that uses phrasal features. Our approach differs in two ways. First, their approach is tightly coupled to the input alignments, while we perform a full search over the space of ITG alignments. Also, their approach uses greedy search, while our search is optimal aside from pruning and beaming. Despite these differences, their strong results reinforce our claim that phraselevel information is useful for alignment.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Our model is certainly not the first alignment approach to include structures larger than words.</text>
              <doc_id>239</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002).</text>
              <doc_id>240</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008).</text>
              <doc_id>241</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation.</text>
              <doc_id>242</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Our model scores the larger overlapping phrases that result from composing these minimal phrases.</text>
              <doc_id>243</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Discriminative alignment is also a wellexplored area.</text>
              <doc_id>244</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006).</text>
              <doc_id>245</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007).</text>
              <doc_id>246</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008).</text>
              <doc_id>247</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009).</text>
              <doc_id>248</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function.</text>
              <doc_id>249</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>K&#228;&#228;ri&#228;inen (2009) trains a translation model discriminatively using features on overlapping phrase pairs.</text>
              <doc_id>250</doc_id>
              <sec_id>11</sec_id>
            </sentence>
            <sentence>
              <text>That work differs from ours in that it uses fixed word alignments and focuses on translation model estimation, while we focus on alignment and translate using standard relative frequency estimators.</text>
              <doc_id>251</doc_id>
              <sec_id>12</sec_id>
            </sentence>
            <sentence>
              <text>Deng and Zhou (2009) present an alignment combination technique that uses phrasal features.</text>
              <doc_id>252</doc_id>
              <sec_id>13</sec_id>
            </sentence>
            <sentence>
              <text>Our approach differs in two ways.</text>
              <doc_id>253</doc_id>
              <sec_id>14</sec_id>
            </sentence>
            <sentence>
              <text>First, their approach is tightly coupled to the input alignments, while we perform a full search over the space of ITG alignments.</text>
              <doc_id>254</doc_id>
              <sec_id>15</sec_id>
            </sentence>
            <sentence>
              <text>Also, their approach uses greedy search, while our search is optimal aside from pruning and beaming.</text>
              <doc_id>255</doc_id>
              <sec_id>16</sec_id>
            </sentence>
            <sentence>
              <text>Despite these differences, their strong results reinforce our claim that phraselevel information is useful for alignment.</text>
              <doc_id>256</doc_id>
              <sec_id>17</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>6</index>
        <title>6 Experiments</title>
        <text>We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations generated by two end-to-end systems. Table 1 compares the five systems described below, including three baselines. All supervised aligners were optimized for bispan F 5 . Unsupervised Baseline: GIZA++. We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with
1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner. 7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009). We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison. To remain within the alignment class, MIRA updates this model toward a pseudogold alignment with only sure links. This model does not score any overlapping bispans. Extraction Set Coarse Pass. We add possible links to the output of the block ITG model by adding the mixed terminal block productions described in Section 2.3. This model scores overlapping phrasal rules contained within terminal blocks that result from including or excluding possible links. However, this model does not score bispans that cross bracketing of ITG derivations. Full Extraction Set Model. Our full model includes possible links and features on extraction sets for phrasal bispans with a maximum size of 3. Model inference is performed using the coarseto-fine scheme described in Section 4.2.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations generated by two end-to-end systems.</text>
              <doc_id>257</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Table 1 compares the five systems described below, including three baselines.</text>
              <doc_id>258</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>All supervised aligners were optimized for bispan F 5 .</text>
              <doc_id>259</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Unsupervised Baseline: GIZA++.</text>
              <doc_id>260</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007).</text>
              <doc_id>261</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>The designated regimen concludes by Viterbi aligning under Model 4 in both directions.</text>
              <doc_id>262</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>We combined these alignments with</text>
              <doc_id>263</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1459 the grow-diag heuristic (Koehn et al., 2003).</text>
              <doc_id>264</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Unsupervised Baseline: Joint HMM.</text>
              <doc_id>265</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.</text>
              <doc_id>266</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline.</text>
              <doc_id>267</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Supervised Baseline: Block ITG.</text>
              <doc_id>268</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size.</text>
              <doc_id>269</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009).</text>
              <doc_id>270</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison.</text>
              <doc_id>271</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>To remain within the alignment class, MIRA updates this model toward a pseudogold alignment with only sure links.</text>
              <doc_id>272</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>This model does not score any overlapping bispans.</text>
              <doc_id>273</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>Extraction Set Coarse Pass.</text>
              <doc_id>274</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>We add possible links to the output of the block ITG model by adding the mixed terminal block productions described in Section 2.3.</text>
              <doc_id>275</doc_id>
              <sec_id>11</sec_id>
            </sentence>
            <sentence>
              <text>This model scores overlapping phrasal rules contained within terminal blocks that result from including or excluding possible links.</text>
              <doc_id>276</doc_id>
              <sec_id>12</sec_id>
            </sentence>
            <sentence>
              <text>However, this model does not score bispans that cross bracketing of ITG derivations.</text>
              <doc_id>277</doc_id>
              <sec_id>13</sec_id>
            </sentence>
            <sentence>
              <text>Full Extraction Set Model.</text>
              <doc_id>278</doc_id>
              <sec_id>14</sec_id>
            </sentence>
            <sentence>
              <text>Our full model includes possible links and features on extraction sets for phrasal bispans with a maximum size of 3.</text>
              <doc_id>279</doc_id>
              <sec_id>15</sec_id>
            </sentence>
            <sentence>
              <text>Model inference is performed using the coarseto-fine scheme described in Section 4.2.</text>
              <doc_id>280</doc_id>
              <sec_id>16</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>6.1 Data</title>
            <text>In this paper, we focus exclusively on Chinese-to- English translation. We performed our discriminative training and alignment evaluations using a hand-aligned portion of the NIST MT02 test set, which consists of 150 training and 191 test sentences (Ayan and Dorr, 2006). We trained the baseline HMM on 11.3 million words of FBIS newswire data, a comparable dataset to those used in previous alignment evaluations on our test set (DeNero and Klein, 2007; Haghighi et al., 2009).
7 http://code.google.com/p/berkeleyaligner
Our end-to-end translation experiments were tuned and evaluated on sentences up to length 40 from the NIST MT04 and MT05 test sets. For these experiments, we trained on a 22.1 million word parallel corpus consisting of sentences up to length 40 of newswire data from the GALE program, subsampled from a larger data set to promote overlap with the tune and test sets. This corpus also includes a bilingual dictionary. To improve performance, we retrained our aligner on a retokenized version of the hand-annotated data to match the tokenization of our corpus. 8 We trained a language model with Kneser-Ney smoothing on 262 million words of newswire using SRILM (Stolcke, 2002).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>In this paper, we focus exclusively on Chinese-to- English translation.</text>
                  <doc_id>281</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We performed our discriminative training and alignment evaluations using a hand-aligned portion of the NIST MT02 test set, which consists of 150 training and 191 test sentences (Ayan and Dorr, 2006).</text>
                  <doc_id>282</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We trained the baseline HMM on 11.3 million words of FBIS newswire data, a comparable dataset to those used in previous alignment evaluations on our test set (DeNero and Klein, 2007; Haghighi et al., 2009).</text>
                  <doc_id>283</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>7 http://code.google.com/p/berkeleyaligner</text>
                  <doc_id>284</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Our end-to-end translation experiments were tuned and evaluated on sentences up to length 40 from the NIST MT04 and MT05 test sets.</text>
                  <doc_id>285</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For these experiments, we trained on a 22.1 million word parallel corpus consisting of sentences up to length 40 of newswire data from the GALE program, subsampled from a larger data set to promote overlap with the tune and test sets.</text>
                  <doc_id>286</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This corpus also includes a bilingual dictionary.</text>
                  <doc_id>287</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To improve performance, we retrained our aligner on a retokenized version of the hand-annotated data to match the tokenization of our corpus.</text>
                  <doc_id>288</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>8 We trained a language model with Kneser-Ney smoothing on 262 million words of newswire using SRILM (Stolcke, 2002).</text>
                  <doc_id>289</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>6.2 Word and Phrase Alignment</title>
            <text>The first panel of Table 1 gives a word-level evaluation of all five aligners. We use the alignment error rate (AER) measure: precision is the fraction of sure links in the system output that are sure or possible in the reference, and recall is the fraction of sure links in the reference that the system outputs as sure. For this evaluation, possible links produced by our extraction set models are ignored. The full extraction set model performs the best by a small margin, although it was not tuned for word alignment.
The second panel gives a phrasal rule-level evaluation, which measures the degree to which these aligners matched the extraction sets of handannotated alignments, R 3 (A t ). 9 To compete fairly, all models were evaluated on the full extraction sets induced by the word alignments they predicted. Again, the extraction set model outperformed the baselines, particularly on the F 5 measure for which these systems were trained.
Our coarse pass extraction set model performed nearly as well as the full model. We believe these models perform similarly for two reasons. First, most of the information needed to predict an extraction set can be inferred from word links and phrasal rules contained within ITG terminal productions. Second, the coarse-to-fine inference may be constraining the full phrasal model to predict similar output to the coarse model. This similarity persists in translation experiments.
8 All alignment results are reported under the annotated
data set&#8217;s original tokenization. 9 While pseudo-gold approximations to the annotation
were used for training, the evaluation is always performed relative to the original human annotation.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The first panel of Table 1 gives a word-level evaluation of all five aligners.</text>
                  <doc_id>290</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We use the alignment error rate (AER) measure: precision is the fraction of sure links in the system output that are sure or possible in the reference, and recall is the fraction of sure links in the reference that the system outputs as sure.</text>
                  <doc_id>291</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For this evaluation, possible links produced by our extraction set models are ignored.</text>
                  <doc_id>292</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The full extraction set model performs the best by a small margin, although it was not tuned for word alignment.</text>
                  <doc_id>293</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The second panel gives a phrasal rule-level evaluation, which measures the degree to which these aligners matched the extraction sets of handannotated alignments, R 3 (A t ).</text>
                  <doc_id>294</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>9 To compete fairly, all models were evaluated on the full extraction sets induced by the word alignments they predicted.</text>
                  <doc_id>295</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Again, the extraction set model outperformed the baselines, particularly on the F 5 measure for which these systems were trained.</text>
                  <doc_id>296</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Our coarse pass extraction set model performed nearly as well as the full model.</text>
                  <doc_id>297</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We believe these models perform similarly for two reasons.</text>
                  <doc_id>298</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>First, most of the information needed to predict an extraction set can be inferred from word links and phrasal rules contained within ITG terminal productions.</text>
                  <doc_id>299</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Second, the coarse-to-fine inference may be constraining the full phrasal model to predict similar output to the coarse model.</text>
                  <doc_id>300</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This similarity persists in translation experiments.</text>
                  <doc_id>301</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>8 All alignment results are reported under the annotated</text>
                  <doc_id>302</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>data set&#8217;s original tokenization.</text>
                  <doc_id>303</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>9 While pseudo-gold approximations to the annotation</text>
                  <doc_id>304</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>were used for training, the evaluation is always performed relative to the original human annotation.</text>
                  <doc_id>305</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>6.3 Translation Experiments</title>
            <text>We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems. Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007). Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007).
Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume. To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability. These three sets were aggregated and rules were extracted from all three. The training set we used for MT experiments is quite heterogenous and noisy compared to our alignment test sets, and the supervised aligners did not handle certain sentence pairs in our parallel corpus well. In some cases, pruning based on consistency with the HMM caused parse failures, which in turn caused training sentences to be skipped. To account for these issues, we added counts of phrasal rules extracted from the baseline HMM to the counts produced by supervised aligners.
In Moses, our extraction set model predicts the set of phrases extracted by the system, and so the estimation techniques for the alignment model and translation model both share a common underlying representation: extraction sets. Empirically, we observe a BLEU score improvement of 1.2 over the best unsupervised baseline and 0.8 over the block ITG supervised baseline (Papineni et al., 2002).
In Joshua, hierarchical rule extraction is based upon phrasal rule extraction, but abstracts away sub-phrases to create a grammar. Hence, the extraction sets we predict are closely linked to the representation that this system uses to translate. The extraction model again outperformed both unsupervised and supervised baselines, by 1.4 BLEU and 1.2 BLEU respectively.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems.</text>
                  <doc_id>306</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007).</text>
                  <doc_id>307</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007).</text>
                  <doc_id>308</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume.</text>
                  <doc_id>309</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability.</text>
                  <doc_id>310</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>These three sets were aggregated and rules were extracted from all three.</text>
                  <doc_id>311</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The training set we used for MT experiments is quite heterogenous and noisy compared to our alignment test sets, and the supervised aligners did not handle certain sentence pairs in our parallel corpus well.</text>
                  <doc_id>312</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>In some cases, pruning based on consistency with the HMM caused parse failures, which in turn caused training sentences to be skipped.</text>
                  <doc_id>313</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>To account for these issues, we added counts of phrasal rules extracted from the baseline HMM to the counts produced by supervised aligners.</text>
                  <doc_id>314</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Moses, our extraction set model predicts the set of phrases extracted by the system, and so the estimation techniques for the alignment model and translation model both share a common underlying representation: extraction sets.</text>
                  <doc_id>315</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Empirically, we observe a BLEU score improvement of 1.2 over the best unsupervised baseline and 0.8 over the block ITG supervised baseline (Papineni et al., 2002).</text>
                  <doc_id>316</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In Joshua, hierarchical rule extraction is based upon phrasal rule extraction, but abstracts away sub-phrases to create a grammar.</text>
                  <doc_id>317</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Hence, the extraction sets we predict are closely linked to the representation that this system uses to translate.</text>
                  <doc_id>318</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The extraction model again outperformed both unsupervised and supervised baselines, by 1.4 BLEU and 1.2 BLEU respectively.</text>
                  <doc_id>319</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>7</index>
        <title>7 Conclusion</title>
        <text>Our extraction set model serves to coordinate the alignment and translation model components of a statistical translation system by unifying their representations. Moreover, our model provides an effective alternative to phrase alignment models that choose a particular phrase segmentation; instead, we predict many overlapping phrases, both large and small, that are mutually consistent. In future work, we look forward to developing extraction set models for richer formalisms, including hierarchical grammars.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Our extraction set model serves to coordinate the alignment and translation model components of a statistical translation system by unifying their representations.</text>
              <doc_id>320</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Moreover, our model provides an effective alternative to phrase alignment models that choose a particular phrase segmentation; instead, we predict many overlapping phrases, both large and small, that are mutually consistent.</text>
              <doc_id>321</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In future work, we look forward to developing extraction set models for richer formalisms, including hierarchical grammars.</text>
              <doc_id>322</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>8</index>
        <title>Acknowledgments</title>
        <text>This project is funded in part by BBN under DARPA contract HR0011-06-C-0022 and by the NSF under grant 0643742. We thank the anonymous reviewers for their helpful comments.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This project is funded in part by BBN under DARPA contract HR0011-06-C-0022 and by the NSF under grant 0643742.</text>
              <doc_id>323</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We thank the anonymous reviewers for their helpful comments.</text>
              <doc_id>324</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: Experimental results demonstrate that the full extraction set model outperforms supervised and unsupervised baselines in evaluations of word alignment quality, extraction set quality, and translation. In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate for parse failures.</caption>
        <reference_text></reference_text>
        <page_num>8</page_num>
        <head>
          <rows>
            <row>
              <cell>Word</cell>
              <cell>Bispan</cell>
              <cell>BLEU</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>Pr</cell>
              <cell>Rc</cell>
              <cell>AER</cell>
              <cell>Pr</cell>
              <cell>Rc</cell>
              <cell>F 1</cell>
              <cell>F 5</cell>
              <cell>Joshua</cell>
              <cell>Moses</cell>
            </row>
            <row>
              <cell>Baseline</cell>
              <cell>GIZA++</cell>
              <cell>72.5</cell>
              <cell>71.8</cell>
              <cell>27.8</cell>
              <cell>69.4</cell>
              <cell>45.4</cell>
              <cell>54.9</cell>
              <cell>46.0</cell>
              <cell>33.8</cell>
              <cell>32.6</cell>
            </row>
            <row>
              <cell>models</cell>
              <cell>Joint HMM</cell>
              <cell>84.0</cell>
              <cell>76.9</cell>
              <cell>19.6</cell>
              <cell>69.5</cell>
              <cell>59.5</cell>
              <cell>64.1</cell>
              <cell>59.9</cell>
              <cell>34.5</cell>
              <cell>33.2</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Block ITG</cell>
              <cell>83.4</cell>
              <cell>83.8</cell>
              <cell>16.4</cell>
              <cell>75.8</cell>
              <cell>62.3</cell>
              <cell>68.4</cell>
              <cell>62.8</cell>
              <cell>34.7</cell>
              <cell>33.6</cell>
            </row>
            <row>
              <cell>Extraction</cell>
              <cell>Coarse Pass</cell>
              <cell>82.2</cell>
              <cell>84.2</cell>
              <cell>16.9</cell>
              <cell>70.0</cell>
              <cell>72.9</cell>
              <cell>71.4</cell>
              <cell>72.8</cell>
              <cell>35.7</cell>
              <cell>34.2</cell>
            </row>
            <row>
              <cell>set models</cell>
              <cell>Full Model</cell>
              <cell>84.7</cell>
              <cell>84.0</cell>
              <cell>15.6</cell>
              <cell>69.0</cell>
              <cell>74.2</cell>
              <cell>71.6</cell>
              <cell>74.0</cell>
              <cell>35.9</cell>
              <cell>34.4</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Necip Fazil Ayan</author>
          <author>Bonnie J Dorr</author>
        </authors>
        <title>Going beyond AER: An extensive analysis of word alignments and their impact on MT.</title>
        <publication>In Proceedings of 1461 Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Necip Fazil Ayan</author>
          <author>Bonnie J Dorr</author>
          <author>Christof Monz</author>
        </authors>
        <title>Neuralign: combining word alignments using neural networks.</title>
        <publication>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Alexandra Birch</author>
          <author>Chris Callison-Burch</author>
          <author>Miles Osborne</author>
        </authors>
        <title>Constraining the phrase-based, joint probability statistical translation model.</title>
        <publication>In Proceedings of the Conference for the Association for Machine Translation in the Americas.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Phil Blunsom</author>
          <author>Trevor Cohn</author>
          <author>Chris Dyer</author>
          <author>Miles Osborne</author>
        </authors>
        <title>A Gibbs sampler for phrasal synchronous grammar induction.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Eugene Charniak</author>
          <author>Sharon Caraballo</author>
        </authors>
        <title>New figures of merit for best-first probabilistic chart parsing.</title>
        <publication>In Computational Linguistics.</publication>
        <pages>None</pages>
        <date>1998</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Colin Cherry</author>
          <author>Dekang Lin</author>
        </authors>
        <title>Soft syntactic constraints for word alignment through discriminative training.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Colin Cherry</author>
          <author>Dekang Lin</author>
        </authors>
        <title>Inversion transduction grammar for joint phrasal translation modeling.</title>
        <publication>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics Workshop on Syntax and Structure in Statistical Translation.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>David Chiang</author>
          <author>Yuval Marton</author>
          <author>Philip Resnik</author>
        </authors>
        <title>Online large-margin training of syntactic and structural translation features.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>David Chiang</author>
        </authors>
        <title>Hierarchical phrase-based translation. Computational Linguistics.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>Koby Crammer</author>
          <author>Yoram Singer</author>
        </authors>
        <title>Ultraconservative online algorithms for multiclass problems.</title>
        <publication>None</publication>
        <pages>3--951</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>John DeNero</author>
          <author>Dan Klein</author>
        </authors>
        <title>Tailoring word alignments to syntactic machine translation.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>John DeNero</author>
          <author>Dan Klein</author>
        </authors>
        <title>The complexity of phrase alignment problems.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>John DeNero</author>
          <author>Dan Gillick</author>
          <author>James Zhang</author>
          <author>Dan Klein</author>
        </authors>
        <title>Why generative phrase models underperform surface heuristics.</title>
        <publication>In Proceedings of the NAACL Workshop on Statistical Machine Translation.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>John DeNero</author>
          <author>Alexandre Bouchard-Cote</author>
          <author>Dan Klein</author>
        </authors>
        <title>Sampling alignment structure under a bayesian translation model.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Yonggang Deng</author>
          <author>Bowen Zhou</author>
        </authors>
        <title>Optimizing word alignment combination for phrase table training.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>Alexander Fraser</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>Semisupervised training for statistical word alignment.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Alexander Fraser</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>Getting the structure right for word alignment: Leaf.</title>
        <publication>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Michel Galley</author>
          <author>Jonathan Graehl</author>
          <author>Kevin Knight</author>
          <author>Daniel Marcu</author>
          <author>Steve DeNeefe</author>
          <author>Wei Wang</author>
          <author>Ignacio Thayer</author>
        </authors>
        <title>Scalable inference and training of context-rich syntactic translation models.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Joshua Goodman</author>
        </authors>
        <title>Parsing algorithms and metrics.</title>
        <publication>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>1996</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>Aria Haghighi</author>
          <author>John Blitzer</author>
          <author>John DeNero</author>
          <author>Dan Klein</author>
        </authors>
        <title>Better word alignments with supervised ITG models.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>Liang Huang</author>
          <author>David Chiang</author>
        </authors>
        <title>Forest rescoring: Faster decoding with integrated language models.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>Matti K&#228;&#228;ri&#228;inen</author>
        </authors>
        <title>Sinuhe&#8212;statistical machine translation using a globally trained conditional exponential family translation model.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>Dan Klein</author>
          <author>Chris Manning</author>
        </authors>
        <title>A* parsing: Fast exact Viterbi parse selection.</title>
        <publication>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>23</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Barry Haddow</author>
        </authors>
        <title>Edinburghs submission to all tracks of the WMT2009 shared task with reordering and speed improvements to Moses.</title>
        <publication>In Proceedings of the Workshop on Statistical Machine Translation.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>24</id>
        <authors>
          <author>Philipp Koehn</author>
          <author>Franz Josef Och</author>
          <author>Daniel Marcu</author>
        </authors>
        <title>Statistical phrase-based translation.</title>
        <publication>In Proceedings of the Conference of</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>25</id>
        <authors>
          <author>Simon Lacoste-Julien</author>
          <author>Ben Taskar</author>
          <author>Dan Klein</author>
          <author>Michael I Jordan</author>
        </authors>
        <title>Word alignment via quadratic assignment.</title>
        <publication>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>26</id>
        <authors>
          <author>Zhifei Li</author>
          <author>Chris Callison-Burch</author>
          <author>Chris Dyer</author>
          <author>Juri Ganitkevitch</author>
          <author>Sanjeev Khudanpur</author>
          <author>Lane Schwartz</author>
          <author>Wren Thornton</author>
          <author>Jonathan Weese</author>
          <author>Omar Zaidan</author>
        </authors>
        <title>Joshua: An open source toolkit for parsing-based machine translation.</title>
        <publication>In Proceedings of the Workshop on Statistical Machine Translation.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>27</id>
        <authors>
          <author>Percy Liang</author>
          <author>Ben Taskar</author>
          <author>Dan Klein</author>
        </authors>
        <title>Alignment by agreement.</title>
        <publication>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>28</id>
        <authors>
          <author>Adam Lopez</author>
        </authors>
        <title>Hierarchical phrase-based translation with suffix arrays.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>29</id>
        <authors>
          <author>Daniel Marcu</author>
          <author>Daniel Wong</author>
        </authors>
        <title>A phrasebased, joint probability model for statistical machine translation.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>30</id>
        <authors>
          <author>Kishore Papineni</author>
          <author>Salim Roukos</author>
          <author>Todd Ward</author>
          <author>WeiJing Zhu</author>
        </authors>
        <title>BLEU: A method for automatic evaluation of machine translation.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>31</id>
        <authors>
          <author>Andreas Stolcke</author>
        </authors>
        <title>Srilm an extensible language modeling toolkit.</title>
        <publication>In Proceedings of the International Conference on Spoken Language Processing.</publication>
        <pages>None</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>32</id>
        <authors>
          <author>Ben Taskar</author>
          <author>Simon Lacoste-Julien</author>
          <author>Dan Klein</author>
        </authors>
        <title>A discriminative matching approach to word alignment.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>33</id>
        <authors>
          <author>Dekai Wu</author>
        </authors>
        <title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
        <publication>None</publication>
        <pages>23--377</pages>
        <date>1997</date>
      </reference>
      <reference>
        <id>34</id>
        <authors>
          <author>Hao Zhang</author>
          <author>Daniel Gildea</author>
        </authors>
        <title>Stochastic lexicalized inversion transduction grammar for alignment.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>35</id>
        <authors>
          <author>Hao Zhang</author>
          <author>Daniel Gildea</author>
        </authors>
        <title>Efficient search for inversion transduction grammar.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>36</id>
        <authors>
          <author>Hao Zhang</author>
          <author>Chris Quirk</author>
          <author>Robert C Moore</author>
          <author>Daniel Gildea</author>
        </authors>
        <title>Bayesian learning of noncompositional phrases with synchronous parsing.</title>
        <publication>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</publication>
        <pages>None</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>37</id>
        <authors>
          <author>I Dan Melamed</author>
        </authors>
        <title>Models of translational equivalence among words. Computational Linguistics.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2000</date>
      </reference>
      <reference>
        <id>38</id>
        <authors>
          <author>Robert Moore</author>
          <author>Chris Quirk</author>
        </authors>
        <title>Faster beam-search decoding for phrasal statistical machine translation.</title>
        <publication>In Proceedings of MT Summit XI.</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>39</id>
        <authors>
          <author>Robert C Moore</author>
        </authors>
        <title>A discriminative framework for bilingual word alignment.</title>
        <publication>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</publication>
        <pages>None</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>40</id>
        <authors>
          <author>Hermann Ney</author>
          <author>Stephan Vogel</author>
        </authors>
        <title>HMM-based word alignment in statistical translation.</title>
        <publication>In Proceedings of the Conference on Computational linguistics.</publication>
        <pages>None</pages>
        <date>1996</date>
      </reference>
      <reference>
        <id>41</id>
        <authors>
          <author>Franz Josef Och</author>
          <author>Hermann Ney</author>
        </authors>
        <title>A systematic comparison of various statistical alignment models.</title>
        <publication>None</publication>
        <pages>29--19</pages>
        <date>2003</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Ayan and Dorr, 2006</string>
        <sentence_id>30978</sentence_id>
        <char_offset>178</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Ayan et al., 2005</string>
        <sentence_id>30807</sentence_id>
        <char_offset>101</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>2</reference_id>
        <string>Birch et al., 2006</string>
        <sentence_id>30961</sentence_id>
        <char_offset>163</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>Blunsom et al., 2009</string>
        <sentence_id>30961</sentence_id>
        <char_offset>93</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>4</reference_id>
        <string>Charniak and Caraballo, 1998</string>
        <sentence_id>30929</sentence_id>
        <char_offset>14</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>5</reference_id>
        <string>Cherry and Lin, 2006</string>
        <sentence_id>30968</sentence_id>
        <char_offset>134</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>6</reference_id>
        <string>Cherry and Lin, 2007</string>
        <sentence_id>30832</sentence_id>
        <char_offset>315</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>6</reference_id>
        <string>Cherry and Lin, 2007</string>
        <sentence_id>30961</sentence_id>
        <char_offset>183</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>6</reference_id>
        <string>Cherry and Lin, 2007</string>
        <sentence_id>30967</sentence_id>
        <char_offset>177</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>7</reference_id>
        <string>Chiang et al., 2008</string>
        <sentence_id>30870</sentence_id>
        <char_offset>120</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>8</reference_id>
        <string>Chiang, 2007</string>
        <sentence_id>30770</sentence_id>
        <char_offset>245</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>8</reference_id>
        <string>Chiang, 2007</string>
        <sentence_id>30918</sentence_id>
        <char_offset>171</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>8</reference_id>
        <string>Chiang, 2007</string>
        <sentence_id>30938</sentence_id>
        <char_offset>97</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>8</reference_id>
        <string>Chiang, 2007</string>
        <sentence_id>31004</sentence_id>
        <char_offset>56</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>9</reference_id>
        <string>Crammer and Singer (2003)</string>
        <sentence_id>30869</sentence_id>
        <char_offset>124</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>10</reference_id>
        <string>DeNero and Klein, 2007</string>
        <sentence_id>30807</sentence_id>
        <char_offset>120</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>10</reference_id>
        <string>DeNero and Klein, 2007</string>
        <sentence_id>30979</sentence_id>
        <char_offset>159</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>10</reference_id>
        <string>DeNero and Klein (2007)</string>
        <sentence_id>31026</sentence_id>
        <char_offset>222</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>11</reference_id>
        <string>DeNero and Klein, 2008</string>
        <sentence_id>30836</sentence_id>
        <char_offset>88</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>12</reference_id>
        <string>DeNero et al., 2006</string>
        <sentence_id>30961</sentence_id>
        <char_offset>142</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>13</reference_id>
        <string>DeNero et al., 2008</string>
        <sentence_id>30961</sentence_id>
        <char_offset>72</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>14</reference_id>
        <string>Deng and Zhou (2009)</string>
        <sentence_id>30972</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>15</reference_id>
        <string>Fraser and Marcu, 2006</string>
        <sentence_id>30966</sentence_id>
        <char_offset>129</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>16</reference_id>
        <string>Fraser and Marcu, 2007</string>
        <sentence_id>30966</sentence_id>
        <char_offset>153</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>17</reference_id>
        <string>Galley et al., 2006</string>
        <sentence_id>30770</sentence_id>
        <char_offset>290</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>18</reference_id>
        <string>Goodman, 1996</string>
        <sentence_id>30932</sentence_id>
        <char_offset>69</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30807</sentence_id>
        <char_offset>144</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30837</sentence_id>
        <char_offset>149</char_offset>
      </citation>
      <citation>
        <id>28</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30870</sentence_id>
        <char_offset>73</char_offset>
      </citation>
      <citation>
        <id>29</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30926</sentence_id>
        <char_offset>207</char_offset>
      </citation>
      <citation>
        <id>30</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30968</sentence_id>
        <char_offset>174</char_offset>
      </citation>
      <citation>
        <id>31</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al., 2009</string>
        <sentence_id>30979</sentence_id>
        <char_offset>183</char_offset>
      </citation>
      <citation>
        <id>32</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al. (2009)</string>
        <sentence_id>30854</sentence_id>
        <char_offset>109</char_offset>
      </citation>
      <citation>
        <id>33</id>
        <reference_id>19</reference_id>
        <string>Haghighi et al. (2009)</string>
        <sentence_id>31029</sentence_id>
        <char_offset>76</char_offset>
      </citation>
      <citation>
        <id>34</id>
        <reference_id>20</reference_id>
        <string>Huang and Chiang, 2007</string>
        <sentence_id>30938</sentence_id>
        <char_offset>87</char_offset>
      </citation>
      <citation>
        <id>35</id>
        <reference_id>21</reference_id>
        <string>K&#228;&#228;ri&#228;inen (2009)</string>
        <sentence_id>30970</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>36</id>
        <reference_id>22</reference_id>
        <string>Klein and Manning, 2003</string>
        <sentence_id>30943</sentence_id>
        <char_offset>29</char_offset>
      </citation>
      <citation>
        <id>37</id>
        <reference_id>23</reference_id>
        <string>Koehn and Haddow, 2009</string>
        <sentence_id>30938</sentence_id>
        <char_offset>111</char_offset>
      </citation>
      <citation>
        <id>38</id>
        <reference_id>24</reference_id>
        <string>Koehn et al., 2003</string>
        <sentence_id>30727</sentence_id>
        <char_offset>84</char_offset>
      </citation>
      <citation>
        <id>39</id>
        <reference_id>24</reference_id>
        <string>Koehn et al., 2003</string>
        <sentence_id>30770</sentence_id>
        <char_offset>208</char_offset>
      </citation>
      <citation>
        <id>40</id>
        <reference_id>24</reference_id>
        <string>Koehn et al., 2003</string>
        <sentence_id>30852</sentence_id>
        <char_offset>142</char_offset>
      </citation>
      <citation>
        <id>41</id>
        <reference_id>24</reference_id>
        <string>Koehn et al., 2003</string>
        <sentence_id>31023</sentence_id>
        <char_offset>30</char_offset>
      </citation>
      <citation>
        <id>42</id>
        <reference_id>25</reference_id>
        <string>Lacoste-Julien et al., 2006</string>
        <sentence_id>30965</sentence_id>
        <char_offset>144</char_offset>
      </citation>
      <citation>
        <id>43</id>
        <reference_id>26</reference_id>
        <string>Li et al., 2009</string>
        <sentence_id>30769</sentence_id>
        <char_offset>273</char_offset>
      </citation>
      <citation>
        <id>44</id>
        <reference_id>26</reference_id>
        <string>Li et al., 2009</string>
        <sentence_id>31004</sentence_id>
        <char_offset>8</char_offset>
      </citation>
      <citation>
        <id>45</id>
        <reference_id>27</reference_id>
        <string>Liang et al., 2006</string>
        <sentence_id>30849</sentence_id>
        <char_offset>104</char_offset>
      </citation>
      <citation>
        <id>46</id>
        <reference_id>27</reference_id>
        <string>Liang et al., 2006</string>
        <sentence_id>31026</sentence_id>
        <char_offset>83</char_offset>
      </citation>
      <citation>
        <id>47</id>
        <reference_id>28</reference_id>
        <string>Lopez, 2007</string>
        <sentence_id>31004</sentence_id>
        <char_offset>126</char_offset>
      </citation>
      <citation>
        <id>48</id>
        <reference_id>29</reference_id>
        <string>Marcu and Wong, 2002</string>
        <sentence_id>30960</sentence_id>
        <char_offset>146</char_offset>
      </citation>
      <citation>
        <id>49</id>
        <reference_id>30</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>31012</sentence_id>
        <char_offset>140</char_offset>
      </citation>
      <citation>
        <id>50</id>
        <reference_id>31</reference_id>
        <string>Stolcke, 2002</string>
        <sentence_id>30985</sentence_id>
        <char_offset>102</char_offset>
      </citation>
      <citation>
        <id>51</id>
        <reference_id>32</reference_id>
        <string>Taskar et al., 2005</string>
        <sentence_id>30965</sentence_id>
        <char_offset>110</char_offset>
      </citation>
      <citation>
        <id>52</id>
        <reference_id>33</reference_id>
        <string>Wu, 1997</string>
        <sentence_id>30744</sentence_id>
        <char_offset>160</char_offset>
      </citation>
      <citation>
        <id>53</id>
        <reference_id>33</reference_id>
        <string>Wu, 1997</string>
        <sentence_id>30836</sentence_id>
        <char_offset>78</char_offset>
      </citation>
      <citation>
        <id>54</id>
        <reference_id>33</reference_id>
        <string>Wu, 1997</string>
        <sentence_id>30967</sentence_id>
        <char_offset>143</char_offset>
      </citation>
      <citation>
        <id>55</id>
        <reference_id>34</reference_id>
        <string>Zhang and Gildea, 2005</string>
        <sentence_id>30967</sentence_id>
        <char_offset>153</char_offset>
      </citation>
      <citation>
        <id>56</id>
        <reference_id>35</reference_id>
        <string>Zhang and Gildea, 2006</string>
        <sentence_id>30926</sentence_id>
        <char_offset>183</char_offset>
      </citation>
      <citation>
        <id>57</id>
        <reference_id>36</reference_id>
        <string>Zhang et al., 2008</string>
        <sentence_id>30832</sentence_id>
        <char_offset>337</char_offset>
      </citation>
      <citation>
        <id>58</id>
        <reference_id>36</reference_id>
        <string>Zhang et al., 2008</string>
        <sentence_id>30961</sentence_id>
        <char_offset>205</char_offset>
      </citation>
      <citation>
        <id>59</id>
        <reference_id>36</reference_id>
        <string>Zhang et al., 2008</string>
        <sentence_id>30967</sentence_id>
        <char_offset>199</char_offset>
      </citation>
      <citation>
        <id>60</id>
        <reference_id>37</reference_id>
        <string>Melamed, 2000</string>
        <sentence_id>30965</sentence_id>
        <char_offset>95</char_offset>
      </citation>
      <citation>
        <id>61</id>
        <reference_id>38</reference_id>
        <string>Moore and Quirk, 2007</string>
        <sentence_id>30938</sentence_id>
        <char_offset>135</char_offset>
      </citation>
      <citation>
        <id>62</id>
        <reference_id>39</reference_id>
        <string>Moore, 2005</string>
        <sentence_id>30965</sentence_id>
        <char_offset>131</char_offset>
      </citation>
      <citation>
        <id>63</id>
        <reference_id>40</reference_id>
        <string>Ney and Vogel, 1996</string>
        <sentence_id>30925</sentence_id>
        <char_offset>17</char_offset>
      </citation>
      <citation>
        <id>64</id>
        <reference_id>40</reference_id>
        <string>Ney and Vogel, 1996</string>
        <sentence_id>31025</sentence_id>
        <char_offset>50</char_offset>
      </citation>
      <citation>
        <id>65</id>
        <reference_id>41</reference_id>
        <string>Och and Ney, 2003</string>
        <sentence_id>31020</sentence_id>
        <char_offset>19</char_offset>
      </citation>
    </citations>
  </content>
</document>
