<PAPER>
  <FILENO/>
  <TITLE>Combining Bilingual and Comparable Corpora for Low Resource Machine Translation</TITLE>
  <AUTHORS>
    <AUTHOR>Ann Irvine</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-53860">Statistical machine translation (SMT) performance suffers when models are trained on only small amounts of parallel data.</A-S>
    <A-S ID="S-53861">The learned models typically have both low accuracy (incorrect translations and feature scores) and low coverage (high out-of-vocabulary rates).</A-S>
    <A-S ID="S-53862">In this work, we use an additional data resource, comparable corpora, to improve both.</A-S>
    <A-S ID="S-53863">Beginning with a small bitext and corresponding phrase-based SMT model, we improve coverage by using bilingual lexicon induction techniques to learn new translations from comparable corpora.</A-S>
    <A-S ID="S-53864">Then, we supplement the model&#8217;s feature space with translation scores estimated over comparable corpora in order to improve accuracy.</A-S>
    <A-S ID="S-53865">We observe improvements between 0.5 and 1.7 BLEU translating Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu into English.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-53866">Standard statistical machine translation (SMT) models (Koehn et al., 2003) are trained using large, sentence-aligned parallel corpora.</S>
        <S ID="S-53867">Unfortunately, parallel corpora are not always available in large enough quantities to train robust models (<REF ID="R-16" RPTR="23">Kolachina et al., 2012</REF>).</S>
        <S ID="S-53868">In this work, we consider the situation in which we have access to only a small amount of bitext for a given low resource language pair, and we wish to supplement an SMT model with additional translations and features estimated using comparable corpora in the source and target languages.</S>
        <S ID="S-53869">Assuming access to a small amount</S>
      </P>
      <P>
        <S ID="S-53870">&#8727; Performed while faculty at Johns Hopkins University</S>
      </P>
      <P>
        <S ID="S-53871">of parallel text is realistic, especially considering the recent success of crowdsourcing translations (<REF ID="R-28" RPTR="35">Zaidan and Callison-Burch, 2011</REF>; <REF ID="R-01" RPTR="1">Ambati, 2011</REF>; <REF ID="R-30" RPTR="45">Post et al., 2012</REF>).</S>
        <S ID="S-53872">We frame the shortcomings of SMT models trained on limited amounts of parallel text 1 in terms of accuracy and coverage.</S>
        <S ID="S-53873">In this context, coverage refers to the number of words and phrases that a model has any knowledge of at all, and it is low when the training text is small, which results in a high out-of-vocabulary (OOV) rate.</S>
        <S ID="S-53874">Accuracy refers to the correctness of the translation pairs and their corresponding probability features that make up the translation model.</S>
        <S ID="S-53875">Because the quality of unsupervised automatic word alignments correlates with the amount of available parallel text and alignment errors result in errors in extracted translation pairs, accuracy tends to be low in low resource settings.</S>
        <S ID="S-53876">Additionally, estimating translation probabilities 2 over sparse training sets results in inaccurate feature scores.</S>
      </P>
      <P>
        <S ID="S-53877">Given these deficiencies, we begin with a baseline SMT model learned from a small parallel corpus and supplement the model to improve its accuracy and coverage.</S>
        <S ID="S-53878">We apply techniques presented in prior work that use comparable corpora to estimate similarities between word and phrases.</S>
        <S ID="S-53879">In particular, we build on prior work in bilingual lexicon induction in order to predict translations for OOV words, improving coverage.</S>
        <S ID="S-53880">We then use the same corpora to estimate additional translation feature scores, improving model accuracy.</S>
        <S ID="S-53881">We see improvements in translation quality between 0.5</S>
      </P>
      <P>
        <S ID="S-53882">1 We consider low resource settings to be those with parallel datasets of fewer than 1 million words.</S>
        <S ID="S-53883">Most standard MT datasets contain tens or hundreds of millions of words.</S>
        <S ID="S-53884">2 Estimating reordering probabilities over sparse data also</S>
      </P>
      <P>
        <S ID="S-53885">leads to model inaccuracies; we do not tackle that here.</S>
      </P>
      <P>
        <S ID="S-53886">and 1.7 BLEU points translating the following low resource languages into English: Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Previous Work</HEADER>
      <P>
        <S ID="S-53887">Prior work shows that a variety of signals, including distributional, temporal, topic, and string similarity, may inform bilingual lexicon induction (<REF ID="R-31" RPTR="46">Rapp, 1995</REF>; <REF ID="R-07" RPTR="8">Fung and Yee, 1998</REF>; Rapp, 1999; <REF ID="R-23" RPTR="30">Schafer and Yarowsky, 2002</REF>; <REF ID="R-13" RPTR="21">Koehn and Knight, 2002</REF>; <REF ID="R-19" RPTR="26">Monz and Dorr, 2005</REF>; <REF ID="R-09" RPTR="10">Huang et al., 2005</REF>; <REF ID="R-24" RPTR="31">Schafer, 2006</REF>; <REF ID="R-11" RPTR="16">Klementiev and Roth, 2006</REF>; <REF ID="R-08" RPTR="9">Haghighi et al., 2008</REF>; <REF ID="R-18" RPTR="25">Mimno et al., 2009</REF>; <REF ID="R-17" RPTR="24">Mausam et al., 2010</REF>).</S>
        <S ID="S-53888">Other work has used decipherment techniques to learn translations from monolingual and comparable data (<REF ID="R-22" RPTR="29">Ravi and Knight, 2011</REF>; <REF ID="R-06" RPTR="7">Dou and Knight, 2012</REF>; <REF ID="R-21" RPTR="28">Nuhn et al., 2012</REF>).</S>
        <S ID="S-53889"><REF ID="R-05" RPTR="5">Daum&#233; and Jagarlamudi (2011)</REF> use contextual and string similarity to mine translations for OOV words in a high resource language domain adaptation for a machine translation setting.</S>
        <S ID="S-53890">Unlike most other prior work on bilingual lexicon induction, <REF ID="R-05" RPTR="6">Daum&#233; and Jagarlamudi (2011)</REF> use the translations in end-to-end SMT.</S>
      </P>
      <P>
        <S ID="S-53891">More recently, <REF ID="R-10" RPTR="11">Irvine and Callison-Burch (2013)</REF> combine a variety of the techniques for estimating word pair similarity using source and target language comparable corpora.</S>
        <S ID="S-53892">That work shows that only a small amount of supervision is needed to learn how to effectively combine similarity features into a single model for doing bilingual lexicon induction.</S>
        <S ID="S-53893">In this work, because we assume access to a small amount of bilingual data, it is natural to take such a supervised approach to inducing new translations, and we directly apply that of <REF ID="R-10" RPTR="12">Irvine and Callison-Burch (2013)</REF>.</S>
        <S ID="S-53894"><REF ID="R-12" RPTR="17">Klementiev et al. (2012)</REF> use comparable corpora to score an existing Spanish-English phrase table extracted from the Europarl corpus.</S>
        <S ID="S-53895">In this work, we directly apply their technique for scoring an existing phrase table.</S>
        <S ID="S-53896">However, unlike that work, our initial phrase tables are estimated from small parallel corpora for genuine low resource languages.</S>
        <S ID="S-53897">Additionally, we include new translations discovered in comparable corpora.</S>
      </P>
      <P>
        <S ID="S-53898">Other prior work has mined supplemental parallel data from comparable corpora (<REF ID="R-20" RPTR="27">Munteanu and Marcu, 2006</REF>; <REF ID="R-00" RPTR="0">AbduI-Rauf and Schwenk, 2009</REF>; <REF ID="R-25" RPTR="32">Smith et al., 2010</REF>; <REF ID="R-27" RPTR="34">Uszkoreit et al., 2010</REF>; <REF ID="R-26" RPTR="33">Smith et al., 2013</REF>).</S>
        <S ID="S-53899">Such efforts are orthogonal and complementary to the approach that we take.</S>
      </P>
      <P>
        <S ID="S-53900">(2012): thousands of words in the source language parallel sentences and dictionaries, and percent of development set word types (unique word tokens) and word tokens that are OOV (do not appear in either section of the training data).</S>
      </P>
      <P>
        <S ID="S-53901">Wikipedia text, by language.</S>
      </P>
      <P>
        <S ID="S-53902">3 Using Comparable Corpora to Improve Accuracy and Coverage</S>
      </P>
      <P>
        <S ID="S-53903">After describing our bilingual and comparable corpora, we briefly describe the techniques proposed by <REF ID="R-10" RPTR="13">Irvine and Callison-Burch (2013)</REF> and <REF ID="R-12" RPTR="18">Klementiev et al. (2012)</REF>.</S>
        <S ID="S-53904">The contribution of this paper is the application and combination of these techniques in truly low resource translation conditions.</S>
      </P>
      <P>
        <S ID="S-53905">3.1 Datasets</S>
      </P>
      <P>
        <S ID="S-53906"><REF ID="R-30" RPTR="37">Post et al. (2012)</REF> used Mechanical Turk to collect small parallel corpora for the following Indian languages and English: Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu.</S>
        <S ID="S-53907">They collected both parallel sentence pairs and a dictionary of word translations.</S>
        <S ID="S-53908">3 We use all six datasets, which provide real low resource data conditions for six truly low resource language pairs.</S>
        <S ID="S-53909">Table 1 shows statistics about the datasets.</S>
        <S ID="S-53910">Table 2 lists the amount of comparable data that we use for each language.</S>
        <S ID="S-53911">Following both <REF ID="R-12" RPTR="19">Klementiev et al. (2012)</REF> and Irvine and Callison- Burch (2013), we use time-stamped web crawls as well as interlingually linked Wikipedia documents.</S>
        <S ID="S-53912">We use the time-stamped data to estimate temporal similarity and the interlingual Wikipedia links, which indicate documents about the same topic written in different languages, to estimate</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 No dictionary was provided for Hindi.</HEADER>
      <P>
        <S ID="S-53939">topic similarity.</S>
        <S ID="S-53940">We use both datasets in combination with a dictionary derived from the small parallel corpora to estimate contextual similarity.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.2 Improving Coverage</HEADER>
        <P>
          <S ID="S-53913">In order to improve the coverage of our low resource translation models, we use bilingual lexicon induction techniques to learn translations for words which appear in our test sets but not in our training data (OOVs).</S>
          <S ID="S-53914">Bilingual lexicon induction is the task of inducing pairs of words that are translations of one another from monolingual or comparable corpora.</S>
          <S ID="S-53915"><REF ID="R-10" RPTR="14">Irvine and Callison-Burch (2013)</REF> use a diverse set of features estimated over comparable corpora and a small set of known translations as supervision for training a discriminative classifier, which makes predictions (translation or not a translation) on test set words paired with all possible translations.</S>
          <S ID="S-53916">Possible translations are taken from the set of all target words appearing in the comparable corpora.</S>
          <S ID="S-53917">Candidates are ranked according to their classification scores.</S>
          <S ID="S-53918">They achieve very good performance on the induction task itself compared with an unsupervised baseline that aggregates the same similarity features uniformly.</S>
          <S ID="S-53919">In our setting, we have access to a small parallel corpus, which makes such a supervised approach to bilingual lexicon induction a natural choice.</S>
          <S ID="S-53920">We use the framework described in <REF ID="R-10" RPTR="15">Irvine and Callison-Burch (2013)</REF> directly, and further details may be found there.</S>
          <S ID="S-53921">In particular, we use the same feature set, which includes the temporal, contextual, topic, orthographic, and frequency similarity between a candidate translation pair.</S>
          <S ID="S-53922">We derive translations to serve as positive supervision from our automatically aligned parallel text 4 and, like the prior work, use random word pairs as negative supervision.</S>
          <S ID="S-53923">Figure 1 shows some examples of Bengali words, their correct translations, and the top-3 translations that this framework induces.</S>
          <S ID="S-53924">In our initial experiments, we add the highest ranked English candidate translation for each source language OOV to our phrase tables.</S>
          <S ID="S-53925">Because all of the OOVs appear at least once in our comparable corpora, 5 we are able to mine translations for all of them.</S>
          <S ID="S-53926">Adding these translations by definition improves the coverage of our MT models.</S>
          <S ID="S-53927">Then, in additional sets of experiments, we</S>
        </P>
        <P>
          <S ID="S-53928">4 GIZA++ intersection alignments over all training data.</S>
          <S ID="S-53929">5 The <REF ID="R-30" RPTR="38">Post et al. (2012)</REF> datasets are crowdsourced English</S>
        </P>
        <P>
          <S ID="S-53930">translations of source Wikipedia text.</S>
          <S ID="S-53931">Using Wikipedia as comparable corpora, we observe all OOVs at least once.</S>
        </P>
        <P>
          <S ID="S-53932">Source Induced Translations Correct Translation</S>
        </P>
        <P>
          <S ID="S-53933">ranked induced translations, and their correct translations.</S>
        </P>
        <P>
          <S ID="S-53934">also induce translations for source language words which are low frequency in the training data and supplement our SMT models with top-k translations, not just the highest ranked.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 Improving Accuracy</HEADER>
        <P>
          <S ID="S-53935">In order to improve the accuracy of our models, we use comparable corpora to estimate additional features over the translation pairs in our phrase tables and include those features in tuning and decoding.</S>
          <S ID="S-53936">This approach follows that of <REF ID="R-12" RPTR="20">Klementiev et al. (2012)</REF>.</S>
          <S ID="S-53937">We compute both phrasal features and lexically smoothed features (using word alignments, like the Moses lexical translation probabilities) for all of the following except orthographic similarity, for which we only use lexically smoothed features, 6 resulting in nine additional features: temporal similarity based on timestamped web crawls, contextual similarity based on web crawls and Wikipedia (separately), orthographic similarity using normalized edit distance, and topic similarity based on inter-lingually linked Wikipedia pages.</S>
          <S ID="S-53938">Our hope is that by adding a diverse set of similarity features to the phrase tables, our models will better distinguish between good and bad translation pairs, improving accuracy.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Experiments</HEADER>
      <P>
        <S ID="S-54095"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Experimental setup</HEADER>
        <P>
          <S ID="S-53941">We use the data splits given by <REF ID="R-30" RPTR="39">Post et al. (2012)</REF> and, following that work, include the dictionaries in the training data and report results on the devtest set using case-insensitive BLEU and four references.</S>
          <S ID="S-53942">We use the Moses phrase-based MT framework (<REF ID="R-15" RPTR="22">Koehn et al., 2007</REF>).</S>
          <S ID="S-53943">For each language, we extract a phrase table with a phrase limit of seven.</S>
          <S ID="S-53944">In order to make our results comparable to those of <REF ID="R-30" RPTR="40">Post et al. (2012)</REF>, we follow that work and use</S>
        </P>
        <P>
          <S ID="S-53945">6 Because the words within a phrase pair are often reordered, phrase-level orthographic similarity is unreliable.</S>
        </P>
        <P>
          <S ID="S-53946">the English side of the training data to train a language model.</S>
          <S ID="S-53947">Using a language model trained on a larger corpus (e.g. the English side of our comparable corpora) may yield better results, but such an improvement is orthogonal to the focus of this work.</S>
          <S ID="S-53948">Throughout our experiments, we use the batch version of MIRA (<REF ID="R-02" RPTR="2">Cherry and Foster, 2012</REF>) for tuning the feature set.</S>
          <S ID="S-53949">7 We rerun tuning for all experimental conditions and report results averaged over three tuning runs (<REF ID="R-04" RPTR="4">Clark et al., 2011</REF>).</S>
        </P>
        <P>
          <S ID="S-53950">Our baseline uses the bilingually extracted phrase pairs and standard translation probability features.</S>
          <S ID="S-53951">We supplement it with the top ranked translation for each OOV to improve coverage (+ OOV Trans) and with additional features to improve accuracy (+Features).</S>
          <S ID="S-53952">In Section 4.2, we make each modification separately and then together.</S>
          <S ID="S-53953">Then we present additional experiments where we induce translations for low frequency words, in addition to OOVs (4.3), append top-k translations (4.4), vary the amount of training data used to induce the baseline model (4.5), and vary the amount of comparable corpora used to estimate features and induce translations (4.6).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Results</HEADER>
        <P>
          <S ID="S-53954">Before presenting end-to-end MT results, we examine the performance of the supervised bilingual lexicon induction technique that we use for translating OOVs.</S>
          <S ID="S-53955">In Table 3, top-1 accuracy is the percent of source language words in a held out portion of the training data 8 for which the highest ranked English candidate is a correct translation.</S>
          <S ID="S-53956">9 Performance is lowest for Tamil and highest for Hindi.</S>
          <S ID="S-53957">For all languages, top-10 accuracy is much higher than the top-1 accuracy.</S>
          <S ID="S-53958">In Section 4.4, we explore</S>
        </P>
        <P>
          <S ID="S-53959">7 We experimented with MERT and PRO as well but saw</S>
        </P>
        <P>
          <S ID="S-53960">consistently better baseline performance using batch MIRA.</S>
          <S ID="S-53961">8 Described in Section 3.2.</S>
          <S ID="S-53962">We retrain with all training</S>
        </P>
        <P>
          <S ID="S-53963">data for MT experiments.</S>
          <S ID="S-53964">9 <REF ID="R-30" RPTR="41">Post et al. (2012)</REF> gathered up to six translations for each</S>
        </P>
        <P>
          <S ID="S-53965">source word, so some have multiple correct translations</S>
        </P>
        <P>
          <S ID="S-53966">appending the top-k translations for OOV words to our model instead of just the top-1.</S>
        </P>
        <P>
          <S ID="S-53967">Table 4 shows our results adding OOV translations, adding features, and then both.</S>
          <S ID="S-53968">Additional translation features alone, which improve our models&#8217; accuracy, increase BLEU scores between 0.18 (Bengali) and 0.60 (Malayalam) points.</S>
          <S ID="S-53969">Adding OOV translations makes a big difference for some languages, such as Bengali and Urdu, and almost no difference for others, like Malayalam and Tamil.</S>
          <S ID="S-53970">The OOV rate (Table 1) is low in the Malayalam dataset and high in the Tamil dataset.</S>
          <S ID="S-53971">However, as Table 3 shows, the translation induction accuracy is low for both.</S>
          <S ID="S-53972">Since few of the supplemental translations are correct, we don&#8217;t observe BLEU gains.</S>
          <S ID="S-53973">In contrast, induction accuracies for the other languages are higher, OOV rates are substantial, and we do observe moderate BLEU improvements by supplementing phrase tables with OOV translations.</S>
          <S ID="S-53974">In order to compute the potential BLEU gains that we could realize by correctly translating all OOV words (achieving 100% accuracy in Table 3), we perform an oracle experiment.</S>
          <S ID="S-53975">We use automatic word alignments over the test sets to identify correct translations and append those to the phrase tables.</S>
          <S ID="S-53976">10 The results, in Table 4, show possible gains between 4.3 (Telugu and Bengali) and 0 (Malayalam) BLEU points above the baseline.</S>
          <S ID="S-53977">Not surprisingly, the possible gain for Malayalam, which has a very low OOV rate, is very low.</S>
          <S ID="S-53978">Our +OOV Trans.</S>
          <S ID="S-53979">model gains between 0% (Tamil) and 38% (Urdu) of the potential improvement.</S>
        </P>
        <P>
          <S ID="S-53980">Using comparable corpora to improve both accuracy (+Features) and coverage (+OOV Trans.</S>
          <S ID="S-53981">) results in translations that are better than applying either technique alone for five of the six languages.</S>
          <S ID="S-53982">BLEU gains range from 0.48 (Bengali) to 1.39 (Urdu).</S>
          <S ID="S-53983">We attribute the particularly good Urdu performance to the relatively large comparable corpora (Table 2).</S>
          <S ID="S-53984">As a result, we have already begun to expand our web crawls for all languages.</S>
          <S ID="S-53985">In Section 4.6, we present results varying the amount of Urdu-English comparable corpora used to induce translations and estimate additional features.</S>
          <S ID="S-53986">Table 4 also shows the Hiero (<REF ID="R-03" RPTR="3">Chiang, 2005</REF>) and SAMT (<REF ID="R-29" RPTR="36">Zollmann and Venugopal, 2006</REF>) results that <REF ID="R-30" RPTR="42">Post et al. (2012)</REF> report for the same</S>
        </P>
        <P>
          <S ID="S-53987">10 Because the automatic word alignments are noisy, this</S>
        </P>
        <P>
          <S ID="S-53988">oracle is conservative.</S>
        </P>
        <P>
          <S ID="S-53989">datasets.</S>
          <S ID="S-53990">Both syntax-based models outperform the phrase-based MT baseline for each language except Urdu, where the phrase-based model outperforms Hiero.</S>
          <S ID="S-53991">Here, we extend a phrase-based rather than a syntax-based system because it is simpler.</S>
          <S ID="S-53992">However, our improvements may also apply to syntactic models (future work).</S>
          <S ID="S-53993">Because our efforts have focused on the accuracy and coverage of translation pairs and have not addressed reordering or syntax, we expect that combining them with an SAMT grammar will result in state-of-the art performance.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.3 Translations of Low Frequency Words</HEADER>
        <P>
          <S ID="S-53994">Given the positive results in Section 4.2, we hypothesize that mining translations for low frequency words, in addition to OOV words, may improve accuracy.</S>
          <S ID="S-53995">For source words which only appear a few times in the parallel training text, the bilingually extracted translations in the standard phrase table are likely to be inaccurate.</S>
          <S ID="S-53996">Therefore, we perform additional experiments varying the minimum source word training data frequency for which we induce additional translations.</S>
          <S ID="S-53997">That is, if freq(w src ) &#8804; M, we induce a new translation for it and include that translation in our phrase table.</S>
          <S ID="S-53998">Note that in the results presented in Table 4, M = 0.</S>
          <S ID="S-53999">In these experiments, we include our additional phrase table features estimated over comparable corpora and hope that these scores will assist the model in choosing among multiple translation options for low frequency words, one or more of which is extracted bilingually and one of which is induced using comparable corpora.</S>
          <S ID="S-54000">Table 5 shows the results when we vary M.</S>
          <S ID="S-54001">As before, we average BLEU scores over three tuning runs.</S>
        </P>
        <P>
          <S ID="S-54002">In general, modest BLEU score gains are made as we supplement our phrase-based models with induced translations of low frequency words.</S>
          <S ID="S-54003">The highest performance is achieved when M is between 5 and 50, depending on language.</S>
          <S ID="S-54004">The</S>
        </P>
        <P>
          <S ID="S-54005">of source words for which new translations are induced and included in the phrase-based model.</S>
          <S ID="S-54006">In all cases, the top-1 induced translation is added to the phrase table and features estimated over comparable corpora are included (i.e. +Feats &amp; Trans model).</S>
        </P>
        <P>
          <S ID="S-54007">largest gains are 0.5 and 0.3 BLEU points for Bengali and Urdu, respectively, at M = 25.</S>
          <S ID="S-54008">This is not surprising; we also saw the largest relative gains for those two languages when we added OOV translations to our baseline model.</S>
          <S ID="S-54009">With the addition of low frequency translations, our highest performing Urdu model achieves a BLEU score that is 1.7 points higher than the baseline.</S>
          <S ID="S-54010">In different data conditions, inducing translations for low frequency words may result in better or worse performance.</S>
          <S ID="S-54011">For example, the size of the training set impacts the quality of automatic word alignments, which in turn impacts the reliability of translations of low frequency words.</S>
          <S ID="S-54012">However, the experiments detailed here suggest that including induced translations of low frequency words will not hurt performance and may improve it.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.4 Appending Top-K Translations</HEADER>
        <P>
          <S ID="S-54013">So far we have only added the top-1 induced translation for OOV and low frequency source words to our phrase-based model.</S>
          <S ID="S-54014">However, the bilingual lexicon induction results in Table 3 show that accuracies in the top-10 ranked translations are, on average, nearly twice the top-1 accuracies.</S>
          <S ID="S-54015">Here, we explore adding the top-k induced translations.</S>
          <S ID="S-54016">We hope that our additional phrase table features estimated over comparable corpora will enable the</S>
        </P>
        <P>
          <S ID="S-54017">decoder to correctly choose between the k translation options.</S>
          <S ID="S-54018">We induce translations for OOV words only (M = 0) and include all comparable corpora features.</S>
        </P>
        <P>
          <S ID="S-54019">Table 6 shows performance as we append the top-k ranked translations for each OOV word and vary k.</S>
          <S ID="S-54020">With the exception of Bengali, using a k greater than 1 does not increase performance.</S>
          <S ID="S-54021">In the case of Bengali, and additional 0.2 BLEU is observed when the top-25 translations are appended.</S>
          <S ID="S-54022">In contrast, we see performance decrease substantially for other languages (0.7 BLEU for Telugu and 0.2 for Urdu) when the top-25 translations are used.</S>
          <S ID="S-54023">Therefore, we conclude that, in general, the models do not sufficiently distinguish good from bad translations when we append more than just the top-1.</S>
          <S ID="S-54024">Although using a k greater than 1 means that more correct translations are in the phrase table, it also increases the number of possible outputs over which the decoder must search.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.5 Learning Curves over Parallel Data</HEADER>
        <P>
          <S ID="S-54025">In the experiments above, we only evaluated our methods for improving the accuracy and coverage of models trained on small amounts of bitext using the full parallel training corpora released by <REF ID="R-30" RPTR="43">Post et al. (2012)</REF>.</S>
          <S ID="S-54026">Here, we apply the same techniques but vary the amount of parallel data in order to generate learning curves.</S>
          <S ID="S-54027">Figure 2 shows learning cures for all six languages.</S>
          <S ID="S-54028">In all cases, results are averaged over three tuning runs.</S>
          <S ID="S-54029">We sample both parallel sentences and dictionary entries.</S>
        </P>
        <P>
          <S ID="S-54030">All six learning curves show similar trends.</S>
          <S ID="S-54031">In all experimental conditions, BLEU performance increases approximately linearly with the log of the amount of training data.</S>
          <S ID="S-54032">Additionally, supplementing the baseline with OOV translations improves performance more than supplementing the baseline with additional phrase table scores based</S>
        </P>
        <P>
          <S ID="S-54033">20.0</S>
        </P>
        <P>
          <S ID="S-54034">5 10 20 50 100 200</S>
        </P>
        <P>
          <S ID="S-54035">Comparable Corpora (Millions of Tokens)</S>
        </P>
        <P>
          <S ID="S-54036">on comparable corpora.</S>
          <S ID="S-54037">However, in most cases, supplementing the baseline with both translations and features improves performance more than either alone.</S>
          <S ID="S-54038">Performance gains are greatest when very little training data is used.</S>
          <S ID="S-54039">The Urdu learning curve shows the most gains as well as the cleanest trends across training data amounts.</S>
          <S ID="S-54040">As before, we attribute this to the relatively large comparable corpora available for Urdu.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.6 Learning Curves over Comparable Corpora</HEADER>
        <P>
          <S ID="S-54041">In our final experiment, we consider the effect of the amount of comparable corpora that we use to estimate features and induce translations.</S>
          <S ID="S-54042">We present learning curves for Urdu-English because we have the largest amount of comparable corpora for that pair.</S>
          <S ID="S-54043">We use the full amount of parallel data to train a baseline model, and then we randomly sample varying amounts of our Urdu- English comparable corpora.</S>
          <S ID="S-54044">Sampling is done separately for the web crawl and Wikipedia comparable corpora.</S>
          <S ID="S-54045">Figure 3 shows the results.</S>
          <S ID="S-54046">As before, results are averaged over three tuning runs.</S>
          <S ID="S-54047">The phrase table features estimated over comparable corpora improve end-to-end MT performance more with increasing amounts of comparable corpora.</S>
          <S ID="S-54048">In contrast, the amount of comparable corpora used to induce OOV translations does not impact the performance of the resulting MT system as much.</S>
          <S ID="S-54049">The difference may be due</S>
        </P>
        <P>
          <S ID="S-54050">0</S>
        </P>
        <P>
          <S ID="S-54051">500 1000 2000 5000 10000 50000</S>
        </P>
        <P>
          <S ID="S-54052">Malayalam</S>
        </P>
        <P>
          <S ID="S-54053">Training Data (a) Telugu</S>
        </P>
        <P>
          <S ID="S-54054">0</S>
        </P>
        <P>
          <S ID="S-54055">500 1000 2000 5000 10000 20000 Tamil</S>
        </P>
        <P>
          <S ID="S-54056">Training Data (b) Bengali</S>
        </P>
        <P>
          <S ID="S-54057">BLEU</S>
        </P>
        <P>
          <S ID="S-54058">0</S>
        </P>
        <P>
          <S ID="S-54059">&#9679;</S>
        </P>
        <P>
          <S ID="S-54060">&#9679;</S>
        </P>
        <P>
          <S ID="S-54061">Baseline +Trans.</S>
          <S ID="S-54062">+Feats.</S>
          <S ID="S-54063">+Trans.</S>
          <S ID="S-54064">&amp; Feats.</S>
        </P>
        <P>
          <S ID="S-54065">&#9679;</S>
        </P>
        <P>
          <S ID="S-54066">&#9679; &#9679; &#9679; &#9679;</S>
        </P>
        <P>
          <S ID="S-54067">&#9679;</S>
        </P>
        <P>
          <S ID="S-54068">&#9679;</S>
        </P>
        <P>
          <S ID="S-54069">&#9679; &#9679;</S>
        </P>
        <P>
          <S ID="S-54070">500 1000 2000 5000 20000 50000 200000 500 1000 2000 5000 10000 50000 Hindi Urdu</S>
        </P>
        <P>
          <S ID="S-54071">Training Data Training Data (c) Malayalam</S>
        </P>
        <P>
          <S ID="S-54072">BLEU</S>
        </P>
        <P>
          <S ID="S-54073">0</S>
        </P>
        <P>
          <S ID="S-54074">&#9679;</S>
        </P>
        <P>
          <S ID="S-54075">&#9679;</S>
        </P>
        <P>
          <S ID="S-54076">Baseline +Trans.</S>
          <S ID="S-54077">+Feats.</S>
          <S ID="S-54078">+Trans.</S>
          <S ID="S-54079">&amp; Feats.</S>
        </P>
        <P>
          <S ID="S-54080">&#9679; &#9679; &#9679;</S>
        </P>
        <P>
          <S ID="S-54081">&#9679;</S>
        </P>
        <P>
          <S ID="S-54082">(d) Tamil</S>
        </P>
        <P>
          <S ID="S-54083">&#9679;</S>
        </P>
        <P>
          <S ID="S-54084">&#9679; &#9679; &#9679;</S>
        </P>
        <P>
          <S ID="S-54085">0</S>
        </P>
        <P>
          <S ID="S-54086">500 1000 2000 5000 10000 20000</S>
        </P>
        <P>
          <S ID="S-54087">Training Data (e) Hindi</S>
        </P>
        <P>
          <S ID="S-54088">0</S>
        </P>
        <P>
          <S ID="S-54089">500 1000 2000 5000 20000 50000</S>
        </P>
        <P>
          <S ID="S-54090">Training Data</S>
        </P>
        <P>
          <S ID="S-54091">(f) Urdu</S>
        </P>
        <P>
          <S ID="S-54092">to the fact that data sparsity is always more of an issue when estimating features over phrase pairs than when estimating features over word pairs because phrases appear less frequently than words in monolingual corpora.</S>
          <S ID="S-54093">Our comparable corpora features are estimated over phrase pairs while translations are only induced for OOV words, not phrases.</S>
          <S ID="S-54094">So, it makes sense that the former would benefit more from larger comparable corpora.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Conclusion</HEADER>
      <P>
        <S ID="S-54096">As <REF ID="R-30" RPTR="44">Post et al. (2012)</REF> showed, it is reasonable to assume a small parallel corpus for training an SMT model even in a low resource setting.</S>
        <S ID="S-54097">We have used comparable corpora to improve the accuracy and coverage of phrase-based MT models built using small bilingual corpora for six low resource languages.</S>
        <S ID="S-54098">We have shown that our methods improve BLEU score performance independently and that their combined impact is nearly additive.</S>
        <S ID="S-54099">Additionally, our results show that adding induced translations of low frequency words improves performance beyond what is achieved by inducing translations for OOVs alone.</S>
        <S ID="S-54100">Finally, our results show that our techniques improve relative performance most when very little parallel training data is available.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-54101">This material is based on research sponsored by DARPA under contract HR0011-09-1-0044 and by the Johns Hopkins University Human Language Technology Center of Excellence.</S>
      <S ID="S-54102">The views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of DARPA or the U.S. Government.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>Sadaf AbduI-Rauf</RAUTHOR>
      <REFTITLE>On the use of comparable corpora to improve smt performance.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Vamshi Ambati</RAUTHOR>
      <REFTITLE>Active Learning for Machine Translation in Scarce Data Scenarios.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Colin Cherry</RAUTHOR>
      <REFTITLE>Batch tuning strategies for statistical machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>David Chiang</RAUTHOR>
      <REFTITLE>A hierarchical phrase-based model for statistical machine translation.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Jonathan H Clark</RAUTHOR>
      <REFTITLE>Better hypothesis testing for statistical machine translation: controlling for optimizer instability.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Hal Daum&#233;</RAUTHOR>
      <REFTITLE>Domain adaptation for machine translation by mining unseen words.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>Qing Dou</RAUTHOR>
      <REFTITLE>Large scale decipherment for out-of-domain machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Pascale Fung</RAUTHOR>
      <REFTITLE>An IR approach for translating new words from nonparallel, comparable texts.</REFTITLE>
      <DATE>1998</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Aria Haghighi</RAUTHOR>
      <REFTITLE>Learning bilingual lexicons from monolingual corpora.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Fei Huang</RAUTHOR>
      <REFTITLE>Mining key phrase translations from web corpora.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Ann Irvine</RAUTHOR>
      <REFTITLE>Supervised bilingual lexicon induction with multiple monolingual signals.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Alexandre Klementiev</RAUTHOR>
      <REFTITLE>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Alex Klementiev</RAUTHOR>
      <REFTITLE>Toward statistical machine translation without parallel corpora.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Learning a translation lexicon from monolingual corpora.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>Franz Joseph Och Koehn</RAUTHOR>
      <REFTITLE>Statistical phrase-based translation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Moses: Open source toolkit for statistical machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>Prasanth Kolachina</RAUTHOR>
      <REFTITLE>Prediction of learning curves in machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>Stephen Soderland Mausam</RAUTHOR>
      <REFTITLE>Panlingual lexical translation via probabilistic inference.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>David Mimno</RAUTHOR>
      <REFTITLE>Polylingual topic models.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>Christof Monz</RAUTHOR>
      <REFTITLE>Iterative translation disambiguation for cross-language information retrieval.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="20">
      <RAUTHOR>Dragos Munteanu</RAUTHOR>
      <REFTITLE>Extracting parallel sub-sentential fragments from non-parallel corpora.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="21">
      <RAUTHOR>Malte Nuhn</RAUTHOR>
      <REFTITLE>Deciphering foreign language by combining language models and context vectors.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="22">
      <RAUTHOR>Sujith Ravi</RAUTHOR>
      <REFTITLE>Deciphering foreign language.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="23">
      <RAUTHOR>Charles Schafer</RAUTHOR>
      <REFTITLE>Inducing translation lexicons via diverse similarity measures and bridge languages.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="24">
      <RAUTHOR>Charles Schafer</RAUTHOR>
      <REFTITLE>Translation Discovery Using Diverse Similarity Measures.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="25">
      <RAUTHOR>Jason R Smith</RAUTHOR>
      <REFTITLE>Extracting parallel sentences from comparable corpora using document level alignment.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="26">
      <RAUTHOR>Jason Smith</RAUTHOR>
      <REFTITLE>Dirt cheap web-scale parallel text from the common crawl.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="27">
      <RAUTHOR>Jakob Uszkoreit</RAUTHOR>
      <REFTITLE>Large scale parallel document mining for machine translation.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="28">
      <RAUTHOR>Omar F Zaidan</RAUTHOR>
      <REFTITLE>Crowdsourcing translation: Professional quality from non-professionals.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="29">
      <RAUTHOR>Andreas Zollmann</RAUTHOR>
      <REFTITLE>Syntax augmented machine translation via chart parsing.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="30">
      <RAUTHOR>Matt Post</RAUTHOR>
      <REFTITLE>Constructing parallel corpora for six indian languages via crowdsourcing.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="31">
      <RAUTHOR>Reinhard Rapp</RAUTHOR>
      <REFTITLE>Identifying word translations in non-parallel texts.</REFTITLE>
      <DATE>1995</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
