<document>
  <filename>W14-3326</filename>
  <authors>
    <author>Ond&#345;ej Du&#353;ek</author>
    <author>Jan Haji&#269;</author>
    <author>Jaroslava Hlav&#225;&#269;ov&#225;</author>
    <author>Michal Nov&#225;k</author>
    <author>Pavel Pecina</author>
    <author>Rudolf Rosa</author>
    <author>Ale&#353; Tamchyna</author>
    <author>Zde&#328;ka Ure&#353;ov&#225;</author>
  </authors>
  <title>Machine Translation of Medical Texts in the Khresmoi Project</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>This paper presents the participation of the Charles University team in the WMT 2014 Medical Translation Task. Our systems are developed within the Khresmoi project, a large integrated project aiming to deliver a multi-lingual multi-modal search and access system for biomedical information and documents. Being involved in the organization of the Medical Translation Task, our primary goal is to set up a baseline for both its subtasks (summary translation and query translation) and for all translation directions. Our systems are based on the phrasebased Moses system and standard methods for domain adaptation. The constrained/unconstrained systems differ in the training data only.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This paper presents the participation of the Charles University team in the WMT 2014 Medical Translation Task.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our systems are developed within the Khresmoi project, a large integrated project aiming to deliver a multi-lingual multi-modal search and access system for biomedical information and documents.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Being involved in the organization of the Medical Translation Task, our primary goal is to set up a baseline for both its subtasks (summary translation and query translation) and for all translation directions.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Our systems are based on the phrasebased Moses system and standard methods for domain adaptation.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>The constrained/unconstrained systems differ in the training data only.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>The WMT 2014 Medical Translation Task poses an interesting challenge for Machine Translation (MT). In the &#8220;standard&#8221; translation task, the end application is the translation itself. In the Medical Translation Task, the MT system is considered a part of a larger system for Cross-Lingual Information Retrieval (CLIR) and is used to solve two different problems: (i) translation of user search queries, and (ii) translation of summaries of retrieved documents.
In query translation, the end user does not even necessarily see the MT output as their queries are translated and search is performed on documents in the target language. In summary translation, the sentences to be translated come from document summaries (snippets) displayed to provide information on each of the documents retrieved by the search. Therefore, translation quality may not be the most important measure in this task &#8211; the performance of the CLIR system as a whole is the final criterion. Another fundamental difference from the standard task is the nature of the translated texts. While we can consider document summaries to be ordinary texts (despite their higher information density in terms of terminology from a narrow domain), search queries in the medical domain are an extremely specific type of data, and traditional techniques for system development and domain adaptation are truly put to a test here.
This work is a part of the of the large integrated EU-funded Khresmoi project. 1 Among other goals, such as joint text and image retrieval of radiodiagnostic records, Khresmoi aims to develop technology for transparent cross-lingual search of medical sources for both professionals and laypeople, with the emphasis primarily on publicly available web sources. In this paper, we describe the Khresmoi systems submitted to the WMT 2014 Medical Translation Task. We participate in both subtasks (summary translation and query translation) for all language pairs (Czech&#8211;English, German&#8211;English, and French&#8211;English) in both directions (to English and from English). Our systems are based on the Moses phrase-based translation toolkit and standard methods for domain adaptation. We submit one constrained and one unconstrained system for each subtask and translation direction. The constrained and unconstrained systems differ in training data only: The former use all allowed training data, the latter take advantage of additional webcrawled data.
We first summarize previous works in MT domain adaptation in Section 2, then describe the data we used for our systems in Section 3. Sec-
1 http://www.khresmoi.eu/
tion 4 contains an account of the submitted systems and their performance in translation of search queries and document summaries. Section 5 concludes the paper.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The WMT 2014 Medical Translation Task poses an interesting challenge for Machine Translation (MT).</text>
              <doc_id>5</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In the &#8220;standard&#8221; translation task, the end application is the translation itself.</text>
              <doc_id>6</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In the Medical Translation Task, the MT system is considered a part of a larger system for Cross-Lingual Information Retrieval (CLIR) and is used to solve two different problems: (i) translation of user search queries, and (ii) translation of summaries of retrieved documents.</text>
              <doc_id>7</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In query translation, the end user does not even necessarily see the MT output as their queries are translated and search is performed on documents in the target language.</text>
              <doc_id>8</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In summary translation, the sentences to be translated come from document summaries (snippets) displayed to provide information on each of the documents retrieved by the search.</text>
              <doc_id>9</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Therefore, translation quality may not be the most important measure in this task &#8211; the performance of the CLIR system as a whole is the final criterion.</text>
              <doc_id>10</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Another fundamental difference from the standard task is the nature of the translated texts.</text>
              <doc_id>11</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>While we can consider document summaries to be ordinary texts (despite their higher information density in terms of terminology from a narrow domain), search queries in the medical domain are an extremely specific type of data, and traditional techniques for system development and domain adaptation are truly put to a test here.</text>
              <doc_id>12</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This work is a part of the of the large integrated EU-funded Khresmoi project.</text>
              <doc_id>13</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>1 Among other goals, such as joint text and image retrieval of radiodiagnostic records, Khresmoi aims to develop technology for transparent cross-lingual search of medical sources for both professionals and laypeople, with the emphasis primarily on publicly available web sources.</text>
              <doc_id>14</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In this paper, we describe the Khresmoi systems submitted to the WMT 2014 Medical Translation Task.</text>
              <doc_id>15</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We participate in both subtasks (summary translation and query translation) for all language pairs (Czech&#8211;English, German&#8211;English, and French&#8211;English) in both directions (to English and from English).</text>
              <doc_id>16</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Our systems are based on the Moses phrase-based translation toolkit and standard methods for domain adaptation.</text>
              <doc_id>17</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We submit one constrained and one unconstrained system for each subtask and translation direction.</text>
              <doc_id>18</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>The constrained and unconstrained systems differ in training data only: The former use all allowed training data, the latter take advantage of additional webcrawled data.</text>
              <doc_id>19</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We first summarize previous works in MT domain adaptation in Section 2, then describe the data we used for our systems in Section 3.</text>
              <doc_id>20</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Sec-</text>
              <doc_id>21</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1 http://www.khresmoi.eu/</text>
              <doc_id>22</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>tion 4 contains an account of the submitted systems and their performance in translation of search queries and document summaries.</text>
              <doc_id>23</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 5 concludes the paper.</text>
              <doc_id>24</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Related work</title>
        <text>To put our work in the context of other approaches, we first describe previous work on domain adaptation in Statistical Machine Translation (SMT), then focus specifically on SMT in the medical domain.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>To put our work in the context of other approaches, we first describe previous work on domain adaptation in Statistical Machine Translation (SMT), then focus specifically on SMT in the medical domain.</text>
              <doc_id>25</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>2.1 Domain adaptation of Statistical machine translation</title>
            <text>Many works on domain adaptation examine the usage of available in-domain data to directly improve in-domain performance of SMT. Some authors attempt to combine the predictions of two separate (in-domain and general-domain) translation models (Langlais, 2002; Sanchis-Trilles and Casacuberta, 2010; Bisazza et al., 2011; Nakov, 2008) or language models (Koehn and Schroeder, 2007). Wu and Wang (2004) use in-domain data to improve word alignment in the training phase. Carpuat et al. (2012) explore the possibility of using word sense disambiguation to discriminate between domains.
Other approaches concentrate on the acquisition of larger in-domain corpora. Some of them exploit existing general-domain corpora by selecting data that resemble the properties of in-domain data (e.g., using cross-entropy), thus building a larger pseudo-in-domain training corpus. This technique is used to adapt language models (Eck et al., 2004b; Moore and Lewis, 2010) as well as translation models (Hildebrand et al., 2005; Axelrod et al., 2011) or their combination (Mansour et al., 2011). Similar approaches to domain adaptation are also applied in other tasks, e.g., automatic speech recognition (Byrne et al., 2004).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Many works on domain adaptation examine the usage of available in-domain data to directly improve in-domain performance of SMT.</text>
                  <doc_id>26</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Some authors attempt to combine the predictions of two separate (in-domain and general-domain) translation models (Langlais, 2002; Sanchis-Trilles and Casacuberta, 2010; Bisazza et al., 2011; Nakov, 2008) or language models (Koehn and Schroeder, 2007).</text>
                  <doc_id>27</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Wu and Wang (2004) use in-domain data to improve word alignment in the training phase.</text>
                  <doc_id>28</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Carpuat et al. (2012) explore the possibility of using word sense disambiguation to discriminate between domains.</text>
                  <doc_id>29</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Other approaches concentrate on the acquisition of larger in-domain corpora.</text>
                  <doc_id>30</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Some of them exploit existing general-domain corpora by selecting data that resemble the properties of in-domain data (e.g., using cross-entropy), thus building a larger pseudo-in-domain training corpus.</text>
                  <doc_id>31</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>This technique is used to adapt language models (Eck et al., 2004b; Moore and Lewis, 2010) as well as translation models (Hildebrand et al., 2005; Axelrod et al., 2011) or their combination (Mansour et al., 2011).</text>
                  <doc_id>32</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Similar approaches to domain adaptation are also applied in other tasks, e.g., automatic speech recognition (Byrne et al., 2004).</text>
                  <doc_id>33</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>2.2 Statistical machine translation in the medical domain</title>
            <text>Eck et al. (2004a) employ an SMT system for the translation of dialogues between doctors and patients and show that according to automatic metrics, a dictionary extracted from the Unified Medical Language System (UMLS) Metathesaurus and its semantic type classification (U.S. National Library of Medicine, 2009) significantly improves translation quality from Spanish to English when applied to generalize the training data.
Wu et al. (2011) analyze the quality of MT on PubMed 2 titles and whether it is sufficient for patients. The conclusions are very positive especially for languages with large training resources (English, Spanish, German) &#8211; the average fluency and content scores (based on human evaluation) are above four on a five-point scale. In automatic evaluation, their systems substantially outperform Google Translate. However, the SMT systems are specifically trained, tuned, and tested on the domain of PubMed titles, and it is not evident how they would perform on other medical texts.
Costa-juss&#224; et al. (2012) are less optimistic regarding SMT quality in the medical domain. They analyze and evaluate the quality of public webbased MT systems (such as Google Translate) and conclude that in both automatic and manual evaluation (on 7 language pairs), the performance of these systems is still not good enough to be used in daily routines of medical doctors in hospitals. Jimeno Yepes et al. (2013) propose a method for obtaining in-domain parallel corpora from titles and abstracts of publications in the MED- LINE 3 database. The acquired corpora contain from 30,000 to 130,000 sentence pairs (depending on the language pair) and are reported to improve translation quality when used for SMT training, compared to a baseline trained on out-of-domain data. However, the authors use only one source of in-domain parallel data to adapt the translation model, and do not use any in-domain monolingual data to adapt the language model.
In this work, we investigate methods combining the different kinds of data &#8211; general-domain, indomain, and pseudo-in-domain &#8211; to find the optimal approach to this problem.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Eck et al. (2004a) employ an SMT system for the translation of dialogues between doctors and patients and show that according to automatic metrics, a dictionary extracted from the Unified Medical Language System (UMLS) Metathesaurus and its semantic type classification (U.S. National Library of Medicine, 2009) significantly improves translation quality from Spanish to English when applied to generalize the training data.</text>
                  <doc_id>34</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Wu et al. (2011) analyze the quality of MT on PubMed 2 titles and whether it is sufficient for patients.</text>
                  <doc_id>35</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The conclusions are very positive especially for languages with large training resources (English, Spanish, German) &#8211; the average fluency and content scores (based on human evaluation) are above four on a five-point scale.</text>
                  <doc_id>36</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In automatic evaluation, their systems substantially outperform Google Translate.</text>
                  <doc_id>37</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>However, the SMT systems are specifically trained, tuned, and tested on the domain of PubMed titles, and it is not evident how they would perform on other medical texts.</text>
                  <doc_id>38</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Costa-juss&#224; et al. (2012) are less optimistic regarding SMT quality in the medical domain.</text>
                  <doc_id>39</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>They analyze and evaluate the quality of public webbased MT systems (such as Google Translate) and conclude that in both automatic and manual evaluation (on 7 language pairs), the performance of these systems is still not good enough to be used in daily routines of medical doctors in hospitals.</text>
                  <doc_id>40</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Jimeno Yepes et al. (2013) propose a method for obtaining in-domain parallel corpora from titles and abstracts of publications in the MED- LINE 3 database.</text>
                  <doc_id>41</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The acquired corpora contain from 30,000 to 130,000 sentence pairs (depending on the language pair) and are reported to improve translation quality when used for SMT training, compared to a baseline trained on out-of-domain data.</text>
                  <doc_id>42</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>However, the authors use only one source of in-domain parallel data to adapt the translation model, and do not use any in-domain monolingual data to adapt the language model.</text>
                  <doc_id>43</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In this work, we investigate methods combining the different kinds of data &#8211; general-domain, indomain, and pseudo-in-domain &#8211; to find the optimal approach to this problem.</text>
                  <doc_id>44</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>3</index>
        <title>3 Data description</title>
        <text>This section includes an overview of the parallel and monolingual data sources used to train our systems. Following the task specification, they are split into constrained and unconstrained sections. The constrained section includes medicaldomain data provided for this task (extracted by the provided scripts), and general-domain texts provided as constrained data for the standard task (&#8220;general domain&#8221; here is used to denote data
2 http://www.ncbi.nlm.nih.gov/pubmed/ 3 http://www.nlm.nih.gov/pubs/
factsheets/medline.html
which comes from a mixture of various different domains, mostly news, parliament proceedings, web-crawls, etc.). The unconstrained section contains automatically crawled data from medical and health websites and non-medical data from patent collections.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This section includes an overview of the parallel and monolingual data sources used to train our systems.</text>
              <doc_id>45</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Following the task specification, they are split into constrained and unconstrained sections.</text>
              <doc_id>46</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The constrained section includes medicaldomain data provided for this task (extracted by the provided scripts), and general-domain texts provided as constrained data for the standard task (&#8220;general domain&#8221; here is used to denote data</text>
              <doc_id>47</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2 http://www.ncbi.nlm.nih.gov/pubmed/ 3 http://www.nlm.nih.gov/pubs/</text>
              <doc_id>48</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>factsheets/medline.html</text>
              <doc_id>49</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>which comes from a mixture of various different domains, mostly news, parliament proceedings, web-crawls, etc.).</text>
              <doc_id>50</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The unconstrained section contains automatically crawled data from medical and health websites and non-medical data from patent collections.</text>
              <doc_id>51</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Parallel data</title>
            <text>The parallel data summary is presented in Table 1.
The main sources of the medical-domain data for all the language pairs include the EMEA corpus (Tiedemann, 2009), the UMLS metathesaurus of health and biomedical vocabularies and standards (U.S. National Library of Medicine, 2009), and bilingual titles of Wikipedia articles belonging to the categories identified to be medical domain. Additional medical-domain data comes from the MAREC patent collection: PatTR (W&#228;schle and Riezler, 2012) available for DE&#8211;EN and FR&#8211;EN, and COPPA (Pouliquen and Mazenc, 2011) for FR&#8211;EN (only patents from the medical categories A61, C12N, and C12P are allowed in the constrained systems). The constrained general-domain data include three parallel corpora for all the language pairs: CommonCrawl (Smith et al., 2013), Europarl version 6 (Koehn, 2005), the News Commentary corpus (Callison-Burch et al., 2012). Further, the constrained data include CzEng (Bojar et al., 2012) for CS&#8211;EN and the UN corpus for FR&#8211;EN.
For our unconstrained experiments, we also employ parallel data from the non-medical patents from the PatTR and COPPA collections (other categories than A61, C12N, and C12P).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The parallel data summary is presented in Table 1.</text>
                  <doc_id>52</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The main sources of the medical-domain data for all the language pairs include the EMEA corpus (Tiedemann, 2009), the UMLS metathesaurus of health and biomedical vocabularies and standards (U.S. National Library of Medicine, 2009), and bilingual titles of Wikipedia articles belonging to the categories identified to be medical domain.</text>
                  <doc_id>53</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Additional medical-domain data comes from the MAREC patent collection: PatTR (W&#228;schle and Riezler, 2012) available for DE&#8211;EN and FR&#8211;EN, and COPPA (Pouliquen and Mazenc, 2011) for FR&#8211;EN (only patents from the medical categories A61, C12N, and C12P are allowed in the constrained systems).</text>
                  <doc_id>54</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The constrained general-domain data include three parallel corpora for all the language pairs: CommonCrawl (Smith et al., 2013), Europarl version 6 (Koehn, 2005), the News Commentary corpus (Callison-Burch et al., 2012).</text>
                  <doc_id>55</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Further, the constrained data include CzEng (Bojar et al., 2012) for CS&#8211;EN and the UN corpus for FR&#8211;EN.</text>
                  <doc_id>56</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For our unconstrained experiments, we also employ parallel data from the non-medical patents from the PatTR and COPPA collections (other categories than A61, C12N, and C12P).</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Monolingual data</title>
            <text>The monolingual data is summarized in Table 2.
The main sources of the medical-domain monolingual data for all languages involve Wikipedia pages, UMLS concept descriptions, and nonparallel texts extracted from the medical patents of the PatTR collections. For English, the main source is the AACT collection of texts from ClinicalTrials.gov. Smaller resources include: Drug- Bank (Knox et al., 2011), GENIA (Kim et al., 2003), FMA (Rosse and Mejino Jr., 2008), GREC (Thompson et al., 2009), and PIL (Bouayad-Agha et al., 2000).
In the unconstrained systems, we use additional monolingual data from web pages crawled within the Khresmoi project: a collection of about one million HON-certified 4 webpages in English released as the test collection for the CLEF 2013 eHealth Task 3 evaluation campaign, 5 additional web-crawled HON-certified pages (not publicly available), and other webcrawled medical-domain related webpages. The constrained general-domain resources include: the News corpus for CS, DE, EN, and FR collected for the purpose of the WMT 2014 Standard Task, monolingual parts of the Europarl and News-Commentary corpora, and the Gigaword for EN and FR.
For the FR&#8211;EN and DE&#8211;EN unconstrained systems, the additional general domain monolingual data is taken from monolingual texts of nonmedical patents in the PatTR collection.
4 https://www.hon.ch/ 5 https://sites.google.com/site/
shareclefehealth/</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The monolingual data is summarized in Table 2.</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The main sources of the medical-domain monolingual data for all languages involve Wikipedia pages, UMLS concept descriptions, and nonparallel texts extracted from the medical patents of the PatTR collections.</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>For English, the main source is the AACT collection of texts from ClinicalTrials.gov.</text>
                  <doc_id>60</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Smaller resources include: Drug- Bank (Knox et al., 2011), GENIA (Kim et al., 2003), FMA (Rosse and Mejino Jr., 2008), GREC (Thompson et al., 2009), and PIL (Bouayad-Agha et al., 2000).</text>
                  <doc_id>61</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In the unconstrained systems, we use additional monolingual data from web pages crawled within the Khresmoi project: a collection of about one million HON-certified 4 webpages in English released as the test collection for the CLEF 2013 eHealth Task 3 evaluation campaign, 5 additional web-crawled HON-certified pages (not publicly available), and other webcrawled medical-domain related webpages.</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The constrained general-domain resources include: the News corpus for CS, DE, EN, and FR collected for the purpose of the WMT 2014 Standard Task, monolingual parts of the Europarl and News-Commentary corpora, and the Gigaword for EN and FR.</text>
                  <doc_id>63</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For the FR&#8211;EN and DE&#8211;EN unconstrained systems, the additional general domain monolingual data is taken from monolingual texts of nonmedical patents in the PatTR collection.</text>
                  <doc_id>64</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>4 https://www.hon.ch/ 5 https://sites.google.com/site/</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>shareclefehealth/</text>
                  <doc_id>66</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Data preprocessing</title>
            <text>The data consisting of crawled web pages, namely CLEF, HON, and non-HON, needed to be cleaned and transformed into a set of sentences. The Boilerpipe (Kohlsch&#252;tter et al., 2010) and Justext (Pomik&#225;lek, 2011) tools were used to remove boilerplate texts and extract just the main content from the web pages. The YALI language detection tool (Majli&#353;, 2012) trained on both in-domain and general domain data then filtered out those cleaned pages which were not identified as written in one of the concerned languages.
The rest of the preprocessing procedure was applied to all the datasets mentioned above, both parallel and monolingual. The data were tokenized and normalized by converting or omitting some (mostly punctuation) characters. A set of language-dependent heuristics was applied in an attempt to restore and normalize the opening/closing quotation marks, i.e. convert "quoted" to &#8220;quoted&#8221; (Zeman, 2012). The motivation here is twofold: First, we hope that paired quotation marks could occasionally work as brackets and better denote parallel phrases for Moses; second, if Moses learns to output directed quotation marks, the subsequent detokenization will be easier. For all systems which translate from German, decompounding is employed to reduce source-side data sparsity. We used BananaSplit for this task (M&#252;ller and Gurevych, 2006).
We perform all training and internal evaluation on lowercased data; we trained recasers to postprocess the final submissions.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The data consisting of crawled web pages, namely CLEF, HON, and non-HON, needed to be cleaned and transformed into a set of sentences.</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The Boilerpipe (Kohlsch&#252;tter et al., 2010) and Justext (Pomik&#225;lek, 2011) tools were used to remove boilerplate texts and extract just the main content from the web pages.</text>
                  <doc_id>68</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The YALI language detection tool (Majli&#353;, 2012) trained on both in-domain and general domain data then filtered out those cleaned pages which were not identified as written in one of the concerned languages.</text>
                  <doc_id>69</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The rest of the preprocessing procedure was applied to all the datasets mentioned above, both parallel and monolingual.</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The data were tokenized and normalized by converting or omitting some (mostly punctuation) characters.</text>
                  <doc_id>71</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A set of language-dependent heuristics was applied in an attempt to restore and normalize the opening/closing quotation marks, i.e. convert "quoted" to &#8220;quoted&#8221; (Zeman, 2012).</text>
                  <doc_id>72</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The motivation here is twofold: First, we hope that paired quotation marks could occasionally work as brackets and better denote parallel phrases for Moses; second, if Moses learns to output directed quotation marks, the subsequent detokenization will be easier.</text>
                  <doc_id>73</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>For all systems which translate from German, decompounding is employed to reduce source-side data sparsity.</text>
                  <doc_id>74</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>We used BananaSplit for this task (M&#252;ller and Gurevych, 2006).</text>
                  <doc_id>75</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>We perform all training and internal evaluation on lowercased data; we trained recasers to postprocess the final submissions.</text>
                  <doc_id>76</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 Submitted systems</title>
        <text>We first describe our technique of psedo-indomain data selection in Section 4.1, then compare two methods of combining the selected data in Section 4.2. This, along with using constrained and unconstrained data sets to train the systems (see Section 3), amounts to a total of four system variants submitted for each task. A description of the system settings used is given in Section 4.3.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We first describe our technique of psedo-indomain data selection in Section 4.1, then compare two methods of combining the selected data in Section 4.2.</text>
              <doc_id>77</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This, along with using constrained and unconstrained data sets to train the systems (see Section 3), amounts to a total of four system variants submitted for each task.</text>
              <doc_id>78</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A description of the system settings used is given in Section 4.3.</text>
              <doc_id>79</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>4.1 Data selection</title>
            <text>We follow an approach originally proposed for selection of monolingual sentences for language modeling (Moore and Lewis, 2010) and its modification applied to selection of parallel sentences (Axelrod et al., 2011). This technique assumes two language models for sentence scoring, one trained on (true) in-domain text and one trained on (any) general-domain text in the same language (e.g., English). For both data domains (general and medical), we score each sentence by the difference of its cross-perplexity given the in-domain language model and cross-perplexity given the general-domain language model (in this order). We only keep sentences with a negative score in our data, assuming that these are the most &#8220;medical-like&#8221;. Visualisation of the domainspecificity scores (cross-perplexity difference) in the FR&#8211;EN parallel data and FR monolingual data is illustrated in Figures 1 and 2, respectively. 6 The scores (Y axis) are presented for each sentence in increasing order from left to right (X axis).
6 For the medical domain, constrained and unconstrained
parallel data are identical.
The two language models for sentence scoring are trained with a restricted vocabulary extracted from the in-domain training data as words occurring at least twice (singletons and other words are treated as out-of-vocabulary). In our experiments, we apply this technique to select both monolingual data for language models and parallel data for translation models. Selection of parallel data is based on the English side only. The in-domain models are trained on the monolingual data in the target language (constrained or unconstrained, depending on the setting). The general-domain models are trained on the WMT News data.
Compared to the approach of Moore and Lewis (2010) and Axelrod et al. (2011), we prune the model vocabulary more aggressively &#8211; we discard not only the singletons, but also all words with non-Latin characters, which helps clean the models from noise introduced by the automatic process of data acquisition by web crawling.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We follow an approach originally proposed for selection of monolingual sentences for language modeling (Moore and Lewis, 2010) and its modification applied to selection of parallel sentences (Axelrod et al., 2011).</text>
                  <doc_id>80</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This technique assumes two language models for sentence scoring, one trained on (true) in-domain text and one trained on (any) general-domain text in the same language (e.g., English).</text>
                  <doc_id>81</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>For both data domains (general and medical), we score each sentence by the difference of its cross-perplexity given the in-domain language model and cross-perplexity given the general-domain language model (in this order).</text>
                  <doc_id>82</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We only keep sentences with a negative score in our data, assuming that these are the most &#8220;medical-like&#8221;.</text>
                  <doc_id>83</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Visualisation of the domainspecificity scores (cross-perplexity difference) in the FR&#8211;EN parallel data and FR monolingual data is illustrated in Figures 1 and 2, respectively.</text>
                  <doc_id>84</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>6 The scores (Y axis) are presented for each sentence in increasing order from left to right (X axis).</text>
                  <doc_id>85</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>6 For the medical domain, constrained and unconstrained</text>
                  <doc_id>86</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>parallel data are identical.</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The two language models for sentence scoring are trained with a restricted vocabulary extracted from the in-domain training data as words occurring at least twice (singletons and other words are treated as out-of-vocabulary).</text>
                  <doc_id>88</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In our experiments, we apply this technique to select both monolingual data for language models and parallel data for translation models.</text>
                  <doc_id>89</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Selection of parallel data is based on the English side only.</text>
                  <doc_id>90</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The in-domain models are trained on the monolingual data in the target language (constrained or unconstrained, depending on the setting).</text>
                  <doc_id>91</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>The general-domain models are trained on the WMT News data.</text>
                  <doc_id>92</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Compared to the approach of Moore and Lewis (2010) and Axelrod et al. (2011), we prune the model vocabulary more aggressively &#8211; we discard not only the singletons, but also all words with non-Latin characters, which helps clean the models from noise introduced by the automatic process of data acquisition by web crawling.</text>
                  <doc_id>93</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>4.2 Data combination</title>
            <text>For both parallel and monolingual data, we obtain two data sets after applying the data selection:
&#8226; &#8220;medical-like&#8221; data from the medical domain
&#8226; &#8220;medical-like&#8221; data from the general domain.
For each language pair and for each system type (constrained/unconstrained), we submitted two system variants which differ in how the selected data are combined. The first variant uses a simple concatenation of the two datasets both for parallel data and for language model data. In the second variant, we train separate models for each section and use linear interpolation to combine them into a single model. For language models, we use the SRILM linear interpolation feature (Stolcke, 2002). We interpolate phrase tables using Tmcombine (Sennrich, 2012). In both cases, the held-out set for minimizing the perplexity is the system development set.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>For both parallel and monolingual data, we obtain two data sets after applying the data selection:</text>
                  <doc_id>94</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; &#8220;medical-like&#8221; data from the medical domain</text>
                  <doc_id>95</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8226; &#8220;medical-like&#8221; data from the general domain.</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>For each language pair and for each system type (constrained/unconstrained), we submitted two system variants which differ in how the selected data are combined.</text>
                  <doc_id>97</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The first variant uses a simple concatenation of the two datasets both for parallel data and for language model data.</text>
                  <doc_id>98</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>In the second variant, we train separate models for each section and use linear interpolation to combine them into a single model.</text>
                  <doc_id>99</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>For language models, we use the SRILM linear interpolation feature (Stolcke, 2002).</text>
                  <doc_id>100</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>We interpolate phrase tables using Tmcombine (Sennrich, 2012).</text>
                  <doc_id>101</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>In both cases, the held-out set for minimizing the perplexity is the system development set.</text>
                  <doc_id>102</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>4.3 System details</title>
            <text>We compute word alignment on lowercase 4-character stems using fast align (Dyer et al., 2013). We create phrase tables using the Moses toolkit (Koehn et al., 2007) with standard settings. We train 5-gram language models on the target-side lowercase forms using SRILM. We use MERT (Och, 2003) to tune model weights in our systems on the development data provided for the task.
The only difference between the system variants for query and summary translation is the tuning set. In both cases, we use the respective sets provided offcially for the shared task.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We compute word alignment on lowercase 4-character stems using fast align (Dyer et al., 2013).</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>We create phrase tables using the Moses toolkit (Koehn et al., 2007) with standard settings.</text>
                  <doc_id>104</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>We train 5-gram language models on the target-side lowercase forms using SRILM.</text>
                  <doc_id>105</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>We use MERT (Och, 2003) to tune model weights in our systems on the development data provided for the task.</text>
                  <doc_id>106</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The only difference between the system variants for query and summary translation is the tuning set.</text>
                  <doc_id>107</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In both cases, we use the respective sets provided offcially for the shared task.</text>
                  <doc_id>108</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>3</index>
            <title>4.4 Results</title>
            <text>Tables 3 and 4 show case-insensitive BLEU scores of our systems. 7 As expected, the unconstrained systems outperform the constrained ones. Linear interpolation outperforms data concatenation quite reliably across language pairs for summary translation. While the picture for query translation is similar, there is more variance in the results, so we cannot state that interpolation definitely works
7 As we use the same recasers for both summary and query
translation, our systems are heavily penalized for wrong letter case in query translation. However, letter case is not taken into account in most CLIR systems. All BLEU scores reported in this paper will be case-insensitive for this reason.
better in this case. This is due to the sizes of the development and test sets and most importantly due to sentence lengths &#8211; queries are very short, making BLEU unreliable, MERT unstable, and bootstrap resampling intervals wide.
If we compare our score to the other competitors, we are clearly worse than the best systems for summary translation. From this perspective, our data filtering seems overly eager (i.e., discarding all sentence pairs with a positive perplexity difference). An experiment which we leave for future work is doing one more round of interpolation to combine a model trained on the data with negative perplexity with models trained on the remainder.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Tables 3 and 4 show case-insensitive BLEU scores of our systems.</text>
                  <doc_id>109</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>7 As expected, the unconstrained systems outperform the constrained ones.</text>
                  <doc_id>110</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Linear interpolation outperforms data concatenation quite reliably across language pairs for summary translation.</text>
                  <doc_id>111</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>While the picture for query translation is similar, there is more variance in the results, so we cannot state that interpolation definitely works</text>
                  <doc_id>112</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>7 As we use the same recasers for both summary and query</text>
                  <doc_id>113</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>translation, our systems are heavily penalized for wrong letter case in query translation.</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, letter case is not taken into account in most CLIR systems.</text>
                  <doc_id>115</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>All BLEU scores reported in this paper will be case-insensitive for this reason.</text>
                  <doc_id>116</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>better in this case.</text>
                  <doc_id>117</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This is due to the sizes of the development and test sets and most importantly due to sentence lengths &#8211; queries are very short, making BLEU unreliable, MERT unstable, and bootstrap resampling intervals wide.</text>
                  <doc_id>118</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>If we compare our score to the other competitors, we are clearly worse than the best systems for summary translation.</text>
                  <doc_id>119</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>From this perspective, our data filtering seems overly eager (i.e., discarding all sentence pairs with a positive perplexity difference).</text>
                  <doc_id>120</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>An experiment which we leave for future work is doing one more round of interpolation to combine a model trained on the data with negative perplexity with models trained on the remainder.</text>
                  <doc_id>121</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>5</index>
        <title>5 Conclusions</title>
        <text>We described the Charles University MT system used in the Shared Medical Translation Task of WMT 2014. Our primary goal was to set up a baseline for both the subtasks and all translation directions. The systems are based on the Moses toolkit, pseudo-in-domain data selection based on perplexity difference and two different methods of in-domain and out-of-domain data combination: simple data concatenation and linear model interpolation. We report results of constrained and unconstrained systems which differ in the training data only. In most experiments, using additional data improved the results compared to the constrained systems and using linear model interpolation outperformed data concatenation. While our systems are on par with best results for case-insensitive BLEU score in query translation, our overly eager data selection techniques caused lower scores in summary translation. In future work, we plan to include a special out-of-domain model in our setup to compensate for this problem.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We described the Charles University MT system used in the Shared Medical Translation Task of WMT 2014.</text>
              <doc_id>122</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Our primary goal was to set up a baseline for both the subtasks and all translation directions.</text>
              <doc_id>123</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The systems are based on the Moses toolkit, pseudo-in-domain data selection based on perplexity difference and two different methods of in-domain and out-of-domain data combination: simple data concatenation and linear model interpolation.</text>
              <doc_id>124</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We report results of constrained and unconstrained systems which differ in the training data only.</text>
              <doc_id>125</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In most experiments, using additional data improved the results compared to the constrained systems and using linear model interpolation outperformed data concatenation.</text>
              <doc_id>126</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>While our systems are on par with best results for case-insensitive BLEU score in query translation, our overly eager data selection techniques caused lower scores in summary translation.</text>
              <doc_id>127</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>In future work, we plan to include a special out-of-domain model in our setup to compensate for this problem.</text>
              <doc_id>128</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>6</index>
        <title>Acknowledgments</title>
        <text>This work was supported by the EU FP7 project Khresmoi (contract no. 257528), the Czech Science Foundation (grant no. P103/12/G084), and SVV project number 260 104. This work has been using language resources developed, stored, and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2010013).</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This work was supported by the EU FP7 project Khresmoi (contract no.</text>
              <doc_id>129</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>257528), the Czech Science Foundation (grant no.</text>
              <doc_id>130</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>P103/12/G084), and SVV project number 260 104.</text>
              <doc_id>131</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>This work has been using language resources developed, stored, and distributed by the LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2010013).</text>
              <doc_id>132</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: Number of sentence pairs and tokens (source/target) in parallel training data (in thousands).</caption>
        <reference_text></reference_text>
        <page_num>2</page_num>
        <head>
          <rows>
            <row>
              <cell>Czech&#8211;English</cell>
              <cell>German&#8211;English</cell>
              <cell>French&#8211;English</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>dom</cell>
              <cell>set</cell>
              <cell>pairs</cell>
              <cell>source</cell>
              <cell>target</cell>
              <cell>pairs</cell>
              <cell>source</cell>
              <cell>target</cell>
              <cell>pairs</cell>
              <cell>source</cell>
              <cell>target</cell>
            </row>
            <row>
              <cell>med</cell>
              <cell>con</cell>
              <cell>2,498</cell>
              <cell>18,126</cell>
              <cell>19,964</cell>
              <cell>4,998</cell>
              <cell>123,686</cell>
              <cell>130,598</cell>
              <cell>6,139</cell>
              <cell>202,245</cell>
              <cell>171,928</cell>
            </row>
            <row>
              <cell>gen</cell>
              <cell>con</cell>
              <cell>15,788</cell>
              <cell>226,711</cell>
              <cell>260,505</cell>
              <cell>4,520</cell>
              <cell>112,818</cell>
              <cell>119,404</cell>
              <cell>40,842</cell>
              <cell>1,470,016</cell>
              <cell>1,211,516</cell>
            </row>
            <row>
              <cell>gen</cell>
              <cell>unc</cell>
              <cell>&#8211;</cell>
              <cell>&#8211;</cell>
              <cell>&#8211;</cell>
              <cell>9,320</cell>
              <cell>525,782</cell>
              <cell>574,373</cell>
              <cell>13,809</cell>
              <cell>961,991</cell>
              <cell>808,222</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TableSeer</source>
        <caption>Table 1: Number of sentence pairs and tokens (source/target) in parallel training data (in thousands).#@#@Table 2: Number of tokens in monolingual training data (in thousands).</caption>
        <reference_text>None</reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>dom</cell>
              <cell>set</cell>
              <cell>English</cell>
              <cell>Czech</cell>
              <cell>German</cell>
              <cell>French</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>med</cell>
              <cell>con</cell>
              <cell>172,991</cell>
              <cell>1,848</cell>
              <cell>63,499</cell>
              <cell>63,022</cell>
            </row>
            <row>
              <cell>gen</cell>
              <cell>con</cell>
              <cell>6,132,107</cell>
              <cell>627,493</cell>
              <cell>1,728,065</cell>
              <cell>1,837,457</cell>
            </row>
            <row>
              <cell>med</cell>
              <cell>unc</cell>
              <cell>3,275,272</cell>
              <cell>36,348</cell>
              <cell>361,881</cell>
              <cell>908,911</cell>
            </row>
            <row>
              <cell>gen</cell>
              <cell>unc</cell>
              <cell>618,084</cell>
              <cell>?#@#@&#8211;</cell>
              <cell>339,595</cell>
              <cell>204,025</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>3</id>
        <source>TableSeer</source>
        <caption>Table 3: BLEU scores of summary translations.</caption>
        <reference_text>None</reference_text>
        <page_num>5</page_num>
        <head>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>cs?en#@#@cs&#8594;en</cell>
              <cell>de?en#@#@de&#8594;en</cell>
              <cell>en?cs#@#@en&#8594;cs</cell>
              <cell>en?de#@#@en&#8594;de</cell>
              <cell>en?fr#@#@en&#8594;fr</cell>
              <cell>fr?en#@#@fr&#8594;en</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>con</cell>
              <cell>concat</cell>
              <cell>30.87?4.70#@#@33.64&#177;1.14</cell>
              <cell>33.21?5.03#@#@32.84&#177;1.24</cell>
              <cell>23.25?4.85#@#@18.10&#177;0.94</cell>
              <cell>17.72?4.75#@#@18.29&#177;0.92</cell>
              <cell>28.64?3.77#@#@33.39&#177;1.11</cell>
              <cell>35.56?4.94#@#@36.71&#177;1.17</cell>
            </row>
            <row>
              <cell>con</cell>
              <cell>interpol</cell>
              <cell>32.46?5.05#@#@32.94&#177;1.11</cell>
              <cell>33.74?4.97#@#@32.31&#177;1.20</cell>
              <cell>21.56?4.80#@#@18.96&#177;0.93</cell>
              <cell>16.90?4.39#@#@18.41&#177;0.93</cell>
              <cell>29.34?3.73#@#@34.06&#177;1.11</cell>
              <cell>35.28?5.26#@#@37.42&#177;1.21</cell>
            </row>
            <row>
              <cell>unc</cell>
              <cell>concat</cell>
              <cell>34.88?5.04#@#@34.10&#177;1.11</cell>
              <cell>31.24?5.59#@#@34.52&#177;1.20</cell>
              <cell>22.61?4.91#@#@21.12&#177;1.03</cell>
              <cell>19.13?5.66#@#@19.76&#177;0.92</cell>
              <cell>33.08?3.80#@#@36.23&#177;1.03</cell>
              <cell>36.73?4.88#@#@38.15&#177;1.16</cell>
            </row>
            <row>
              <cell>unc</cell>
              <cell>interpol</cell>
              <cell>33.82?5.16#@#@34.48&#177;1.16</cell>
              <cell>34.19?5.27#@#@34.92&#177;1.17</cell>
              <cell>23.93?5.16#@#@22.15&#177;1.06</cell>
              <cell>15.87?11.31#@#@20.81&#177;0.95</cell>
              <cell>31.19?3.73#@#@36.26&#177;1.13</cell>
              <cell>40.25?5.14#@#@37.91&#177;1.13</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>4</id>
        <source>TET</source>
        <caption>Table 4: BLEU scores of query translations.</caption>
        <reference_text></reference_text>
        <page_num>4</page_num>
        <head>
          <rows>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>cs&#8594;en</cell>
              <cell>de&#8594;en</cell>
              <cell>en&#8594;cs</cell>
              <cell>en&#8594;de</cell>
              <cell>en&#8594;fr</cell>
              <cell>fr&#8594;en</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>con</cell>
              <cell>concat</cell>
              <cell>30.87&#177;4.70</cell>
              <cell>33.21&#177;5.03</cell>
              <cell>23.25&#177;4.85</cell>
              <cell>17.72&#177;4.75</cell>
              <cell>28.64&#177;3.77</cell>
              <cell>35.56&#177;4.94</cell>
            </row>
            <row>
              <cell>con</cell>
              <cell>interpol</cell>
              <cell>32.46&#177;5.05</cell>
              <cell>33.74&#177;4.97</cell>
              <cell>21.56&#177;4.80</cell>
              <cell>16.90&#177;4.39</cell>
              <cell>29.34&#177;3.73</cell>
              <cell>35.28&#177;5.26</cell>
            </row>
            <row>
              <cell>unc</cell>
              <cell>concat</cell>
              <cell>34.88&#177;5.04</cell>
              <cell>31.24&#177;5.59</cell>
              <cell>22.61&#177;4.91</cell>
              <cell>19.13&#177;5.66</cell>
              <cell>33.08&#177;3.80</cell>
              <cell>36.73&#177;4.88</cell>
            </row>
            <row>
              <cell>unc</cell>
              <cell>interpol</cell>
              <cell>33.82&#177;5.16</cell>
              <cell>34.19&#177;5.27</cell>
              <cell>23.93&#177;5.16</cell>
              <cell>15.87&#177;11.31</cell>
              <cell>31.19&#177;3.73</cell>
              <cell>40.25&#177;5.14</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>A Axelrod</author>
          <author>X He</author>
          <author>J Gao</author>
        </authors>
        <title>Domain adaptation via pseudo in-domain data selection.</title>
        <publication>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</publication>
        <pages>355--362</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>A Bisazza</author>
          <author>N Ruiz</author>
          <author>M Federico</author>
        </authors>
        <title>Fillup versus interpolation methods for phrase-based SMT adaptation.</title>
        <publication>In Proceedings of the International Workshop on Spoken Language Translation,</publication>
        <pages>136--143</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>O Bojar</author>
          <author>Z &#381;abokrtsk&#253;</author>
          <author>O Du&#353;ek</author>
          <author>P Galu&#353;&#269;&#225;kov&#225;</author>
          <author>M Majli&#353;</author>
          <author>D Mare&#269;ek</author>
          <author>J Mar&#353;&#237;k</author>
          <author>M Nov&#225;k</author>
          <author>M Popel</author>
          <author>A Tamchyna</author>
        </authors>
        <title>The joy of parallelism with CzEng 1.0.</title>
        <publication>In Proceedings of the Eighth International Conference on Language Resources and Evaluation,</publication>
        <pages>3921--3928</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>N Bouayad-Agha</author>
          <author>D R Scott</author>
          <author>R Power</author>
        </authors>
        <title>Integrating content and style in documents: A case study of patient information leaflets.</title>
        <publication>None</publication>
        <pages>9--2</pages>
        <date>2000</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>W Byrne</author>
          <author>D S Doermann</author>
          <author>M Franz</author>
          <author>S Gustman</author>
          <author>J Haji&#269;</author>
          <author>D W Oard</author>
        </authors>
        <title>Automatic recognition of spontaneous speech for access to multilingual oral history archives. Speech and Audio Processing,</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>C Callison-Burch</author>
          <author>P Koehn</author>
          <author>C Monz</author>
          <author>M Post</author>
          <author>R Soricut</author>
          <author>L Specia</author>
        </authors>
        <title>None</title>
        <publication>Findings of the 2012 Workshop on Statistical Machine Translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation,</publication>
        <pages>10--51</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>M Carpuat</author>
          <author>H Daum&#233; A Fraser</author>
          <author>C Quirk</author>
          <author>F Braune</author>
          <author>A Clifton</author>
        </authors>
        <title>Domain adaptation in machine translation: Final report.</title>
        <publication>In 2012 Johns Hopkins Summer Workshop Final Report,</publication>
        <pages>61--72</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>M R Costa-juss&#224;</author>
          <author>M Farr&#250;s</author>
          <author>J Serrano Pons</author>
        </authors>
        <title>Machine translation in medicine. A quality analysis of statistical machine translation in the medical domain.</title>
        <publication>In Proceedings of the 1st Virtual International Conference on Advanced Research in Scientific Areas,</publication>
        <pages>1995--1998</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>C Dyer</author>
          <author>V Chahuneau</author>
          <author>N A Smith</author>
        </authors>
        <title>A simple, fast, and effective reparameterization of IBM model 2.</title>
        <publication>In Proceedings of NAACL-HLT,</publication>
        <pages>644--648</pages>
        <date>2013</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>M Eck</author>
          <author>S Vogel</author>
          <author>A Waibel</author>
        </authors>
        <title>Improving statistical machine translation in the medical domain using the Unified Medical Language System.</title>
        <publication>In COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics,</publication>
        <pages>792--798</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>S Vogel Eck</author>
          <author>A Waibel</author>
        </authors>
        <title>Language model adaptation for statistical machine translation based on information retrieval.</title>
        <publication>In Maria</publication>
        <pages>327--330</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>A S Hildebrand</author>
          <author>M Eck</author>
          <author>S Vogel</author>
          <author>A Waibel</author>
        </authors>
        <title>Adaptation of the translation model for statistical machine translation based on information retrieval.</title>
        <publication>In Proceedings of the 10th Annual Conference of the European Association for Machine Translation,</publication>
        <pages>133--142</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>A Jimeno Yepes</author>
          <author>&#201; Prieur-Gaston</author>
          <author>A N&#233;v&#233;ol</author>
        </authors>
        <title>Combining MEDLINE and publisher data to create parallel corpora for the automatic translation of biomedical text.</title>
        <publication>None</publication>
        <pages>10</pages>
        <date>2013</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>J-D Kim</author>
          <author>T Ohta</author>
          <author>Y Tateisi</author>
          <author>J Tsujii</author>
        </authors>
        <title>GENIA corpus &#8211; a semantically annotated corpus for bio-textmining. Bioinformatics, 19(suppl 1):i180&#8211; i182.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>C Knox</author>
          <author>V Law</author>
          <author>T Jewison</author>
          <author>P Liu</author>
          <author>Son Ly</author>
          <author>A Frolkis</author>
          <author>A Pon</author>
          <author>K Banco</author>
          <author>C Mak</author>
          <author>V Neveu</author>
          <author>Y Djoumbou</author>
          <author>R Eisner</author>
          <author>A C Guo</author>
          <author>D S Wishart</author>
        </authors>
        <title>DrugBank 3.0: a comprehensive resource for &#8216;Omics&#8217; research on drugs. Nucleic acids research, 39(suppl 1):D1035&#8211;D1041.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>P Koehn</author>
          <author>J Schroeder</author>
        </authors>
        <title>Experiments in domain adaptation for statistical machine translation.</title>
        <publication>In Proceedings of the Second Workshop on Statistical Machine Translation,</publication>
        <pages>224--227</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>P Koehn</author>
          <author>H Hoang</author>
          <author>A Birch</author>
          <author>C Callison-Burch</author>
          <author>M Federico</author>
          <author>N Bertoldi</author>
          <author>B Cowan</author>
          <author>W Shen</author>
          <author>C Moran</author>
          <author>R Zens</author>
          <author>C Dyer</author>
          <author>O Bojar</author>
          <author>A Constantin</author>
          <author>E Herbst</author>
        </authors>
        <title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
        <publication>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</publication>
        <pages>177--180</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>P Koehn</author>
        </authors>
        <title>Europarl: a parallel corpus for statistical machine translation.</title>
        <publication>In Conference Proceedings: the tenth Machine Translation Summit,</publication>
        <pages>79--86</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>C Kohlsch&#252;tter</author>
          <author>P Fankhauser</author>
          <author>W Nejdl</author>
        </authors>
        <title>Boilerplate detection using shallow text features.</title>
        <publication>In Proceedings of the Third ACM International Conference on Web Search and Data Mining, WSDM &#8217;10,</publication>
        <pages>441--450</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>P Langlais</author>
        </authors>
        <title>Improving a general-purpose statistical translation engine by terminological lexicons.</title>
        <publication>In COLING-02 on COMPUTERM 2002: second international workshop on computational terminology,</publication>
        <pages>1--7</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>M Majli&#353;</author>
        </authors>
        <title>Yet another language identifier.</title>
        <publication>In Proceedings of the Student Research Workshop at the 13th Conference of the European Chapter of the Association for Computational Linguistics,</publication>
        <pages>46--54</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>S Mansour</author>
          <author>J Wuebker</author>
          <author>H Ney</author>
        </authors>
        <title>Combining translation and language model scoring for domain-specific data filtering.</title>
        <publication>In International Workshop on Spoken Language Translation,</publication>
        <pages>222--229</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>R C Moore</author>
          <author>W Lewis</author>
        </authors>
        <title>Intelligent selection of language model training data.</title>
        <publication>In Proceedings of the ACL 2010 Conference Short Papers,</publication>
        <pages>220--224</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>23</id>
        <authors>
          <author>C M&#252;ller</author>
          <author>I Gurevych</author>
        </authors>
        <title>Exploring the potential of semantic relatedness in information retrieval.</title>
        <publication>In LWA 2006 Lernen &#8211; Wissensentdeckung &#8211; Adaptivit&#228;t, 9.-11.10.2006, Hildesheimer Informatikberichte,</publication>
        <pages>126--131</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>24</id>
        <authors>
          <author>P Nakov</author>
        </authors>
        <title>Improving English&#8211;Spanish statistical machine translation: Experiments in domain adaptation, sentence paraphrasing, tokenization, and recasing.</title>
        <publication>In Proceedings of the Third Workshop on Statistical Machine Translation,</publication>
        <pages>147--150</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>25</id>
        <authors>
          <author>F J Och</author>
        </authors>
        <title>Minimum error rate training in statistical machine translation.</title>
        <publication>In ACL &#8217;03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</publication>
        <pages>160--167</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>26</id>
        <authors>
          <author>J Pomik&#225;lek</author>
        </authors>
        <title>Removing Boilerplate and Duplicate Content from Web Corpora.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>27</id>
        <authors>
          <author>B Pouliquen</author>
          <author>C Mazenc</author>
        </authors>
        <title>COPPA, CLIR and TAPTA: three tools to assist in overcoming the patent barrier at WIPO.</title>
        <publication>In Proceedings of the Thirteenth Machine Translation Summit,</publication>
        <pages>24--30</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>28</id>
        <authors>
          <author>C Rosse</author>
          <author>Jos&#233; L V Mejino Jr</author>
        </authors>
        <title>The foundational model of anatomy ontology.</title>
        <publication>Anatomy Ontologies for Bioinformatics,</publication>
        <pages>59--117</pages>
        <date>2008</date>
      </reference>
      <reference>
        <id>29</id>
        <authors>
          <author>G Sanchis-Trilles</author>
          <author>F Casacuberta</author>
        </authors>
        <title>Loglinear weight optimisation via Bayesian adaptation in statistical machine translation.</title>
        <publication>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</publication>
        <pages>1077--1085</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>30</id>
        <authors>
          <author>Sennrich</author>
        </authors>
        <title>Perplexity minimization for translation model domain adaptation in statistical machine translation.</title>
        <publication>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</publication>
        <pages>539--549</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>31</id>
        <authors>
          <author>J R Smith</author>
          <author>H Saint-Amand</author>
          <author>M Plamada</author>
          <author>P Koehn</author>
          <author>C Callison-Burch</author>
          <author>A Lopez</author>
        </authors>
        <title>Dirt cheap web-scale parallel text from the common crawl.</title>
        <publication>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</publication>
        <pages>1374--1383</pages>
        <date>2013</date>
      </reference>
      <reference>
        <id>32</id>
        <authors>
          <author>A Stolcke</author>
        </authors>
        <title>SRILM &#8211; an extensible language modeling toolkit.</title>
        <publication>In Proceedings of International Conference on Spoken Language Processing,</publication>
        <pages>None</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>33</id>
        <authors>
          <author>P Thompson</author>
          <author>S Iqbal</author>
          <author>J McNaught</author>
          <author>Sophia Ananiadou</author>
        </authors>
        <title>Construction of an annotated corpus to support biomedical information extraction.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>34</id>
        <authors>
          <author>J Tiedemann</author>
        </authors>
        <title>News from OPUS &#8211; a collection of multilingual parallel corpora with tools and interfaces.</title>
        <publication>In Recent Advances in Natural Language Processing,</publication>
        <pages>237--248</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>35</id>
        <authors>
          <author>U S National</author>
        </authors>
        <title>Library of Medicine.</title>
        <publication>UMLS reference manual. Metathesaurus.</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>36</id>
        <authors>
          <author>K W&#228;schle</author>
          <author>S Riezler</author>
        </authors>
        <title>Analyzing parallelism and domain similarities in the MAREC patent corpus.</title>
        <publication>of Lecture Notes in Computer Science,</publication>
        <pages>12--27</pages>
        <date>2012</date>
      </reference>
      <reference>
        <id>37</id>
        <authors>
          <author>H Wu</author>
          <author>H Wang</author>
        </authors>
        <title>Improving domain-specific word alignment with a general bilingual corpus.</title>
        <publication>Machine Translation: From Real Users to Research,</publication>
        <pages>262--271</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>38</id>
        <authors>
          <author>C Wu</author>
          <author>F Xia</author>
          <author>L Deleger</author>
          <author>I Solti</author>
        </authors>
        <title>Statistical machine translation for biomedical text: are we there yet? AMIA Annual Symposium proceedings,</title>
        <publication>None</publication>
        <pages>1290--1299</pages>
        <date>2011</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Axelrod et al., 2011</string>
        <sentence_id>7786</sentence_id>
        <char_offset>147</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>0</reference_id>
        <string>Axelrod et al., 2011</string>
        <sentence_id>7832</sentence_id>
        <char_offset>192</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>0</reference_id>
        <string>Axelrod et al. (2011)</string>
        <sentence_id>7845</sentence_id>
        <char_offset>55</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>1</reference_id>
        <string>Bisazza et al., 2011</string>
        <sentence_id>7781</sentence_id>
        <char_offset>170</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>2</reference_id>
        <string>Bojar et al., 2012</string>
        <sentence_id>7804</sentence_id>
        <char_offset>45</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>3</reference_id>
        <string>Bouayad-Agha et al., 2000</string>
        <sentence_id>7809</sentence_id>
        <char_offset>158</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>4</reference_id>
        <string>Byrne et al., 2004</string>
        <sentence_id>7787</sentence_id>
        <char_offset>109</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>5</reference_id>
        <string>Callison-Burch et al., 2012</string>
        <sentence_id>7803</sentence_id>
        <char_offset>191</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>6</reference_id>
        <string>Carpuat et al. (2012)</string>
        <sentence_id>7783</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>7</reference_id>
        <string>Costa-juss&#224; et al. (2012)</string>
        <sentence_id>7793</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>8</reference_id>
        <string>Dyer et al., 2013</string>
        <sentence_id>7855</sentence_id>
        <char_offset>75</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>9</reference_id>
        <string>Eck et al., 2004</string>
        <sentence_id>7786</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>11</reference_id>
        <string>Hildebrand et al., 2005</string>
        <sentence_id>7786</sentence_id>
        <char_offset>122</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>12</reference_id>
        <string>Yepes et al. (2013)</string>
        <sentence_id>7795</sentence_id>
        <char_offset>7</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>13</reference_id>
        <string>Kim et al., 2003</string>
        <sentence_id>7809</sentence_id>
        <char_offset>66</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>14</reference_id>
        <string>Knox et al., 2011</string>
        <sentence_id>7809</sentence_id>
        <char_offset>39</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>15</reference_id>
        <string>Koehn and Schroeder, 2007</string>
        <sentence_id>7781</sentence_id>
        <char_offset>225</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>16</reference_id>
        <string>Koehn et al., 2007</string>
        <sentence_id>7856</sentence_id>
        <char_offset>49</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>17</reference_id>
        <string>Koehn, 2005</string>
        <sentence_id>7803</sentence_id>
        <char_offset>149</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>18</reference_id>
        <string>Kohlsch&#252;tter et al., 2010</string>
        <sentence_id>7816</sentence_id>
        <char_offset>16</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>19</reference_id>
        <string>Langlais, 2002</string>
        <sentence_id>7781</sentence_id>
        <char_offset>115</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>20</reference_id>
        <string>Majli&#353;, 2012</string>
        <sentence_id>7817</sentence_id>
        <char_offset>34</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>21</reference_id>
        <string>Mansour et al., 2011</string>
        <sentence_id>7786</sentence_id>
        <char_offset>191</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>22</reference_id>
        <string>Moore and Lewis (2010)</string>
        <sentence_id>7845</sentence_id>
        <char_offset>28</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>22</reference_id>
        <string>Moore and Lewis, 2010</string>
        <sentence_id>7786</sentence_id>
        <char_offset>68</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>22</reference_id>
        <string>Moore and Lewis, 2010</string>
        <sentence_id>7832</sentence_id>
        <char_offset>104</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>23</reference_id>
        <string>M&#252;ller and Gurevych, 2006</string>
        <sentence_id>7823</sentence_id>
        <char_offset>35</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>24</reference_id>
        <string>Nakov, 2008</string>
        <sentence_id>7781</sentence_id>
        <char_offset>192</char_offset>
      </citation>
      <citation>
        <id>28</id>
        <reference_id>25</reference_id>
        <string>Och, 2003</string>
        <sentence_id>7858</sentence_id>
        <char_offset>13</char_offset>
      </citation>
      <citation>
        <id>29</id>
        <reference_id>26</reference_id>
        <string>Pomik&#225;lek, 2011</string>
        <sentence_id>7816</sentence_id>
        <char_offset>56</char_offset>
      </citation>
      <citation>
        <id>30</id>
        <reference_id>27</reference_id>
        <string>Pouliquen and Mazenc, 2011</string>
        <sentence_id>7802</sentence_id>
        <char_offset>147</char_offset>
      </citation>
      <citation>
        <id>31</id>
        <reference_id>29</reference_id>
        <string>Sanchis-Trilles and Casacuberta, 2010</string>
        <sentence_id>7781</sentence_id>
        <char_offset>131</char_offset>
      </citation>
      <citation>
        <id>32</id>
        <reference_id>30</reference_id>
        <string>Sennrich, 2012</string>
        <sentence_id>7853</sentence_id>
        <char_offset>46</char_offset>
      </citation>
      <citation>
        <id>33</id>
        <reference_id>31</reference_id>
        <string>Smith et al., 2013</string>
        <sentence_id>7803</sentence_id>
        <char_offset>108</char_offset>
      </citation>
      <citation>
        <id>34</id>
        <reference_id>32</reference_id>
        <string>Stolcke, 2002</string>
        <sentence_id>7852</sentence_id>
        <char_offset>68</char_offset>
      </citation>
      <citation>
        <id>35</id>
        <reference_id>33</reference_id>
        <string>Thompson et al., 2009</string>
        <sentence_id>7809</sentence_id>
        <char_offset>125</char_offset>
      </citation>
      <citation>
        <id>36</id>
        <reference_id>34</reference_id>
        <string>Tiedemann, 2009</string>
        <sentence_id>7801</sentence_id>
        <char_offset>96</char_offset>
      </citation>
      <citation>
        <id>37</id>
        <reference_id>36</reference_id>
        <string>W&#228;schle and Riezler, 2012</string>
        <sentence_id>7802</sentence_id>
        <char_offset>78</char_offset>
      </citation>
      <citation>
        <id>38</id>
        <reference_id>37</reference_id>
        <string>Wu and Wang (2004)</string>
        <sentence_id>7782</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>39</id>
        <reference_id>38</reference_id>
        <string>Wu et al. (2011)</string>
        <sentence_id>7789</sentence_id>
        <char_offset>0</char_offset>
      </citation>
    </citations>
  </content>
</document>
