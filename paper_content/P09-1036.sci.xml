<PAPER>
  <FILENO/>
  <TITLE></TITLE>
  <AUTHORS/>
  <ABSTRACT/>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-26449">The phrase-based approach is widely adopted in statistical machine translation (SMT).</S>
        <S ID="S-26450">It segments a source sentence into a sequence of phrases, then translates and reorder these phrases in the target.</S>
        <S ID="S-26451">In such a process, original phrase-based decoding (Koehn et al., 2003) does not take advantage of any linguistic analysis, which, however, is broadly used in rule-based approaches.</S>
        <S ID="S-26452">Since it is not linguistically motivated, original phrasebased decoding might produce ungrammatical or even wrong translations.</S>
        <S ID="S-26453">Consider the following Chinese fragment with its parse tree:</S>
      </P>
      <P>
        <S ID="S-26454">Src: [&#65533; [[7&#65533; 11&#65533;] NP [&#65533;&#65533; [&#65533; [&#65533;&#65533; &#65533;] NP ] PP ] VP ] IP ] VP</S>
      </P>
      <P>
        <S ID="S-26455">Ref: established July 11 as Sailing Festival day</S>
      </P>
      <P>
        <S ID="S-26456">Output: [to/&#65533; [&#12296;[set up/&#65533; &#65533; [for/&#65533; navigation/&#65533;&#65533;]] on July 11/7&#65533;11&#65533;&#12297; knots/&#65533;]] The output is generated from a phrase-based system which does not involve any syntactic analysis.</S>
        <S ID="S-26457">Here we use &#8220;[]&#8221; (straight orientation) and &#8220;&#12296;&#12297;&#8221; (inverted orientation) to denote the common structure of the source fragment and its translation found by the decoder.</S>
        <S ID="S-26458">We can observe that the decoder inadequately breaks up the second NP phrase and translates the two words &#8220;&#65533;&#65533;&#8221; and &#8220;&#65533;&#8221; separately.</S>
        <S ID="S-26459">However, the parse tree of the source fragment constrains the phrase &#8220;&#65533;&#65533; &#65533;&#8221; to be translated as a unit.</S>
      </P>
      <P>
        <S ID="S-26460">Without considering syntactic constraints from the parse tree, the decoder makes wrong decisions not only on phrase movement but also on the lexical selection for the multi-meaning word &#8220;&#65533;&#8221; 1 .</S>
        <S ID="S-26461">To avert such errors, the decoder can fully respect linguistic structures by only allowing syntactic constituent translations and reorderings.</S>
        <S ID="S-26462">This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries.</S>
        <S ID="S-26463">To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side.</S>
        <S ID="S-26464">On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries.</S>
        <S ID="S-26465">These constituent matching/violation counts are used as a feature in the decoder&#8217;s log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003).</S>
        <S ID="S-26466">In this way, syntactic constraint is integrated into decoding as a soft constraint to enable the decoder to reward hypotheses that respect syntactic analyses or to pe-</S>
      </P>
      <P>
        <S ID="S-26467">1 This word can be translated into &#8220;section&#8221;, &#8220;festival&#8221;,</S>
      </P>
      <P>
        <S ID="S-26468">and &#8220;knot&#8221; in different contexts.</S>
      </P>
      <P>
        <S ID="S-26469">nalize hypotheses that violate syntactic structures.</S>
      </P>
      <P>
        <S ID="S-26470">Although experiments show that this constituent matching/violation counting feature achieves significant improvements on various language-pairs, one issue is that matching syntactic analysis can not always guarantee a good translation, and violating syntactic structure does not always induce a bad translation.</S>
        <S ID="S-26471">Marton and Resnik (2008) find that some constituency types favor matching the source parse while others encourage violations.</S>
        <S ID="S-26472">Therefore it is necessary to integrate more syntactic constraints into phrase translation, not just the constraint of constituent matching/violation.</S>
      </P>
      <P>
        <S ID="S-26473">The other issue is that during decoding we are more concerned with the question of phrase cohesion, i.e. whether the current phrase can be translated as a unit or not within particular syntactic contexts (Fox, 2002) 2 , than that of constituent matching/violation.</S>
        <S ID="S-26474">Phrase cohesion is one of the main reasons that we introduce syntactic constraints (Cherry, 2008).</S>
        <S ID="S-26475">If a source phrase remains contiguous after translation, we refer this type of phrase bracketable, otherwise unbracketable.</S>
        <S ID="S-26476">It is more desirable to translate a bracketable phrase than an unbracketable one.</S>
      </P>
      <P>
        <S ID="S-26477">In this paper, we propose a syntax-driven bracketing (SDB) model to predict whether a phrase (a sequence of contiguous words) is bracketable or not using rich syntactic constraints.</S>
        <S ID="S-26478">We parse the source language sentences in the word-aligned training corpus.</S>
        <S ID="S-26479">According to the word alignments, we define bracketable and unbracketable instances.</S>
        <S ID="S-26480">For each of these instances, we automatically extract relevant syntactic features from the source parse tree as bracketing evidences.</S>
        <S ID="S-26481">Then we tune the weights of these features using a maximum entropy (ME) trainer.</S>
        <S ID="S-26482">In this way, we build two bracketing models: 1) a unary SDB model (UniSDB) which predicts whether an independent phrase is bracketable or not; and 2) a binary SDB model(BiSDB) which predicts whether two neighboring phrases are bracketable.</S>
        <S ID="S-26483">Similar to previous methods, our SDB model is integrated into the decoder&#8217;s log-linear model as a feature so that we can inherit the idea of soft constraints.</S>
      </P>
      <P>
        <S ID="S-26484">In contrast to the constituent matching/violation counting (CMVC) (Chiang, 2005; Marton and Resnik, 2008; Cherry, 2008), our SDB model has</S>
      </P>
      <P>
        <S ID="S-26485">2 Here we expand the definition of phrase to include both</S>
      </P>
      <P>
        <S ID="S-26486">syntactic and non-syntactic phrases.</S>
      </P>
      <P>
        <S ID="S-26487">the following advantages</S>
      </P>
      <P>
        <S ID="S-26488">&#8226; The SDB model automatically learns syntactic constraints from training data while the CMVC uses manually defined syntactic constraints: constituency matching/violation.</S>
        <S ID="S-26489">In our SDB model, each learned syntactic feature from bracketing instances can be considered as a syntactic constraint.</S>
        <S ID="S-26490">Therefore we can use thousands of syntactic constraints to guide phrase translation.</S>
      </P>
      <P>
        <S ID="S-26491">&#8226; The SDB model maintains and protects the strength of the phrase-based approach in a better way than the CMVC does.</S>
        <S ID="S-26492">It is able to reward non-syntactic translations by assigning an adequate probability to them if these translations are appropriate to particular syntactic contexts on the source side, rather than always punish them.</S>
      </P>
      <P>
        <S ID="S-26493">We test our SDB model against the baseline which doest not use any syntactic constraints on Chinese-to-English translation.</S>
        <S ID="S-26494">To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)&#8217;s XP+.</S>
        <S ID="S-26495">The XP+ accumulates a count for each hypothesis whenever it violates the boundaries of a constituent with a label from {NP, VP, CP, IP, PP, ADVP, QP, LCP, DNP}.</S>
        <S ID="S-26496">The XP+ is the best feature among all features that Marton and Resnik use for Chinese-to- English translation.</S>
        <S ID="S-26497">Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric (Papineni et al., 2002).</S>
        <S ID="S-26498">In addition, our analysis shows further evidences of the performance gain from a different perspective than that of BLEU.</S>
      </P>
      <P>
        <S ID="S-26499">The paper proceeds as follows.</S>
        <S ID="S-26500">In section 2 we describe how to learn bracketing instances from a training corpus.</S>
        <S ID="S-26501">In section 3 we elaborate the syntax-driven bracketing model, including feature generation and the integration of the SDB model into phrase-based SMT.</S>
        <S ID="S-26502">In section 4 and 5, we present our experiments and analysis.</S>
        <S ID="S-26503">And we finally conclude in section 6.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 The Acquisition of Bracketing Instances</HEADER>
      <P>
        <S ID="S-26504">In this section, we formally define the bracketing instance, comprising two types namely binary bracketing instance and unary bracketing instance.</S>
      </P>
      <P>
        <S ID="S-26505">We present an algorithm to automatically extract these bracketing instances from word-aligned bilingual corpus where the source language sentences are parsed.</S>
      </P>
      <P>
        <S ID="S-26506">Let c and e be the source sentence and the target sentence, W be the word alignment between them, T be the parse tree of c.</S>
        <S ID="S-26507">We define a binary bracketing instance as a tuple &#12296;b, &#964;(c i..j ), &#964;(c j+1..k ), &#964;(c i..k )&#12297; where b &#8712; {bracketable, unbracketable}, c i..j and c j+1..k are two neighboring source phrases and &#964;(T, s) (&#964;(s) for short) is a subtree function which returns the minimal subtree covering the source sequence s from the source parse tree T .</S>
        <S ID="S-26508">Note that &#964;(c i..k ) includes both &#964;(c i..j ) and &#964;(c j+1..k ).</S>
        <S ID="S-26509">For the two neighboring source phrases, the following conditions are satisfied:</S>
      </P>
      <P>
        <S ID="S-26510">&#8707;e u..v , e p..q &#8712; e s.t.</S>
      </P>
      <P>
        <S ID="S-26511">&#8704;(m, n) &#8712; W, i &#8804; m &#8804; j &#8596; u &#8804; n &#8804; v (1)</S>
      </P>
      <P>
        <S ID="S-26512">&#8704;(m, n) &#8712; W, j + 1 &#8804; m &#8804; k &#8596; p &#8804; n &#8804; q (2)</S>
      </P>
      <P>
        <S ID="S-26513">The above (1) means that there exists a target phrase e u..v aligned to c i..j and (2) denotes a target phrase e p..q aligned to c j+1..k .</S>
        <S ID="S-26514">If e u..v and e p..q are neighboring to each other or all words between the two phrases are aligned to null, we set b = bracketable, otherwise b = unbracketable.</S>
        <S ID="S-26515">From a binary bracketing instance, we derive a unary bracketing instance &#12296;b, &#964;(c i..k )&#12297;, ignoring the subtrees &#964;(c i..j ) and &#964;(c j+1..k ).</S>
      </P>
      <P>
        <S ID="S-26516">Let n be the number of words of c.</S>
        <S ID="S-26517">If we extract all potential bracketing instances, there will be o(n 2 ) unary instances and o(n 3 ) binary instances.</S>
        <S ID="S-26518">To keep the number of bracketing instances tractable, we only record 4 representative bracketing instances for each index j: 1) the bracketable instance with the minimal &#964;(c i..k ), 2) the bracketable instance with the maximal &#964;(c i..k ), 3) the unbracketable instance with the minimal &#964;(c i..k ), and 4) the unbracketable instance with the maximal &#964;(c i..k ).</S>
      </P>
      <P>
        <S ID="S-26519">Figure 1 shows the algorithm to extract bracketing instances.</S>
        <S ID="S-26520">Line 3-11 find all potential bracketing instances for each (i, j, k) &#8712; c but only keep 4 bracketing instances for each index j: two minimal and two maximal instances.</S>
        <S ID="S-26521">This algorithm learns binary bracketing instances, from which we can derive unary bracketing instances.</S>
      </P>
      <P>
        <S ID="S-26522">1: Input: sentence pair (c, e), the parse tree T of c and the</S>
      </P>
      <P>
        <S ID="S-26523">word alignment W between c and e 2: R := &#8709; 3: for each (i, j, k) &#8712; c do 4: if There exist a target phrase e u..v aligned to c i..j and</S>
      </P>
      <P>
        <S ID="S-26524">e p..q aligned to c j+1..k then 5: Get &#964;(c i..j), &#964;(c j+1..k ), and &#964;(c i..k ) 6: Determine b according to the relationship between e u..v and e p..q 7: if &#964;(c i..k ) is currently maximal or minimal then 8: Update bracketing instances for index j 9: end if 10: end if 11: end for 12: for each j &#8712; c do 13: R := R &#8746; {bracketing instances from j} 14: end for 15: Output: bracketing instances R</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 The Syntax-Driven Bracketing Model</HEADER>
      <P>
        <S ID="S-26598"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 The Model</HEADER>
        <P>
          <S ID="S-26525">Our interest is to automatically detect phrase bracketing using rich contextual information.</S>
          <S ID="S-26526">We consider this task as a binary-class classification problem: whether the current source phrase s is bracketable (b) within particular syntactic contexts (&#964;(s)).</S>
          <S ID="S-26527">If two neighboring sub-phrases s 1 and s 2 are given, we can use more inner syntactic contexts to complete this binary classification task.</S>
        </P>
        <P>
          <S ID="S-26528">We construct the syntax-driven bracketing model within the maximum entropy framework.</S>
          <S ID="S-26529">A unary SDB model is defined as:</S>
        </P>
        <P>
          <S ID="S-26530">P UniSDB (b|&#964;(s), T ) =</S>
        </P>
        <P>
          <S ID="S-26531">exp( &#8721; i &#952; ih i (b, &#964;(s), T ) &#8721;</S>
        </P>
        <P>
          <S ID="S-26532">b exp(&#8721; i &#952; ih i (b, &#964;(s), T )</S>
        </P>
        <P>
          <S ID="S-26533">(3)</S>
        </P>
        <P>
          <S ID="S-26534">where h i &#8712; {0, 1} is a binary feature function which we will describe in the next subsection, and &#952; i is the weight of h i .</S>
          <S ID="S-26535">Similarly, a binary SDB model is defined as:</S>
        </P>
        <P>
          <S ID="S-26536">P BiSDB (b|&#964;(s 1 ), &#964;(s 2 ), &#964;(s), T ) =</S>
        </P>
        <P>
          <S ID="S-26537">exp( &#8721; i &#952; ih i (b, &#964;(s 1 ), &#964;(s 2 ), &#964;(s), T ) &#8721;</S>
        </P>
        <P>
          <S ID="S-26538">b exp(&#8721; i &#952; ih i (b, &#964;(s 1 ), &#964;(s 2 ), &#964;(s), T )</S>
        </P>
        <P>
          <S ID="S-26539">(4)</S>
        </P>
        <P>
          <S ID="S-26540">The most important advantage of ME-based SDB model is its capacity of incorporating more fine-grained contextual features besides the binary feature that detects constituent boundary violation or matching.</S>
          <S ID="S-26541">By employing these features, we can investigate the value of various syntactic constraints in phrase translation.</S>
        </P>
        <P>
          <S ID="S-26542">IP</S>
        </P>
        <P>
          <S ID="S-26543">(a) (b) (c)</S>
        </P>
        <P>
          <S ID="S-26544">VP</S>
        </P>
        <P>
          <S ID="S-26545">NP</S>
        </P>
        <P>
          <S ID="S-26546">NN</S>
        </P>
        <P>
          <S ID="S-26547">jingfang police</S>
        </P>
        <P>
          <S ID="S-26548">ADVP</S>
        </P>
        <P>
          <S ID="S-26549">AD</S>
        </P>
        <P>
          <S ID="S-26550">yi</S>
        </P>
        <P>
          <S ID="S-26551">s 1</S>
        </P>
        <P>
          <S ID="S-26552">VV</S>
        </P>
        <P>
          <S ID="S-26553">fengsuo block</S>
        </P>
        <P>
          <S ID="S-26554">s</S>
        </P>
        <P>
          <S ID="S-26555">s 2</S>
        </P>
        <P>
          <S ID="S-26556">VP</S>
        </P>
        <P>
          <S ID="S-26557">AS</S>
        </P>
        <P>
          <S ID="S-26558">le</S>
        </P>
        <P>
          <S ID="S-26559">NN</S>
        </P>
        <P>
          <S ID="S-26560">baozha bomb NP</S>
        </P>
        <P>
          <S ID="S-26561">NN</S>
        </P>
        <P>
          <S ID="S-26562">xianchang scene</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Syntax-Driven Features</HEADER>
        <P>
          <S ID="S-26563">Let s be the source phrase in question, s 1 and s 2 be the two neighboring sub-phrases.</S>
          <S ID="S-26564">&#963;(.</S>
          <S ID="S-26565">) is the root node of &#964;(.).</S>
          <S ID="S-26566">The SDB model exploits various syntactic features as follows.</S>
        </P>
        <P>
          <S ID="S-26567">&#8226; Rule Features (RF) We use the CFG rules of &#963;(s), &#963;(s 1 ) and &#963;(s 2 ) as features.</S>
          <S ID="S-26568">These features capture syntactic &#8220;horizontal context&#8221; which demonstrates the expansion trend of the source phrase s, s 1 and s 2 on the parse tree.</S>
        </P>
        <P>
          <S ID="S-26569">In figure 2, the CFG rule &#8220;ADVP&#8594;AD&#8221;, &#8220;VP&#8594;VV AS NP&#8221;, and &#8220;VP&#8594;ADVP VP&#8221; are used as features for s 1 , s 2 and s respectively.</S>
        </P>
        <P>
          <S ID="S-26570">&#8226; Path Features (PF) The tree path &#963;(s 1 )..&#963;(s) connecting &#963;(s 1 ) and &#963;(s), &#963;(s 2 )..&#963;(s) connecting &#963;(s 2 ) and &#963;(s), and &#963;(s)..&#961; connecting &#963;(s) and the root node &#961; of the whole parse tree are used as features.</S>
          <S ID="S-26571">These features provide syntactic &#8220;vertical context&#8221; which shows the generation history of the source phrases on the parse tree.</S>
        </P>
        <P>
          <S ID="S-26572">In figure 2, the path features are &#8220;ADVP VP&#8221;, &#8220;VP VP&#8221; and &#8220;VP IP&#8221; for s 1 , s 2 and s respectively.</S>
        </P>
        <P>
          <S ID="S-26573">&#8226; Constituent Boundary Matching Features (CBMF) These features are to capture the relationship between a source phrase s and &#964;(s) or &#964;(s)&#8217;s subtrees.</S>
          <S ID="S-26574">There are three different scenarios 3 : 1) exact match, where s exactly matches the boundaries of &#964;(s) (figure 3(a)), 2) inside match, where s exactly spans a sequence of &#964;(s)&#8217;s subtrees (figure 3(b)), and 3) crossing, where s crosses the boundaries of one or two subtrees of &#964;(s) (figure 3(c)).</S>
          <S ID="S-26575">In the case of 1) or 2), we set the value of this feature to &#963;(s)-M or &#963;(s)-I respectively.</S>
          <S ID="S-26576">When s crosses the boundaries of the subconstituent &#603; l on s&#8217;s left, we set the value to &#963;(&#603; l )-LC; If s crosses the boundaries of the sub-constituent &#603; r on s&#8217;s right, we set the value to &#963;(&#603; r )-RC; If both, we set the value to &#963;(&#603; l )-LC-&#963;(&#603; r )-RC.</S>
        </P>
        <P>
          <S ID="S-26577">Let&#8217;s revisit the Figure 2.</S>
          <S ID="S-26578">The source phrase s 1 exactly matches the constituent ADVP, therefore CBMF is &#8220;ADVP-M&#8221;.</S>
          <S ID="S-26579">The source phrase s 2 exactly spans two sub-trees VV and AS of VP, therefore CBMF is &#8220;VP-I&#8221;.</S>
          <S ID="S-26580">Finally, the source phrase s cross boundaries of the lower VP on the right, therefore CBMF is &#8220;VP-RC&#8221;.</S>
        </P>
        <P>
          <S ID="S-26581">3.3 The Integration of the SDB Model into Phrase-Based SMT</S>
        </P>
        <P>
          <S ID="S-26582">We integrate the SDB model into phrase-based SMT to help decoder perform syntax-driven phrase translation.</S>
          <S ID="S-26583">In particular, we add a</S>
        </P>
        <P>
          <S ID="S-26584">3 The three scenarios that we define here are similar to</S>
        </P>
        <P>
          <S ID="S-26585">those in (L&#252; et al., 2002).</S>
        </P>
        <P>
          <S ID="S-26586">new feature into the log-linear translation model: P SDB (b|T, &#964;(.)).</S>
          <S ID="S-26587">This feature is computed by the SDB model described in equation (3) or equation (4), which estimates a probability that a source span is to be translated as a unit within particular syntactic contexts.</S>
          <S ID="S-26588">If a source span can be translated as a unit, the feature will give a higher probability even though this span violates boundaries of a constituent.</S>
          <S ID="S-26589">Otherwise, a lower probability is given.</S>
          <S ID="S-26590">Through this additional feature, we want the decoder to prefer hypotheses that translate source spans which can be translated as a unit, and avoids translating those which are discontinuous after translation.</S>
          <S ID="S-26591">The weight of this new feature is tuned via MERT, which measures the extent to which this feature should be trusted.</S>
        </P>
        <P>
          <S ID="S-26592">In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar (BTG) (Wu, 1997) to phrase translation and reordering, described in (Xiong et al., 2006).</S>
          <S ID="S-26593">Whenever a BTG merging rule (s &#8594; [s 1 s 2 ] or s &#8594; &#12296;s 1 s 2 &#12297;) is used, the SDB model gives a probability to the span s covered by the rule, which estimates the extent to which the span is bracketable.</S>
          <S ID="S-26594">For the unary SDB model, we only consider the features from &#964;(s).</S>
          <S ID="S-26595">For the binary SDB model, we use all features from &#964;(s 1 ), &#964;(s 2 ) and &#964;(s) since the binary SDB model is naturally suitable to the binary BTG rules.</S>
          <S ID="S-26596">The SDB model, however, is not only limited to phrase-based SMT using BTG rules.</S>
          <S ID="S-26597">Since it is applied on a source span each time, any other hierarchical phrase-based or syntax-based system that translates source spans recursively or linearly, can adopt the SDB model.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Experiments</HEADER>
      <P>
        <S ID="S-26620">We carried out the MT experiments on Chineseto-English translation, using (Xiong et al., 2006)&#8217;s system as our baseline system.</S>
        <S ID="S-26621">We modified the baseline decoder to incorporate our SDB models as descried in section 3.3.</S>
        <S ID="S-26622">In order to compare with Marton and Resnik&#8217;s approach, we also adapted the baseline decoder to their XP+ feature.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Experimental Setup</HEADER>
        <P>
          <S ID="S-26599">In order to obtain syntactic trees for SDB models and XP+, we parsed source sentences using a lexicalized PCFG parser (Xiong et al., 2005).</S>
          <S ID="S-26600">The parser was trained on the Penn Chinese Treebank with an F1 score of 79.4%.</S>
        </P>
        <P>
          <S ID="S-26601">All translation models were trained on the FBIS corpus.</S>
          <S ID="S-26602">We removed 15,250 sentences, for which the Chinese parser failed to produce syntactic parse trees.</S>
          <S ID="S-26603">To obtain word-level alignments, we ran GIZA++ (Och and Ney, 2000) on the remaining corpus in both directions, and applied the &#8220;grow-diag-final&#8221; refinement rule (Koehn et al., 2005) to produce the final many-to-many word alignments.</S>
          <S ID="S-26604">We built our four-gram language model using Xinhua section of the English Gigaword corpus (181.1M words) with the SRILM toolkit (Stolcke, 2002).</S>
        </P>
        <P>
          <S ID="S-26605">For the efficiency of MERT, we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 set.</S>
          <S ID="S-26606">We evaluated all models on the NIST MT-05 set using case-sensitive BLEU-4.</S>
          <S ID="S-26607">Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 SDB Training</HEADER>
        <P>
          <S ID="S-26608">We extracted 6.55M bracketing instances from our training corpus using the algorithm shown in figure 1, which contains 4.67M bracketable instances and 1.89M unbracketable instances.</S>
          <S ID="S-26609">From extracted bracketing instances we generated syntaxdriven features, which include 73,480 rule features, 153,614 path features and 336 constituent boundary matching features.</S>
          <S ID="S-26610">To tune weights of features, we ran the MaxEnt toolkit (Zhang, 2004) with iteration number being set to 100 and Gaussian prior to 1 to avoid overfitting.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.3 Results</HEADER>
        <P>
          <S ID="S-26611">We ran the MERT module with our decoders to tune the feature weights.</S>
          <S ID="S-26612">The values are shown in Table 1.</S>
          <S ID="S-26613">The P SDB receives the largest feature weight, 0.29 for UniSDB and 0.38 for BiSDB, indicating that the SDB models exert a nontrivial impact on decoder.</S>
        </P>
        <P>
          <S ID="S-26614">In Table 2, we present our results.</S>
          <S ID="S-26615">Like (Marton and Resnik, 2008), we find that the XP+ feature obtains a significant improvement of 1.08 BLEU over the baseline.</S>
          <S ID="S-26616">However, using all syntax-driven features described in section 3.2, our SDB models achieve larger improvements of up to 1.67 BLEU.</S>
          <S ID="S-26617">The binary SDB (BiSDB) model statistically significantly outperforms Marton and Resnik&#8217;s XP+ by an absolute improvement of 0.59 (relatively 2%).</S>
          <S ID="S-26618">It is also marginally better than the unary SDB model.</S>
        </P>
        <P>
          <S ID="S-26619">Features</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Analysis</HEADER>
      <P>
        <S ID="S-26682">In this section, we present analysis to perceive the influence mechanism of the SDB model on phrase translation by studying the effects of syntax-driven features and differences of 1-best translation outputs.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>5.1 Effects of Syntax-Driven Features</HEADER>
        <P>
          <S ID="S-26623">We conducted further experiments using individual syntax-driven features and their combinations.</S>
          <S ID="S-26624">Table 3 shows the results, from which we have the following key observations.</S>
        </P>
        <P>
          <S ID="S-26625">&#8226; The constituent boundary matching feature (CBMF) is a very important feature, which by itself achieves significant improvement over the baseline (up to 1.13 BLEU).</S>
          <S ID="S-26626">Both our CBMF and Marton and Resnik&#8217;s XP+ feature focus on the relationship between a source phrase and a constituent.</S>
          <S ID="S-26627">Their significant contribution to the improvement implies that this relationship is an important syntactic constraint for phrase translation.</S>
        </P>
        <P>
          <S ID="S-26628">&#8226; Adding more features, such as path feature and rule feature, achieves further improvements.</S>
          <S ID="S-26629">This demonstrates the advantage of using more syntactic constraints in the SDB model, compared with Marton and Resnik&#8217;s XP+.</S>
        </P>
        <P>
          <S ID="S-26630">&#8226; In most cases, the binary SDB is constantly significantly better than the unary SDB, suggesting that inner contexts are useful in predicting phrase bracketing.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>5.2 Beyond BLEU</HEADER>
        <P>
          <S ID="S-26631">We want to further study the happenings after we integrate the constraint feature (our SDB model and Marton and Resnik&#8217;s XP+) into the log-linear translation model.</S>
          <S ID="S-26632">In particular, we want to investigate: to what extent syntactic constraints change translation outputs?</S>
          <S ID="S-26633">And in what direction the changes take place?</S>
          <S ID="S-26634">Since BLEU is not sufficient</S>
        </P>
        <P>
          <S ID="S-26635">to provide such insights, we introduce a new statistical metric which measures the proportion of syntactic constituents 4 whose boundaries are consistently matched by decoder during translation.</S>
          <S ID="S-26636">This proportion, which we call consistent constituent matching (CCM) rate , reflects the extent to which the translation output respects the source parse tree.</S>
        </P>
        <P>
          <S ID="S-26637">In order to calculate this rate, we output translation results as well as phrase alignments found by decoders.</S>
          <S ID="S-26638">Then for each multi-branch constituent c j i spanning from i to j on the source side, we check the following conditions.</S>
        </P>
        <P>
          <S ID="S-26639">&#8226; If its boundaries i and j are aligned to phrase segmentation boundaries found by decoder.</S>
        </P>
        <P>
          <S ID="S-26640">&#8226; If all target phrases inside c j i &#8217;s target span 5</S>
        </P>
        <P>
          <S ID="S-26641">are aligned to the source phrases within c j i and not to the phrases outside c j i .</S>
        </P>
        <P>
          <S ID="S-26642">If both conditions are satisfied, the constituent c j i is consistently matched by decoder.</S>
        </P>
        <P>
          <S ID="S-26643">Table 4 shows the consistent constituent matching rates.</S>
          <S ID="S-26644">Without using any source-side syntactic information, the baseline obtains a low CCM rate of 43.53%, indicating that the baseline decoder violates the source parse tree more than it respects the source structure.</S>
          <S ID="S-26645">The translation output described in section 1 is actually generated by the baseline decoder, where the second NP phrase boundaries are violated.</S>
        </P>
        <P>
          <S ID="S-26646">By integrating syntactic constraints into decoding, we can see that both Marton and Resnik&#8217;s XP+ and our SDB model achieve a significantly higher constituent matching rate, suggesting that they are more likely to respect the source structure.</S>
          <S ID="S-26647">The examples in Table 5 show that the decoder is able to generate better translations if it is</S>
        </P>
        <P>
          <S ID="S-26648">4 We only consider multi-branch constituents.</S>
          <S ID="S-26649">5 Given a phrase alignment P = {c g f &#8596; eq p}, if the segmentation within c j i defined by P is cj i = c j 1</S>
        </P>
        <P>
          <S ID="S-26650">i1</S>
        </P>
        <P>
          <S ID="S-26651">...c j k</S>
        </P>
        <P>
          <S ID="S-26652">ik</S>
        </P>
        <P>
          <S ID="S-26653">, and &#8596; e vr u r &#8712; P, 1 &#8804; r &#8804; k, we define the target span of c j i c jr i r as a pair where the first element is min(e u1 ...e uk ) and the second element is max(e v1 ...e vk ), similar to (Fox, 2002).</S>
        </P>
        <P>
          <S ID="S-26654">faithful to the source parse tree by using syntactic constraints.</S>
        </P>
        <P>
          <S ID="S-26655">We further conducted a deep comparison of translation outputs of BiSDB vs. XP+ with regard to constituent matching and violation.</S>
          <S ID="S-26656">We found two significant differences that may explain why our BiSDB outperforms XP+.</S>
          <S ID="S-26657">First, although the overall CCM rate of XP+ is higher than that of BiSDB, BiSDB obtains higher CCM rates for long-span structures than XP+ does, which are shown in Table 6.</S>
          <S ID="S-26658">Generally speaking, violations of long-span constituents have a more negative impact on performance than short-span violations if these violations are toxic.</S>
          <S ID="S-26659">This explains why BiSDB achieves relatively higher precision improvements for higher n-grams over XP+, as shown in Table 3.</S>
        </P>
        <P>
          <S ID="S-26660">Second, compared with XP+ that only punishes constituent boundary violations, our SDB model is able to encourage violations if these violations are done on bracketable phrases.</S>
          <S ID="S-26661">We observed in many cases that by violating constituent boundaries BiSDB produces better translations than XP+ does, which on the contrary matches these boundaries.</S>
          <S ID="S-26662">Still consider the example shown in section 1.</S>
          <S ID="S-26663">The following translations are found by XP+ and BiSDB respectively.</S>
        </P>
        <P>
          <S ID="S-26664">XP+: [to/&#65533; &#12296;[set up/&#65533; &#65533; [for the/&#65533; [navigation/&#65533;&#65533; section/&#65533;]]] on July 11/7&#65533;11&#65533;&#12297;]</S>
        </P>
        <P>
          <S ID="S-26665">BiSDB: [to/&#65533; &#12296;[[set up/&#65533;&#65533; a/&#65533;] [marine/&#65533;&#65533; festival/&#65533;]] on July 11/7&#65533;11&#65533;&#12297;]</S>
        </P>
        <P>
          <S ID="S-26666">XP+ here matches all constituent boundaries while BiSDB violates the PP constituent to translate the non-syntactic phrase &#8220;&#65533;&#65533; &#65533;&#8221;.</S>
          <S ID="S-26667">Table 7 shows more examples.</S>
          <S ID="S-26668">From these examples, we clearly see that appropriate violations are helpful and even necessary for generating better translations.</S>
          <S ID="S-26669">By allowing appropriate violations to translate nonsyntactic phrases according to particular syntactic contexts, our SDB model better inherits the strength of phrase-based approach than XP+.</S>
        </P>
        <P>
          <S ID="S-26670">Src: Ref: Baseline:</S>
        </P>
        <P>
          <S ID="S-26671">XP+:</S>
        </P>
        <P>
          <S ID="S-26672">BiSDB:</S>
        </P>
        <P>
          <S ID="S-26673">Src: Ref: Baseline:</S>
        </P>
        <P>
          <S ID="S-26674">XP+:</S>
        </P>
        <P>
          <S ID="S-26675">BiSDB:</S>
        </P>
        <P>
          <S ID="S-26676">[[&#65533; [&#65533;&#65533; &#65533; &#65533;&#65533; &#65533;&#65533;] NP ] PP [&#65533;&#65533; [&#65533;&#65533;] NP [&#65533; &#65533; &#65533;&#65533;] NP ] VP ] VP show their loving hearts to people in the Indian Ocean disaster areas &#12296;love/&#65533;&#65533; [for the/&#65533; &#12296;[people/&#65533;&#65533; [to/&#65533;&#65533; [own/&#65533;&#65533; a report/&#65533;&#65533;]]]&#12297; &#12296;in/&#65533;&#65533; the Indian Ocean/&#65533; &#65533;&#65533;&#12297;]&#12297; &#12296;[contribute/&#65533;&#65533; [its/&#65533;&#65533; [part/&#65533;&#65533; love/&#65533;&#65533;]]] [for/&#65533; &#12296;the people/&#65533;&#65533; &#12296;in/&#65533;&#65533; the Indian Ocean/&#65533; &#65533;&#65533;&#12297;&#12297;]&#12297; &#12296;[[[contribute/&#65533;&#65533; its/&#65533;&#65533;] part/&#65533;&#65533;] love/&#65533;&#65533;] [for/&#65533; &#12296;the people/&#65533;&#65533; &#12296;in/&#65533;&#65533; the Indian Ocean&#65533; &#65533;&#65533;&#12297;&#12297;]&#12297; [&#65533;&#65533;&#65533;&#65533; [&#65533;] ADVP [&#65533;&#65533; [[&#65533;&#65533; &#65533;] QP &#65533;&#65533;] NP [&#65533; &#65533;&#65533;] PP ] VP ] IP [&#65533;] PU [&#65533;&#65533; &#65533;&#65533;...] IP The Pentagon has dispatched 20 airplanes to South Asia, including... [[The Pentagon/&#65533;&#65533;&#65533;&#65533; has sent/&#65533;&#65533;&#65533;] [&#12296;[to/&#65533; [[South Asia/&#65533;&#65533; ,/&#65533;] including/&#65533;&#65533;&#65533;&#65533;]] [20/&#65533; &#65533; plane/&#65533;&#65533;&#65533;]&#12297;]] [The Pentagon/&#65533;&#65533;&#65533;&#65533; [has/&#65533; [sent/&#65533;&#65533; [[20/&#65533;&#65533; planes/&#65533;&#65533;&#65533;] [to/&#65533; South Asia/&#65533;&#65533;]]]]] [,/&#65533; [including/&#65533;&#65533;&#65533;&#65533;...]] [The Pentagon/&#65533;&#65533;&#65533;&#65533; [has sent/&#65533;&#65533;&#65533; [[20/&#65533;&#65533; planes/&#65533;&#65533;&#65533;] [to/&#65533; South Asia/&#65533;&#65533;]]] [,/&#65533; [including/&#65533;&#65533;&#65533;&#65533;...]]</S>
        </P>
        <P>
          <S ID="S-26677">Src: Ref: XP+:</S>
        </P>
        <P>
          <S ID="S-26678">BiSDB:</S>
        </P>
        <P>
          <S ID="S-26679">Src: Ref: XP+:</S>
        </P>
        <P>
          <S ID="S-26680">BiSDB: [[&#65533; [[[&#65533;&#65533;&#65533;&#65533;&#65533; &#65533; &#65533;&#65533;] NP [&#65533;&#65533;] ADJP [&#65533;&#65533;] NP ] NP &#65533;] LCP ] PP &#65533;&#65533;] VP said after a brief discussion with Powell at the US State Department [&#12296;after/&#65533; &#12296;&#12296;[a brief/&#65533;&#65533; meeting/&#65533;&#65533;] [with/&#65533; Powell/&#65533;&#65533;]&#12297; [in/&#65533; the US State Department/&#65533;&#65533;&#65533; &#65533;&#65533;]&#12297; said/&#65533;&#65533;] &#12296;said after/&#65533; &#65533;&#65533; &#12296;[a brief/&#65533;&#65533; meeting/&#65533;&#65533;] &#12296; with Powell/&#65533; &#65533;&#65533; [at/&#65533; the State Department of the United States/&#65533;&#65533;&#65533;&#65533;&#65533;]&#12297;&#12297;&#12297; [&#65533; [[&#65533;&#65533; [&#65533;&#65533; &#65533;&#65533; &#65533;&#65533;] NP ] VP ] IP ] PP [&#65533;&#65533; &#65533; [&#65533;&#65533;&#65533; &#65533; &#65533; &#65533;] NP ] VP took a key step towards building future democratic politics &#12296;[a/&#65533; [key/&#65533;&#65533;&#65533; step/&#65533;&#65533;&#65533;]] &#12296;forward/&#65533;&#65533; [to/&#65533; [a/&#65533;&#65533; [future/&#65533;&#65533; political democracy/&#65533;&#65533;&#65533; &#65533;]]]&#12297;&#12297; &#12296;[made a/&#65533;&#65533;&#65533; [key/&#65533;&#65533;&#65533; step/&#65533;&#65533;&#65533;]] [towards establishing a/&#65533; &#65533;&#65533; &#12296;democratic politics/&#65533;&#65533;&#65533;</S>
        </P>
        <P>
          <S ID="S-26681">&#65533; in the future/&#65533;&#65533;&#12297;]&#12297;</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>6 Conclusion</HEADER>
      <P>
        <S ID="S-26683">In this paper, we presented a syntax-driven bracketing model that automatically learns bracketing knowledge from training corpus.</S>
        <S ID="S-26684">With this knowledge, the model is able to predict whether source phrases can be translated together, regardless of matching or crossing syntactic constituents.</S>
        <S ID="S-26685">We integrate this model into phrase-based SMT to increase its capacity of linguistically motivated translation without undermining its strengths.</S>
        <S ID="S-26686">Experiments show that our model achieves substantial improvements over baseline and significantly outperforms (Marton and Resnik, 2008)&#8217;s XP+.</S>
      </P>
      <P>
        <S ID="S-26687">Compared with previous constituency feature, our SDB model is capable of incorporating more syntactic constraints, and rewarding necessary violations of the source parse tree.</S>
        <S ID="S-26688">Marton and Resnik (2008) find that their constituent constraints are sensitive to language pairs.</S>
        <S ID="S-26689">In the future work, we will use other language pairs to test our models so that we could know whether our method is language-independent.</S>
      </P>
      <P>
        <S ID="S-26690">References</S>
      </P>
      <P>
        <S ID="S-26691">Colin Cherry.</S>
        <S ID="S-26692">2008.</S>
        <S ID="S-26693">Cohesive Phrase-based Decoding for Statistical Machine Translation.</S>
        <S ID="S-26694">In Proceedings of ACL.</S>
      </P>
      <P>
        <S ID="S-26695">David Chiang.</S>
        <S ID="S-26696">2005.</S>
        <S ID="S-26697">A Hierarchical Phrase-based Model for Statistical Machine Translation.</S>
        <S ID="S-26698">In Proceedings of ACL, pages 263&#8211;270.</S>
      </P>
      <P>
        <S ID="S-26699">David Chiang, Yuval Marton and Philip Resnik.</S>
        <S ID="S-26700">2008.</S>
        <S ID="S-26701">Online Large-Margin Training of Syntactic and Structural Translation Features.</S>
        <S ID="S-26702">In Proceedings of EMNLP.</S>
      </P>
      <P>
        <S ID="S-26703">Heidi J. Fox 2002.</S>
        <S ID="S-26704">Phrasal Cohesion and Statistical Machine Translation.</S>
        <S ID="S-26705">In Proceedings of EMNLP, pages 304&#8211;311.</S>
      </P>
      <P>
        <S ID="S-26706">Philipp Koehn, Franz Joseph Och, and Daniel Marcu.</S>
        <S ID="S-26707">2003.</S>
        <S ID="S-26708">Statistical Phrase-based Translation.</S>
        <S ID="S-26709">In Proceedings of HLT-NAACL.</S>
      </P>
      <P>
        <S ID="S-26710">Philipp Koehn.</S>
        <S ID="S-26711">2004.</S>
        <S ID="S-26712">Statistical Significance Tests for Machine Translation Evaluation.</S>
        <S ID="S-26713">In Proceedings of EMNLP.</S>
      </P>
      <P>
        <S ID="S-26714">Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne and David Talbot.</S>
        <S ID="S-26715">2005.</S>
        <S ID="S-26716">Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation.</S>
        <S ID="S-26717">In International Workshop on Spoken Language Translation.</S>
      </P>
      <P>
        <S ID="S-26718">Yajuan L&#252;, Sheng Li, Tiezhun Zhao and Muyun Yang.</S>
        <S ID="S-26719">2002.</S>
        <S ID="S-26720">Learning Chinese Bracketing Knowledge Based on a Bilingual Language Model.</S>
        <S ID="S-26721">In Proceedings of COLING.</S>
      </P>
      <P>
        <S ID="S-26722">Yuval Marton and Philip Resnik.</S>
        <S ID="S-26723">2008.</S>
        <S ID="S-26724">Soft Syntactic Constraints for Hierarchical Phrase-Based Translation.</S>
        <S ID="S-26725">In Proceedings of ACL.</S>
      </P>
      <P>
        <S ID="S-26726">Franz Josef Och and Hermann Ney.</S>
        <S ID="S-26727">2000.</S>
        <S ID="S-26728">Improved Statistical Alignment Models.</S>
        <S ID="S-26729">In Proceedings of ACL 2000.</S>
      </P>
      <P>
        <S ID="S-26730">Franz Josef Och.</S>
        <S ID="S-26731">2003.</S>
        <S ID="S-26732">Minimum Error Rate Training in Statistical Machine Translation.</S>
        <S ID="S-26733">In Proceedings of ACL 2003.</S>
      </P>
      <P>
        <S ID="S-26734">Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu.</S>
        <S ID="S-26735">2002.</S>
        <S ID="S-26736">Bleu: a Method for Automatically Evaluation of Machine Translation.</S>
        <S ID="S-26737">In Proceedings of ACL.</S>
      </P>
      <P>
        <S ID="S-26738">Andreas Stolcke.</S>
        <S ID="S-26739">2002.</S>
        <S ID="S-26740">SRILM - an Extensible Language Modeling Toolkit.</S>
        <S ID="S-26741">In Proceedings of International Conference on Spoken Language Processing, volume 2, pages 901-904.</S>
      </P>
      <P>
        <S ID="S-26742">Dekai Wu.</S>
        <S ID="S-26743">1997.</S>
        <S ID="S-26744">Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora.</S>
        <S ID="S-26745">Computational Linguistics, 23(3):377-403.</S>
      </P>
      <P>
        <S ID="S-26746">Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin, Yueliang Qian.</S>
        <S ID="S-26747">2005.</S>
        <S ID="S-26748">Parsing the Penn Chinese Treebank with Semantic Knowledge.</S>
        <S ID="S-26749">In Proceedings of IJCNLP, Jeju Island, Korea.</S>
      </P>
      <P>
        <S ID="S-26750">Deyi Xiong, Qun Liu and Shouxun Lin.</S>
        <S ID="S-26751">2006.</S>
        <S ID="S-26752">Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation.</S>
        <S ID="S-26753">In Proceedings of ACL-COLING 2006.</S>
      </P>
      <P>
        <S ID="S-26754">Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.</S>
        <S ID="S-26755">2008.</S>
        <S ID="S-26756">Linguistically Annotated BTG for Statistical Machine Translation.</S>
        <S ID="S-26757">In Proceedings of COLING 2008.</S>
      </P>
      <P>
        <S ID="S-26758">Le Zhang.</S>
        <S ID="S-26759">2004.</S>
        <S ID="S-26760">Maximum Entropy Modeling Tooklkit for Python and C++.</S>
        <S ID="S-26761">Available at http://homepages.inf.ed.ac.uk/s0450736 /maxent toolkit.html.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS/>
  <REFERENCES/>
</PAPER>
