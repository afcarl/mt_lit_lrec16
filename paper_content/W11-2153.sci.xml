<PAPER>
  <FILENO/>
  <TITLE>Influence of Parser Choice on Dependency-Based MT</TITLE>
  <AUTHORS>
    <AUTHOR>Martin Popel</AUTHOR>
    <AUTHOR>David Mare&#269;ek</AUTHOR>
    <AUTHOR>Nathan Green</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-722689">Accuracy of dependency parsers is one of the key factors limiting the quality of dependencybased machine translation.</A-S>
    <A-S ID="S-722690">This paper deals with the influence of various dependency parsing approaches (and also different training data size) on the overall performance of an English-to-Czech dependency-based statistical translation system implemented in the Treex framework.</A-S>
    <A-S ID="S-722691">We also study the relationship between parsing accuracy in terms of unlabeled attachment score and machine translation quality in terms of BLEU.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-722692">In the last years, statistical n-gram models dominated the field of Machine Translation (MT).</S>
        <S ID="S-722693">However, their results are still far from perfect.</S>
        <S ID="S-722694">Therefore we believe it makes sense to investigate alternative statistical approaches.</S>
        <S ID="S-722695">This paper is focused on an analysis-transfer-synthesis translation system called TectoMT whose transfer representation has a shape of a deep-syntactic dependency tree.</S>
        <S ID="S-722696">The system has been introduced by <REF ID="R-17" RPTR="25">&#381;abokrtsk&#253; et al. (2008)</REF>.</S>
        <S ID="S-722697">The translation direction under consideration is Englishto-Czech.</S>
      </P>
      <P>
        <S ID="S-722698">It has been shown by <REF ID="R-12" RPTR="17">Popel (2009)</REF> that the current accuracy of the dependency parser employed in this translation system is one of the limiting factors from the viewpoint of its output quality.</S>
        <S ID="S-722699">In other words, the parsing phase is responsible for a large portion of translation errors.</S>
        <S ID="S-722700">The biggest source of translation errors in the referred study was (and probably still is) the transfer phase, however the proportion has changed since and the relative importance of the parsing phase has grown, because the tranfer phase errors have already been addressed by improvements based on Hidden Markov Tree Models for lexical and syntactic choice as shown by <REF ID="R-16" RPTR="24">&#381;abokrtsk&#253; and Popel (2009)</REF><REF ID="R-12" RPTR="18">Popel (2009)</REF>, and by context sensitive translation models based on maximum entropy as described by <REF ID="R-08" RPTR="11">Mare&#269;ek et al. (2010)</REF>.</S>
        <S ID="S-722701">Our study proceeds along two directions.</S>
        <S ID="S-722702">First, we train two state-of-the-art dependency parsers on training sets with varying size.</S>
        <S ID="S-722703">Second, we use five parsers based on different parsing techniques.</S>
        <S ID="S-722704">In both cases we document the relation between parsing accuracy (in terms of Unlabeled Attachment Score, UAS) and translation quality (estimated by the well known BLEU metric).</S>
      </P>
      <P>
        <S ID="S-722705">The motivation behind the first set of experiments is that we can extrapolate the learning curve and try to predict how new advances in dependency parsing can affect MT quality in the future.</S>
      </P>
      <P>
        <S ID="S-722706">The second experiment series is motivated by the hypothesis that parsers based on different approaches are likely to have a different distribution of errors, even if they can have competitive performance in parsing accuracy.</S>
        <S ID="S-722707">In dependency parsing metrics, all types of incorrect edges typically have the same weight, 1 but some incorrect edges can be more harmful than others from the MT viewpoint.</S>
        <S ID="S-722708">For instance, an incorrect attachment of an adverbial node is usually harmless, while incorrect attachment of a subject node might have several negative conse-</S>
      </P>
      <P>
        <S ID="S-722709">1 This issue has been tackled already in the parsing literature;</S>
      </P>
      <P>
        <S ID="S-722710">for example, some authors disregard placement of punctuation nodes within trees in the evaluation (<REF ID="R-18" RPTR="27">Zeman, 2004</REF>).</S>
      </P>
      <P>
        <S ID="S-722711">quences such as:</S>
      </P>
      <P>
        <S ID="S-722712">&#8226; unrecognized finiteness of the governing verb, which can lead to a wrong syntactization on the target side (an infinitive verb phrase instead of a finite clause),</S>
      </P>
      <P>
        <S ID="S-722713">&#8226; wrong choice of the target-side verb form (because of unrecognized subject-predicate agreement),</S>
      </P>
      <P>
        <S ID="S-722714">&#8226; missing punctuation (because of wrongly recognized finite clause boundaries),</S>
      </P>
      <P>
        <S ID="S-722715">&#8226; wrong placement of clitics (because of wrongly recognized finite clause boundaries),</S>
      </P>
      <P>
        <S ID="S-722716">&#8226; wrong form of pronouns (personal and possessive pronouns referring to the clause&#8217;s subject should have reflexive forms in Czech).</S>
      </P>
      <P>
        <S ID="S-722717">Thus it is obvious that the parser choice is important and that it might not be enough to choose a parser, for machine translation, only according to its UAS.</S>
      </P>
      <P>
        <S ID="S-722718">Due to growing popularity of dependency syntax in the last years, there are a number of dependency parsers available.</S>
        <S ID="S-722719">The present paper deals with five parsers evaluated within the translation framework: three genuine dependency parsers, namely the parsers described in (<REF ID="R-10" RPTR="14">McDonald et al., 2005</REF>), (<REF ID="R-11" RPTR="16">Nivre et al., 2007</REF>), and (<REF ID="R-19" RPTR="28">Zhang and Nivre, 2011</REF>), and two constituency parsers (<REF ID="R-01" RPTR="1">Charniak and Johnson, 2005</REF>) and (<REF ID="R-06" RPTR="8">Klein and Manning, 2003</REF>), whose outputs were converted to dependency structures by Penn Converter (<REF ID="R-05" RPTR="5">Johansson and Nugues, 2007</REF>).</S>
      </P>
      <P>
        <S ID="S-722720">As for the related literature, there is no published study measuring the influence of dependency parsers on dependency-based MT to our knowledge.</S>
        <S ID="S-722721">2 The remainder of this paper is structured as follows.</S>
        <S ID="S-722722">The overall translation pipeline, within which the parsers are tested, is described in Section 2.</S>
        <S ID="S-722723">Section 3 lists the parsers under consideration and their main features.</S>
        <S ID="S-722724">Section 4 summarizes the influence of the selected parsers on the MT quality in terms of BLEU.</S>
        <S ID="S-722725">Section 5 concludes.</S>
      </P>
      <P>
        <S ID="S-722726">2 However, the parser bottleneck of the dependency-based</S>
      </P>
      <P>
        <S ID="S-722727">MT approach was observed also by other researchers (Robert Moore, personal communication).</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Dependency-based Translation in Treex</HEADER>
      <P>
        <S ID="S-722750">We have implemented our experiments in the Treex software framework (formerly TectoMT, introduced by <REF ID="R-17" RPTR="26">&#381;abokrtsk&#253; et al. (2008)</REF>), which already offers tool chains for analysis and synthesis of Czech and English sentences.</S>
      </P>
      <P>
        <S ID="S-722751">We use the tectogrammatical (deep-syntactic) layer of language representation as the transfer layer in the presented MT experiments.</S>
        <S ID="S-722752">Tectogrammatics was introduced by <REF ID="R-13" RPTR="20">Sgall (1967)</REF> and further elaborated within the Prague Dependency Treebank project (Haji&#269; et al., 2006).</S>
        <S ID="S-722753">On this layer, each sentence is represented as a tectogrammatical tree, whose main properties (from the MT viewpoint) are the following:</S>
      </P>
      <P>
        <S ID="S-722754">1. nodes represent autosemantic words,</S>
      </P>
      <P>
        <S ID="S-722755">2. edges represent semantic dependencies (a node is an argument or a modifier of its parent),</S>
      </P>
      <P>
        <S ID="S-722756">3. there are no functional words (prepositions, auxiliary words) in the tree, and the autosemantic words appear only in their base forms (lemmas).</S>
        <S ID="S-722757">Morphologically indispensable categories (such as number with nouns or tense with verbs, but not number with verbs as it is only imposed by agreement) are stored in separate node attributes (grammatemes).</S>
      </P>
      <P>
        <S ID="S-722758">The intuitions behind the decision to use tectogrammatics for MT are the following: we believe that (1) tectogrammatics largely abstracts from language-specific means (inflection, agglutination, functional words etc.) of expressing non-lexical meanings and thus tectogrammatical trees are supposed to be highly similar across languages, (2) it enables a natural transfer factorization, 3 (3) and local tree contexts in tectogrammatical trees carry more information (especially for lexical choice) than local linear contexts in the original sentences.</S>
      </P>
      <P>
        <S ID="S-722759">The translation scenario is outlined in the rest of this section.</S>
      </P>
      <P>
        <S ID="S-722760">3 Morphological categories can be translated almost independently from lemmas, which makes parallel training data &#8216;denser&#8217;, especially when translating from/to a language with rich inflection such as Czech.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>2.1 Analysis</HEADER>
        <P>
          <S ID="S-722728">The input English text is segmented into sentences and tokens.</S>
          <S ID="S-722729">The tokens are lemmatized and tagged with Penn Treebank tags using the Morce tagger (<REF ID="R-14" RPTR="21">Spoustov&#225; et al., 2007</REF>).</S>
          <S ID="S-722730">Then one of the studied dependency parsers is applied and a surface-syntax dependency tree (analytical tree in the PDT terminology) is created for each sentence.</S>
        </P>
        <P>
          <S ID="S-722731">This tree is converted to a tectogrammatical tree.</S>
          <S ID="S-722732">Each autosemantic word with its associated functional words is collapsed into a single tectogrammatical node, labeled with a lemma, formeme, 4 and semantically indispensable morphologically categories; coreference is also resolved.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.2 Transfer</HEADER>
        <P>
          <S ID="S-722733">The transfer phase follows, whose most difficult part consists especially in labeling the tree with targetside lemmas and formemes.</S>
          <S ID="S-722734">There are also other types of changes, such as node addition and deletion.</S>
          <S ID="S-722735">However, as shown by <REF ID="R-12" RPTR="19">Popel (2009)</REF>, changes of tree topology are required relatively infrequently due to the language abstractions on the tectogrammatical layer.</S>
        </P>
        <P>
          <S ID="S-722736">Currently, translation models based on Maximum Entropy classifiers are used both for lemmas and formemes (<REF ID="R-08" RPTR="12">Mare&#269;ek et al., 2010</REF>).</S>
          <S ID="S-722737">Tree labeling is optimized using Hidden Tree Markov Models (<REF ID="R-16" RPTR="23">&#381;abokrtsk&#253; and Popel, 2009</REF>), which makes use of target-language dependency tree probabilistic model.</S>
        </P>
        <P>
          <S ID="S-722738">All models used in the transfer phase are trained using training sections of the Czech-English parallel corpus CzEng 0.9 (<REF ID="R-00" RPTR="0">Bojar and &#381;abokrtsk&#253;, 2009</REF>).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.3 Synthesis</HEADER>
        <P>
          <S ID="S-722739">Finally, surface sentence shape is synthesized from the tectogrammatical tree, which is basically the reverse operation of the tectogrammatical analysis.</S>
          <S ID="S-722740">It consists of adding punctuation and functional</S>
        </P>
        <P>
          <S ID="S-722741">4 Formeme captures the morphosyntactic means which are</S>
        </P>
        <P>
          <S ID="S-722742">used for expressing the tectogrammatical node in the surface sentence shape.</S>
          <S ID="S-722743">Examples of formeme values: v:that+fin &#8211; finite verb in a subordinated clause introduced with conjunction that, n:sb &#8211; semantic noun in a subject position, n:for+X &#8211; semantic noun in a prepositional group introduced with preposition for, adj:attr &#8211; semantic adjective in an attributive position.</S>
        </P>
        <P>
          <S ID="S-722744">words, spreading morphological categories according to grammatical agreement, performing inflection (using Czech morphology database (<REF ID="R-04" RPTR="4">Haji&#269;, 2004</REF>)), arranging word order etc.</S>
          <S ID="S-722745">The difference from the analysis phase is that there is not very much space for optimization in the synthesis phase.</S>
          <S ID="S-722746">In other words, final sentence shape is determined almost uniquely by the tectogrammatical tree (enriched with formemes) resulting from the transfer phase.</S>
          <S ID="S-722747">However, if there are not enough constraints for a unique choice of a surface form of a lemma, then a unigram language model is used for the final decision.</S>
          <S ID="S-722748">The model was trained using 500 million words from the Czech National Corpus.</S>
          <S ID="S-722749">5</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Involved Parsers</HEADER>
      <P>
        <S ID="S-722795">We performed experiments with parsers from three families: graph-based parsers, transitionbased parsers, and phrase-structure parsers (with constituency-to-dependency postprocessing).</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Graph-based Parser</HEADER>
        <P>
          <S ID="S-722761">In graph-based parsing, we learn a model for scoring graph edges, and we search for the highest-scoring tree composed of the graph&#8217;s edges.</S>
          <S ID="S-722762">We used Maximum Spanning Tree parser (<REF ID="R-09" RPTR="13">Mcdonald and Pereira, 2006</REF>) which is capable of incorporating second order features (MST for short).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Transition-based Parsers</HEADER>
        <P>
          <S ID="S-722763">Transition-based parsers utilize the shift-reduce algorithm.</S>
          <S ID="S-722764">Input words are put into a queue and consumed by shift-reduce actions, while the output parser is gradually built.</S>
          <S ID="S-722765">Unlike graph-based parsers, transition-based parsers have linear time complexity and allow straightforward application of non-local features.</S>
        </P>
        <P>
          <S ID="S-722766">We included two transition-based parsers into our experiments:</S>
        </P>
        <P>
          <S ID="S-722767">&#8226; Malt &#8211; Malt parser introduced by <REF ID="R-11" RPTR="15">Nivre et al. (2007)</REF> 6</S>
        </P>
        <P>
          <S ID="S-722768">5 http://ucnk.ff.cuni.cz 6 We used stackeager algorithm, liblinear learner, and</S>
        </P>
        <P>
          <S ID="S-722769">the enriched feature set for English (the same configuration as in pretrained English models downloadable at http://maltparser.org.</S>
        </P>
        <P>
          <S ID="S-722770">&#8226; ZPar &#8211; Zpar parser 7 which is basically an alternative implementation of the Malt parser, employing a richer set of non-local features as described by <REF ID="R-19" RPTR="29">Zhang and Nivre (2011)</REF>.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 CFG-based Tree Parsers</HEADER>
        <P>
          <S ID="S-722771">Another option how to obtain dependency trees is to apply a constituency parser, recognize heads in the resulting phrase structures and apply a recursive algorithm for converting phrase-structure trees into constituency trees (the convertibility of the two types of syntactic structures was studied already by <REF ID="R-02" RPTR="3">Gaifman (1965)</REF>).</S>
        </P>
        <P>
          <S ID="S-722772">We used two constituency parsers:</S>
        </P>
        <P>
          <S ID="S-722773">&#8226; Stanford &#8211; The Stanford parser (<REF ID="R-06" RPTR="9">Klein and Manning, 2003</REF>), 8</S>
        </P>
        <P>
          <S ID="S-722774">&#8226; CJ &#8211; a MaxEnt-based parser combined with discriminative reranking (<REF ID="R-01" RPTR="2">Charniak and Johnson, 2005</REF>).</S>
          <S ID="S-722775">9</S>
        </P>
        <P>
          <S ID="S-722776">Before applying the parsers on the text, the system removes all spaces within tokens.</S>
          <S ID="S-722777">For instance U.</S>
          <S ID="S-722778">S. becomes U.S. to restrict the parsers from creating two new tokens.</S>
          <S ID="S-722779">Tokenization built into both parsers is bypassed and the default tokenization in Treex is used.</S>
          <S ID="S-722780">After parsing, Penn Converter introduced by <REF ID="R-05" RPTR="7">Johansson and Nugues (2007)</REF> is applied, with the -conll2007 option, to change the constituent structure output, of the two parsers, into CoNLL dependency structure.</S>
          <S ID="S-722781">This allows us to keep the formats consistent with the output of both MST and MaltParser within the Treex framework.</S>
        </P>
        <P>
          <S ID="S-722782">There is an implemented procedure for creating tectogrammatical trees from the English phrase structure trees described by <REF ID="R-07" RPTR="10">Ku&#269;erov&#225; and &#381;abokrtsk&#253; (2002)</REF>.</S>
          <S ID="S-722783">Using the procedure is more straightforward, as it does not go through the CoNLL-style trees; English CoNLL-style trees differ slightly from the PDT conventions (e.g. in attaching auxiliary verbs) and thus needs additional</S>
        </P>
        <P>
          <S ID="S-722784">7 http://sourceforge.net/projects/zpar/ (version 0.4) 8 Only the constituent, phrase based, parsed output is used in</S>
        </P>
        <P>
          <S ID="S-722785">these experiments.</S>
          <S ID="S-722786">9 We are using the default settings from the August 2006 version of the software.</S>
        </P>
        <P>
          <S ID="S-722787">postprocessing for our purposes.</S>
          <S ID="S-722788">However, we decided to stick to Penn Converter, so that the similarity of the translation scenarios is maximized for all parsers.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.4 Common Preprocessing: Shallow Sentence Chunking</HEADER>
        <P>
          <S ID="S-722789">According to our experience, many dependency parsers have troubles with analyzing sentences that contain parenthesed or quoted phrases, especially if they are long.</S>
        </P>
        <P>
          <S ID="S-722790">We use the assumption that in most cases the content of parentheses or quotes should correspond to a connected subgraph (subtree) of the syntactic tree.</S>
          <S ID="S-722791">We implemented a very shallow sentence chunker (SentChunk) which recognizes parenthesed word sequences.</S>
          <S ID="S-722792">These sequences can be passed to a parser first, and be parsed independently of the rest of the sentence.</S>
          <S ID="S-722793">This was shown to improve not only parsing accuracy of the parenthesed word sequence (which is forced to remain in one subtree), but also the rest of the sentence.</S>
          <S ID="S-722794">10 In our experiments, SentChunk is used only in combination with the three genuine dependency parsers.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Experiments and Evaluation</HEADER>
      <P>
        <S ID="S-722861"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Data for Parsers&#8217; Training and Evaluation</HEADER>
        <P>
          <S ID="S-722796">The dependency trees needed for training the parsers and evaluating their UAS were created from the Penn Treebank data (enriched first with internal noun phrase structure applied via scripts provided by <REF ID="R-15" RPTR="22">Vadas and Curran (2007)</REF>) by Penn Converter (<REF ID="R-05" RPTR="6">Johansson and Nugues, 2007</REF>) with the -conll2007 option (PennConv for short).</S>
        </P>
        <P>
          <S ID="S-722797">All the parsers were evaluated on the same data &#8211; section 23.</S>
          <S ID="S-722798">All the parsers were trained on sections 02&#8211;21, except for the Stanford parser which was trained on sections 01&#8211;21.</S>
          <S ID="S-722799">We were able to retrain the parser models only for MST and Malt.</S>
          <S ID="S-722800">For the other parsers we used pretrained models available on the Internet: CJ&#8217;s default model ec50spfinal, Stanford&#8217;s wsjPCFG.ser.gz model, and</S>
        </P>
        <P>
          <S ID="S-722801">10 Edge length is a common feature in dependency parsers, so</S>
        </P>
        <P>
          <S ID="S-722802">&#8220;deleting&#8221; parenthesed words may give higher scores to correct dependency links that happened to span over the parentheses.</S>
        </P>
        <P>
          <S ID="S-722803">ZPar&#8217;s english.tar.gz.</S>
          <S ID="S-722804">The model of ZPar is trained on data converted to dependencies using Penn2Malt tool, 11 which selects the last member of a coordination as the head.</S>
          <S ID="S-722805">To be able to compare ZPar&#8217;s output with the other parsers, we postprocessed it by a simple ConjAsHead code that converts this style of coordinations to the one used in CoNLL2007, where the conjuction is the head.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Reference Translations Used for Evaluation</HEADER>
        <P>
          <S ID="S-722806">Translation experiments were evaluated using reference translations from the new-dev2009 data set, provided by the organizors of shared translation task with the Workshop on Statistical Machine Translation.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.3 Influence of Parser Training Data Size</HEADER>
        <P>
          <S ID="S-722807">We trained a sequence of parser models for MST and Malt, using a roughly exponentially growing sequence of Penn Treebank subsets.</S>
          <S ID="S-722808">The subsets are contiguous and start from the beginning of section 02.</S>
          <S ID="S-722809">The results are collected in Tables 1 and 2.</S>
          <S ID="S-722810">12</S>
        </P>
        <P>
          <S ID="S-722811">#tokens UAS BLEU NIST</S>
        </P>
        <P>
          <S ID="S-722812">The trend of the relation between the training data size and BLEU is visible also in Figure 1.</S>
          <S ID="S-722813">It is obvious that increasing the training data has a positive effect on the translation quality.</S>
          <S ID="S-722814">However, the pace of growth of BLEU is sublogarithmic, and becomes unconvincing above 100,000 training tokens.</S>
          <S ID="S-722815">It indicates that given one of the two parsers integrated</S>
        </P>
        <P>
          <S ID="S-722816">11 http://w3.msi.vxu.se/&#732;nivre/research/</S>
        </P>
        <P>
          <S ID="S-722817">Penn2Malt.html 12 To our knowledge, the best system participating in the</S>
        </P>
        <P>
          <S ID="S-722818">shared task reaches BLEU 17.8 for this translation direction.</S>
        </P>
        <P>
          <S ID="S-722819">#tokens UAS BLEU NIST</S>
        </P>
        <P>
          <S ID="S-722820">BLEU</S>
        </P>
        <P>
          <S ID="S-722821">0.13</S>
        </P>
        <P>
          <S ID="S-722822">0.12</S>
        </P>
        <P>
          <S ID="S-722823">0.11</S>
        </P>
        <P>
          <S ID="S-722824">0.1</S>
        </P>
        <P>
          <S ID="S-722825">0.09</S>
        </P>
        <P>
          <S ID="S-722826">0.08</S>
        </P>
        <P>
          <S ID="S-722827">0.07</S>
        </P>
        <P>
          <S ID="S-722828">0.06</S>
        </P>
        <P>
          <S ID="S-722829">MST Malt</S>
        </P>
        <P>
          <S ID="S-722830">into our translation framework, increasing the parser training data alone would probably not lead to a substantial improvement of the translation performance.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.4 Influence of Parser Choice</HEADER>
        <P>
          <S ID="S-722831">Table 3 summarizes our experiments with the five parsers integrated into the tectogrammatical translation pipeline.</S>
          <S ID="S-722832">Two configurations (with and without SentChunk) are listed for the genuine dependency parsers.</S>
          <S ID="S-722833">The relationship between UAS and BLEU for (the best configurations of) all five parsers is depicted also in Figure 2.</S>
        </P>
        <P>
          <S ID="S-722834">Additionally, we used paired bootstrap 95% confidence interval testing (Zhang et al., 2004), to check which BLEU differences are significant.</S>
          <S ID="S-722835">For the five compared parser (with SentChunk if applicable), only four comparisons are not significant: MST-CJ, MST-Stanford, Malt-Stanford, and CJ-Stanford.</S>
        </P>
        <P>
          <S ID="S-722836">Parser Training data Preprocessing Postprocessing UAS BLEU NIST TER</S>
        </P>
        <P>
          <S ID="S-722837">BLEU</S>
        </P>
        <P>
          <S ID="S-722838">0.15</S>
        </P>
        <P>
          <S ID="S-722839">0.145</S>
        </P>
        <P>
          <S ID="S-722840">0.14</S>
        </P>
        <P>
          <S ID="S-722841">0.135</S>
        </P>
        <P>
          <S ID="S-722842">0.13</S>
        </P>
        <P>
          <S ID="S-722843">0.125</S>
        </P>
        <P>
          <S ID="S-722844">0.12</S>
        </P>
        <P>
          <S ID="S-722845">0.115</S>
        </P>
        <P>
          <S ID="S-722846">0.11</S>
        </P>
        <P>
          <S ID="S-722847">0.105</S>
        </P>
        <P>
          <S ID="S-722848">0.1 0.74 0.76 0.78 0.8 0.82 0.84 0.86 0.88 0.9 0.92 UAS</S>
        </P>
        <P>
          <S ID="S-722849">MST Malt Zpar Stanford CJ</S>
        </P>
        <P>
          <S ID="S-722850">Even if BLEU grows relatively smoothly with UAS for different parsing models of the same parser, one can see that there is no obvious relation between UAS and BLEU accross all parsers.</S>
          <S ID="S-722851">MST and Zpar have the same UAS but quite different BLEU, whereas MST and CJ have very similar BLEU but distant UAS.</S>
          <S ID="S-722852">It confirms the original hypothesis that it is not only the overall UAS, but also the parserspecific distribution of errors what matters.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.5 Influence of Shallow Sentence Chunking</HEADER>
        <P>
          <S ID="S-722853">Table 3 confirms that parsing the contents parentheses separately from the rest of the sentence (SentChunk) has a positive effect with all three dependency parsers.</S>
          <S ID="S-722854">Surprisingly, even if the effect on UAS is negligible, the improvement is almost half of BLEU point which is significant for all the three parsers.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.6 Discussion on Result Comparability</HEADER>
        <P>
          <S ID="S-722855">We tried to isolate the effects of the properties of selected parsers, however, the separation from other influencing factors is not perfect due to several technical issues:</S>
        </P>
        <P>
          <S ID="S-722856">&#8226; So far, we were not able to retrain the models for all parsers ourselves and therefore their pretrained models (one of them based on slightly different Penn Treebank division) must have been used.</S>
        </P>
        <P>
          <S ID="S-722857">&#8226; Some parsers make their own choice of POS tags within the parsed sentences, while other parsers require the sentences to be tagged already on their input.</S>
        </P>
        <P>
          <S ID="S-722858">&#8226; The trees in the CzEng 0.9 parallel treebank were created using MST.</S>
          <S ID="S-722859">CzEng 0.9 was used for training translation models used in the transfer phase of the translation scenario; thus these translation models might compensate for some MST&#8217;s errors, which might handicap other parsers.</S>
          <S ID="S-722860">So far we were not able to reparse 8 million sentence pairs in CzEng 0.9 by all studied parsers.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Conclusions</HEADER>
      <P>
        <S ID="S-722862">This paper is a study of how the choice of a dependency parsing technique influences the quality of English-Czech dependency-based translation.</S>
        <S ID="S-722863">Our main observations are the following.</S>
        <S ID="S-722864">First, BLEU grows with the increasing amount of training dependency trees, but only in a sublogarithmic pace.</S>
        <S ID="S-722865">Second, what seems to be quite effective for translation 438 is to facilitate the parsers&#8217; task by dividing the sentences into smaller chunks using parenthesis boundaries.</S>
        <S ID="S-722866">Third, if the parsers are based on different approaches, their UAS does not correlate well with their effect on the translation quality.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-722867"></S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>Ond&#345;ej Bojar</RAUTHOR>
      <REFTITLE>CzEng 0.9, Building a Large Czech-English Automatic Parallel Treebank.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Eugene Charniak</RAUTHOR>
      <REFTITLE>Coarse-tofine n-best parsing and maxent discriminative reranking.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Haim Gaifman</RAUTHOR>
      <REFTITLE>Dependency systems and phrasestructure systems.</REFTITLE>
      <DATE>1965</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>Jan Haji&#269;</RAUTHOR>
      <REFTITLE></REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Jan Haji&#269;</RAUTHOR>
      <REFTITLE></REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Richard Johansson</RAUTHOR>
      <REFTITLE>Extended constituent-to-dependency conversion for English.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>Dan Klein</RAUTHOR>
      <REFTITLE>Accurate unlexicalized parsing.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Ivona Ku&#269;erov&#225;</RAUTHOR>
      <REFTITLE>Transforming Penn Treebank Phrase Trees into (Praguian) Tectogrammatical Dependency Trees. The Prague Bulletin of Mathematical Linguistics,</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>David Mare&#269;ek</RAUTHOR>
      <REFTITLE>Maximum entropy translation model in dependency-based MT framework.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Ryan Mcdonald</RAUTHOR>
      <REFTITLE>Online learning of approximate dependency parsing algorithms.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Ryan McDonald</RAUTHOR>
      <REFTITLE>Non-projective dependency parsing using spanning tree algorithms.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Joakim Nivre</RAUTHOR>
      <REFTITLE>Atanas Chanev, Gulsen Eryigit, Sandra K&#252;bler, Svetoslav Marinov, and Erwin Marsi.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Martin Popel</RAUTHOR>
      <REFTITLE>Ways to Improve the Quality of English-Czech Machine Translation. Master&#8217;s thesis,</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>Petr Sgall</RAUTHOR>
      <REFTITLE>Generativn&#237; popis jazyka a &#269;esk&#225; deklinace.</REFTITLE>
      <DATE>1967</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>Drahom&#237;ra Spoustov&#225;</RAUTHOR>
      <REFTITLE>The Best of Two Worlds: Cooperation of Statistical and Rule-Based Taggers for Czech.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>David Vadas</RAUTHOR>
      <REFTITLE>Adding Noun Phrase Structure to the Penn Treebank.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>Zden&#283;k &#381;abokrtsk&#253;</RAUTHOR>
      <REFTITLE>Hidden Markov Tree Model in Dependency-based Machine Translation.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>Zden&#283;k &#381;abokrtsk&#253;</RAUTHOR>
      <REFTITLE>TectoMT: Highly Modular MT System with Tectogrammatics Used as Transfer Layer.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>Daniel Zeman</RAUTHOR>
      <REFTITLE>Parsing with a Statistical Dependency Model.</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>Yue Zhang</RAUTHOR>
      <REFTITLE>Transition-based dependency parsing with rich non-local features.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
