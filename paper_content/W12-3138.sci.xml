<PAPER>
  <FILENO/>
  <TITLE>Machine Learning for Hybrid Machine Translation</TITLE>
  <AUTHORS>
    <AUTHOR>Sabine Hunsicker</AUTHOR>
    <AUTHOR>Chen Yu</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-51191">We describe a substitution-based system for hybrid machine translation (MT) that has been extended with machine learning components controlling its phrase selection.</A-S>
    <A-S ID="S-51192">The approach is based on a rule-based MT (RBMT) system which creates template translations.</A-S>
    <A-S ID="S-51193">Based on the rule-based generation parse tree and target-to-target alignments, we identify the set of &#8220;interesting&#8221; translation candidates from one or more translation engines which could be substituted into our translation templates.</A-S>
    <A-S ID="S-51194">The substitution process is either controlled by the output from a binary classifier trained on feature vectors from the different MT engines, or it is depending on weights for the decision factors, which have been tuned using MERT.</A-S>
    <A-S ID="S-51195">We are able to observe improvements in terms of BLEU scores over a baseline version of the hybrid system.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-51196">In recent years, machine translation (MT) systems have achieved increasingly better translation quality.</S>
        <S ID="S-51197">Still each paradigm has its own challenges: while statistical MT (SMT) systems suffer from a lack of grammatical structure, resulting in ungrammatical sentences, RBMT systems have to deal with a lack of lexical coverage.</S>
        <S ID="S-51198">Hybrid architectures intend to combine the advantages of the individual paradigms to achieve an overall better translation.</S>
      </P>
      <P>
        <S ID="S-51199"><REF ID="R-05" RPTR="5">Federmann et al. (2010)</REF> and <REF ID="R-04" RPTR="4">Federmann and Hunsicker (2011)</REF> have shown that using a substitutionbased approach can improve the translation quality of a baseline RBMT system.</S>
        <S ID="S-51200">Our submission to WMT12 is a new, improved version following these approaches.</S>
        <S ID="S-51201">The output of an RBMT engine serves as our translation backbone, and we substitute noun phrases by translations mined from other systems.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 System Architecture</HEADER>
      <P>
        <S ID="S-51296">Our hybrid MT system combines translation output from:</S>
      </P>
      <P>
        <S ID="S-51297">a) the Lucy RBMT system, described in more detail in (<REF ID="R-01" RPTR="1">Alonso and Thurmair, 2003</REF>);</S>
      </P>
      <P>
        <S ID="S-51298">b) the Linguatec RBMT system (<REF ID="R-00" RPTR="0">Aleksic and Thurmair, 2011</REF>);</S>
      </P>
      <P>
        <S ID="S-51299">c) Moses (<REF ID="R-07" RPTR="7">Koehn et al., 2007</REF>);</S>
      </P>
      <P>
        <S ID="S-51300">d) Joshua (<REF ID="R-09" RPTR="9">Li et al., 2009</REF>).</S>
      </P>
      <P>
        <S ID="S-51301">Lucy provides us with the translation skeleton, which is described in more detail in Section 2.2 while systems b)&#8211;d) are aligned to this translation template and mined for substitution candidates.</S>
        <S ID="S-51302">We give more detailed information on these systems in Section 2.3.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>2.1 Basic Approach</HEADER>
        <P>
          <S ID="S-51202">We first identify &#8220;interesting&#8221; phrases inside the rule-based translation and then compute the most probable correspondences in the translation output from the other systems.</S>
          <S ID="S-51203">For the resulting phrases, we apply a factored substitution method that decides whether the original RBMT phrase should be kept or rather be replaced by one of the candidate phrases.</S>
          <S ID="S-51204">A schematic overview of our hybrid system and its main components is given in Figure 1.</S>
        </P>
        <P>
          <S ID="S-51205">4.</S>
          <S ID="S-51206">LM(phrase-1): phrase with left-context;</S>
        </P>
        <P>
          <S ID="S-51207">5.</S>
          <S ID="S-51208">Part-of-speech match?</S>
          <S ID="S-51209">: checks if the part-ofspeech tags of the left/right context match the current candidate phrase&#8217;s context;</S>
        </P>
        <P>
          <S ID="S-51210">6.</S>
          <S ID="S-51211">LM(pos) LM score for part-of-speech (PoS);</S>
        </P>
        <P>
          <S ID="S-51212">7.</S>
          <S ID="S-51213">LM(pos+1) PoS with right-context;</S>
        </P>
        <P>
          <S ID="S-51214">8.</S>
          <S ID="S-51215">LM(pos-1) PoS with left-context;</S>
        </P>
        <P>
          <S ID="S-51216">9.</S>
          <S ID="S-51217">Lemma checks if the lemma of the candidate phrase fits the reference;</S>
        </P>
        <P>
          <S ID="S-51218">10.</S>
          <S ID="S-51219">LM(lemma) LM score for the lemma;</S>
        </P>
        <P>
          <S ID="S-51220">11.</S>
          <S ID="S-51221">LM(lemma+1) lemma with right-context;</S>
        </P>
        <P>
          <S ID="S-51222">12.</S>
          <S ID="S-51223">LM(lemma-1) lemma with left-context.</S>
        </P>
        <P>
          <S ID="S-51224">In previous years, it turned out that the alignment of the candidate translations to the source contained too many errors.</S>
          <S ID="S-51225">In this version of our system, we thus changed the alignment method that connects the other translations.</S>
          <S ID="S-51226">Only the rule-based template is aligned to the source.</S>
          <S ID="S-51227">As we make use of the Lucy RBMT analysis parse trees, this alignment is very good.</S>
          <S ID="S-51228">The other translations are now connected to the rule-based template using a confusion network approach.</S>
          <S ID="S-51229">This also reduces computational efforts, as we now can compute the substitution candidates directly from the template without detouring over the source.</S>
          <S ID="S-51230">During system training and tuning, this new approach has resulted in a reduced number of erroneous alignment links.</S>
        </P>
        <P>
          <S ID="S-51231">Additionally, we also changed our set of decision factors, increasing their total number.</S>
          <S ID="S-51232">Whereas an older version of this system only used four factors, we now consider the following twelve factors:</S>
        </P>
        <P>
          <S ID="S-51233">1. frequency: frequency of a given candidate phrase compared to total number of candidates for the current phrase;</S>
        </P>
        <P>
          <S ID="S-51234">2.</S>
          <S ID="S-51235">LM(phrase): language model (LM) score of the phrase;</S>
        </P>
        <P>
          <S ID="S-51236">3.</S>
          <S ID="S-51237">LM(phrase+1): phrase with right-context;</S>
        </P>
        <P>
          <S ID="S-51238">The language model was trained using the SRILM toolkit (<REF ID="R-18" RPTR="16">Stolcke, 2002</REF>), on the EuroParl (<REF ID="R-08" RPTR="8">Koehn, 2005</REF>) corpus, and lemmatised or part-of-speech tagged versions, respectively.</S>
          <S ID="S-51239">We used the Tree- Tagger (<REF ID="R-14" RPTR="13">Schmid, 1994</REF>) for lemmatisation as well as part-of-speech tagging.</S>
        </P>
        <P>
          <S ID="S-51240">The substitution algorithm itself was also adapted.</S>
          <S ID="S-51241">We investigated two machine learning approaches.</S>
          <S ID="S-51242">In the previous version, the system used a handwritten decision tree to perform the substitution:</S>
        </P>
        <P>
          <S ID="S-51243">1. the first of the two new approaches consisted of machine learning this decision tree from annotated data;</S>
        </P>
        <P>
          <S ID="S-51244">2. the second approach was to assign a weight to each factor and using MERT tuning of these weights on a development set.</S>
        </P>
        <P>
          <S ID="S-51245">Both approaches are described in more detail later in Section 2.4.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.2 Rule-Based Translation Templates</HEADER>
        <P>
          <S ID="S-51246">The Lucy RBMT system provides us with parse tree structures for each of the three phases of its transferbased translation approach: analysis, transfer and generation.</S>
          <S ID="S-51247">Out of these structures, we can extract linguistic phrases which later represent the &#8220;slots&#8221; for substitution.</S>
          <S ID="S-51248">Previous work has shown that these structures are of a good grammatical quality due to the grammar Lucy uses.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.3 Substitution Candidate Translations</HEADER>
        <P>
          <S ID="S-51249">Whereas in our previous work, we solely relied on candidates retrieved from SMT systems, this time we also included an additional RBMT system into the architecture.</S>
          <S ID="S-51250">Knowing that statistical systems make similar errors, we hope to balance out this fact by exploiting also a system of a different paradigm, namely RBMT.</S>
        </P>
        <P>
          <S ID="S-51251">To create the statistical translations, we used stateof-the-art SMT systems.</S>
          <S ID="S-51252">Both our Moses and Joshua systems were trained on the EuroParl corpus and News Commentary 1 training data.</S>
          <S ID="S-51253">We performed tuning on the &#8220;newstest2011&#8221; data set using MERT.</S>
        </P>
        <P>
          <S ID="S-51254">We compile alignments between translations with the alignment module of MANY (<REF ID="R-02" RPTR="2">Barrault, 2010</REF>).</S>
          <S ID="S-51255">This module uses a modified version of TERp (<REF ID="R-17" RPTR="15">Snover et al., 2009</REF>) and a set of different costs to create the best alignment between any two given sentences.</S>
          <S ID="S-51256">In our case, each single candidate translation is aligned to the translation template that has been produced by the Lucy RBMT system.</S>
          <S ID="S-51257">As we do not use the source in this alignment technique, we can use any translation system, regardless of whether this system provides us with a source-totarget alignment.</S>
        </P>
        <P>
          <S ID="S-51258">In earlier versions of this system, we compiled the source-to-target alignments for the candidate translations using GIZA++ (<REF ID="R-11" RPTR="10">Och and Ney, 2003</REF>), but these alignments contained many errors.</S>
          <S ID="S-51259">By using target-to-target alignments, we are able to reduce the amount of those errors which is, of course, preferred.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>2.4 Substitution Approaches</HEADER>
        <P>
          <S ID="S-51260">Using the parse tree structures provided by Lucy, we extract &#8220;interesting&#8221; phrases for substitution.</S>
          <S ID="S-51261">This includes noun phrases of various complexity, then simple verb phrases consisting of only the main verb, and finally adjective phrases.</S>
          <S ID="S-51262">Through the target-to-target alignments we identify and collect the set of potential substitution candidates.</S>
          <S ID="S-51263">Phrase substitution can be performed using two methods.</S>
        </P>
        <P>
          <S ID="S-51264">2.4.1 Machine-Learned Decision Tree</S>
        </P>
        <P>
          <S ID="S-51265">Previous work used hand-crafted rules.</S>
          <S ID="S-51266">These are now replaced by a classifier which was trained on annotated data.</S>
          <S ID="S-51267">Our training set D can formally be</S>
        </P>
        <P>
          <S ID="S-51268">1 Available at http://www.statmt.org/wmt12/</S>
        </P>
        <P>
          <S ID="S-51269">represented as</S>
        </P>
        <P>
          <S ID="S-51270">D = {(x i , y i )|x i &#8712; R p , y i &#8712; {&#8722;1, 1}} n i=1 (1)</S>
        </P>
        <P>
          <S ID="S-51271">where each x i represents the feature vector for some sentence i while the y i value contains the annotated class information.</S>
          <S ID="S-51272">We use a binary classification scheme, simply defining 1 as &#8220;good&#8221; and &#8722;1 as &#8220;bad&#8221; translations.</S>
        </P>
        <P>
          <S ID="S-51273">In order to make use of machine (ML) learning methods such as decision trees (<REF ID="R-03" RPTR="3">Breiman et al., 1984</REF>), Support Vector Machines (<REF ID="R-19" RPTR="17">Vapnik, 1995</REF>), or the Perceptron (<REF ID="R-13" RPTR="12">Rosenblatt, 1958</REF>) algorithm, we have to prepare our training set with a sufficiently large amount of annotated training instances.</S>
        </P>
        <P>
          <S ID="S-51274">To create the training data set, we computed the feature vectors and all possible substitution candidates for the WMT12 &#8220;newstest2011&#8221; development set.</S>
          <S ID="S-51275">Human annotators were then given the task to assign to each candidate whether it was a &#8220;good&#8221; or a &#8220;bad&#8221; substitution.</S>
          <S ID="S-51276">We used Appraise (<REF ID="R-06" RPTR="6">Federmann, 2010</REF>) for the annotation, and collected a set of 24,996 labeled training instances with the help of six human annotators.</S>
          <S ID="S-51277">Table 1 gives an overview of the data sets characteristics.</S>
          <S ID="S-51278">The decision tree learned from this data replaces the hand-crafted rules.</S>
        </P>
        <P>
          <S ID="S-51279">2.4.2 Weights Tuned with MERT</S>
        </P>
        <P>
          <S ID="S-51280">Another approach we followed was to assign weights to the chosen decision factors and to use Minimal Error Rate Training to get the best weights.</S>
          <S ID="S-51281">Using the twelve factors described in Section 2.1, we assign uniformly distributed weights and create n-best lists.</S>
          <S ID="S-51282">Each n-best lists contains a total of n+2 hypotheses, with n being the number of candidate systems.</S>
          <S ID="S-51283">It contains the Lucy template translations, the hybrid translation using the best candidates as well as a hypothesis for each candidate system.</S>
          <S ID="S-51284">In the latter translation, each potential candidate for substitution is selected and replaces the original sub phrase in the baseline.</S>
          <S ID="S-51285">The n-best list is</S>
        </P>
        <P>
          <S ID="S-51286">Translation Candidates</S>
        </P>
        <P>
          <S ID="S-51287">Total &#8220;good&#8221; &#8220;bad&#8221;</S>
        </P>
        <P>
          <S ID="S-51288">Count 24,996 10,666 14,330</S>
        </P>
        <P>
          <S ID="S-51289">Hybrid Systems Baseline Systems</S>
        </P>
        <P>
          <S ID="S-51290">Baseline +Decision Tree +MERT Lucy Linguatec Joshua Moses</S>
        </P>
        <P>
          <S ID="S-51291">BLEU 13.9 14.2 14.3 14.0 14.7 14.6 15.9</S>
        </P>
        <P>
          <S ID="S-51292">BLEU-cased 13.5 13.8 13.9 13.7 14.2 13.5 14.9</S>
        </P>
        <P>
          <S ID="S-51293">TER 0.776 0.773 0.768 0.774 0.775 0.772 0.774</S>
        </P>
        <P>
          <S ID="S-51294">sorted by the final score of the feature vectors making up each hypothesis.</S>
          <S ID="S-51295">We used Z-MERT (Zaidan, 2009) to optimise the set of feature weights on the &#8220;newstest2011&#8221; development set.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Evaluation</HEADER>
      <P>
        <S ID="S-51303">Using the &#8220;newstest2012&#8221; test set, we created baseline translations for the four MT systems used in our hybrid system.</S>
        <S ID="S-51304">Then we performed three runs of our hybrid system:</S>
      </P>
      <P>
        <S ID="S-51305">a) a baseline run, using the factors and uniformly distributed weights;</S>
      </P>
      <P>
        <S ID="S-51306">b) a run using the weights trained on the development set;</S>
      </P>
      <P>
        <S ID="S-51307">c) a run using the decision tree learned from annotated data.</S>
      </P>
      <P>
        <S ID="S-51308">Table 2 shows the results for automatic metrics&#8217; scores.</S>
        <S ID="S-51309">Besides BLEU (<REF ID="R-12" RPTR="11">Papineni et al., 2001</REF>), we also report its case-sensitive variant, BLEU-cased, and TER (<REF ID="R-16" RPTR="14">Snover et al., 2006</REF>) scores.</S>
      </P>
      <P>
        <S ID="S-51310">Comparing the scores, we see that both advanced hybrid methods perform better than the original, baseline hybrid as well as the Lucy baseline system.</S>
        <S ID="S-51311">The MERT approach performs slightly better than the decision tree.</S>
        <S ID="S-51312">This proves that using machinelearning to adapt the substitution approach results in better translation quality.</S>
      </P>
      <P>
        <S ID="S-51313">Other baseline systems, however, still outperform the hybrid systems.</S>
        <S ID="S-51314">In part this is due to the fact that we are preserving the basic structure of the RBMT translation and do not reorder the new hybrid translation.</S>
        <S ID="S-51315">To improve the hybrid approach further, there is more research required.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Conclusion and Outlook</HEADER>
      <P>
        <S ID="S-51316">In this paper, we have described how machinelearning approaches can be used to improve the phrase substitution component of a hybrid machine translation system.</S>
        <S ID="S-51317">We reported on two different approaches, the first using a binary classifier learned from annotated data, and the second using feature weights tuned with MERT.</S>
        <S ID="S-51318">Both systems achieved improved automatic metrics&#8217; scores on the WMT12 &#8220;newstest2012&#8221; test set for the language pair English&#8594;German.</S>
        <S ID="S-51319">Future work will have to investigate ways how to achieve a closer integration of the individual baseline translations.</S>
        <S ID="S-51320">This might be done by also taking into account reordering of the linguistic phrases as shown in the tree structures.</S>
        <S ID="S-51321">We will also need to examine the differences between the classifier and MERT approach, to see whether we can integrate them to improve the selection process even further.</S>
        <S ID="S-51322">Also, we have to further evaluate the machine learning performance via, e.g., cross-validationbased tuning, to improve the prediction rate of the classifier model.</S>
        <S ID="S-51323">We intend to explore other machine learning techniques such as SVMs as well.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-51324">This work has been funded under the Seventh Framework Programme for Research and Technological Development of the European Commission through the T4ME contract (grant agreement no.</S>
      <S ID="S-51325">: 249119).</S>
      <S ID="S-51326">It was also supported by the EuroMatrix- Plus project (IST-231720).</S>
      <S ID="S-51327">We are grateful to the anonymous reviewers for their valuable feedback.</S>
      <S ID="S-51328">Special thanks go to Herv&#233; Saint-Amand for help with fixing the automated metrics scores.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>Vera Aleksic</RAUTHOR>
      <REFTITLE>Personal Translator at WMT</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Juan A Alonso</RAUTHOR>
      <REFTITLE>The Comprendium Translator System.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Lo&#239;c Barrault</RAUTHOR>
      <REFTITLE>MANY : Open Source Machine Translation System Combination.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>L Breiman</RAUTHOR>
      <REFTITLE>Classification and Regression Trees. Wadsworth and Brooks,</REFTITLE>
      <DATE>1984</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Christian Federmann</RAUTHOR>
      <REFTITLE>Stochastic parse tree selection for an existing rbmt system.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Christian Federmann</RAUTHOR>
      <REFTITLE>Further experiments with shallow hybrid mt systems.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>Christian Federmann</RAUTHOR>
      <REFTITLE>Appraise: An Open-Source Toolkit for Manual Phrase-Based Evaluation of Translations. In</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Moses: Open Source Toolkit for Statistical Machine Translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Europarl: A Parallel Corpus for Statistical Machine Translation.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Zhifei Li</RAUTHOR>
      <REFTITLE>Joshua: An Open Source Toolkit for Parsing-Based Machine Translation.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Evgeny Matusov</RAUTHOR>
      <REFTITLE>Computing Consensus Translation from Multiple Machine Translation Systems Using Enhanced Hypotheses Alignment.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Franz Josef Och</RAUTHOR>
      <REFTITLE>A Systematic Comparison of Various Statistical Alignment Models.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Kishore Papineni</RAUTHOR>
      <REFTITLE>Bleu: a Method for Automatic Evaluation of Machine Translation.</REFTITLE>
      <DATE>2001</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>F Rosenblatt</RAUTHOR>
      <REFTITLE>The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain. Psychological Review,</REFTITLE>
      <DATE>1958</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>Helmut Schmid</RAUTHOR>
      <REFTITLE>Probabilistic Part-of-Speech Tagging Using Decision Trees.</REFTITLE>
      <DATE>1994</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>Toby Segaran</RAUTHOR>
      <REFTITLE>Programming Collective Intelligence: Building Smart Web 2.0 Applications.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>Matthew Snover</RAUTHOR>
      <REFTITLE>A Study of Translation Edit Rate with Targeted Human Annotation.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>Matthew Snover</RAUTHOR>
      <REFTITLE>Fluency, Adequacy, or HTER? Exploring Different Human Judgments with a Tunable MT Metric.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>Andreas Stolcke</RAUTHOR>
      <REFTITLE>SRILM - An Extensible Language Modeling Toolkit.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>V N Vapnik</RAUTHOR>
      <REFTITLE>The Nature of Statistical Learning Theory.</REFTITLE>
      <DATE>1995</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
