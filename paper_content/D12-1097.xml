<document>
  <filename>D12-1097</filename>
  <authors>
    <author>Billy T M Wong</author>
  </authors>
  <title>Extending Machine Translation Evaluation Metrics with Lexical Cohesion To Document Level</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level. As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning. A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine. Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation. Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation.</text>
              <doc_id>3</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</text>
              <doc_id>4</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>Machine translation (MT) has benefited a lot from the advancement of automatic evaluation in the past decade. To a certain degree, its progress is also confined to the limitations of evaluation metrics in use. Most efforts devoted to evaluate the quality of MT output so far have still focused on the sentence level without sufficient attention to how a larger text is structured. This is notably reflected in the representative MT evaluation metrics, such as BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006), that adopt a sentence-by-sentence fashion to score MT outputs. The evaluation result for a document by any of them is usually a simple average of its sentence scores. A drawback of this kind of sentence-based evaluation is the neglect of document structure. There is no guarantee for the coherence of a text if it is produced by simply putting together stand-alone sentences, no matter how well-translated, without adequate intersentential connection. As a consequence, MT system optimized this way to any of these metrics can only have a very dim chance of producing translated document that reads as natural as human writing.
The accuracy of MT output at the document level is particularly important to MT users, for they care about the overall meaning of a text in question more than the grammatical correctness of each sentence (Visser and Fuji, 1996). Post-editors particularly need to ensure the quality of a whole document of MT output when revising its sentences. The connectivity of sentences is surely a significant factor contributing to the understandability of a text as a whole.
This paper studies the inter-sentential linguistic features of cohesion and coherence and presents plausible ways to incorporate them into the sentence-based metrics to support MT evaluation at the document level. In the Framework for MT Evaluation in the International Standards of Language Engineering (FEMTI) (King et al., 2003), coherence is defined as &#8220;the degree to which the reader can describe the role of each individual sentence (or group of sentences) with respect to the text as a whole&#8221;. The measurement of coherence has to rely on cohesion, referring to the &#8220;relations of meaning that exist within the text&#8221; (Halliday and Hasan, 1976). Cohesion is realized via the interlinkage of grammatical and lexical elements across sentences. Grammatical
cohesion refers to the syntactic links between text items, while lexical cohesion is achieved through the word choices in a text. This paper focuses on the latter. A quantitative comparison of lexical cohesion devices between MT output and human translation is first conducted, to examine the weakness of current MT systems in handling this feature. Different ways of exploiting lexical cohesion devices for MT evaluation at the document level are then illustrated.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Machine translation (MT) has benefited a lot from the advancement of automatic evaluation in the past decade.</text>
              <doc_id>5</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>To a certain degree, its progress is also confined to the limitations of evaluation metrics in use.</text>
              <doc_id>6</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Most efforts devoted to evaluate the quality of MT output so far have still focused on the sentence level without sufficient attention to how a larger text is structured.</text>
              <doc_id>7</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>This is notably reflected in the representative MT evaluation metrics, such as BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006), that adopt a sentence-by-sentence fashion to score MT outputs.</text>
              <doc_id>8</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>The evaluation result for a document by any of them is usually a simple average of its sentence scores.</text>
              <doc_id>9</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>A drawback of this kind of sentence-based evaluation is the neglect of document structure.</text>
              <doc_id>10</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>There is no guarantee for the coherence of a text if it is produced by simply putting together stand-alone sentences, no matter how well-translated, without adequate intersentential connection.</text>
              <doc_id>11</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>As a consequence, MT system optimized this way to any of these metrics can only have a very dim chance of producing translated document that reads as natural as human writing.</text>
              <doc_id>12</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The accuracy of MT output at the document level is particularly important to MT users, for they care about the overall meaning of a text in question more than the grammatical correctness of each sentence (Visser and Fuji, 1996).</text>
              <doc_id>13</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Post-editors particularly need to ensure the quality of a whole document of MT output when revising its sentences.</text>
              <doc_id>14</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The connectivity of sentences is surely a significant factor contributing to the understandability of a text as a whole.</text>
              <doc_id>15</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>This paper studies the inter-sentential linguistic features of cohesion and coherence and presents plausible ways to incorporate them into the sentence-based metrics to support MT evaluation at the document level.</text>
              <doc_id>16</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>In the Framework for MT Evaluation in the International Standards of Language Engineering (FEMTI) (King et al., 2003), coherence is defined as &#8220;the degree to which the reader can describe the role of each individual sentence (or group of sentences) with respect to the text as a whole&#8221;.</text>
              <doc_id>17</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The measurement of coherence has to rely on cohesion, referring to the &#8220;relations of meaning that exist within the text&#8221; (Halliday and Hasan, 1976).</text>
              <doc_id>18</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Cohesion is realized via the interlinkage of grammatical and lexical elements across sentences.</text>
              <doc_id>19</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Grammatical</text>
              <doc_id>20</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>cohesion refers to the syntactic links between text items, while lexical cohesion is achieved through the word choices in a text.</text>
              <doc_id>21</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This paper focuses on the latter.</text>
              <doc_id>22</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A quantitative comparison of lexical cohesion devices between MT output and human translation is first conducted, to examine the weakness of current MT systems in handling this feature.</text>
              <doc_id>23</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Different ways of exploiting lexical cohesion devices for MT evaluation at the document level are then illustrated.</text>
              <doc_id>24</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Related Works</title>
        <text>Cohesion and coherence are both necessary monolingual features in a target text. They can hardly be evaluated in isolation and have to be conjoined with other quality criteria such as adequacy and fluency. A survey of MT post-editing (Vasconcellos, 1989) suggests that cohesion and coherence serve as higher level quality criteria beyond many others such as syntactic well-formedness. Post-editors tend to correct syntactic errors first before any amendment for improving the cohesion and coherence of an MT output. Also, as Wilks (1978) 1 noted, it is rather unlikely for a sufficiently large sample of translations to be coherent and totally wrong at the same time. Cohesion and coherence are appropriate to serve as criteria for the overall quality of MT output. Previous researches in MT predominantly focus on specific types of cohesion devices. For grammatical cohesion, a series of works, including Nakaiwa and Ikehara (1992), Nakaiwa et al. (1995), and Nakaiwa and Shirai (1996), present approaches to resolving Japanese zero pronouns and to integrating them into a Japanese-English transferred-based MT system. Peral et al. (1999) propose an interlingual mechanism for pronominal anaphora generation by exploiting a rich set of lexical, syntactic, morphologic and semantic information. Murata and Nagao (1993) and Murata et al. (2001) develop a rule base to identify the referential properties of Japanese noun phrases, so as to facilitate anaphora resolution for Japanese and article generation for English during translation. A recent COMTIS project (Cartoni et al., 2011) begins to exploit inter-sentential information for statistical MT. A phase of its work is to have grammatical devices,
1 As cited in van Slype (1979).
such as verbal tense/aspect/mode, discourse connectives and pronouns, manually annotated in multilingual corpora, in hopes of laying a foundation for the development of automatic labelers for them that can be integrated into an MT model.
For lexical cohesion, it has been only partially and indirectly addressed in terms of translation consistency in MT output. Different approaches to maintaining consistency in target word choices are proposed (Itagaki et al., 2007; Gong et al., 2011; Xiao et al., 2011). Carpuat (2009) also observes a general tendency in human translation that a given sense is usually lexicalized in a consistent manner throughout the whole translation.
Nevertheless there are only a few evaluation methods explicitly targeting on the quality of a document. Miller and Vanni (2001) devise a human evaluation approach to measure the comprehensibility of a text as a whole, based on the Rhetorical Structure Theory (Mann and Thompson, 1988), a theory of text organization specifying coherence relations in an authentic text. Snover et al. (2006) proposes HTER to assess post-editing effort through human annotation. Its automatic versions TER and TERp (Snover et al., 2009), however, remain sentencebased metrics. Comelles et al. (2010) present a family of automatic MT evaluation measures, based on the Discourse Representation Theory (Kamp and Reyle, 1993), that generate semantic trees to put together different text entities for the same referent according to their contexts and grammatical connections. Apart from MT evaluation, automated essay scoring programs such as E-rater (Burstein, 2003) also employ a rich set of discourse features for assessment. However, the parsing process needed for these linguistic-heavy approaches may suffer seriously from grammatical errors, which are unavoidable in MT output. Hence their accuracy and reliability inevitably fluctuate in accord with different evaluation data. Lexical cohesion has far been neglected in both MT and MT evaluation, even though it is the single most important form of cohesion devices, accounting for nearly half of the cohesion devices in English (Halliday and Hasan, 1976). It is also a significant feature contributing to translation equivalence of texts by preserving their texture (Lotfipour-Saedi, 1997). The lexical cohesion devices in a text can be
represented as lexical chains conjoining related entities. There are many methods of computing lexical chains for various purposes, e.g., Morris and Hirst (1991), Barzilay and Elhadad (1997), Chan (2004), Li et al. (2007), among many others. Contrary to grammatical cohesion highly depending on syntactic well-formedness of a text, lexical cohesion is less affected by grammatical errors. Its computation has to rely on a thesaurus, which is usually available for almost every language. In this research, a number of formulations of lexical cohesion, with or without reliance on external language resource, will be explored for the purpose of MT evaluation.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Cohesion and coherence are both necessary monolingual features in a target text.</text>
              <doc_id>25</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>They can hardly be evaluated in isolation and have to be conjoined with other quality criteria such as adequacy and fluency.</text>
              <doc_id>26</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>A survey of MT post-editing (Vasconcellos, 1989) suggests that cohesion and coherence serve as higher level quality criteria beyond many others such as syntactic well-formedness.</text>
              <doc_id>27</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Post-editors tend to correct syntactic errors first before any amendment for improving the cohesion and coherence of an MT output.</text>
              <doc_id>28</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Also, as Wilks (1978) 1 noted, it is rather unlikely for a sufficiently large sample of translations to be coherent and totally wrong at the same time.</text>
              <doc_id>29</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Cohesion and coherence are appropriate to serve as criteria for the overall quality of MT output.</text>
              <doc_id>30</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Previous researches in MT predominantly focus on specific types of cohesion devices.</text>
              <doc_id>31</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>For grammatical cohesion, a series of works, including Nakaiwa and Ikehara (1992), Nakaiwa et al. (1995), and Nakaiwa and Shirai (1996), present approaches to resolving Japanese zero pronouns and to integrating them into a Japanese-English transferred-based MT system.</text>
              <doc_id>32</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Peral et al. (1999) propose an interlingual mechanism for pronominal anaphora generation by exploiting a rich set of lexical, syntactic, morphologic and semantic information.</text>
              <doc_id>33</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>Murata and Nagao (1993) and Murata et al. (2001) develop a rule base to identify the referential properties of Japanese noun phrases, so as to facilitate anaphora resolution for Japanese and article generation for English during translation.</text>
              <doc_id>34</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>A recent COMTIS project (Cartoni et al., 2011) begins to exploit inter-sentential information for statistical MT.</text>
              <doc_id>35</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>A phase of its work is to have grammatical devices,</text>
              <doc_id>36</doc_id>
              <sec_id>11</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1 As cited in van Slype (1979).</text>
              <doc_id>37</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>such as verbal tense/aspect/mode, discourse connectives and pronouns, manually annotated in multilingual corpora, in hopes of laying a foundation for the development of automatic labelers for them that can be integrated into an MT model.</text>
              <doc_id>38</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>For lexical cohesion, it has been only partially and indirectly addressed in terms of translation consistency in MT output.</text>
              <doc_id>39</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Different approaches to maintaining consistency in target word choices are proposed (Itagaki et al., 2007; Gong et al., 2011; Xiao et al., 2011).</text>
              <doc_id>40</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Carpuat (2009) also observes a general tendency in human translation that a given sense is usually lexicalized in a consistent manner throughout the whole translation.</text>
              <doc_id>41</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Nevertheless there are only a few evaluation methods explicitly targeting on the quality of a document.</text>
              <doc_id>42</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Miller and Vanni (2001) devise a human evaluation approach to measure the comprehensibility of a text as a whole, based on the Rhetorical Structure Theory (Mann and Thompson, 1988), a theory of text organization specifying coherence relations in an authentic text.</text>
              <doc_id>43</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Snover et al. (2006) proposes HTER to assess post-editing effort through human annotation.</text>
              <doc_id>44</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Its automatic versions TER and TERp (Snover et al., 2009), however, remain sentencebased metrics.</text>
              <doc_id>45</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Comelles et al. (2010) present a family of automatic MT evaluation measures, based on the Discourse Representation Theory (Kamp and Reyle, 1993), that generate semantic trees to put together different text entities for the same referent according to their contexts and grammatical connections.</text>
              <doc_id>46</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Apart from MT evaluation, automated essay scoring programs such as E-rater (Burstein, 2003) also employ a rich set of discourse features for assessment.</text>
              <doc_id>47</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>However, the parsing process needed for these linguistic-heavy approaches may suffer seriously from grammatical errors, which are unavoidable in MT output.</text>
              <doc_id>48</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Hence their accuracy and reliability inevitably fluctuate in accord with different evaluation data.</text>
              <doc_id>49</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Lexical cohesion has far been neglected in both MT and MT evaluation, even though it is the single most important form of cohesion devices, accounting for nearly half of the cohesion devices in English (Halliday and Hasan, 1976).</text>
              <doc_id>50</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>It is also a significant feature contributing to translation equivalence of texts by preserving their texture (Lotfipour-Saedi, 1997).</text>
              <doc_id>51</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>The lexical cohesion devices in a text can be</text>
              <doc_id>52</doc_id>
              <sec_id>10</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>represented as lexical chains conjoining related entities.</text>
              <doc_id>53</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>There are many methods of computing lexical chains for various purposes, e.g., Morris and Hirst (1991), Barzilay and Elhadad (1997), Chan (2004), Li et al. (2007), among many others.</text>
              <doc_id>54</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Contrary to grammatical cohesion highly depending on syntactic well-formedness of a text, lexical cohesion is less affected by grammatical errors.</text>
              <doc_id>55</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Its computation has to rely on a thesaurus, which is usually available for almost every language.</text>
              <doc_id>56</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>In this research, a number of formulations of lexical cohesion, with or without reliance on external language resource, will be explored for the purpose of MT evaluation.</text>
              <doc_id>57</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>3</index>
        <title>3 Lexical Cohesion in Machine and Human Translation</title>
        <text>This section presents a comparative study of MT and human translation (HT) in terms of the use of lexical cohesion devices. It is an intuition that more cohesion devices are used by humans than machines in translation, as part of the superior quality of HT. Two different datasets are used to ensure the reliability and generality of the comparison. The results confirm the incapability of MT in handling this feature and the necessity of using lexical cohesion in MT evaluation.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This section presents a comparative study of MT and human translation (HT) in terms of the use of lexical cohesion devices.</text>
              <doc_id>58</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It is an intuition that more cohesion devices are used by humans than machines in translation, as part of the superior quality of HT.</text>
              <doc_id>59</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Two different datasets are used to ensure the reliability and generality of the comparison.</text>
              <doc_id>60</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The results confirm the incapability of MT in handling this feature and the necessity of using lexical cohesion in MT evaluation.</text>
              <doc_id>61</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Data</title>
            <text>The MetricsMATR 2008 development set (Przybocki et al., 2009) and the Multiple-Translation Chinese (MTC) part 4 (Ma, 2006) are used for this study. They consist of MT outputs of different source languages in company with reference translations. The data of MetricsMATR is selected from the NIST Open MT 2006 evaluation, while MTC4 is from the TIDES 2003 MT evaluation. Both datasets include human assessments of MT output, from which the part of adequacy assessment is selected for this study. Table 1 provides overall statistics of the datasets.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The MetricsMATR 2008 development set (Przybocki et al., 2009) and the Multiple-Translation Chinese (MTC) part 4 (Ma, 2006) are used for this study.</text>
                  <doc_id>62</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>They consist of MT outputs of different source languages in company with reference translations.</text>
                  <doc_id>63</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The data of MetricsMATR is selected from the NIST Open MT 2006 evaluation, while MTC4 is from the TIDES 2003 MT evaluation.</text>
                  <doc_id>64</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>Both datasets include human assessments of MT output, from which the part of adequacy assessment is selected for this study.</text>
                  <doc_id>65</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Table 1 provides overall statistics of the datasets.</text>
                  <doc_id>66</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Identification of Lexical Cohesion Devices</title>
            <text>Lexical cohesion is achieved through word choices of two major types: reiteration and collocation. Reiteration can be realized in a continuum or a cline of specificity, with repetition of the same lexical item at one end and the use of a general noun to point to the
same referent at the other. In between the two ends is to use a synonym (or near-synonym) and superordinate. Collocation refers to those lexical items that share the same or similar semantic relations, including complementarity, antonym, converse, coordinate term, meronym, troponym, and so on.
In this study, lexical cohesion devices are defined as content words (i.e., tokens after stopword having been removed) that reiterate once or more times in a document, including synonym, near-synonym and superordinate, besides those repetition and collocation. Repetition refers to the same words or stems in a document. Stems are identified with the aid of Porter stemmer (1980). To classify the semantic relationships of words, WordNet (Fellbaum, 1998) is used as a lexical resource, which clusters words of the same sense (i.e., synonyms) into a semantic group, namely a synset. Synsets are interlinked in WordNet according to their semantic relationships. Superordinate and collocation are formed by words in a proximate semantic relationship, such as bicycle and vehicle (hypernym), bicycle and wheel (meronym), bicycle and car (coordinate term), and so on. They are defined as synset pairs with a distance of 1 in WordNet. The measure of semantic distance (Wu and Palmer, 1994) is also applied to identify near-synonyms, i.e., words that are synonyms in a broad sense but not grouped in the same synset. It quantifies the semantic similarity of word pairs as a real number in between 0 and 1 (the higher the more similar) as
sim(c 1 , c 2 ) = 2 d(lcs(c 1, c 2 )) d(c 1 ) + d(c 2 )
where c 1 and c 2 are the concepts (synsets) that the two words in question belong to, d is the distance in terms of the shortest path from a concept to the
Values of RC &amp; LC
0.55
0.50
0.55
0.50
0.45
0.40
0.35
0.30
0.25 0.45
0.40
0.35
0.30
0.25 RC (MT)
RC (HT)
LC (MT)
LC (HT)
global root node in WordNet, and lcs is the least common subsumer (i.e., the most specific ancestor concept) of c 1 and c 2 . A threshold is set to 0.96 for words to be considered near-synonyms of each other, based on the empirical observation in a previous study (Wong, 2010).</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>Lexical cohesion is achieved through word choices of two major types: reiteration and collocation.</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Reiteration can be realized in a continuum or a cline of specificity, with repetition of the same lexical item at one end and the use of a general noun to point to the</text>
                  <doc_id>68</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>same referent at the other.</text>
                  <doc_id>69</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In between the two ends is to use a synonym (or near-synonym) and superordinate.</text>
                  <doc_id>70</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Collocation refers to those lexical items that share the same or similar semantic relations, including complementarity, antonym, converse, coordinate term, meronym, troponym, and so on.</text>
                  <doc_id>71</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In this study, lexical cohesion devices are defined as content words (i.e., tokens after stopword having been removed) that reiterate once or more times in a document, including synonym, near-synonym and superordinate, besides those repetition and collocation.</text>
                  <doc_id>72</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Repetition refers to the same words or stems in a document.</text>
                  <doc_id>73</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Stems are identified with the aid of Porter stemmer (1980).</text>
                  <doc_id>74</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>To classify the semantic relationships of words, WordNet (Fellbaum, 1998) is used as a lexical resource, which clusters words of the same sense (i.e., synonyms) into a semantic group, namely a synset.</text>
                  <doc_id>75</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Synsets are interlinked in WordNet according to their semantic relationships.</text>
                  <doc_id>76</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>Superordinate and collocation are formed by words in a proximate semantic relationship, such as bicycle and vehicle (hypernym), bicycle and wheel (meronym), bicycle and car (coordinate term), and so on.</text>
                  <doc_id>77</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>They are defined as synset pairs with a distance of 1 in WordNet.</text>
                  <doc_id>78</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>The measure of semantic distance (Wu and Palmer, 1994) is also applied to identify near-synonyms, i.e., words that are synonyms in a broad sense but not grouped in the same synset.</text>
                  <doc_id>79</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>It quantifies the semantic similarity of word pairs as a real number in between 0 and 1 (the higher the more similar) as</text>
                  <doc_id>80</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>sim(c 1 , c 2 ) = 2 d(lcs(c 1, c 2 )) d(c 1 ) + d(c 2 )</text>
                  <doc_id>81</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where c 1 and c 2 are the concepts (synsets) that the two words in question belong to, d is the distance in terms of the shortest path from a concept to the</text>
                  <doc_id>82</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Values of RC &amp; LC</text>
                  <doc_id>83</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.55</text>
                  <doc_id>84</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.50</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.55</text>
                  <doc_id>86</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.50</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.45</text>
                  <doc_id>88</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.40</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.35</text>
                  <doc_id>90</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.30</text>
                  <doc_id>91</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.25 0.45</text>
                  <doc_id>92</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.40</text>
                  <doc_id>93</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.35</text>
                  <doc_id>94</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.30</text>
                  <doc_id>95</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>0.25 RC (MT)</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>RC (HT)</text>
                  <doc_id>97</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>LC (MT)</text>
                  <doc_id>98</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>LC (HT)</text>
                  <doc_id>99</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>global root node in WordNet, and lcs is the least common subsumer (i.e., the most specific ancestor concept) of c 1 and c 2 .</text>
                  <doc_id>100</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A threshold is set to 0.96 for words to be considered near-synonyms of each other, based on the empirical observation in a previous study (Wong, 2010).</text>
                  <doc_id>101</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 Results</title>
            <text>The difference between MT and HT (reference translation) in terms of the frequencies of lexical cohesion devices in MetricsMATR and MTC4 datasets is presented in Table 2. The frequencies are averaged by the number of MT/HT versions. A further categorization breaks down content words into lexical cohesion devices and those that are not. The count of each type of lexical cohesion device is also provided. In general the two datasets provide highly similar statistics. There are 4.7&#8211;5.1% more content words in HT than in MT. The numbers of ordinary content words (i.e., not lexical cohesion devices) are close in MT and HT. The difference of content words in HT and MT is mostly due to that of lexical cohesion devices, which are mostly repetition. 8.9&#8211; 11.4% more lexical cohesion devices are found in HT than in MT in the datasets.
A further analysis is carried out to investigate into the use of lexical cohesion devices in each version of MT and HT in terms of the following two ratios,
LC = lexical cohesion devices / content words, RC = repetition / content words. A higher LC or RC ratio means that a greater proportion of content words are used as lexical cohesion devices.
Figure 1 illustrates the RC and LC ratios in the two datasets. The ratios of different MT systems are presented in an ascending order in each graph from left to right, according to their human assessment results. The distributions of these values show a strong similarity between the two datasets. First, most of the RC and LC ratios are within an observable range, i.e., 0.25&#8211;0.35 for the former and 0.40&#8211; 0.50 for the latter, except a particularly low LC for
MT 1 1 Chine scrambled research on 16 key technical 2 These techniques are from within headline everyones boosting science and technology and achieving goals and contend of delivered on time bound through achieving breakthroughs in essential technology and complimentarity resources . national
BLEU: 0.224 (1-gram:7, 2-gram:0, 3-gram:2, 4-gram:1) LC: 0.107 (number of lexical cohesion devices: 5) Human assessment: 2.67 MT 2 1 China is accelerating research 16 main technologies 2 These technologies are within the important realm to promote sciences and technology and
achieve national goals and must be completed in a timely manner through achieving main discoveries in technology and integration of resources .
BLEU: 0.213 (1-gram:5, 2-gram:3, 3-gram:2, 4-gram:1) LC: 0.231 (number of lexical cohesion devices: 9) Human assessment: 4.33 Reference 1 China Accelerates Research on 16 Main Technologies 2 These technologies represent a significant part in the development of science and technology and
the achievement of national goals. They must be accomplished within a fixed period of time by realizing breakthroughs in essential technologies and integration of resources.
one MT system. Second, the ratios in those different HT versions are very stable in comparison with those of MT. Especially, all four HT versions in the MetricsMATR dataset share the same RC ratio 0.31. This shows a typical level of the use of lexical cohesion device. Third, the ratios in MT are lower than or at most equal to those in HT, suggesting their correlation with translation quality: the closer their RC and LC ratios to those in HT, the better the MT. These results verify our assumption that lexical cohesion can serve as an effective proxy of the level of translation quality.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The difference between MT and HT (reference translation) in terms of the frequencies of lexical cohesion devices in MetricsMATR and MTC4 datasets is presented in Table 2.</text>
                  <doc_id>102</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The frequencies are averaged by the number of MT/HT versions.</text>
                  <doc_id>103</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>A further categorization breaks down content words into lexical cohesion devices and those that are not.</text>
                  <doc_id>104</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>The count of each type of lexical cohesion device is also provided.</text>
                  <doc_id>105</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>In general the two datasets provide highly similar statistics.</text>
                  <doc_id>106</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>There are 4.7&#8211;5.1% more content words in HT than in MT.</text>
                  <doc_id>107</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
                <sentence>
                  <text>The numbers of ordinary content words (i.e., not lexical cohesion devices) are close in MT and HT.</text>
                  <doc_id>108</doc_id>
                  <sec_id>6</sec_id>
                </sentence>
                <sentence>
                  <text>The difference of content words in HT and MT is mostly due to that of lexical cohesion devices, which are mostly repetition.</text>
                  <doc_id>109</doc_id>
                  <sec_id>7</sec_id>
                </sentence>
                <sentence>
                  <text>8.9&#8211; 11.4% more lexical cohesion devices are found in HT than in MT in the datasets.</text>
                  <doc_id>110</doc_id>
                  <sec_id>8</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A further analysis is carried out to investigate into the use of lexical cohesion devices in each version of MT and HT in terms of the following two ratios,</text>
                  <doc_id>111</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>LC = lexical cohesion devices / content words, RC = repetition / content words.</text>
                  <doc_id>112</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>A higher LC or RC ratio means that a greater proportion of content words are used as lexical cohesion devices.</text>
                  <doc_id>113</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Figure 1 illustrates the RC and LC ratios in the two datasets.</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The ratios of different MT systems are presented in an ascending order in each graph from left to right, according to their human assessment results.</text>
                  <doc_id>115</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The distributions of these values show a strong similarity between the two datasets.</text>
                  <doc_id>116</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>First, most of the RC and LC ratios are within an observable range, i.e., 0.25&#8211;0.35 for the former and 0.40&#8211; 0.50 for the latter, except a particularly low LC for</text>
                  <doc_id>117</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>MT 1 1 Chine scrambled research on 16 key technical 2 These techniques are from within headline everyones boosting science and technology and achieving goals and contend of delivered on time bound through achieving breakthroughs in essential technology and complimentarity resources .</text>
                  <doc_id>118</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>national</text>
                  <doc_id>119</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU: 0.224 (1-gram:7, 2-gram:0, 3-gram:2, 4-gram:1) LC: 0.107 (number of lexical cohesion devices: 5) Human assessment: 2.67 MT 2 1 China is accelerating research 16 main technologies 2 These technologies are within the important realm to promote sciences and technology and</text>
                  <doc_id>120</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>achieve national goals and must be completed in a timely manner through achieving main discoveries in technology and integration of resources .</text>
                  <doc_id>121</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>BLEU: 0.213 (1-gram:5, 2-gram:3, 3-gram:2, 4-gram:1) LC: 0.231 (number of lexical cohesion devices: 9) Human assessment: 4.33 Reference 1 China Accelerates Research on 16 Main Technologies 2 These technologies represent a significant part in the development of science and technology and</text>
                  <doc_id>122</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>the achievement of national goals.</text>
                  <doc_id>123</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>They must be accomplished within a fixed period of time by realizing breakthroughs in essential technologies and integration of resources.</text>
                  <doc_id>124</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>one MT system.</text>
                  <doc_id>125</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Second, the ratios in those different HT versions are very stable in comparison with those of MT.</text>
                  <doc_id>126</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>Especially, all four HT versions in the MetricsMATR dataset share the same RC ratio 0.31.</text>
                  <doc_id>127</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This shows a typical level of the use of lexical cohesion device.</text>
                  <doc_id>128</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>Third, the ratios in MT are lower than or at most equal to those in HT, suggesting their correlation with translation quality: the closer their RC and LC ratios to those in HT, the better the MT.</text>
                  <doc_id>129</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>These results verify our assumption that lexical cohesion can serve as an effective proxy of the level of translation quality.</text>
                  <doc_id>130</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 MT Evaluation at Document Level</title>
        <text>As a feature at the discourse level, lexical cohesion is a good complement to current evaluation metrics focusing on features at the sentence level. Table 3 illustrates an example selected from the MetricsMATR dataset, consisting two versions of MT output for a short document of two segments only. The n-grams matched with the reference are underlined, while the lexical cohesion devices are italicized. The two MT outputs have a similar number of matched n-grams and hence receive similar BLEU scores. These scores, however, do not reflect their real difference in quality: the second version is better, according to human assessment of adequacy. Instead, their LC ratios seem to represent such a variation more accurately. The theme of the second output is also highlighted through the lexical chains, including main/important, technology/technologies and achieve/achieving, which create a tight texture between the two sentences, a crucial factor of text quality.
To perform MT evaluation at the document level, the LC and RC ratios can be used alone or integrated into a sentence-level metric. The former way has an advantage that it does not have to rely on any reference translation. LC mainly requires a thesaurus for computing semantic relation, while RC only needs a morphological processor such as stemmer, both of which are available for most lan-
guages. Its drawback, however, lies in the risk of relying on a single discourse feature. Although lexical cohesion gives a strong indication of text coherence, it is not indispensable, because a text can be coherent without any surface cohesive clue. Furthermore, the quality of a document is also reflected in that of its sentences. A coherent translation may be mistranslated, and on the other hand, a text containing lots of sentence-level errors would make it difficult to determine its document-level quality. A previous study comparing MT evaluation at the sentence versus document level (Wong et al., 2011) reports a poor consistency in the evaluation results at these two levels when the sentence-level scores of MT output are low. In regard of these, how to integrate these two levels of MT evaluation is particularly worth studying.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>As a feature at the discourse level, lexical cohesion is a good complement to current evaluation metrics focusing on features at the sentence level.</text>
              <doc_id>131</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Table 3 illustrates an example selected from the MetricsMATR dataset, consisting two versions of MT output for a short document of two segments only.</text>
              <doc_id>132</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The n-grams matched with the reference are underlined, while the lexical cohesion devices are italicized.</text>
              <doc_id>133</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The two MT outputs have a similar number of matched n-grams and hence receive similar BLEU scores.</text>
              <doc_id>134</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>These scores, however, do not reflect their real difference in quality: the second version is better, according to human assessment of adequacy.</text>
              <doc_id>135</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Instead, their LC ratios seem to represent such a variation more accurately.</text>
              <doc_id>136</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>The theme of the second output is also highlighted through the lexical chains, including main/important, technology/technologies and achieve/achieving, which create a tight texture between the two sentences, a crucial factor of text quality.</text>
              <doc_id>137</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>To perform MT evaluation at the document level, the LC and RC ratios can be used alone or integrated into a sentence-level metric.</text>
              <doc_id>138</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The former way has an advantage that it does not have to rely on any reference translation.</text>
              <doc_id>139</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>LC mainly requires a thesaurus for computing semantic relation, while RC only needs a morphological processor such as stemmer, both of which are available for most lan-</text>
              <doc_id>140</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>guages.</text>
              <doc_id>141</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Its drawback, however, lies in the risk of relying on a single discourse feature.</text>
              <doc_id>142</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Although lexical cohesion gives a strong indication of text coherence, it is not indispensable, because a text can be coherent without any surface cohesive clue.</text>
              <doc_id>143</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Furthermore, the quality of a document is also reflected in that of its sentences.</text>
              <doc_id>144</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>A coherent translation may be mistranslated, and on the other hand, a text containing lots of sentence-level errors would make it difficult to determine its document-level quality.</text>
              <doc_id>145</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>A previous study comparing MT evaluation at the sentence versus document level (Wong et al., 2011) reports a poor consistency in the evaluation results at these two levels when the sentence-level scores of MT output are low.</text>
              <doc_id>146</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>In regard of these, how to integrate these two levels of MT evaluation is particularly worth studying.</text>
              <doc_id>147</doc_id>
              <sec_id>6</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>5</index>
        <title>5 Experiments</title>
        <text>We examine, through experiments, the effectiveness of using LC and RC ratios alone and integrating them into other evaluation metrics for MT evaluation at the document and system levels. Three evaluation metrics, namely BLEU, TER and METEOR, 2 are selected for testing. They represent three distinctive types of evaluation metrics: n-gram, editdistance, and unigram with external language resources, respectively. These metrics are evaluated in terms of their correlation with human assessments, using Pearson&#8217;s r correlation coefficient. The MetricsMATR and MTC4 datasets and their adequacy assessments are used as evaluation data. Note that the adequacy assessment is in fact an evaluation method for the sentence level. We have to rely on an assumption that this evaluation data may emulate document-level quality, since its MT outputs were assessed sentence by sentence in sequence as in a document. All experiments are performed under a setting of multiple reference translations.
The integration of the two ratios into an evaluation metric follows a simple weighted average approach. A hybrid metric H is formulated as
H = &#945; m doc + (1 &#8722; &#945;) m seg
where m doc refers to the document-level feature in
2 METEOR 1.0 with default parameters optimized over the
adequacy assessments.
use (i.e., LC or RC), m seg to a sentence-level metric, and &#945; to a weight controlling their proportion. The MetricsMATR dataset is used as training data to optimize the values of &#945; for different metrics, while the MTC4 is used as evaluation data. Table 4 shows the optimized weights for the metrics for evaluation at the document level.
Table 5 presents the correlation rates of evaluation metrics obtained in our experiments under different settings, with their 95% conference intervals (CI) provided. The LC and RC ratios are found to have strong correlations with human assessments at the system level even when used alone, highly comparable to BLEU and TER. At the document level, however, they are not as good as the others. They show their advantages when integrated into other metrics, especially BLEU and TER. LC raises the correlation of BLEU from 0.447 to 0.472 and from 0.861 to 0.905 at the document and system levels, respectively. It improves TER even more significantly, in that the correlation rates are boosted up from -0.326 to -0.390 at the document level, and even from -0.601 to -0.763 at the system level. Since there are only six systems in the MTC4 data, such a dramatic change may not be as meaningful as the smooth improvement at the document level. ME- TEOR is a special case in this experiment. Its correlation cannot be improved by integrating LC or RC, and is even slightly dropped at the document level. The cause for this is yet to be identified. Nevertheless, these results confirm the close relationship of an MT system&#8217;s capability to appropriately generate lexical cohesion devices with the quality of its output.
Table 6 presents the Pearson correlations between evaluation results at the document level using different evaluation metrics in the MTC4 data. It illustrates the homogeneity/heterogeneity of different metrics and helps explain the performance change
by combining sentence- and document-level metrics. The table shows that the two ratios LC and RC highly correlate with each other, as if they are two variants of quantifying lexical cohesion devices. The three sentence-level metrics, BLEU, TER and METEOR, also show strong correlations with each other, especially between BLEU and METEOR. The correlations are generally weaker between sentenceand document-level metrics, for instance, 0.263 between BLEU and LC and only -0.097 between TER and LC, showing that they are quite heterogeneous in nature. This accounts for the significant performance gain from their combination: their difference allows them to complement each other. It is also worth noting that between METEOR and LC the correlation of 0.437 is mildly strong, explaining the negative result of their integration. On the one hand, lexical cohesion is word choice oriented, which is only sensitive to the reiteration and semantic relatedness of words in MT output. On the other hand, METEOR is strong in unigram matching, with multiple strategies to maximize the matching rate between MT output and reference translation. In this sense they are homogeneous to a certain extent, explaining the null effect of their combination.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>We examine, through experiments, the effectiveness of using LC and RC ratios alone and integrating them into other evaluation metrics for MT evaluation at the document and system levels.</text>
              <doc_id>148</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Three evaluation metrics, namely BLEU, TER and METEOR, 2 are selected for testing.</text>
              <doc_id>149</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>They represent three distinctive types of evaluation metrics: n-gram, editdistance, and unigram with external language resources, respectively.</text>
              <doc_id>150</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>These metrics are evaluated in terms of their correlation with human assessments, using Pearson&#8217;s r correlation coefficient.</text>
              <doc_id>151</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>The MetricsMATR and MTC4 datasets and their adequacy assessments are used as evaluation data.</text>
              <doc_id>152</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Note that the adequacy assessment is in fact an evaluation method for the sentence level.</text>
              <doc_id>153</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>We have to rely on an assumption that this evaluation data may emulate document-level quality, since its MT outputs were assessed sentence by sentence in sequence as in a document.</text>
              <doc_id>154</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>All experiments are performed under a setting of multiple reference translations.</text>
              <doc_id>155</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The integration of the two ratios into an evaluation metric follows a simple weighted average approach.</text>
              <doc_id>156</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>A hybrid metric H is formulated as</text>
              <doc_id>157</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>H = &#945; m doc + (1 &#8722; &#945;) m seg</text>
              <doc_id>158</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>where m doc refers to the document-level feature in</text>
              <doc_id>159</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>2 METEOR 1.0 with default parameters optimized over the</text>
              <doc_id>160</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>adequacy assessments.</text>
              <doc_id>161</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>use (i.e., LC or RC), m seg to a sentence-level metric, and &#945; to a weight controlling their proportion.</text>
              <doc_id>162</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The MetricsMATR dataset is used as training data to optimize the values of &#945; for different metrics, while the MTC4 is used as evaluation data.</text>
              <doc_id>163</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Table 4 shows the optimized weights for the metrics for evaluation at the document level.</text>
              <doc_id>164</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Table 5 presents the correlation rates of evaluation metrics obtained in our experiments under different settings, with their 95% conference intervals (CI) provided.</text>
              <doc_id>165</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The LC and RC ratios are found to have strong correlations with human assessments at the system level even when used alone, highly comparable to BLEU and TER.</text>
              <doc_id>166</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>At the document level, however, they are not as good as the others.</text>
              <doc_id>167</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>They show their advantages when integrated into other metrics, especially BLEU and TER.</text>
              <doc_id>168</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>LC raises the correlation of BLEU from 0.447 to 0.472 and from 0.861 to 0.905 at the document and system levels, respectively.</text>
              <doc_id>169</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>It improves TER even more significantly, in that the correlation rates are boosted up from -0.326 to -0.390 at the document level, and even from -0.601 to -0.763 at the system level.</text>
              <doc_id>170</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Since there are only six systems in the MTC4 data, such a dramatic change may not be as meaningful as the smooth improvement at the document level.</text>
              <doc_id>171</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>ME- TEOR is a special case in this experiment.</text>
              <doc_id>172</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Its correlation cannot be improved by integrating LC or RC, and is even slightly dropped at the document level.</text>
              <doc_id>173</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>The cause for this is yet to be identified.</text>
              <doc_id>174</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>Nevertheless, these results confirm the close relationship of an MT system&#8217;s capability to appropriately generate lexical cohesion devices with the quality of its output.</text>
              <doc_id>175</doc_id>
              <sec_id>10</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Table 6 presents the Pearson correlations between evaluation results at the document level using different evaluation metrics in the MTC4 data.</text>
              <doc_id>176</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It illustrates the homogeneity/heterogeneity of different metrics and helps explain the performance change</text>
              <doc_id>177</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>by combining sentence- and document-level metrics.</text>
              <doc_id>178</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The table shows that the two ratios LC and RC highly correlate with each other, as if they are two variants of quantifying lexical cohesion devices.</text>
              <doc_id>179</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The three sentence-level metrics, BLEU, TER and METEOR, also show strong correlations with each other, especially between BLEU and METEOR.</text>
              <doc_id>180</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The correlations are generally weaker between sentenceand document-level metrics, for instance, 0.263 between BLEU and LC and only -0.097 between TER and LC, showing that they are quite heterogeneous in nature.</text>
              <doc_id>181</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>This accounts for the significant performance gain from their combination: their difference allows them to complement each other.</text>
              <doc_id>182</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>It is also worth noting that between METEOR and LC the correlation of 0.437 is mildly strong, explaining the negative result of their integration.</text>
              <doc_id>183</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>On the one hand, lexical cohesion is word choice oriented, which is only sensitive to the reiteration and semantic relatedness of words in MT output.</text>
              <doc_id>184</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>On the other hand, METEOR is strong in unigram matching, with multiple strategies to maximize the matching rate between MT output and reference translation.</text>
              <doc_id>185</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>In this sense they are homogeneous to a certain extent, explaining the null effect of their combination.</text>
              <doc_id>186</doc_id>
              <sec_id>8</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>6</index>
        <title>6 Discussion and Conclusion</title>
        <text>In this study we have attempted to address the problem that most existing MT evaluation metrics disregard the connectivity of sentences in a document. By focusing on a typical type of cohesion, i.e., lexical cohesion, we have shown that its use frequency is a significant factor to differentiate HT from MT and MT outputs of different quality from each other. The high correlation rate of its use with translation adequacy also suggests that the more lexical cohesion devices in use, the better the quality of MT output. Accordingly we have used two ratios, LC and RC, to capture such correlativity. Our experimental results have confirmed the effectiveness of this feature in accounting for the document-level quality of MT output. The performance of two evaluation metrics, BLEU and TER, is highly improved through incorporating this document-level feature, in terms of the 1066 change of their correlation with human assessments. This finding is positive and sheds light on a region of MT research that is still severely under-explored. Our approach to extending the granularity of MT evaluation from sentence to document through lexical cohesion is highly applicable to different languages. It has a relatively weak demand for language resource in comparison with the processing of other discourse features like grammatical cohesion. It is also much unaffected by grammatical problems or errors commonly seen in natural languages and, in particular, MT outputs. Our future work will continue to explore the relationship of lexical cohesion to translation quality, so as to identify, apart from its use frequency, other significant aspects for MT evaluation at the document level. A frequent use of cohesion devices in a text is not necessarily appropriate, because an excess of them may decrease the quality and readability of a text. Human writers can strategically change the ways of expression to achieve appropriate coherence and also avoid overuse of the same lexical item. To a certain extent, this is one of the causes for the unnaturalness of MT output: it may contain a large number of lexical cohesion devices which are simply direct translation of those in a source text that do not fit in the target context. How to use lexical cohesion devices appropriately instead of frequently is thus an important issue to tackle before we can adopt them in MT and MT evaluation by a suitable means.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>In this study we have attempted to address the problem that most existing MT evaluation metrics disregard the connectivity of sentences in a document.</text>
              <doc_id>187</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>By focusing on a typical type of cohesion, i.e., lexical cohesion, we have shown that its use frequency is a significant factor to differentiate HT from MT and MT outputs of different quality from each other.</text>
              <doc_id>188</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The high correlation rate of its use with translation adequacy also suggests that the more lexical cohesion devices in use, the better the quality of MT output.</text>
              <doc_id>189</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Accordingly we have used two ratios, LC and RC, to capture such correlativity.</text>
              <doc_id>190</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Our experimental results have confirmed the effectiveness of this feature in accounting for the document-level quality of MT output.</text>
              <doc_id>191</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>The performance of two evaluation metrics, BLEU and TER, is highly improved through incorporating this document-level feature, in terms of the 1066 change of their correlation with human assessments.</text>
              <doc_id>192</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>This finding is positive and sheds light on a region of MT research that is still severely under-explored.</text>
              <doc_id>193</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>Our approach to extending the granularity of MT evaluation from sentence to document through lexical cohesion is highly applicable to different languages.</text>
              <doc_id>194</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>It has a relatively weak demand for language resource in comparison with the processing of other discourse features like grammatical cohesion.</text>
              <doc_id>195</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>It is also much unaffected by grammatical problems or errors commonly seen in natural languages and, in particular, MT outputs.</text>
              <doc_id>196</doc_id>
              <sec_id>9</sec_id>
            </sentence>
            <sentence>
              <text>Our future work will continue to explore the relationship of lexical cohesion to translation quality, so as to identify, apart from its use frequency, other significant aspects for MT evaluation at the document level.</text>
              <doc_id>197</doc_id>
              <sec_id>10</sec_id>
            </sentence>
            <sentence>
              <text>A frequent use of cohesion devices in a text is not necessarily appropriate, because an excess of them may decrease the quality and readability of a text.</text>
              <doc_id>198</doc_id>
              <sec_id>11</sec_id>
            </sentence>
            <sentence>
              <text>Human writers can strategically change the ways of expression to achieve appropriate coherence and also avoid overuse of the same lexical item.</text>
              <doc_id>199</doc_id>
              <sec_id>12</sec_id>
            </sentence>
            <sentence>
              <text>To a certain extent, this is one of the causes for the unnaturalness of MT output: it may contain a large number of lexical cohesion devices which are simply direct translation of those in a source text that do not fit in the target context.</text>
              <doc_id>200</doc_id>
              <sec_id>13</sec_id>
            </sentence>
            <sentence>
              <text>How to use lexical cohesion devices appropriately instead of frequently is thus an important issue to tackle before we can adopt them in MT and MT evaluation by a suitable means.</text>
              <doc_id>201</doc_id>
              <sec_id>14</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>7</index>
        <title>Acknowledgments</title>
        <text>The research described in this paper was substantially supported by the Research Grants Council (RGC) of Hong Kong SAR, P. R. China through GRF grant 144410.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The research described in this paper was substantially supported by the Research Grants Council (RGC) of Hong Kong SAR, P. R. China through GRF grant 144410.</text>
              <doc_id>202</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TableSeer</source>
        <caption>Table 1: Information about the datasets in use</caption>
        <reference_text>In PAGE 3: ... Both datasets include human assessments of MT output, from which the part of adequacy assessment is selected for this study.  Table1  provides overall statistics of the datasets. 3....</reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell></cell>
              <cell>MetricsMATR</cell>
              <cell>MetricsMATR MTC4#@#@MTC4</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Number of systems</cell>
              <cell>8</cell>
              <cell>6</cell>
            </row>
            <row>
              <cell>Number of documents</cell>
              <cell>25</cell>
              <cell>100</cell>
            </row>
            <row>
              <cell>Number of segments</cell>
              <cell>249</cell>
              <cell>919</cell>
            </row>
            <row>
              <cell>Number of references</cell>
              <cell>4</cell>
              <cell>4</cell>
            </row>
            <row>
              <cell>Source language</cell>
              <cell>Arabic</cell>
              <cell>Chinese</cell>
            </row>
            <row>
              <cell>Genre</cell>
              <cell>Newswire</cell>
              <cell>Newswire</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TableSeer</source>
        <caption>Table 2: Statistics of lexical cohesion devices in machine versus human translation (average frequencies per version of MT/HT)</caption>
        <reference_text>In PAGE 4: ... 3.3 Results The difference between MT and HT (reference translation) in terms of the frequencies of lexical co- hesion devices in MetricsMATR and MTC4 datasets is presented in  Table2 . The frequencies are aver- aged by the number of MT/HT versions....</reference_text>
        <page_num>4</page_num>
        <head>
          <rows>
            <row>
              <cell>Word type</cell>
              <cell>MetricsMATR
MTC4
MT HT Difference (%) MT HT Difference (%)</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Content word</cell>
              <cell>4428</cell>
              <cell>4636</cell>
              <cell>208 (4.7)</cell>
              <cell>16162</cell>
              <cell>16982</cell>
              <cell>830 (5.1)</cell>
            </row>
            <row>
              <cell>- Not lexical cohesion device</cell>
              <cell>2403</cell>
              <cell>2381</cell>
              <cell>-22 (-1.0)</cell>
              <cell>8657</cell>
              <cell>8814</cell>
              <cell>157</cell>
              <cell>(1.8)</cell>
            </row>
            <row>
              <cell>- Lexical cohesion device</cell>
              <cell>2025</cell>
              <cell>2255</cell>
              <cell>230 (11.4)</cell>
              <cell>7505</cell>
              <cell>8168</cell>
              <cell>663</cell>
              <cell>(8.9)</cell>
            </row>
            <row>
              <cell>- Repetition</cell>
              <cell>1297</cell>
              <cell>1445</cell>
              <cell>148 (11.4)</cell>
              <cell>4888</cell>
              <cell>5509</cell>
              <cell>621 (12.7)</cell>
            </row>
            <row>
              <cell>- Synonym and near-synonym</cell>
              <cell>318</cell>
              <cell>350</cell>
              <cell>32 (10.1)</cell>
              <cell>1323</cell>
              <cell>1311</cell>
              <cell>-12 (-0.9)</cell>
            </row>
            <row>
              <cell>- Superordinate and collocation</cell>
              <cell>410</cell>
              <cell>460</cell>
              <cell>50 (12.4)</cell>
              <cell>1294</cell>
              <cell>1348</cell>
              <cell>54</cell>
              <cell>(4.2)</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>4</id>
        <source>TableSeer</source>
        <caption>Table 4: Optimized weights for the integration of discourse feature into sentence-level metrics</caption>
        <reference_text>In PAGE 6: ... The MetricsMATR dataset is used as training data to optimize the values of ? for different metrics, while the MTC4 is used as evaluation data.  Table4  shows the optimized weights for the metrics for evaluation...</reference_text>
        <page_num>6</page_num>
        <head>
          <rows>
            <row>
              <cell>at the document level.</cell>
              <cell>None</cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Metrics</cell>
              <cell>RC</cell>
              <cell>LC</cell>
            </row>
            <row>
              <cell>BLEU</cell>
              <cell>0.28</cell>
              <cell>0.29</cell>
            </row>
            <row>
              <cell>TER</cell>
              <cell>0.40</cell>
              <cell>0.38</cell>
            </row>
            <row>
              <cell>METEOR</cell>
              <cell>0.19</cell>
              <cell>0.18</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>5</id>
        <source>TET</source>
        <caption>Table 5: Correlation of different metrics with adequacy assessment in MTC4 data</caption>
        <reference_text></reference_text>
        <page_num>6</page_num>
        <head>
          <rows>
            <row>
              <cell>Document</cell>
              <cell>System</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>Metrics</cell>
              <cell>Correlation</cell>
              <cell>95% CI</cell>
              <cell>Correlation</cell>
              <cell>95% CI</cell>
            </row>
            <row>
              <cell>RC</cell>
              <cell>0.243</cell>
              <cell>(0.167, 0.316)</cell>
              <cell>0.873</cell>
              <cell>(0.211, 0.985)</cell>
            </row>
            <row>
              <cell>LC</cell>
              <cell>0.267</cell>
              <cell>(0.192, 0.339)</cell>
              <cell>0.818</cell>
              <cell>(0.020, 0.979)</cell>
            </row>
            <row>
              <cell>BLEU</cell>
              <cell>0.447</cell>
              <cell>(0.381, 0.508)</cell>
              <cell>0.861</cell>
              <cell>(0.165, 0.984)</cell>
            </row>
            <row>
              <cell>BLEU+RC</cell>
              <cell>0.463</cell>
              <cell>(0.398, 0.523)</cell>
              <cell>0.890</cell>
              <cell>(0.283, 0.987)</cell>
            </row>
            <row>
              <cell>BLEU+LC</cell>
              <cell>0.472</cell>
              <cell>(0.408, 0.531)</cell>
              <cell>0.905</cell>
              <cell>(0.352, 0.989)</cell>
            </row>
            <row>
              <cell>TER</cell>
              <cell>-0.326</cell>
              <cell>(-0.253, -0.395)</cell>
              <cell>-0.601</cell>
              <cell>(-0.411, -0.949)</cell>
            </row>
            <row>
              <cell>TER+RC</cell>
              <cell>-0.370</cell>
              <cell>(-0.299, -0.437)</cell>
              <cell>-0.740</cell>
              <cell>(-0.179, -0.969)</cell>
            </row>
            <row>
              <cell>TER+LC</cell>
              <cell>-0.390</cell>
              <cell>(-0.320, -0.455)</cell>
              <cell>-0.763</cell>
              <cell>(-0.127, -0.972)</cell>
            </row>
            <row>
              <cell>METEOR</cell>
              <cell>0.557</cell>
              <cell>(0.500, 0.609)</cell>
              <cell>0.961</cell>
              <cell>(0.679, 0.995)</cell>
            </row>
            <row>
              <cell>METEOR+RC</cell>
              <cell>0.555</cell>
              <cell>(0.498, 0.608)</cell>
              <cell>0.960</cell>
              <cell>(0.672, 0.995)</cell>
            </row>
            <row>
              <cell>METEOR+LC</cell>
              <cell>0.556</cell>
              <cell>(0.499, 0.609)</cell>
              <cell>0.962</cell>
              <cell>(0.687, 0.995)</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>6</id>
        <source>TableSeer</source>
        <caption>Table 5: Correlation of different metrics with adequacy assessment in MTC4 data#@#@Table 6: Correlation between the evaluation results of different metrics</caption>
        <reference_text>In PAGE 6: ...19 0.18 Table 4: Optimized weights for the integration of dis- course feature into sentence-level metrics  Table5  presents the correlation rates of evalua- tion metrics obtained in our experiments under dif- ferent settings, with their 95% conference intervals (CI) provided. The LC and RC ratios are found to have strong correlations with human assessments at the system level even when used alone, highly com- parable to BLEU and TER....</reference_text>
        <page_num>7</page_num>
        <head>
          <rows>
            <row>
              <cell>BLEU</cell>
              <cell>1</cell>
              <cell></cell>
              <cell></cell>
              <cell></cell>
              <cell></cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>TER</cell>
              <cell>-0.699</cell>
              <cell>1</cell>
              <cell></cell>
              <cell></cell>
              <cell></cell>
            </row>
            <row>
              <cell>METEOR</cell>
              <cell>0.834</cell>
              <cell>-0.510</cell>
              <cell>1</cell>
              <cell></cell>
              <cell></cell>
            </row>
            <row>
              <cell>RC</cell>
              <cell>0.287</cell>
              <cell>-0.204</cell>
              <cell>0.405</cell>
              <cell>1</cell>
              <cell></cell>
            </row>
            <row>
              <cell>LC</cell>
              <cell>0.263</cell>
              <cell>-0.097</cell>
              <cell>0.437</cell>
              <cell>0.736</cell>
              <cell>1</cell>
            </row>
            <row>
              <cell></cell>
              <cell>BLEU</cell>
              <cell>TER</cell>
              <cell>METEOR</cell>
              <cell>RC</cell>
              <cell>LC</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>Satanjeev Banerjee</author>
          <author>Alon Lavie</author>
        </authors>
        <title>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.</title>
        <publication>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</publication>
        <pages>65--72</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>Regina Barzilay</author>
          <author>Michael Elhadad</author>
        </authors>
        <title>Using lexical chains for text summarization.</title>
        <publication>In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization,</publication>
        <pages>10--17</pages>
        <date>1997</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>Jill Burstein</author>
        </authors>
        <title>The E-rater scoring engine: Automated essay scoring with natural language processing.</title>
        <publication>Automated Essay Scoring: A Cross-Disciplinary Perspective, chapter 7,</publication>
        <pages>113--122</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>Marine Carpuat</author>
        </authors>
        <title>One translation per discourse.</title>
        <publication>In Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions,</publication>
        <pages>pages</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>Bruno Cartoni</author>
          <author>Andrea Gesmundo</author>
          <author>James Henderson</author>
          <author>Cristina Grisot</author>
          <author>Paola Merlo</author>
          <author>Thomas Meyer</author>
          <author>Jacques Moeschler</author>
          <author>Sandrine Zufferey</author>
          <author>Andrei PopescuBelis</author>
        </authors>
        <title>Improving MT coherence through textlevel processing of input texts: The COMTIS project. In Tralogy,</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Samuel W K Chan</author>
        </authors>
        <title>Extraction of sailent textual patterns: Synergy between lexical cohesion and contextual coherence.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2004</date>
      </reference>
      <reference>
        <id>6</id>
        <authors>
          <author>Elisabet Comelles</author>
          <author>Jesus Gim&#233;nez</author>
          <author>Llu&#236;s M&#225;rquez</author>
          <author>Irene Castell&#242;n</author>
          <author>Victoria Arranz</author>
        </authors>
        <title>Documentlevel automatic MT evaluation based on discourse representations.</title>
        <publication>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</publication>
        <pages>333--338</pages>
        <date>2010</date>
      </reference>
      <reference>
        <id>7</id>
        <authors>
          <author>Christiane Fellbaum</author>
        </authors>
        <title>WordNet: An Electronic Lexical Database.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1998</date>
      </reference>
      <reference>
        <id>8</id>
        <authors>
          <author>Zhengxian Gong</author>
          <author>Min Zhang</author>
          <author>Guodong Zhou</author>
        </authors>
        <title>Cache-based document-level statistical machine translation.</title>
        <publication>In EMNLP 2011,</publication>
        <pages>909--919</pages>
        <date>2011</date>
      </reference>
      <reference>
        <id>9</id>
        <authors>
          <author>M A K Halliday</author>
          <author>Ruqaiya Hasan</author>
        </authors>
        <title>None</title>
        <publication>Cohesion in English.</publication>
        <pages>None</pages>
        <date>1976</date>
      </reference>
      <reference>
        <id>10</id>
        <authors>
          <author>Masaki Itagaki</author>
        </authors>
        <title>Takako Aikawa, and Xiaodong He.</title>
        <publication>In MT Summit XI,</publication>
        <pages>269--274</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>11</id>
        <authors>
          <author>Hans Kamp</author>
          <author>Uwe Reyle</author>
        </authors>
        <title>From Discourse to Logic: An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1993</date>
      </reference>
      <reference>
        <id>12</id>
        <authors>
          <author>Margaret King</author>
          <author>Andrei Popescu-Belis</author>
          <author>Eduard Hovy</author>
        </authors>
        <title>FEMTI: Creating and using a framework for MT evaluation.</title>
        <publication>In MT Summit IX,</publication>
        <pages>224--231</pages>
        <date>2003</date>
      </reference>
      <reference>
        <id>13</id>
        <authors>
          <author>Jing Li</author>
          <author>Chunyu Kit Le Sun</author>
          <author>Jonathan Webster</author>
        </authors>
        <title>A query-focused multi-document summarizer based on lexical chains.</title>
        <publication>In DUC 2007,</publication>
        <pages>None</pages>
        <date>2007</date>
      </reference>
      <reference>
        <id>14</id>
        <authors>
          <author>Xiaoyi Ma</author>
        </authors>
        <title>Multiple-Translation Chinese (MTC) part 4. Linguistic Data Consortium.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>15</id>
        <authors>
          <author>William C Mann</author>
          <author>Sandra A Thompson</author>
        </authors>
        <title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1988</date>
      </reference>
      <reference>
        <id>16</id>
        <authors>
          <author>Keith J Miller</author>
          <author>Michelle Vanni</author>
        </authors>
        <title>Scaling the ISLE taxonomy: Development of metrics for the multi-dimensional characterisation of machine translation quality.</title>
        <publication>In MT Summit VIII,</publication>
        <pages>229--238</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>17</id>
        <authors>
          <author>Jane Morris</author>
          <author>Graeme Hirst</author>
        </authors>
        <title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1991</date>
      </reference>
      <reference>
        <id>18</id>
        <authors>
          <author>Masaki Murata</author>
          <author>Makoto Nagao</author>
        </authors>
        <title>Determination of referential property and number of nouns in Japanese sentences for machine translation into English.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1993</date>
      </reference>
      <reference>
        <id>19</id>
        <authors>
          <author>In TMI</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>218--225</pages>
        <date>1993</date>
      </reference>
      <reference>
        <id>20</id>
        <authors>
          <author>Masaki Murata</author>
          <author>Kiyotaka Uchimoto</author>
          <author>Qing Ma</author>
          <author>Hitoshi Isahara</author>
        </authors>
        <title>A machine-learning approach to estimating the referential properties of Japanese noun phrases. In CICLING</title>
        <publication>None</publication>
        <pages>142--153</pages>
        <date>2001</date>
      </reference>
      <reference>
        <id>21</id>
        <authors>
          <author>Hiromi Nakaiwa</author>
          <author>Satoru Ikehara</author>
        </authors>
        <title>Zero pronoun resolution in a machine translation system by using Japanese to English verbal semantic attributes. In ANLP</title>
        <publication>None</publication>
        <pages>201--208</pages>
        <date>1992</date>
      </reference>
      <reference>
        <id>22</id>
        <authors>
          <author>Hiromi Nakaiwa</author>
          <author>Satoshi Shirai</author>
        </authors>
        <title>Anaphora resolution of Japanese zero pronouns with deictic reference.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1996</date>
      </reference>
      <reference>
        <id>23</id>
        <authors>
          <author>In COLING</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>812--817</pages>
        <date>1996</date>
      </reference>
      <reference>
        <id>24</id>
        <authors>
          <author>Hiromi Nakaiwa</author>
          <author>Satoshi Shirai</author>
          <author>Satoru Ikehara</author>
          <author>Tsukasa Kawaok</author>
        </authors>
        <title>Extrasentential resolution of Japanese zero pronouns using semantic and pragmatic constraints.</title>
        <publication>In Proceedings of the AAAI 1995 Spring Symposium Series: Empirical Methods in Discourse Interpretation and Generation,</publication>
        <pages>99--105</pages>
        <date>1995</date>
      </reference>
      <reference>
        <id>25</id>
        <authors>
          <author>Kishore Papineni</author>
          <author>Salim Roukos</author>
          <author>Todd Ward</author>
          <author>WeiJing Zhu</author>
        </authors>
        <title>BLEU: A method for automatic evaluation of machine translation.</title>
        <publication>In ACL</publication>
        <pages>311--318</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>26</id>
        <authors>
          <author>Jes&#250;s Peral</author>
          <author>Manuel Palomar</author>
          <author>Antonio Ferr&#224;ndez</author>
        </authors>
        <title>Coreference-oriented interlingual slot structure and machine translation.</title>
        <publication>In Proceedings of the ACL Workshop on Coreference and its Applications,</publication>
        <pages>69--76</pages>
        <date>1999</date>
      </reference>
      <reference>
        <id>27</id>
        <authors>
          <author>Martin F Porter</author>
        </authors>
        <title>An algorithm for suffix stripping.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1980</date>
      </reference>
      <reference>
        <id>28</id>
        <authors>
          <author>Mark Przybocki</author>
          <author>Kay Peterson</author>
          <author>S&#233;bastien Bronsart</author>
        </authors>
        <title>NIST metrics for machine translation (MetricsMATR08) development data. Linguistic Data Consortium.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>29</id>
        <authors>
          <author>Matthew Snover</author>
          <author>Bonnie Dorr</author>
          <author>Richard Schwartz</author>
          <author>Linnea Micciulla</author>
          <author>John Makhoul</author>
        </authors>
        <title>A study of translation edit rate with targeted human annotation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>30</id>
        <authors>
          <author>In AMTA</author>
        </authors>
        <title>None</title>
        <publication>None</publication>
        <pages>223--231</pages>
        <date>2006</date>
      </reference>
      <reference>
        <id>31</id>
        <authors>
          <author>Matthew Snover</author>
          <author>Nitin Madnani</author>
          <author>Bonnie J Dorr</author>
          <author>Richard Schwartz</author>
        </authors>
        <title>Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric.</title>
        <publication>In Proceedings of the 4th Workshop on Statistical Machine Translation,</publication>
        <pages>259--268</pages>
        <date>2009</date>
      </reference>
      <reference>
        <id>32</id>
        <authors>
          <author>Georges van Slype</author>
        </authors>
        <title>Critical Study of Methods for Evaluating the Quality of Machine Translation.</title>
        <publication>None</publication>
        <pages>None</pages>
        <date>1979</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Banerjee and Lavie, 2005</string>
        <sentence_id>14180</sentence_id>
        <char_offset>117</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Barzilay and Elhadad (1997)</string>
        <sentence_id>14226</sentence_id>
        <char_offset>104</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>2</reference_id>
        <string>Burstein, 2003</string>
        <sentence_id>14219</sentence_id>
        <char_offset>76</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>3</reference_id>
        <string>Carpuat (2009)</string>
        <sentence_id>14213</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>4</reference_id>
        <string>Cartoni et al., 2011</string>
        <sentence_id>14207</sentence_id>
        <char_offset>25</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>5</reference_id>
        <string>Chan (2004)</string>
        <sentence_id>14226</sentence_id>
        <char_offset>133</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>6</reference_id>
        <string>Comelles et al. (2010)</string>
        <sentence_id>14218</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>7</reference_id>
        <string>Fellbaum, 1998</string>
        <sentence_id>14243</sentence_id>
        <char_offset>58</char_offset>
      </citation>
      <citation>
        <id>8</id>
        <reference_id>8</reference_id>
        <string>Gong et al., 2011</string>
        <sentence_id>14212</sentence_id>
        <char_offset>107</char_offset>
      </citation>
      <citation>
        <id>9</id>
        <reference_id>9</reference_id>
        <string>Halliday and Hasan, 1976</string>
        <sentence_id>14190</sentence_id>
        <char_offset>122</char_offset>
      </citation>
      <citation>
        <id>10</id>
        <reference_id>9</reference_id>
        <string>Halliday and Hasan, 1976</string>
        <sentence_id>14222</sentence_id>
        <char_offset>203</char_offset>
      </citation>
      <citation>
        <id>11</id>
        <reference_id>11</reference_id>
        <string>Kamp and Reyle, 1993</string>
        <sentence_id>14218</sentence_id>
        <char_offset>123</char_offset>
      </citation>
      <citation>
        <id>12</id>
        <reference_id>12</reference_id>
        <string>King et al., 2003</string>
        <sentence_id>14189</sentence_id>
        <char_offset>99</char_offset>
      </citation>
      <citation>
        <id>13</id>
        <reference_id>14</reference_id>
        <string>Ma, 2006</string>
        <sentence_id>14230</sentence_id>
        <char_offset>113</char_offset>
      </citation>
      <citation>
        <id>14</id>
        <reference_id>15</reference_id>
        <string>Mann and Thompson, 1988</string>
        <sentence_id>14215</sentence_id>
        <char_offset>156</char_offset>
      </citation>
      <citation>
        <id>15</id>
        <reference_id>16</reference_id>
        <string>Miller and Vanni (2001)</string>
        <sentence_id>14215</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>16</id>
        <reference_id>17</reference_id>
        <string>Morris and Hirst (1991)</string>
        <sentence_id>14226</sentence_id>
        <char_offset>79</char_offset>
      </citation>
      <citation>
        <id>17</id>
        <reference_id>18</reference_id>
        <string>Murata and Nagao (1993)</string>
        <sentence_id>14206</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>18</id>
        <reference_id>20</reference_id>
        <string>Murata et al. (2001)</string>
        <sentence_id>14206</sentence_id>
        <char_offset>28</char_offset>
      </citation>
      <citation>
        <id>19</id>
        <reference_id>21</reference_id>
        <string>Nakaiwa and Ikehara (1992)</string>
        <sentence_id>14204</sentence_id>
        <char_offset>55</char_offset>
      </citation>
      <citation>
        <id>20</id>
        <reference_id>22</reference_id>
        <string>Nakaiwa and Shirai (1996)</string>
        <sentence_id>14204</sentence_id>
        <char_offset>110</char_offset>
      </citation>
      <citation>
        <id>21</id>
        <reference_id>24</reference_id>
        <string>Nakaiwa et al. (1995)</string>
        <sentence_id>14204</sentence_id>
        <char_offset>83</char_offset>
      </citation>
      <citation>
        <id>22</id>
        <reference_id>25</reference_id>
        <string>Papineni et al., 2002</string>
        <sentence_id>14180</sentence_id>
        <char_offset>85</char_offset>
      </citation>
      <citation>
        <id>23</id>
        <reference_id>26</reference_id>
        <string>Peral et al. (1999)</string>
        <sentence_id>14205</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>24</id>
        <reference_id>28</reference_id>
        <string>Przybocki et al., 2009</string>
        <sentence_id>14230</sentence_id>
        <char_offset>38</char_offset>
      </citation>
      <citation>
        <id>25</id>
        <reference_id>29</reference_id>
        <string>Snover et al. (2006)</string>
        <sentence_id>14216</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>26</id>
        <reference_id>29</reference_id>
        <string>Snover et al., 2006</string>
        <sentence_id>14180</sentence_id>
        <char_offset>152</char_offset>
      </citation>
      <citation>
        <id>27</id>
        <reference_id>31</reference_id>
        <string>Snover et al., 2009</string>
        <sentence_id>14217</sentence_id>
        <char_offset>37</char_offset>
      </citation>
    </citations>
  </content>
</document>
