<document>
  <filename>W09-0212</filename>
  <authors/>
  <title>A Graph-Theoretic Algorithm for Automatic Extension of Translation Lexicons</title>
  <content>
    <sections>
      <section>
        <index>0</index>
        <title>Abstract</title>
        <text>This paper presents a graph-theoretic approach to the identification of yetunknown word translations. The proposed algorithm is based on the recursive Sim- Rank algorithm and relies on the intuition that two words are similar if they establish similar grammatical relationships with similar other words. We also present a formulation of SimRank in matrix form and extensions for edge weights, edge labels and multiple graphs.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This paper presents a graph-theoretic approach to the identification of yetunknown word translations.</text>
              <doc_id>0</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The proposed algorithm is based on the recursive Sim- Rank algorithm and relies on the intuition that two words are similar if they establish similar grammatical relationships with similar other words.</text>
              <doc_id>1</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We also present a formulation of SimRank in matrix form and extensions for edge weights, edge labels and multiple graphs.</text>
              <doc_id>2</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>1</index>
        <title>1 Introduction</title>
        <text>This paper describes a cross-linguistic experiment which attempts to extend a given translation dictionary with translations of novel words.
In our experiment, we use an English and a German text corpus and represent each corpus as a graph whose nodes are words and whose edges represent grammatical relationships between words. The corpora need not be parallel.
Our intuition is that a node in the English and a node in the German graph are similar (that is, are likely to be translations of one another), if their neighboring nodes are. Figure 1 shows part of the English and the German word graph. Many of the (first and higher order) neighbors of food and Lebensmittel translate to one another (marked by dotted lines), indicating that food and Lebensmittel, too, are likely mutual translations.
Our hypothesis yields a recursive algorithm for computing node similarities based on the similarities of the nodes they are connected to. We initialize the node similarities using an English- German dictionary whose entries correspond to known pairs of equivalent nodes (words). These node equivalences constitute the &#8220;seeds&#8221; from which novel English-German node (word) correspondences are bootstrapped.
We are not aware of any previous work using a measure of similarity between nodes in graphs for cross-lingual lexicon acquisition.
Our approach is appealing in that it is language independent, easily implemented and visualized, and readily generalized to other types of data. Section 2 is dedicated to related research on the automatic extension of translation lexicons. In Section 3 we review SimRank (Jeh and Widom, 2002), an algorithm for computing similarities of nodes in a graph, which forms the basis of our work. We provide a formulation of SimRank in terms of simple matrix operations which allows an efficient implementation using optimized matrix packages. We further present a generalization of SimRank to edge-weighted and edge-labeled graphs and to inter-graph node comparison.
Section 4 describes the process used for building the word graphs. Section 5 presents an experiment for evaluating our approach to bilingual lexicon acquisition. Section 6 reports the results. We present our conclusions and directions for future research in Section 7.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>This paper describes a cross-linguistic experiment which attempts to extend a given translation dictionary with translations of novel words.</text>
              <doc_id>3</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In our experiment, we use an English and a German text corpus and represent each corpus as a graph whose nodes are words and whose edges represent grammatical relationships between words.</text>
              <doc_id>4</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The corpora need not be parallel.</text>
              <doc_id>5</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our intuition is that a node in the English and a node in the German graph are similar (that is, are likely to be translations of one another), if their neighboring nodes are.</text>
              <doc_id>6</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Figure 1 shows part of the English and the German word graph.</text>
              <doc_id>7</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Many of the (first and higher order) neighbors of food and Lebensmittel translate to one another (marked by dotted lines), indicating that food and Lebensmittel, too, are likely mutual translations.</text>
              <doc_id>8</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our hypothesis yields a recursive algorithm for computing node similarities based on the similarities of the nodes they are connected to.</text>
              <doc_id>9</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We initialize the node similarities using an English- German dictionary whose entries correspond to known pairs of equivalent nodes (words).</text>
              <doc_id>10</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>These node equivalences constitute the &#8220;seeds&#8221; from which novel English-German node (word) correspondences are bootstrapped.</text>
              <doc_id>11</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We are not aware of any previous work using a measure of similarity between nodes in graphs for cross-lingual lexicon acquisition.</text>
              <doc_id>12</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Our approach is appealing in that it is language independent, easily implemented and visualized, and readily generalized to other types of data.</text>
              <doc_id>13</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 2 is dedicated to related research on the automatic extension of translation lexicons.</text>
              <doc_id>14</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>In Section 3 we review SimRank (Jeh and Widom, 2002), an algorithm for computing similarities of nodes in a graph, which forms the basis of our work.</text>
              <doc_id>15</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We provide a formulation of SimRank in terms of simple matrix operations which allows an efficient implementation using optimized matrix packages.</text>
              <doc_id>16</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We further present a generalization of SimRank to edge-weighted and edge-labeled graphs and to inter-graph node comparison.</text>
              <doc_id>17</doc_id>
              <sec_id>4</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Section 4 describes the process used for building the word graphs.</text>
              <doc_id>18</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Section 5 presents an experiment for evaluating our approach to bilingual lexicon acquisition.</text>
              <doc_id>19</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Section 6 reports the results.</text>
              <doc_id>20</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We present our conclusions and directions for future research in Section 7.</text>
              <doc_id>21</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>2</index>
        <title>2 Related Work on cross-lingual lexical acquisition</title>
        <text>The work by Rapp (1999) is driven by the idea that a word and its translation to another language are likely to co-occur with similar words. Given a German and an English corpus, he computes two word-by-word co-occurrence matrices, one for each language, whose columns span a vector space representing the corresponding corpus.
In order to find the English translation of a German word, he uses a base dictionary to translate all known column labels to English. This yields a new vector representation of the German word in the English vector space. This mapped vector is then compared to all English word vectors, the most similar ones being candidate translations.
award Preis
Rapp reports an accuracy of 72% for a small number of test words with well-defined meaning.
Diab and Finch (2000) first compute word similarities within each language corpus separately by comparing their co-occurrence vectors. Their challenge then is to derive a mapping from one language to the other (i.e. a translation lexicon) which best preserves the intra-language word similarities. The mapping is initialized with a few seed &#8220;translations&#8221; (punctuation marks) which are assumed to be common to both corpora. They test their method on two corpora written in the same language and report accuracy rates of over 90% on this pseudo-translation task. The approach is attractive in that it does not require a seed lexicon. A drawback is its high computational cost. Koehn and Knight (2002) use a (linear) combination of clues for bootstrapping an English- German noun translation dictionary. In addition to similar assumptions as above, they consider words to be likely translations of one another if they have the same or similar spelling and/or occur with similar frequencies. Koehn and Knight reach an accuracy of 39% on a test set consisting of the 1,000 most frequent English and German nouns. The experiment excludes verbs whose semantics are more complex than those of nouns.
Otero and Campos (2005) extract English- Spanish pairs of lexico-syntactic patterns from a small parallel corpus. They then construct context vectors for all English and Spanish words by recording their frequency of occurrence in each of these patterns. English and Spanish vectors thus reside in the same vector space and are readily compared.
The approach reaches an accuracy of 89% on a test set consisting of 100 randomly chosen words from among those with a frequency of 100 or higher. The authors do not report results for lowfrequency words.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The work by Rapp (1999) is driven by the idea that a word and its translation to another language are likely to co-occur with similar words.</text>
              <doc_id>22</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Given a German and an English corpus, he computes two word-by-word co-occurrence matrices, one for each language, whose columns span a vector space representing the corresponding corpus.</text>
              <doc_id>23</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In order to find the English translation of a German word, he uses a base dictionary to translate all known column labels to English.</text>
              <doc_id>24</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>This yields a new vector representation of the German word in the English vector space.</text>
              <doc_id>25</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This mapped vector is then compared to all English word vectors, the most similar ones being candidate translations.</text>
              <doc_id>26</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>award Preis</text>
              <doc_id>27</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Rapp reports an accuracy of 72% for a small number of test words with well-defined meaning.</text>
              <doc_id>28</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Diab and Finch (2000) first compute word similarities within each language corpus separately by comparing their co-occurrence vectors.</text>
              <doc_id>29</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Their challenge then is to derive a mapping from one language to the other (i.e. a translation lexicon) which best preserves the intra-language word similarities.</text>
              <doc_id>30</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The mapping is initialized with a few seed &#8220;translations&#8221; (punctuation marks) which are assumed to be common to both corpora.</text>
              <doc_id>31</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>They test their method on two corpora written in the same language and report accuracy rates of over 90% on this pseudo-translation task.</text>
              <doc_id>32</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>The approach is attractive in that it does not require a seed lexicon.</text>
              <doc_id>33</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>A drawback is its high computational cost.</text>
              <doc_id>34</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>Koehn and Knight (2002) use a (linear) combination of clues for bootstrapping an English- German noun translation dictionary.</text>
              <doc_id>35</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>In addition to similar assumptions as above, they consider words to be likely translations of one another if they have the same or similar spelling and/or occur with similar frequencies.</text>
              <doc_id>36</doc_id>
              <sec_id>7</sec_id>
            </sentence>
            <sentence>
              <text>Koehn and Knight reach an accuracy of 39% on a test set consisting of the 1,000 most frequent English and German nouns.</text>
              <doc_id>37</doc_id>
              <sec_id>8</sec_id>
            </sentence>
            <sentence>
              <text>The experiment excludes verbs whose semantics are more complex than those of nouns.</text>
              <doc_id>38</doc_id>
              <sec_id>9</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Otero and Campos (2005) extract English- Spanish pairs of lexico-syntactic patterns from a small parallel corpus.</text>
              <doc_id>39</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>They then construct context vectors for all English and Spanish words by recording their frequency of occurrence in each of these patterns.</text>
              <doc_id>40</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>English and Spanish vectors thus reside in the same vector space and are readily compared.</text>
              <doc_id>41</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The approach reaches an accuracy of 89% on a test set consisting of 100 randomly chosen words from among those with a frequency of 100 or higher.</text>
              <doc_id>42</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The authors do not report results for lowfrequency words.</text>
              <doc_id>43</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>3</index>
        <title>3 The SimRank algorithm</title>
        <text>An algorithm for computing similarities of nodes in graphs is the SimRank algorithm (Jeh and Widom, 2002). It was originally proposed for directed unweighted graphs of web pages (nodes) and hyperlinks (links). The idea of SimRank is to recursively compute node similarity scores based on the scores of neighboring nodes. The similarity S ij of two different nodes i and j in a graph is defined as the normalized sum of the pairwise similarities of their neighbors:
S ij =
c |N(i)| |N(j)| &#8721;
k&#8712;N(i),l&#8712;N(j)
S kl . (1)
N(i) and N(j) are the set of i&#8217;s and j&#8217;s neighbors respectively, and c is a multiplicative factor smaller than but close to 1 which demotes the contribution of higher order neighbors. S ij is set to 1 if i and j are identical, which provides a basis for the recursion.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>An algorithm for computing similarities of nodes in graphs is the SimRank algorithm (Jeh and Widom, 2002).</text>
              <doc_id>44</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>It was originally proposed for directed unweighted graphs of web pages (nodes) and hyperlinks (links).</text>
              <doc_id>45</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The idea of SimRank is to recursively compute node similarity scores based on the scores of neighboring nodes.</text>
              <doc_id>46</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>The similarity S ij of two different nodes i and j in a graph is defined as the normalized sum of the pairwise similarities of their neighbors:</text>
              <doc_id>47</doc_id>
              <sec_id>3</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>S ij =</text>
              <doc_id>48</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>c |N(i)| |N(j)| &#8721;</text>
              <doc_id>49</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>k&#8712;N(i),l&#8712;N(j)</text>
              <doc_id>50</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>S kl .</text>
              <doc_id>51</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>(1)</text>
              <doc_id>52</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>N(i) and N(j) are the set of i&#8217;s and j&#8217;s neighbors respectively, and c is a multiplicative factor smaller than but close to 1 which demotes the contribution of higher order neighbors.</text>
              <doc_id>53</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>S ij is set to 1 if i and j are identical, which provides a basis for the recursion.</text>
              <doc_id>54</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections>
          <subsection>
            <index>0</index>
            <title>3.1 Matrix formulation of SimRank</title>
            <text>We derive a formulation of the SimRank similarity updates which merely consists of matrix multiplications as follows. In terms of the graph&#8217;s (binary) adjacency matrix A, the SimRank recursion reads:
S ij =
c |N(i)| |N(j)| &#8721;
k&#8712;N(i),l&#8712;N(j)
A ik A jl S kl
(2) noting that A ik A jl = 1, iff k is a neighbor of i and l is a neighbor of j at the same time. This is
equivalent to
S ij
= c &#8721; k,l
= c &#8721; k,l
A ik |N(i)|
A ik &#8721;
&#957; A i&#957;
A jl |N(j)| S kl (3)
A jl &#8721;
&#957; A j&#957;
S kl .
The S ij can be assembled in a square node similarity matrix S, and it is easy to see that the individual similarity updates can be summarized as:
S k = c &#195; S k&#8722;1&#195;T (4)
where &#195; is the row-normalized adjacency matrix and k denotes the current level of recursion. &#195; is obtained by dividing each entry of A by the sum of the entries in its row. The SimRank iteration is initialized with S = I, and the diagonal of S, which contains the node self-similarities, is reset to ones after each iteration. This representation of SimRank in closed matrix form allows the use of optimized off-the-shelf sparse matrix packages for the implementation of the algorithm. This rendered the pruning strategies proposed in the original paper unnecessary. We also note that the Bipartite SimRank algorithm introduced in (Jeh and Widom, 2002) is just a special case of Equation 4.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>We derive a formulation of the SimRank similarity updates which merely consists of matrix multiplications as follows.</text>
                  <doc_id>55</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>In terms of the graph&#8217;s (binary) adjacency matrix A, the SimRank recursion reads:</text>
                  <doc_id>56</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S ij =</text>
                  <doc_id>57</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>c |N(i)| |N(j)| &#8721;</text>
                  <doc_id>58</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>k&#8712;N(i),l&#8712;N(j)</text>
                  <doc_id>59</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A ik A jl S kl</text>
                  <doc_id>60</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(2) noting that A ik A jl = 1, iff k is a neighbor of i and l is a neighbor of j at the same time.</text>
                  <doc_id>61</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>This is</text>
                  <doc_id>62</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>equivalent to</text>
                  <doc_id>63</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S ij</text>
                  <doc_id>64</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>= c &#8721; k,l</text>
                  <doc_id>65</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>= c &#8721; k,l</text>
                  <doc_id>66</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A ik |N(i)|</text>
                  <doc_id>67</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A ik &#8721;</text>
                  <doc_id>68</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#957; A i&#957;</text>
                  <doc_id>69</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A jl |N(j)| S kl (3)</text>
                  <doc_id>70</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>A jl &#8721;</text>
                  <doc_id>71</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#957; A j&#957;</text>
                  <doc_id>72</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S kl .</text>
                  <doc_id>73</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The S ij can be assembled in a square node similarity matrix S, and it is easy to see that the individual similarity updates can be summarized as:</text>
                  <doc_id>74</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S k = c &#195; S k&#8722;1&#195;T (4)</text>
                  <doc_id>75</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where &#195; is the row-normalized adjacency matrix and k denotes the current level of recursion.</text>
                  <doc_id>76</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>&#195; is obtained by dividing each entry of A by the sum of the entries in its row.</text>
                  <doc_id>77</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The SimRank iteration is initialized with S = I, and the diagonal of S, which contains the node self-similarities, is reset to ones after each iteration.</text>
                  <doc_id>78</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>This representation of SimRank in closed matrix form allows the use of optimized off-the-shelf sparse matrix packages for the implementation of the algorithm.</text>
                  <doc_id>79</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
                <sentence>
                  <text>This rendered the pruning strategies proposed in the original paper unnecessary.</text>
                  <doc_id>80</doc_id>
                  <sec_id>4</sec_id>
                </sentence>
                <sentence>
                  <text>We also note that the Bipartite SimRank algorithm introduced in (Jeh and Widom, 2002) is just a special case of Equation 4.</text>
                  <doc_id>81</doc_id>
                  <sec_id>5</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>1</index>
            <title>3.2 Extension with weights and link types</title>
            <text>The SimRank algorithm assumes an unweighted graph, i.e. a binary adjacency matrix A. Equation 4 can equally be used to compute similarities in a weighted graph by letting &#195; be the graph&#8217;s row-normalized weighted adjacency matrix. The entries of &#195; then represent transition probabilities between nodes rather than hard (binary) adjacency. The proof of the existence and uniqueness of a solution to this more general recursion proceeds in analogy to the proof given in the original paper.
Furthermore, we allow the links in the graph to be of different types and define the following generalized SimRank recursion, where T is the set of link types and N t (i) denotes the set of nodes connected to node i via a link of type t.
S ij = c |T | &#8721;
t&#8712;T
1 |N t (i)| |N t (j)| &#8721;
k&#8712;N t(i),l&#8712;N t(j)
In matrix formulation: S k = c &#8721;
T
&#195; t S k&#8722;1 &#195; t |T |
t&#8712;T
S kl .
(5)
(6)
where A t is the adjacency matrix associated with link type t and, again, may be weighted.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>The SimRank algorithm assumes an unweighted graph, i.e. a binary adjacency matrix A. Equation 4 can equally be used to compute similarities in a weighted graph by letting &#195; be the graph&#8217;s row-normalized weighted adjacency matrix.</text>
                  <doc_id>82</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>The entries of &#195; then represent transition probabilities between nodes rather than hard (binary) adjacency.</text>
                  <doc_id>83</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The proof of the existence and uniqueness of a solution to this more general recursion proceeds in analogy to the proof given in the original paper.</text>
                  <doc_id>84</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>Furthermore, we allow the links in the graph to be of different types and define the following generalized SimRank recursion, where T is the set of link types and N t (i) denotes the set of nodes connected to node i via a link of type t.</text>
                  <doc_id>85</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S ij = c |T | &#8721;</text>
                  <doc_id>86</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>t&#8712;T</text>
                  <doc_id>87</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>1 |N t (i)| |N t (j)| &#8721;</text>
                  <doc_id>88</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>k&#8712;N t(i),l&#8712;N t(j)</text>
                  <doc_id>89</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>In matrix formulation: S k = c &#8721;</text>
                  <doc_id>90</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>T</text>
                  <doc_id>91</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#195; t S k&#8722;1 &#195; t |T |</text>
                  <doc_id>92</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>t&#8712;T</text>
                  <doc_id>93</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S kl .</text>
                  <doc_id>94</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(5)</text>
                  <doc_id>95</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>(6)</text>
                  <doc_id>96</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>where A t is the adjacency matrix associated with link type t and, again, may be weighted.</text>
                  <doc_id>97</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
          <subsection>
            <index>2</index>
            <title>3.3 SimRank across graphs</title>
            <text>SimRank was originally designed for the comparison of nodes within a single graph. However, SimRank is readily and accordingly applied to the comparison of nodes of two different graphs. The original SimRank algorithm starts off with the nodes&#8217; self-similarities which propagate to other non-identical pairs of nodes. In the case of two different graphs A and B, we can instead initialize the algorithm with a set of initially known node-node correspondences.
The original SimRank equation (2) then becomes
S ij =
c |N(i)| |N(j)|
which is equivalent to
or, if links are typed,
&#8721; A ik B jl S kl , (7)
k,l
S k = c &#195; S k&#8722;1 &#732;B T , (8)
S k = c |T | &#8721;
T
&#195; t S k&#8722;1 &#732;Bt . (9)
t&#8712;T
The similarity matrix S is now a rectangular matrix containing the similarities between nodes in A and nodes in B. Those entries of S which correspond to known node-node correspondences are reset to 1 after each iteration.</text>
            <paragraphs>
              <paragraph>
                <sentence>
                  <text>SimRank was originally designed for the comparison of nodes within a single graph.</text>
                  <doc_id>98</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>However, SimRank is readily and accordingly applied to the comparison of nodes of two different graphs.</text>
                  <doc_id>99</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
                <sentence>
                  <text>The original SimRank algorithm starts off with the nodes&#8217; self-similarities which propagate to other non-identical pairs of nodes.</text>
                  <doc_id>100</doc_id>
                  <sec_id>2</sec_id>
                </sentence>
                <sentence>
                  <text>In the case of two different graphs A and B, we can instead initialize the algorithm with a set of initially known node-node correspondences.</text>
                  <doc_id>101</doc_id>
                  <sec_id>3</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The original SimRank equation (2) then becomes</text>
                  <doc_id>102</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S ij =</text>
                  <doc_id>103</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>c |N(i)| |N(j)|</text>
                  <doc_id>104</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>which is equivalent to</text>
                  <doc_id>105</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>or, if links are typed,</text>
                  <doc_id>106</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#8721; A ik B jl S kl , (7)</text>
                  <doc_id>107</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>k,l</text>
                  <doc_id>108</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S k = c &#195; S k&#8722;1 &#732;B T , (8)</text>
                  <doc_id>109</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>S k = c |T | &#8721;</text>
                  <doc_id>110</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>T</text>
                  <doc_id>111</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>&#195; t S k&#8722;1 &#732;Bt .</text>
                  <doc_id>112</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>(9)</text>
                  <doc_id>113</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>t&#8712;T</text>
                  <doc_id>114</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
              </paragraph>
              <paragraph>
                <sentence>
                  <text>The similarity matrix S is now a rectangular matrix containing the similarities between nodes in A and nodes in B.</text>
                  <doc_id>115</doc_id>
                  <sec_id>0</sec_id>
                </sentence>
                <sentence>
                  <text>Those entries of S which correspond to known node-node correspondences are reset to 1 after each iteration.</text>
                  <doc_id>116</doc_id>
                  <sec_id>1</sec_id>
                </sentence>
              </paragraph>
            </paragraphs>
          </subsection>
        </subsections>
      </section>
      <section>
        <index>4</index>
        <title>4 The graph model</title>
        <text>The grammatical relationships were extracted from the British National Corpus (BNC) (100 million words), and the Huge German Corpus (HGC) (180 million words of newspaper text). We compiled a list of English verb-object (V-O) pairs based on the verb-argument information extracted by (Schulte im Walde, 1998) from the BNC. The German V-O pairs were extracted from a syntactic analysis of the HGC carried out using the BitPar parser (Schmid, 2004). We used only V-O pairs because they constitute far more sense-discriminative contexts than, for example, verb-subject pairs, but we plan to examine these and other grammatical relationships in future work. We reduced English compound nouns to their heads and lemmatized all data. In English phrasal
English German
Low Mid High Low Mid High
verbs, we attach the particles to the verbs to distinguish them from the original verb (e.g put off vs. put). Both the English and German V-O pairs were filtered using stop lists consisting of modal and auxiliary verbs as well as pronouns. To reduce noise, we decided to keep only those relationships which occurred at least three times in the respective corpus.
The English and German data alike are then represented as a bipartite graph whose nodes divide into two sets, verbs and nouns, and whose edges are the V-O relationships which connect verbs to nouns (cf. Figure 1). The edges of the graph are weighted by frequency of occurrence.
We &#8220;prune&#8221; both the English and German graph by recursively removing all leaf nodes (nodes with a single neighbor). As these correspond to words which appear only in a single relationship, there is only limited evidence of their meaning.
After pruning, there are 4,926 nodes (3,365 nouns, 1,561 verbs) and 43,762 links in the English, and 3,074 nodes (2,207 nouns, 867 verbs) and 15,386 links in the German word graph.
mid- (&gt; 20 and &#8804; 100), and low- (&#8804; 20) frequent as well as word class (noun, verb). Thus, we obtain 12 categories of test words (summarized in Table 1), each of which is filled with 50 randomly selected words, giving a total of 600 test words. SimRank returns a matrix of English-German node-node similarities. Given a test word, we extract its row from the similarity matrix and sort the corresponding words by their similarities to the test word. We then scan this sorted list of words and their similarities for the test word&#8217;s reference translations (those listed in the original dictionary) and record their positions (i.e. ranks) in this list. We then replace absolute ranks with relative ranks by dividing by the total number of candidate translations.
6 Results
Table 1 lists the mean relative rank of the reference translations for each of the test categories. The values of around 0.2-0.3 clearly indicate that our approach ranks the reference translations much higher than a random process would.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The grammatical relationships were extracted from the British National Corpus (BNC) (100 million words), and the Huge German Corpus (HGC) (180 million words of newspaper text).</text>
              <doc_id>117</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We compiled a list of English verb-object (V-O) pairs based on the verb-argument information extracted by (Schulte im Walde, 1998) from the BNC.</text>
              <doc_id>118</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The German V-O pairs were extracted from a syntactic analysis of the HGC carried out using the BitPar parser (Schmid, 2004).</text>
              <doc_id>119</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We used only V-O pairs because they constitute far more sense-discriminative contexts than, for example, verb-subject pairs, but we plan to examine these and other grammatical relationships in future work.</text>
              <doc_id>120</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We reduced English compound nouns to their heads and lemmatized all data.</text>
              <doc_id>121</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>In English phrasal</text>
              <doc_id>122</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>English German</text>
              <doc_id>123</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Low Mid High Low Mid High</text>
              <doc_id>124</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>verbs, we attach the particles to the verbs to distinguish them from the original verb (e.g put off vs. put).</text>
              <doc_id>125</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Both the English and German V-O pairs were filtered using stop lists consisting of modal and auxiliary verbs as well as pronouns.</text>
              <doc_id>126</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>To reduce noise, we decided to keep only those relationships which occurred at least three times in the respective corpus.</text>
              <doc_id>127</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The English and German data alike are then represented as a bipartite graph whose nodes divide into two sets, verbs and nouns, and whose edges are the V-O relationships which connect verbs to nouns (cf.</text>
              <doc_id>128</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Figure 1).</text>
              <doc_id>129</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The edges of the graph are weighted by frequency of occurrence.</text>
              <doc_id>130</doc_id>
              <sec_id>2</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We &#8220;prune&#8221; both the English and German graph by recursively removing all leaf nodes (nodes with a single neighbor).</text>
              <doc_id>131</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>As these correspond to words which appear only in a single relationship, there is only limited evidence of their meaning.</text>
              <doc_id>132</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>After pruning, there are 4,926 nodes (3,365 nouns, 1,561 verbs) and 43,762 links in the English, and 3,074 nodes (2,207 nouns, 867 verbs) and 15,386 links in the German word graph.</text>
              <doc_id>133</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>mid- (&gt; 20 and &#8804; 100), and low- (&#8804; 20) frequent as well as word class (noun, verb).</text>
              <doc_id>134</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Thus, we obtain 12 categories of test words (summarized in Table 1), each of which is filled with 50 randomly selected words, giving a total of 600 test words.</text>
              <doc_id>135</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>SimRank returns a matrix of English-German node-node similarities.</text>
              <doc_id>136</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Given a test word, we extract its row from the similarity matrix and sort the corresponding words by their similarities to the test word.</text>
              <doc_id>137</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We then scan this sorted list of words and their similarities for the test word&#8217;s reference translations (those listed in the original dictionary) and record their positions (i.e. ranks) in this list.</text>
              <doc_id>138</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>We then replace absolute ranks with relative ranks by dividing by the total number of candidate translations.</text>
              <doc_id>139</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>6 Results</text>
              <doc_id>140</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Table 1 lists the mean relative rank of the reference translations for each of the test categories.</text>
              <doc_id>141</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The values of around 0.2-0.3 clearly indicate that our approach ranks the reference translations much higher than a random process would.</text>
              <doc_id>142</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>5</index>
        <title>5 Evaluation experiment</title>
        <text></text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text></text>
              <doc_id>143</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>6</index>
        <title>6 Results</title>
        <text>Table 1 lists the mean relative rank of the reference translations for each of the test categories. The values of around 0.2-0.3 clearly indicate that our approach ranks the reference translations much higher than a random process would.
5 Evaluation experiment
The aim of our evaluation experiment is to test the extended SimRank algorithm for its ability to identify novel word translations given the English and German word graph of the previous section and an English-German seed lexicon. We use the dict.cc English-German dictionary 1 . Our evaluation strategy is as follows. We select a set of test words at random from among the words listed in the dictionary, and remove their entries from the dictionary. We run six iterations of SimRank using the remaining dictionary entries as the seed translations (the known node equivalences), and record the similarities of each test word to its known translations. As in the original SimRank paper, c is set to 0.8.
We include both English and German test words and let them vary in frequency: high- (&gt; 100),
1 http://www.dict.cc/ (May 5th 2008)
Frequency
0 5 15 25 0.0 0.2 0.4 0.6 0.8 1.0
Relative rank
Exemplary of all test sets, Figure 2 shows the distribution of the relative ranks of the reference translations for the test words in English-High-N. The bulk of the distribution lies below 0.3, i.e. in the top 30% of the candidate list.
In order to give the reader an idea of the results, we present some examples of test words and their
Test word Top 10 predicted translations Ranks sanction Ausgangssperre Wirtschaftssanktion Sanktion(6) Ausnahmezustand Embargo Moratorium Ma&#223;nahme(1407) Sanktion Todesurteil Geldstrafe Bu&#223;geld Anmeldung delay anfechten revidieren zur&#252;ckstellen f&#252;llen verk&#252;nden quittieren vertagen verschieben aufheben respektieren Kosten hallmark trouser blouse makup uniform armour robe testimony witness jumper &#246;ffnen unlock lock usher step peer shut guard hurry slam close
verz&#246;gern(78) aufhalten(712)
cost(285)
open(12) undo(481)
predicted translations in Table 2. Most of the 10 top-ranked candidate translations of sanction are hyponyms of the correct translations. This is mainly due to insufficient noun compound analysis. Both the English and German nouns in our graph model are single words. Whereas the English nouns consist only of head nouns, the German nouns include many compounds (as they are written without spaces), and thus tend to be more specific. Some of the top candidate translations of delay are correct (verschieben) or at least acceptable (vertagen), but do not count as such as they are missing in the gold standard dictionary.
The mistranslation of the German noun Kosten is due to semantic ambiguity. Kosten co-occurs often with the verb tragen as in to bear costs. The verb tragen however is ambiguous and may as well be translated as to wear which is strongly associated with clothes. We find several antonyms of &#246;ffnen among its top predicted translations. Verb-object relationships alone do not suffice to distinguish synonyms from antonyms. Similarly, it is extremely difficult to differentiate between the members of closed categories (e.g. the days of the week, months of the year, mass and time units) using only syntactic relationships.</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>Table 1 lists the mean relative rank of the reference translations for each of the test categories.</text>
              <doc_id>144</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The values of around 0.2-0.3 clearly indicate that our approach ranks the reference translations much higher than a random process would.</text>
              <doc_id>145</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>5 Evaluation experiment</text>
              <doc_id>146</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The aim of our evaluation experiment is to test the extended SimRank algorithm for its ability to identify novel word translations given the English and German word graph of the previous section and an English-German seed lexicon.</text>
              <doc_id>147</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We use the dict.cc English-German dictionary 1 .</text>
              <doc_id>148</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>Our evaluation strategy is as follows.</text>
              <doc_id>149</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We select a set of test words at random from among the words listed in the dictionary, and remove their entries from the dictionary.</text>
              <doc_id>150</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We run six iterations of SimRank using the remaining dictionary entries as the seed translations (the known node equivalences), and record the similarities of each test word to its known translations.</text>
              <doc_id>151</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>As in the original SimRank paper, c is set to 0.8.</text>
              <doc_id>152</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>We include both English and German test words and let them vary in frequency: high- (&gt; 100),</text>
              <doc_id>153</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>1 http://www.dict.cc/ (May 5th 2008)</text>
              <doc_id>154</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Frequency</text>
              <doc_id>155</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>0 5 15 25 0.0 0.2 0.4 0.6 0.8 1.0</text>
              <doc_id>156</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Relative rank</text>
              <doc_id>157</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Exemplary of all test sets, Figure 2 shows the distribution of the relative ranks of the reference translations for the test words in English-High-N.</text>
              <doc_id>158</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>The bulk of the distribution lies below 0.3, i.e. in the top 30% of the candidate list.</text>
              <doc_id>159</doc_id>
              <sec_id>1</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>In order to give the reader an idea of the results, we present some examples of test words and their</text>
              <doc_id>160</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>Test word Top 10 predicted translations Ranks sanction Ausgangssperre Wirtschaftssanktion Sanktion(6) Ausnahmezustand Embargo Moratorium Ma&#223;nahme(1407) Sanktion Todesurteil Geldstrafe Bu&#223;geld Anmeldung delay anfechten revidieren zur&#252;ckstellen f&#252;llen verk&#252;nden quittieren vertagen verschieben aufheben respektieren Kosten hallmark trouser blouse makup uniform armour robe testimony witness jumper &#246;ffnen unlock lock usher step peer shut guard hurry slam close</text>
              <doc_id>161</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>verz&#246;gern(78) aufhalten(712)</text>
              <doc_id>162</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>cost(285)</text>
              <doc_id>163</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>open(12) undo(481)</text>
              <doc_id>164</doc_id>
              <sec_id>0</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>predicted translations in Table 2.</text>
              <doc_id>165</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Most of the 10 top-ranked candidate translations of sanction are hyponyms of the correct translations.</text>
              <doc_id>166</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>This is mainly due to insufficient noun compound analysis.</text>
              <doc_id>167</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Both the English and German nouns in our graph model are single words.</text>
              <doc_id>168</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Whereas the English nouns consist only of head nouns, the German nouns include many compounds (as they are written without spaces), and thus tend to be more specific.</text>
              <doc_id>169</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Some of the top candidate translations of delay are correct (verschieben) or at least acceptable (vertagen), but do not count as such as they are missing in the gold standard dictionary.</text>
              <doc_id>170</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
          <paragraph>
            <sentence>
              <text>The mistranslation of the German noun Kosten is due to semantic ambiguity.</text>
              <doc_id>171</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>Kosten co-occurs often with the verb tragen as in to bear costs.</text>
              <doc_id>172</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>The verb tragen however is ambiguous and may as well be translated as to wear which is strongly associated with clothes.</text>
              <doc_id>173</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>We find several antonyms of &#246;ffnen among its top predicted translations.</text>
              <doc_id>174</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>Verb-object relationships alone do not suffice to distinguish synonyms from antonyms.</text>
              <doc_id>175</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>Similarly, it is extremely difficult to differentiate between the members of closed categories (e.g. the days of the week, months of the year, mass and time units) using only syntactic relationships.</text>
              <doc_id>176</doc_id>
              <sec_id>5</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
      <section>
        <index>7</index>
        <title>7 Conclusions and Future Research</title>
        <text>The matrix formulation of the SimRank algorithm given in this paper allows an implementation using efficient off-the-shelf software libraries for matrix computation. We presented an extension of the SimRank algorithm to edge-weighted and edge-labeled graphs. We further generalized the SimRank equations to permit the comparison of nodes from two different graphs, and proposed an application to bilingual lexicon induction. Our system is not yet accurate enough to be used for actual compilation of translation dictionaries. We further need to address the problem of data sparsity. In particular, we need to remove the bias towards low-degree words whose similarities to other words are unduly high. In order to solve the problem of ambiguity, we intend to apply SimRank to the incidence representation of the word graphs, which is constructed by putting a node on each link. The proposed algorithm will then naturally return similarities between the more sense-discriminative links (syntactic relationships) in addition to similarities between the often ambiguous nodes (isolated words).</text>
        <paragraphs>
          <paragraph>
            <sentence>
              <text>The matrix formulation of the SimRank algorithm given in this paper allows an implementation using efficient off-the-shelf software libraries for matrix computation.</text>
              <doc_id>177</doc_id>
              <sec_id>0</sec_id>
            </sentence>
            <sentence>
              <text>We presented an extension of the SimRank algorithm to edge-weighted and edge-labeled graphs.</text>
              <doc_id>178</doc_id>
              <sec_id>1</sec_id>
            </sentence>
            <sentence>
              <text>We further generalized the SimRank equations to permit the comparison of nodes from two different graphs, and proposed an application to bilingual lexicon induction.</text>
              <doc_id>179</doc_id>
              <sec_id>2</sec_id>
            </sentence>
            <sentence>
              <text>Our system is not yet accurate enough to be used for actual compilation of translation dictionaries.</text>
              <doc_id>180</doc_id>
              <sec_id>3</sec_id>
            </sentence>
            <sentence>
              <text>We further need to address the problem of data sparsity.</text>
              <doc_id>181</doc_id>
              <sec_id>4</sec_id>
            </sentence>
            <sentence>
              <text>In particular, we need to remove the bias towards low-degree words whose similarities to other words are unduly high.</text>
              <doc_id>182</doc_id>
              <sec_id>5</sec_id>
            </sentence>
            <sentence>
              <text>In order to solve the problem of ambiguity, we intend to apply SimRank to the incidence representation of the word graphs, which is constructed by putting a node on each link.</text>
              <doc_id>183</doc_id>
              <sec_id>6</sec_id>
            </sentence>
            <sentence>
              <text>The proposed algorithm will then naturally return similarities between the more sense-discriminative links (syntactic relationships) in addition to similarities between the often ambiguous nodes (isolated words).</text>
              <doc_id>184</doc_id>
              <sec_id>7</sec_id>
            </sentence>
          </paragraph>
        </paragraphs>
        <subsections/>
      </section>
    </sections>
    <tables>
      <table>
        <id>1</id>
        <source>TET</source>
        <caption>Table 1: The 12 categories of test words, with mean relative ranks of test words</caption>
        <reference_text></reference_text>
        <page_num>3</page_num>
        <head>
          <rows>
            <row>
              <cell>N</cell>
              <cell>V</cell>
              <cell>N</cell>
              <cell>V</cell>
              <cell>N</cell>
              <cell>V</cell>
              <cell>N</cell>
              <cell>V</cell>
              <cell>N</cell>
              <cell>V</cell>
              <cell>N</cell>
              <cell>V</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>0.313</cell>
              <cell>0.228</cell>
              <cell>0.253</cell>
              <cell>0.288</cell>
              <cell>0.253</cell>
              <cell>0.255</cell>
              <cell>0.232</cell>
              <cell>0.247</cell>
              <cell>0.205</cell>
              <cell>0.237</cell>
              <cell>0.211</cell>
              <cell>0.205</cell>
            </row>
          </rows>
        </body>
      </table>
      <table>
        <id>2</id>
        <source>TableSeer</source>
        <caption>Table 2: Some examples of test words, their pre- dicted translations, and the ranks of their true translations.</caption>
        <reference_text>None</reference_text>
        <page_num>5</page_num>
        <head>
          <rows>
            <row>
              <cell>Test word</cell>
              <cell>Top 10 predicted translations</cell>
              <cell>Top 10 predicted translations</cell>
              <cell>Top 10 predicted translations</cell>
              <cell>Ranks</cell>
            </row>
          </rows>
        </head>
        <body>
          <rows>
            <row>
              <cell>sanction</cell>
              <cell>Ausgangssperre</cell>
              <cell>Ausgangssperre</cell>
              <cell>Wirtschaftssanktion</cell>
              <cell>Sanktion(6)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>AusnahmezustandEmbargo Moratorium</cell>
              <cell>AusnahmezustandEmbargo Moratorium</cell>
              <cell>AusnahmezustandEmbargo Moratorium</cell>
              <cell>Ma?nahme(1407)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>Sanktion Todesurteil Geldstrafe Bu?geld</cell>
              <cell>Sanktion Todesurteil Geldstrafe Bu?geld</cell>
              <cell>Sanktion Todesurteil Geldstrafe Bu?geld</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>Anmeldung</cell>
            </row>
            <row>
              <cell>delay</cell>
              <cell>anfechten</cell>
              <cell>revidieren</cell>
              <cell>zur? uckstellen</cell>
              <cell>verz? ogern(78)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>f?</cell>
              <cell>unden quittieren vertagen</cell>
              <cell>unden quittieren vertagen</cell>
              <cell>aufhalten(712)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>verschieben aufheben respektieren</cell>
              <cell>verschieben aufheben respektieren</cell>
              <cell>verschieben aufheben respektieren</cell>
            </row>
            <row>
              <cell>Kosten</cell>
              <cell>hallmark trouser blouse makup uniform</cell>
              <cell>hallmark trouser blouse makup uniform</cell>
              <cell>hallmark trouser blouse makup uniform</cell>
              <cell>cost(285)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>armour robe testimony witness jumper</cell>
              <cell>armour robe testimony witness jumper</cell>
              <cell>armour robe testimony witness jumper</cell>
            </row>
            <row>
              <cell>? offnen</cell>
              <cell>unlock lock usher step peer shut guard</cell>
              <cell>unlock lock usher step peer shut guard</cell>
              <cell>unlock lock usher step peer shut guard</cell>
              <cell>open(12)</cell>
            </row>
            <row>
              <cell>None</cell>
              <cell>hurry slam close</cell>
              <cell>hurry slam close</cell>
              <cell>None</cell>
              <cell>undo(481)</cell>
            </row>
          </rows>
        </body>
      </table>
    </tables>
    <references>
      <reference>
        <id>0</id>
        <authors>
          <author>M Diab</author>
          <author>S Finch</author>
        </authors>
        <title>A statistical wordlevel translation model for comparable corpora. In</title>
        <publication>In Proceedings of the Conference on Content-Based Multimedia Information Access (RIAO).</publication>
        <pages>None</pages>
        <date>2000</date>
      </reference>
      <reference>
        <id>1</id>
        <authors>
          <author>G Jeh</author>
          <author>J Widom</author>
        </authors>
        <title>Simrank: A measure of structural-context similarity.</title>
        <publication>In KDD &#8217;02: Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</publication>
        <pages>538--543</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>2</id>
        <authors>
          <author>P Koehn</author>
          <author>K Knight</author>
        </authors>
        <title>Learning a translation lexicon from monolingual corpora.</title>
        <publication>In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition,</publication>
        <pages>9--16</pages>
        <date>2002</date>
      </reference>
      <reference>
        <id>3</id>
        <authors>
          <author>P Gamallo Otero</author>
          <author>J Ramon Pichel Campos</author>
        </authors>
        <title>An approach to acquire word translations from nonparallel texts.</title>
        <publication>In EPIA,</publication>
        <pages>600--610</pages>
        <date>2005</date>
      </reference>
      <reference>
        <id>4</id>
        <authors>
          <author>R Rapp</author>
        </authors>
        <title>Automatic identification of word translations from unrelated English and German corpora.</title>
        <publication>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics,</publication>
        <pages>519--526</pages>
        <date>1999</date>
      </reference>
      <reference>
        <id>5</id>
        <authors>
          <author>Helmut Schmid</author>
        </authors>
        <title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
        <publication>In COLING &#8217;04: Proceedings of the 20th International Conference on Computational Linguistics,</publication>
        <pages>162</pages>
        <date>2004</date>
      </reference>
    </references>
    <citations>
      <citation>
        <id>0</id>
        <reference_id>0</reference_id>
        <string>Diab and Finch (2000)</string>
        <sentence_id>40453</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>1</id>
        <reference_id>1</reference_id>
        <string>Jeh and Widom, 2002</string>
        <sentence_id>40439</sentence_id>
        <char_offset>32</char_offset>
      </citation>
      <citation>
        <id>2</id>
        <reference_id>1</reference_id>
        <string>Jeh and Widom, 2002</string>
        <sentence_id>40530</sentence_id>
        <char_offset>85</char_offset>
      </citation>
      <citation>
        <id>3</id>
        <reference_id>1</reference_id>
        <string>Jeh and Widom, 2002</string>
        <sentence_id>40494</sentence_id>
        <char_offset>65</char_offset>
      </citation>
      <citation>
        <id>4</id>
        <reference_id>2</reference_id>
        <string>Koehn and Knight (2002)</string>
        <sentence_id>40459</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>5</id>
        <reference_id>3</reference_id>
        <string>Otero and Campos (2005)</string>
        <sentence_id>40463</sentence_id>
        <char_offset>0</char_offset>
      </citation>
      <citation>
        <id>6</id>
        <reference_id>4</reference_id>
        <string>Rapp (1999)</string>
        <sentence_id>40446</sentence_id>
        <char_offset>12</char_offset>
      </citation>
      <citation>
        <id>7</id>
        <reference_id>5</reference_id>
        <string>Schmid, 2004</string>
        <sentence_id>40543</sentence_id>
        <char_offset>110</char_offset>
      </citation>
    </citations>
  </content>
</document>
