<PAPER>
  <FILENO/>
  <TITLE>Monolingual Marginal Matching for Translation Model Adaptation</TITLE>
  <AUTHORS>
    <AUTHOR>Ann Irvine</AUTHOR>
    <AUTHOR>Chris Quirk</AUTHOR>
  </AUTHORS>
  <ABSTRACT>
    <A-S ID="S-15847">When using a machine translation (MT) model trained on OLD-domain parallel data to translate NEW-domain text, one major challenge is the large number of out-of-vocabulary (OOV) and new-translation-sense words.</A-S>
    <A-S ID="S-15848">We present a method to identify new translations of both known and unknown source language words that uses NEW-domain comparable document pairs.</A-S>
    <A-S ID="S-15849">Starting with a joint distribution of source-target word pairs derived from the OLD-domain parallel corpus, our method recovers a new joint distribution that matches the marginal distributions of the NEW-domain comparable document pairs, while minimizing the divergence from the OLD-domain distribution.</A-S>
    <A-S ID="S-15850">Adding learned translations to our French-English MT model results in gains of about 2 BLEU points over strong baselines.</A-S>
  </ABSTRACT>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-15851">When a statistical machine translation (SMT) model trained on OLD-domain (e.g. parliamentary proceedings) parallel text is used to translate text in a NEWdomain (e.g. medical or scientific), performance degrades drastically.</S>
        <S ID="S-15852">One of the major causes is the large number of NEW-domain words that are out-ofvocabulary (OOV) with respect to the OLD-domain text.</S>
        <S ID="S-15853">Figure 1 shows the OOV rate for text in several NEW-domains, with respect to OLD-domain parliamentary proceedings.</S>
        <S ID="S-15854">Even more challenging are the difficult-to-detect new-translation-sense (NTS) words: French words that are present in both the</S>
      </P>
      <P>
        <S ID="S-15855">OLD and NEW domains but that are translated differently in each domain.</S>
        <S ID="S-15856">For example, the French</S>
      </P>
      <P>
        <S ID="S-15857">Percent of Word Types that are OOV</S>
      </P>
      <P>
        <S ID="S-15858">0 10 20 30 40 50 60</S>
      </P>
      <P>
        <S ID="S-15859">3.95</S>
      </P>
      <P>
        <S ID="S-15860">27.03</S>
      </P>
      <P>
        <S ID="S-15861">41.42</S>
      </P>
      <P>
        <S ID="S-15862">50.93</S>
      </P>
      <P>
        <S ID="S-15863">Parliament Subtitles Medical Science</S>
      </P>
      <P>
        <S ID="S-15864">word enceinte is mostly translated in parliamentary proceedings as place, house, or chamber; in medical text, the translation is mostly pregnant; in scientific text, enclosures.</S>
      </P>
      <P>
        <S ID="S-15865">One potential remedy is to collect parallel data in the NEW-domain, from which we can train a new SMT model.</S>
        <S ID="S-15866"><REF ID="R-35" RPTR="37">Smith et al. (2010)</REF>, for example, mine parallel text from comparable corpora.</S>
        <S ID="S-15867">Parallel sentences are informative but also rare: in the data released by <REF ID="R-35" RPTR="38">Smith et al. (2010)</REF>, only 21% of the foreign sentences have a near-parallel counterpart in the English article.</S>
        <S ID="S-15868">1 Furthermore, these sentences do not capture all terms.</S>
        <S ID="S-15869">In that same dataset, we find that on average only 20% of foreign and 28% of English word types in a given article are represented in the parallel sentence pairs.</S>
      </P>
      <P>
        <S ID="S-15870">In this work, we seek to learn a joint distribu-</S>
      </P>
      <P>
        <S ID="S-15871">1 Only 12% of sentences from generally longer English articles have a near-parallel counterpart in the foreign language.</S>
      </P>
      <P>
        <S ID="S-15872">tion of translation probabilities over all source and target word pairs in the NEW-domain.</S>
        <S ID="S-15873">We begin with a maximum likelihood estimate of the joint based on a word aligned OLD-domain corpus and update this distribution using NEW-domain comparable data.</S>
        <S ID="S-15874">We define a model based on a single comparable corpus and then extend it to learn from document aligned comparable corpora with any number of comparable document pairs.</S>
        <S ID="S-15875">This approach allows us to identify translations for OOV words in the OLD-domain (e.g. French cisaillement and per&#231;age, which translate as shear and drilling, in the scientific domain) as well as new translations for previously observed NTS words (e.g. enceinte translates as enclosures, not place, in the scientific domain).</S>
        <S ID="S-15876">In our MT experiments, we use the learned NEWdomain joint distribution to update our SMT model with translations of OOV and low frequency words; we leave the integration of new translations for NTS words to future work.</S>
      </P>
      <P>
        <S ID="S-15877">Our approach crucially depends on finding comparable document pairs relevant to the NEW-domain.</S>
        <S ID="S-15878">Such pairs could be derived from a number of sources, with document pairings inferred from timestamps (e.g. news articles) or topics (inferred or manually labeled).</S>
        <S ID="S-15879">We use Wikipedia 2 as a source of comparable pairs.</S>
        <S ID="S-15880">So-called &#8220;interwiki links&#8221; (which link Wikipedia articles written on the same topic but in different languages) act as rough guidance that pages may contain similar information.</S>
        <S ID="S-15881">Our approach does not exploit any Wikipedia structure beyond this signal, and thus is portable to alternate sources of comparable articles, such as multilingual news articles covering the same event.</S>
      </P>
      <P>
        <S ID="S-15882">Our model also relies on the assumption that each comparable document pair describes generally the same concepts, though the order and structure of presentation may differ significantly.</S>
        <S ID="S-15883">The efficacy of this method likely depends on the degree of comparability of the data; exploring the correlation between comparability and MT performance is an interesting question for future work.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Previous Work</HEADER>
      <P>
        <S ID="S-15884">In prior work (<REF ID="R-15" RPTR="15">Irvine et al., 2013</REF>), we presented a systematic analysis of errors that occur when shift-</S>
      </P>
      <P>
        <S ID="S-15885">2 www.wikipedia.org</S>
      </P>
      <P>
        <S ID="S-15886">ing domains in machine translation.</S>
        <S ID="S-15887">That work concludes that errors resulting from unseen (OOV) and new translation sense words cause the majority of the degradation in translation performance that occurs when an MT model trained on OLD-domain data is used to translate data in a NEW-domain.</S>
        <S ID="S-15888">Here, we target OOV errors, though our marginal matching method is also applicable to learning translations for NTS words.</S>
        <S ID="S-15889">A plethora of prior work learns bilingual lexicons from monolingual and comparable corpora with many signals including distributional, temporal, and topic similarity (<REF ID="R-28" RPTR="28">Rapp, 1995</REF>; <REF ID="R-09" RPTR="10">Fung and Yee, 1998</REF>; <REF ID="R-29" RPTR="29">Rapp, 1999</REF>; <REF ID="R-33" RPTR="34">Schafer and Yarowsky, 2002</REF>; <REF ID="R-34" RPTR="36">Schafer, 2006</REF>; <REF ID="R-16" RPTR="16">Klementiev and Roth, 2006</REF>; <REF ID="R-17" RPTR="17">Koehn and Knight, 2002</REF>; <REF ID="R-13" RPTR="13">Haghighi et al., 2008</REF>; <REF ID="R-21" RPTR="21">Mimno et al., 2009</REF>; <REF ID="R-20" RPTR="20">Mausam et al., 2010</REF>; <REF ID="R-26" RPTR="26">Prochasson and Fung, 2011</REF>; <REF ID="R-14" RPTR="14">Irvine and Callison-Burch, 2013</REF>).</S>
        <S ID="S-15890">However, this prior work stops short of using these lexicons in translation.</S>
        <S ID="S-15891">We augment a baseline MT system with learned translations.</S>
        <S ID="S-15892">Our approach bears some similarity to <REF ID="R-30" RPTR="30">Ravi and Knight (2011)</REF>, <REF ID="R-07" RPTR="8">Dou and Knight (2012)</REF>, and <REF ID="R-24" RPTR="24">Nuhn et al. (2012)</REF>; we learn a translation distribution despite a lack of parallel data.</S>
        <S ID="S-15893">However, we focus on the domain adaptation setting.</S>
        <S ID="S-15894">Parallel data in an OLD-domain acts as a starting point (prior) for this translation distribution.</S>
        <S ID="S-15895">It is reasonable to assume an initial bilingual dictionary can be obtained even in low resource settings, for example by crowdsourcing (<REF ID="R-00" RPTR="0">Callison-Burch and Dredze, 2010</REF>) or pivoting through related languages (<REF ID="R-33" RPTR="35">Schafer and Yarowsky, 2002</REF>; <REF ID="R-23" RPTR="23">Nakov and Ng, 2009</REF>).</S>
        <S ID="S-15896">Daum&#233; III and Jagarlamudi (2011) mine translations for high frequency OOV words in NEWdomain text in order to do domain adaptation.</S>
        <S ID="S-15897">Although that work shows significant MT improvements, it is based primarily on distributional similarity, thus making it difficult to learn translations for low frequency source words with sparse word context counts.</S>
        <S ID="S-15898">Additionally, that work reports results using artificially created monolingual corpora taken from separate source and target halves of a NEWdomain parallel corpus, which may have more lexical overlap with the corresponding test set than we could expect from true monolingual corpora.</S>
        <S ID="S-15899">Our work mines NEW-domain-like document pairs from Wikipedia.</S>
        <S ID="S-15900">In this work, we show that, keeping</S>
      </P>
      <P>
        <S ID="S-15901">data resources constant, our model drastically outperforms this previous approach.</S>
        <S ID="S-15902"><REF ID="R-31" RPTR="32">Razmara et al. (2013)</REF> take a fundamentally different approach and construct a graph using source language monolingual text and identify translations for source language OOV words by pivoting through paraphrases.</S>
      </P>
      <P>
        <S ID="S-15903">Della <REF ID="R-06" RPTR="7">Pietra et al. (1992)</REF> and <REF ID="R-08" RPTR="9">Federico (1999)</REF> explore models for combining foreground and background distributions for the purpose of language modeling, and their approaches are somewhat similar to ours.</S>
        <S ID="S-15904">However, our focus is on translation.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Model</HEADER>
      <P>
        <S ID="S-16000">Our goal is to recover a probabilistic translation dictionary in a NEW-domain, represented as a joint probability distribution p new (s, t) over source/target word pairs.</S>
        <S ID="S-16001">At our disposal, we have access to a joint distribution p old (s, t) from the OLD-domain (computed from word alignments), plus comparable document pairs in the NEW-domain.</S>
        <S ID="S-16002">From these comparable documents, we can extract raw word frequencies on both the source and target side, represented as marginal distributions q(s) and q(t).</S>
        <S ID="S-16003">The key idea is to estimate this NEW-domain joint distribution to be as similar to the OLD-domain distribution as possible, subject to the constraint that its marginals match those of q.</S>
      </P>
      <P>
        <S ID="S-16004">To illustrate our goal, consider an example.</S>
        <S ID="S-16005">Imagine in the OLD-domain parallel data we find that accorder translates as grant 10 times and as tune 1 time.</S>
        <S ID="S-16006">In the NEW-domain comparable data, we find that accorder occurs 5 times, but grant occurs only once, and tune occurs 4 times.</S>
        <S ID="S-16007">Clearly accorder no longer translates as grant most of the time; perhaps we should shift much of its mass onto the translation tune instead.</S>
        <S ID="S-16008">Figure 2 shows the intuition.</S>
      </P>
      <P>
        <S ID="S-16009">First, we present an objective function and set of constraints over joint distributions to minimize the divergence from the OLD-domain distribution while matching both the source and target NEW-domain marginal distributions.</S>
        <S ID="S-16010">Next, we augment the objective with information about word string similarity, which is particularly useful for the French-English language pair.</S>
        <S ID="S-16011">Optimizing this objective with a single pair of source and target marginals can be performed using an off-the-shelf solver.</S>
        <S ID="S-16012">In practice, though, we have a large set of document pairs, each of which can induce a pair of marginals.</S>
        <S ID="S-16013">Using these per-document marginals provides additional information to the learning function but would overwhelm a common solver.</S>
        <S ID="S-16014">Therefore, we present a sequential learning method for approximately matching the large set of document pair marginal distributions.</S>
        <S ID="S-16015">Finally, we describe how we identify comparable document pairs relevant to the NEW-domain.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Marginal Matching Objective</HEADER>
        <P>
          <S ID="S-15905">Given word-aligned parallel data in the OLD-domain and source and target comparable corpora in the NEW-domain, we first estimate a joint distribution p old (s, t) over word pairs (s, t) in the OLD-domain, where s and t range over source and target language words, respectively.</S>
          <S ID="S-15906">For the OLD-domain joint distribution, we use a simple maximum likelihood estimate based on non-null automatic word alignments (using grow-diag-final GIZA++ alignments (<REF ID="R-25" RPTR="25">Och and Ney, 2003</REF>)).</S>
          <S ID="S-15907">Next, we find source and target marginal distributions, q(s) and q(t), by relative frequency estimates over the source and target comparable corpora.</S>
          <S ID="S-15908">Our goal is to recover a joint distribution p new (s, t) for the new domain that matches the marginals, q(s) and q(t), but is minimally different from the original joint distribution, p old (s, t).</S>
        </P>
        <P>
          <S ID="S-15909">We cast this as a linear programming problem: p new = arg min</S>
        </P>
        <P>
          <S ID="S-15910">p</S>
        </P>
        <P>
          <S ID="S-15911">&#8741; &#8741;&#8741;p &#8722; p</S>
        </P>
        <P>
          <S ID="S-15912">old &#8741; (1)</S>
        </P>
        <P>
          <S ID="S-15913">subject to: &#8721; p(s, t) = 1, p(s, t) &#8805; 0</S>
        </P>
        <P>
          <S ID="S-15914">s,t</S>
        </P>
        <P>
          <S ID="S-15915">&#8721; &#8721; p(s, t) = q(t), p(s, t) = q(s)</S>
        </P>
        <P>
          <S ID="S-15916">s</S>
        </P>
        <P>
          <S ID="S-15917">In the objective function, the joint probability matrices p and p old are interpreted as large vectors over all word pairs (s, t).</S>
          <S ID="S-15918">The first two constraints force the result to be a well-formed distribution, and the final two force the marginals to match.</S>
          <S ID="S-15919">Following prior work (<REF ID="R-30" RPTR="31">Ravi and Knight, 2011</REF>), we would like the matrix to remain as sparse as possible; that is, introduce the smallest number of new translation pairs necessary.</S>
          <S ID="S-15920">A regularization term captures this goal:</S>
        </P>
        <P>
          <S ID="S-15921">&#937;(p) =</S>
        </P>
        <P>
          <S ID="S-15922">t</S>
        </P>
        <P>
          <S ID="S-15923">enceinte ?</S>
        </P>
        <P>
          <S ID="S-15924">habiller</S>
        </P>
        <P>
          <S ID="S-15925">fille</S>
        </P>
        <P>
          <S ID="S-15926">house place pregnant dress girl q(s)</S>
        </P>
        <P>
          <S ID="S-15927">0.60</S>
        </P>
        <P>
          <S ID="S-15928">?</S>
        </P>
        <P>
          <S ID="S-15929">0.20</S>
        </P>
        <P>
          <S ID="S-15930">0.20</S>
        </P>
        <P>
          <S ID="S-15931">q(t) 0.12 0.08 0.40 0.20 0.20</S>
        </P>
        <P>
          <S ID="S-15932">(a) OLD-Domain Joint (b) NEW-Domain Marginals</S>
        </P>
        <P>
          <S ID="S-15933">house place pregnant dress girl q new (s)</S>
        </P>
        <P>
          <S ID="S-15934">Matched Marginals</S>
        </P>
        <P>
          <S ID="S-15935">enceinte 0.12 0.08 0.40 0 0 0.60</S>
        </P>
        <P>
          <S ID="S-15936">habiller 0 0 0 0.20 = 0 0.20</S>
        </P>
        <P>
          <S ID="S-15937">fille 0 0 0 0 0.20 0.20</S>
        </P>
        <P>
          <S ID="S-15938">q new (t) 0.12 0.08 0.40 0.20 0.20</S>
        </P>
        <P>
          <S ID="S-15939">(c) Inferred NEW-Domain Joint</S>
        </P>
        <P>
          <S ID="S-15940">If the old domain joint probability p old (s, t) was nonzero, there is no penalty.</S>
          <S ID="S-15941">Otherwise, the penalty is &#955; r times the new joint probability p(s, t).</S>
          <S ID="S-15942">To discourage the addition of translation pairs that are unnecessary in the new domain, we use a value of &#955; r greater than one.</S>
          <S ID="S-15943">Thus, the benefit of a more sparse matrix overwhelms the desire for preventing change.</S>
          <S ID="S-15944">Any value greater than one seems to suffice; we use &#955; r = 1.1 in our experiments.</S>
        </P>
        <P>
          <S ID="S-15945">Inspired by the preference for sparse matrices captured by &#937;(p), we include another orthogonal cue that words are translations of one another: their string similarity.</S>
          <S ID="S-15946">In prior work, string similarity was a valuable signal for inducing translations, particularly for closely related languages such as French and English (Daum&#233; III and Jagarlamudi, 2011).</S>
          <S ID="S-15947">We define a penalty function f(p) as follows: if the normalized Levenshtein edit distance between s without accents and t is less than 0.2, no penalty is applied; a penalty of 1 is applied otherwise.</S>
          <S ID="S-15948">We chose the 0.2 threshold manually by inspecting results on our development sets.</S>
        </P>
        <P>
          <S ID="S-15949">f(p) = &#8721; s,t p(s, t) &#183;</S>
        </P>
        <P>
          <S ID="S-15950">{</S>
        </P>
        <P>
          <S ID="S-15951">0 if lev(t,strip(s)) len(s)+len(t) &lt; 0.2 1 otherwise</S>
        </P>
        <P>
          <S ID="S-15952">The objective function including this penalty is: p new = arg min</S>
        </P>
        <P>
          <S ID="S-15953">p</S>
        </P>
        <P>
          <S ID="S-15954">&#8741; &#8741;&#8741;p &#8722; p</S>
        </P>
        <P>
          <S ID="S-15955">old &#8741; + &#937;(p) + f(p)</S>
        </P>
        <P>
          <S ID="S-15956">In principle, additional penalties could be encoded in a similar way.</S>
          <S ID="S-15957">3 This objective can be optimized by any standard LP solver; we use the Gurobi package (Gurobi Optimization Inc., 2013).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Document Pair Modification</HEADER>
        <P>
          <S ID="S-15958">The above formulation applies whenever we have access to comparable corpora.</S>
          <S ID="S-15959">However, often we have access to comparable documents, such as those given by Wikipedia inter-language links.</S>
          <S ID="S-15960">We modify our approach to take advantage of the document correspondences within our comparable corpus.</S>
          <S ID="S-15961">In particular, we would like to match the marginals for all document pairs.</S>
          <S ID="S-15962">4 By maintaining separate marginal distributions, our algorithm is presented with more</S>
        </P>
        <P>
          <S ID="S-15963">3 We experimented with penalties measuring document-pair</S>
        </P>
        <P>
          <S ID="S-15964">co-occurrence and monolingual frequency differences but did not see gains on our development sets.</S>
          <S ID="S-15965">4 This situation is not unique to our application; multiple</S>
        </P>
        <P>
          <S ID="S-15966">marginals are likely to exist in many cases.</S>
        </P>
        <P>
          <S ID="S-15967">information.</S>
          <S ID="S-15968">For example, imagine that one document pair uses &#8220;dog&#8221; and &#8220;chien&#8221;, where another document pair uses &#8220;cat&#8221; and &#8220;chat&#8221;, each with similar frequency.</S>
          <S ID="S-15969">If we sum these marginals to produce a single marginal distribution, it is now difficult to identify that &#8220;dog&#8221; should correspond to &#8220;chien&#8221; and not &#8220;chat.&#8221; Document pair alignments add information at the cost of additional constraints.</S>
          <S ID="S-15970">An initial formulation of our problem with multiple comparable document pairs might require the p new marginals to match all of the document marginals.</S>
          <S ID="S-15971">In general, this constraint set is likely to result in an infeasible problem.</S>
          <S ID="S-15972">Instead, we take an incremental, online solution, considering a single comparable document pair at a time.</S>
          <S ID="S-15973">For document pair k, we solve the optimization problem in Eq (1) to find the joint distribution minimally different from p k-1 , while matching the marginals of this pair only.</S>
          <S ID="S-15974">This gives a new joint distribution, tuned specifically for this pair.</S>
          <S ID="S-15975">We then update our current guess of the new domain joint toward this document-pair-specific distribution, much like a step in stochastic gradient ascent.</S>
        </P>
        <P>
          <S ID="S-15976">More formally, suppose that before processing the kth document we have a guess at the NEW-domain joint distribution, p new 1:k&#8722;1 (the subscript indicates that it includes all document pairs up to and including document k &#8722; 1).</S>
          <S ID="S-15977">We first solve Eq (1) solely on the basis of this document pair, finding a joint distribution p new k that matches the marginals of the kth document pair only and is minimally different from p new 1:k&#8722;1 .</S>
          <S ID="S-15978">Finally, we form a new estimate of the joint distribution by moving p new 1:k&#8722;1 in the direction of</S>
        </P>
        <P>
          <S ID="S-15979">, via: p new k [ ] p new 1:k = pnew 1:k&#8722;1 + &#951; u p new k &#8722; p new 1:k&#8722;1</S>
        </P>
        <P>
          <S ID="S-15980">The learning rate &#951; u is set to 0.001.</S>
          <S ID="S-15981">5 This incremental update of parameters is similar to the margin infused relaxed algorithm (MIRA) (<REF ID="R-04" RPTR="6">Crammer et al., 2006</REF>).</S>
          <S ID="S-15982">Like MIRA and the perceptron, there is not an overall &#8220;objective&#8221; function that we are attempting to optimize (as one would in many stochastic gradient steps).</S>
          <S ID="S-15983">Instead, we&#8217;re aiming for</S>
        </P>
        <P>
          <S ID="S-15984">5 We tuned &#951; u on semi-extrinsic results on the development</S>
        </P>
        <P>
          <S ID="S-15985">set.</S>
          <S ID="S-15986">Note that although 0.001 seems small, the values we are moving are joint probabilities, which are tiny and so small learning rates make sense.</S>
        </P>
        <P>
          <S ID="S-15987">a solution that makes a small amount of progress on each example, in such a way if it received that example again, it would &#8220;do better&#8221; (in this case: have a closer match of marginals).</S>
          <S ID="S-15988">Also like MIRA, our learning rate is constant.</S>
          <S ID="S-15989">We parallelize learning with mini-batches for increased speed.</S>
          <S ID="S-15990">Eight parallel learners update an initial joint distribution based on 100 document pairs (i.e. each learner makes 100 incremental updates), and then we merge results using an average over the 8 learned joint distributions.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 Comparable Data Selection</HEADER>
        <P>
          <S ID="S-15991">It remains to select comparable document pairs.</S>
          <S ID="S-15992">We assume that we have enough monolingual NEWdomain data in one language to rank comparable document pairs (here, Wikipedia pages) according to how NEW-domain-like they are.</S>
          <S ID="S-15993">In particular, we estimate the similarity to a source language (here, French) corpus in the NEW domain.</S>
          <S ID="S-15994">For our experiments, we use the French side of a NEW-domain parallel corpus.</S>
          <S ID="S-15995">6 We could have targeted our learning even more by using our NEW-domain MT test sets.</S>
          <S ID="S-15996">Doing so would increase the chances that our source language words of interest appear in the comparable corpus.</S>
          <S ID="S-15997">However, to avoid overfitting any particular test set, we use the French side of the training data.</S>
        </P>
        <P>
          <S ID="S-15998">For each Wikipedia document pair, we compute the percent of French phrases up to length four that are observed in the French monolingual NEW-domain corpus and rank document pairs by the geometric mean of the four overlap measures.</S>
          <S ID="S-15999">More sophisticated ways to identify NEW-domainlike Wikipedia pages (e.g. <REF ID="R-22" RPTR="22">Moore and Lewis (2010)</REF>) may yield additional performance gains, but, qualitatively, the ranked Wikipedia pages seemed reasonable to the authors.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Experimental setup</HEADER>
      <P>
        <S ID="S-16041"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 Data</HEADER>
        <P>
          <S ID="S-16016">We use French-English Hansard parliamentary proceedings 7 as our OLD-domain parallel corpus.</S>
          <S ID="S-16017">With over 8 million parallel lines of text, it is one of the largest freely available parallel corpora for any lan-</S>
        </P>
        <P>
          <S ID="S-16018">6 We could have, analogously, used the target language (English) side of the parallel corpus and measure overlap with the English Wikipedia documents, or even used both.</S>
          <S ID="S-16019">7 http://www.parl.gc.ca</S>
        </P>
        <P>
          <S ID="S-16020">guage pair.</S>
          <S ID="S-16021">In order to simulate more typical data settings, we sample every 32nd line, using the resulting parallel corpus of 253, 387 lines and 5, 051, 016 tokens to train our baseline model.</S>
        </P>
        <P>
          <S ID="S-16022">We test our model using three NEW-domain corpora: (1) the EMEA medical corpus (Tiedemann, 2009), (2) a corpus of scientific abstracts (<REF ID="R-01" RPTR="1">Carpuat et al., 2013</REF><REF ID="R-02" RPTR="3">Carpuat et al., 2013</REF>a), and (3) a corpus of translated movie subtitles (Tiedemann, 2009).</S>
          <S ID="S-16023">We use development and test sets to tune and evaluate our MT models.</S>
          <S ID="S-16024">We use the NEW-domain parallel training corpora only for language modeling and for identifying NEW-domain-like comparable documents.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Machine translation</HEADER>
        <P>
          <S ID="S-16025">We use the Moses MT framework (<REF ID="R-18" RPTR="18">Koehn et al., 2007</REF>) to build a standard statistical phrase-based MT model using our OLD-domain training data.</S>
          <S ID="S-16026">Using Moses, we extract a phrase table with a phrase limit of five words and estimate the standard set of five feature functions (phrase and lexical translation probabilities in each direction and a constant phrase penalty feature).</S>
          <S ID="S-16027">We also use a standard lexicalized reordering model and two language models based on the English side of the Hansard data and the given NEW-domain training corpora.</S>
          <S ID="S-16028">Features are combined using a log-linear model optimized for BLEU, using the n-best batch MIRA algorithm (<REF ID="R-03" RPTR="5">Cherry and Foster, 2012</REF>).</S>
          <S ID="S-16029">We call this the &#8220;simple baseline.&#8221; In Section 5.2 we describe several other baseline approaches.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.3 Experiments</HEADER>
        <P>
          <S ID="S-16030">For each domain, we use the marginal matching method described in Section 3 to learn a new, domain-adapted joint distribution, p new k (s, t), over all French and English words.</S>
          <S ID="S-16031">We use the learned joint to compute conditional probabilities, p new k (t|s), for each French word s and rank English translations t accordingly.</S>
          <S ID="S-16032">First, we evaluate the learned joint directly using the distribution based on the wordaligned NEW-domain development set as a gold standard.</S>
          <S ID="S-16033">Then, we perform end-to-end MT experiments.</S>
          <S ID="S-16034">We supplement phrase tables with translations for OOV and low frequency words (we experiment with training data frequencies less than 101, 11, and 1) and include p new k (t|s) and p new k (s|t) as new translation features for those supplemental translations.</S>
          <S ID="S-16035">For these new phrase pairs, we use the average lexicalized reordering values from the existing reordering tables.</S>
          <S ID="S-16036">For phrase pairs extracted bilingually, we use the bilingually estimated translation probabilities and uniform scores for the new translation features.</S>
          <S ID="S-16037">We experimented with using p new k</S>
        </P>
        <P>
          <S ID="S-16038">(t|s) and p new k (s|t) to estimate additional lexical translation probabilities for the bilingually extracted phrase pairs but did not observe any gains (experimental details omitted due to space constraints).</S>
          <S ID="S-16039">We re-run tuning in all experiments.</S>
        </P>
        <P>
          <S ID="S-16040">We also perform oracle experiments in which we identify translations for French words in wordaligned development and test sets and append these translations to baseline phrase tables.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Results</HEADER>
      <P>
        <S ID="S-16125"></S>
      </P>
      <DIV DEPTH="1">
        <HEADER>5.1 Semi-extrinsic evaluation</HEADER>
        <P>
          <S ID="S-16042">Before doing end-to-end MT experiments, we evaluate our learned joint distribution, p new k (s, t), by comparing it to the joint distribution taken from a word aligned NEW-domain parallel development set, p gold (s, t).</S>
          <S ID="S-16043">We call this evaluation semi-extrinsic because it involves neither end-to-end MT (our extrinsic task) nor an intrinsic evaluation based on our training objective (L1 norm).</S>
          <S ID="S-16044">We find it informative to evaluate the models using bilingual lexicon induction metrics before integrating our output into full MT.</S>
          <S ID="S-16045">That is, we do not compare the full joint distributions, but, rather, for a given French word, how our learned model ranks the word&#8217;s most probable translation under the gold distribution.</S>
          <S ID="S-16046">In particular, because we are primarily concerned with learning translations for previously unseen words, we evaluate over OOV French word types.</S>
          <S ID="S-16047">In some cases, the correct translation for OOV words is the identical string (e.g. na+, lycium).</S>
          <S ID="S-16048">Because it is trivial to produce these translations, 8 we evaluate over the subset of OOV development set French words for which the correct translation is not the same string.</S>
        </P>
        <P>
          <S ID="S-16049">Figure 3 shows the mean reciprocal rank for the learned distribution, p new k (s, t), for each domains as a function of the number of comparable document pairs used in learning.</S>
          <S ID="S-16050">In all domains, the comparable document pairs are sorted according to their sim-</S>
        </P>
        <P>
          <S ID="S-16051">8 And, indeed, by default our decoder copies OOV strings</S>
        </P>
        <P>
          <S ID="S-16052">into its output directly.</S>
        </P>
        <P>
          <S ID="S-16053">0 10000 20000 30000 40000 50000 0 10000 20000 30000 40000 50000 0 10000 20000 30000 40000 50000</S>
        </P>
        <P>
          <S ID="S-16054">Number of Document Pairs Number of Document Pairs Number of Document Pairs</S>
        </P>
        <P>
          <S ID="S-16055">(a) Science (b) EMEA (c) Subtitles</S>
        </P>
        <P>
          <S ID="S-16056">ilarity with the NEW-domain.</S>
          <S ID="S-16057">Figure 3 also shows the performance of baseline models and our learner without the edit distance penalty.</S>
          <S ID="S-16058">For each source word s, the edit distance (ED) baseline ranks all English words t in our monolingual data by their edit distance with s.</S>
          <S ID="S-16059">9 The Canonical Correlation Analysis (CCA) baseline uses the approach of Daum&#233; III and Jagarlamudi (2011) and the top 25, 000 ranked document pairs as a comparable corpus.</S>
          <S ID="S-16060">That model performs poorly largely because of sparse word context counts.</S>
          <S ID="S-16061">Interestingly, for Science and EMEA, the performance of our full model at 50, 000 document pairs is higher than the sum of the edit distance baseline and the model without the edit distance penalty, indicating that our approach effectively combines the marginal matching and edit distance signals.</S>
          <S ID="S-16062">The learning curves for the three domains vary substantially.</S>
          <S ID="S-16063">For Science, learning is gradual and it appears that additional gains could be made by iterating over even more document pairs.</S>
          <S ID="S-16064">In contrast, the model learns quickly for the EMEA domain; performance is stable after 20, 000 document pairs.</S>
          <S ID="S-16065">Given these results and our experience with the two domains, we hypothesize that the difference is due to the fact that the Science data is much more heterogenous than the EMEA data.</S>
          <S ID="S-16066">The Science data</S>
        </P>
        <P>
          <S ID="S-16067">9 In particular, for each domain and each OOV French word,</S>
        </P>
        <P>
          <S ID="S-16068">we ranked the set of all English words that appeared at least five times in the set of 50,000 most NEW-domain like Wikipedia pages.</S>
          <S ID="S-16069">Using a frequency threshold of five helped eliminate French words and improperly tokenized English words from the set of candidates.</S>
        </P>
        <P>
          <S ID="S-16070">includes physics, chemistry, and biology abstracts, among others.</S>
          <S ID="S-16071">The drug labels that make up most of the EMEA data are more homogeneous.</S>
          <S ID="S-16072">In Section 6 we comment on the poor Subtitles performance, which persists in our MT experiments.</S>
        </P>
        <P>
          <S ID="S-16073">We experimented with making multiple learning passes over the document pairs and observed relatively small gains from doing so.</S>
          <S ID="S-16074">In all experiments, learning from some number of additional new document pairs resulted in higher semi-extrinsic performance gains than passing over document pairs which were already observed.</S>
        </P>
        <P>
          <S ID="S-16075">In the case of OOV words, it&#8217;s clear that learning something about how to translate a previously unobserved French word is beneficial.</S>
          <S ID="S-16076">However, our learning method also learns domain-specific newtranslation senses (NTS).</S>
          <S ID="S-16077">Table 1 shows some examples of what the marginal matching method learns for different types of source words (OOVs, low frequency, and NTS).</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>5.2 MT evaluation</HEADER>
        <P>
          <S ID="S-16078">By default, the Moses decoder copies OOV words directly into its translated output.</S>
          <S ID="S-16079">In some cases, this is correct (e.g. ensembles, blumeria, google).</S>
          <S ID="S-16080">In other cases, French words can be translated into English correctly by simply stripping accent marks off of the OOV word and then copying it to the output (e.g. cam&#233;ra, &#233;l&#233;ments, mol&#233;cules).</S>
          <S ID="S-16081">In the Science and EMEA domains, we found that our baseline BLEU scores improved from 21.91 to 22.20 and 23.67 to 24.45, respectively, when we changed the default handling of OOVs to strip accents before</S>
        </P>
        <P>
          <S ID="S-16082">copying into the output.</S>
          <S ID="S-16083">Interestingly, performance on the Subtitles domain text did not change at all with this baseline modification.</S>
          <S ID="S-16084">This is likely due to the fact that there are fewer technical OOVs (the terms typically captured by this accent-stripping pattern) in the subtitles domain.</S>
        </P>
        <P>
          <S ID="S-16085">Throughout our experiments, we found it critical to retain correct &#8216;freebie&#8217; OOV translations.</S>
          <S ID="S-16086">In the results presented below, including the baselines, we supplement phrase tables with a new candidate translation but also include accent-stripped identity, or &#8216;freebie,&#8217; translations in the table for all OOV words.</S>
          <S ID="S-16087">We experimented with classifying French words as freebies or needing a new translation, but oracle experiments showed very little improvement (about 0.2 BLEU improvement in the Science domain), so instead we simply include both types of translations in the phrase tables.</S>
        </P>
        <P>
          <S ID="S-16088">In addition to the strip-accents baseline, we compare results with four other baselines.</S>
          <S ID="S-16089">First, we drop OOVs from the output translations.</S>
          <S ID="S-16090">Second, like our semi-extrinsic baseline, we rank English words by their edit distance away from each French OOV word (ED baseline).</S>
          <S ID="S-16091">Third, we rank English words by their document-pair co-occurrence score with each French OOV word.</S>
          <S ID="S-16092">That is, for all words w, we compute D(w), the vector indicating the document pairs in which w occurs, over the set of 50,000 document-pairs which are most NEWdomain-like.</S>
          <S ID="S-16093">For French and English words s and t, if D(s) and D(t) are dissimilar, it is less likely (s, t) is a valid translation pair.</S>
          <S ID="S-16094">We weight D(w) entries with BM25 (<REF ID="R-32" RPTR="33">Robertson et al., 1994</REF>).</S>
          <S ID="S-16095">For all French OOVs, we rank all English translations according to the cosine similarity between the pair of D(w) vectors.</S>
          <S ID="S-16096">The fourth baseline uses the CCA model described in Daum&#233; III and Jagarlamudi (2011) to rank English words according to their distributional similarity with each French word.</S>
          <S ID="S-16097">For the CCA baseline comparison, we only learned translations using 25,000 Science-domain document pairs, rather than the full 50,000 and for all domains.</S>
          <S ID="S-16098">However, it&#8217;s unlikely that learning over more data would overcome the low performance observed so far.</S>
          <S ID="S-16099">For the final three baselines, we append French OOV words and their highest ranked English translation to the phrase table.</S>
          <S ID="S-16100">Along with each new translation pair, we include one new phrase table feature with the relevant translation score (edit distance, document similarity, or CCA distributional similarity).</S>
          <S ID="S-16101">For all baselines other than drop-OOVs, we also include accent-stripped translation pairs with an additional indicator feature.</S>
        </P>
        <P>
          <S ID="S-16102">Table 3 shows results appending the top ranked English translation for each OOV French word using each baseline method.</S>
          <S ID="S-16103">None of the alternate baselines outperform the simplest baseline on the subtitles data.</S>
          <S ID="S-16104">Using document pair co-occurrences is the strongest baseline for the Science and EMEA domains.</S>
          <S ID="S-16105">This confirms our intuition that taking advantage of document pair alignments is worthwhile.</S>
          <S ID="S-16106">For Science and EMEA, supplementing a model with OOV translations learned through our marginal matching method drastically outperforms all base-</S>
        </P>
        <P>
          <S ID="S-16107">lines.</S>
          <S ID="S-16108">Using our model to translate OOV words yields scores of 23.62 and 26.97 in the Science and EMEA domains, or 1.19 and 1.94 BLEU points, respectively, above the strongest baseline.</S>
          <S ID="S-16109">We observe additional gains by also supplementing the model with translations for low frequency French words.</S>
          <S ID="S-16110">For example, when we use our approach to translate source words in the Science domain which appear ten or fewer times in our OLD-domain training data, the BLEU score increases to 24.28.</S>
        </P>
        <P>
          <S ID="S-16111">We tried appending top-k translations, varying k.</S>
          <S ID="S-16112">However, we found that for the baselines as well as our MM translations, using only the top-1 English translations outperformed using more.</S>
        </P>
        <P>
          <S ID="S-16113">Table 3 also shows the result of supplementing a baseline phrase table with oracle OOV translations.</S>
          <S ID="S-16114">Using the marginal matching learned OOV translations takes us 30% and 40% of the way from the baseline to the oracle upper bound for Science and EMEA, respectively.</S>
        </P>
        <P>
          <S ID="S-16115">We have focused on supplementing an SMT model trained on a sample of the Hansard parallel corpus in order to mimic typical data conditions, but we have also performed experiments supplementing</S>
        </P>
        <P>
          <S ID="S-16116">a model trained on the full dataset.</S>
          <S ID="S-16117">10 Beginning with the larger model, we observe performance gains of 0.8 BLEU points for both the EMEA and the Science domains over the strongest baselines, which are based on document similarity, when we add OOV</S>
        </P>
        <P>
          <S ID="S-16118">10 We still use the joint that was learned starting with the one</S>
        </P>
        <P>
          <S ID="S-16119">estimated over the sample; we may observe greater gains over the full Hansard baseline with a stronger initial joint.</S>
        </P>
        <P>
          <S ID="S-16120">translations.</S>
          <S ID="S-16121">As expected, these gains are less than what we observe when our baseline model is estimated over less data, but they are still substantial.</S>
        </P>
        <P>
          <S ID="S-16122">In all experiments, we have assumed that we have no NEW-domain parallel training data, which is the case for the vast majority of language pairs and domains.</S>
          <S ID="S-16123">However, In the case that we do have some NEW-domain parallel data, OOV rates will be somewhat lower, but our method is still applicable.</S>
          <S ID="S-16124">For example, we would need 2.3 million words of Science (NEW-domain) parallel data to cover just 50% of the OOVs in our Science test set, and 4.3 million words to cover 70%.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>6 Discussion</HEADER>
      <P>
        <S ID="S-16126">BLEU score performance gains are substantial for the Science and EMEA domains, but we don&#8217;t observe gains on the subtitles text.</S>
        <S ID="S-16127">We believe this difference relates to the difference between a corpus domain and a corpus register.</S>
        <S ID="S-16128">As <REF ID="R-19" RPTR="19">Lee (2002)</REF> explains, a text&#8217;s domain is most related to its topic, while a text&#8217;s register is related to its type and purpose.</S>
        <S ID="S-16129">For example, religious, scientific, and dialogue texts may be classified as separate registers, while political and scientific expositions may have a single register but different domains.</S>
        <S ID="S-16130">Our science and EMEA corpora are certainly different in domain from the OLD-domain parliamentary proceedings, and our success in boosting MT performance with our methods indicates that the Wikipedia comparable corpora that we mined match those domains well.</S>
        <S ID="S-16131">In contrast, the subtitles data differs from the OLD-domain parliamentary proceedings in both domain and register.</S>
        <S ID="S-16132">Although the Wikipedia data that we mined may be closer in domain to the subtitles data than the parliamentary proceedings, 11 its register is certainly not film dialogues.</S>
      </P>
      <P>
        <S ID="S-16133">Although the use of marginal matching is, to the best of our knowledge, novel in MT, there are related threads of research that might inspire future work.</S>
        <S ID="S-16134">The intuition that we should match marginal distributions is similar to work using no example labels but only label proportions to estimate labels, for example in <REF ID="R-27" RPTR="27">Quadrianto et al. (2008)</REF>.</S>
        <S ID="S-16135">Unlike that work,</S>
      </P>
      <P>
        <S ID="S-16136">11 In fact, we believe that it is.</S>
        <S ID="S-16137">Wikipedia pages that ranked</S>
      </P>
      <P>
        <S ID="S-16138">very high in our subtitles-like list included, for example, the movie The Other Side of Heaven and actor Frank Sutton.</S>
      </P>
      <P>
        <S ID="S-16139">our label set corresponds to entire vocabularies, and we have multiple observed label proportions.</S>
        <S ID="S-16140">Also, while the marginal matching objective seems effective in practice, it is difficult to optimize.</S>
        <S ID="S-16141">A number of recently developed approximate inference methods use a decomposition that bears a strong resemblance to this objective function.</S>
        <S ID="S-16142">Considering the marginal distributions from each document pair to be a separate subproblem, we could approach the global objective of satisfying all subproblems as an instance of dual decomposition (<REF ID="R-36" RPTR="39">Sontag et al., 2010</REF>) or ADMM (<REF ID="R-10" RPTR="11">Gabay and Mercier, 1976</REF>; <REF ID="R-11" RPTR="12">Glowinski and Marrocco, 1975</REF>).</S>
      </P>
      <P>
        <S ID="S-16143">We experiment with French-English because tuning and test sets are available in several domains for that language pair.</S>
        <S ID="S-16144">However, our techniques are directly applicable to other language pairs, including those that are less related.</S>
        <S ID="S-16145">We have observed that many domain-specific terms, particularly in medical and science domains, are borrowed across languages, whether or not the languages are related.</S>
        <S ID="S-16146">Even for languages with different character sets, one could do transliteration before measuring orthographical similarity.</S>
      </P>
      <P>
        <S ID="S-16147">Although we were able to identify translations for some NTS words (Table 1), we did not make use of them in our MT experiments.</S>
        <S ID="S-16148">Recent work has identified NTS words in NEW-domain corpora (<REF ID="R-01" RPTR="2">Carpuat et al., 2013</REF><REF ID="R-02" RPTR="4">Carpuat et al., 2013</REF>b), and in future work we plan to incorporate discovered translations for such words into MT.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>7 Conclusions</HEADER>
      <P>
        <S ID="S-16149">We proposed a model for learning a joint distribution of source-target word pairs based on the idea that its marginals should match those observed in NEW-domain comparable corpora.</S>
        <S ID="S-16150">Supplementing a baseline phrase-based SMT model with learned translations results in BLEU score gains of about two points in the medical and science domains.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-16151">We gratefully acknowledge the support of the 2012 JHU Summer Workshop and NSF Grant No 1005411.</S>
      <S ID="S-16152">We would like to thank the entire DAMT team (http://hal3.name/damt/) and Sanjeev Khudanpur for their help and suggestions.</S>
      <S ID="S-16153">We also acknowledge partial support from DARPA 1086 CSSG Grant D11AP00279 and DARPA BOLT Contract HR0011-12-C-0015 for Hal Daum&#233; III and support from the Johns Hopkins University Human Language Technology Center of Excellence for Ann Irvine.</S>
      <S ID="S-16154">The views and conclusions contained in this publication are those of the authors and should not be interpreted as representing official policies or endorsements of DARPA or the U.S. Government.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>Chris Callison-Burch</RAUTHOR>
      <REFTITLE>Creating speech and language data with Amazon&#8217;s Mechanical Turk.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Marine Carpuat</RAUTHOR>
      <REFTITLE>Domain adaptation in machine translation: Final report.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Marine Carpuat</RAUTHOR>
      <REFTITLE>Sensespotting: Never let your parallel data tie you to an old domain.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>Colin Cherry</RAUTHOR>
      <REFTITLE>Batch tuning strategies for statistical machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Koby Crammer</RAUTHOR>
      <REFTITLE>Online passiveaggressive algorithms.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Hal Daum&#233;</RAUTHOR>
      <REFTITLE>Domain adaptation for machine translation by mining unseen words.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>S Della Pietra</RAUTHOR>
      <REFTITLE>Adaptive language modeling using minimum discriminant estimation.</REFTITLE>
      <DATE>1992</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>Qing Dou</RAUTHOR>
      <REFTITLE>Large scale decipherment for out-of-domain machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Marcello Federico</RAUTHOR>
      <REFTITLE>Efficient language model adaptation through mdi estimation.</REFTITLE>
      <DATE>1999</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>Pascale Fung</RAUTHOR>
      <REFTITLE>An IR approach for translating new words from nonparallel, comparable texts.</REFTITLE>
      <DATE>1998</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Daniel Gabay</RAUTHOR>
      <REFTITLE>A dual algorithm for the solution of nonlinear variational problems via finite element approximation.</REFTITLE>
      <DATE>1976</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Roland Glowinski</RAUTHOR>
      <REFTITLE>Sur l&#8217;approximation, par &#233;l&#233;ments finis d&#8217;ordre un, et la r&#233;solution, par p&#233;nalisation-dualit&#233;, d&#8217;une classe de probl&#232;mes de dirichlet non lin&#233;aires.</REFTITLE>
      <DATE>1975</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Gurobi Optimization Inc</RAUTHOR>
      <REFTITLE></REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>Aria Haghighi</RAUTHOR>
      <REFTITLE>Learning bilingual lexicons from monolingual corpora.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>Ann Irvine</RAUTHOR>
      <REFTITLE>Supervised bilingual lexicon induction with multiple monolingual signals.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>Ann Irvine</RAUTHOR>
      <REFTITLE>Measuring machine translation errors in new domains. Transactions of the Association for Computational Linguistics (TACL).</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>Alexandre Klementiev</RAUTHOR>
      <REFTITLE>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Learning a translation lexicon from monolingual corpora.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Moses: Open source toolkit for statistical machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>David Lee</RAUTHOR>
      <REFTITLE>Genres, registers, text types, domains and styles: Clarifying the concepts and navigating a path through the bnc jungle.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="20">
      <RAUTHOR>Stephen Soderland Mausam</RAUTHOR>
      <REFTITLE>Marcus Sammer, 1087 Jeff Bilmes.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="21">
      <RAUTHOR>David Mimno</RAUTHOR>
      <REFTITLE>Polylingual topic models.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="22">
      <RAUTHOR>Robert C Moore</RAUTHOR>
      <REFTITLE>Intelligent selection of language model training data.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="23">
      <RAUTHOR>Preslav Nakov</RAUTHOR>
      <REFTITLE>Improved statistical machine translation for resource-poor languages using related resource-rich languages.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="24">
      <RAUTHOR>Malte Nuhn</RAUTHOR>
      <REFTITLE>Deciphering foreign language by combining language models and context vectors.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="25">
      <RAUTHOR>Franz Josef Och</RAUTHOR>
      <REFTITLE>A systematic comparison of various statistical alignment models.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="26">
      <RAUTHOR>Emmanuel Prochasson</RAUTHOR>
      <REFTITLE>Rare word translation extraction from aligned comparable documents.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="27">
      <RAUTHOR>Novi Quadrianto</RAUTHOR>
      <REFTITLE>Estimating labels from label proportions.</REFTITLE>
      <DATE>2008</DATE>
    </REFERENCE>
    <REFERENCE ID="28">
      <RAUTHOR>Reinhard Rapp</RAUTHOR>
      <REFTITLE>Identifying word translations in non-parallel texts.</REFTITLE>
      <DATE>1995</DATE>
    </REFERENCE>
    <REFERENCE ID="29">
      <RAUTHOR>Reinhard Rapp</RAUTHOR>
      <REFTITLE>Automatic identification of word translations from unrelated English and German corpora.</REFTITLE>
      <DATE>1999</DATE>
    </REFERENCE>
    <REFERENCE ID="30">
      <RAUTHOR>Sujith Ravi</RAUTHOR>
      <REFTITLE>Deciphering foreign language.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="31">
      <RAUTHOR>Majid Razmara</RAUTHOR>
      <REFTITLE>Graph propagation for paraphrasing out-of-vocabulary words in statistical machine translation.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="32">
      <RAUTHOR>S E Robertson</RAUTHOR>
      <REFTITLE>Okapi at TREC-3.</REFTITLE>
      <DATE>1994</DATE>
    </REFERENCE>
    <REFERENCE ID="33">
      <RAUTHOR>Charles Schafer</RAUTHOR>
      <REFTITLE>Inducing translation lexicons via diverse similarity measures and bridge languages.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="34">
      <RAUTHOR>Charles Schafer</RAUTHOR>
      <REFTITLE>Translation Discovery Using Diverse Similarity Measures.</REFTITLE>
      <DATE>2006</DATE>
    </REFERENCE>
    <REFERENCE ID="35">
      <RAUTHOR>Jason R Smith</RAUTHOR>
      <REFTITLE>Extracting parallel sentences from comparable corpora using document level alignment.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="36">
      <RAUTHOR>David Sontag</RAUTHOR>
      <REFTITLE>Introduction to dual decomposition for inference, chapter 1.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
