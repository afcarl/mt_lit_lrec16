<PAPER>
  <FILENO/>
  <TITLE>ccb@cs.jhu.edu &#8727;</TITLE>
  <AUTHORS>
    <AUTHOR>Jason R Smith</AUTHOR>
    <AUTHOR>Philipp Koehn</AUTHOR>
    <AUTHOR>Herve Saint-Amand</AUTHOR>
    <AUTHOR>Magdalena Plamada</AUTHOR>
  </AUTHORS>
  <ABSTRACT/>
  <BODY>
    <DIV DEPTH="0">
      <HEADER>1 Introduction</HEADER>
      <P>
        <S ID="S-37762">A key bottleneck in porting statistical machine translation (SMT) technology to new languages and domains is the lack of readily available parallel corpora beyond curated datasets.</S>
        <S ID="S-37763">For a handful of language pairs, large amounts of parallel data</S>
      </P>
      <P>
        <S ID="S-37764">&#8727; This research was conducted while Chris Callison-</S>
      </P>
      <P>
        <S ID="S-37765">Burch was at Johns Hopkins University.</S>
        <S ID="S-37766">1 github.com/jrs026/CommonCrawlMiner</S>
      </P>
      <P>
        <S ID="S-37767">are readily available, ordering in the hundreds of millions of words for Chinese-English and Arabic- English, and in tens of millions of words for many European languages (<REF ID="R-09" RPTR="10">Koehn, 2005</REF>).</S>
        <S ID="S-37768">In each case, much of this data consists of government and news text.</S>
        <S ID="S-37769">However, for most language pairs and domains there is little to no curated parallel data available.</S>
        <S ID="S-37770">Hence discovery of parallel data is an important first step for translation between most of the world&#8217;s languages.</S>
      </P>
      <P>
        <S ID="S-37771">The Web is an important source of parallel text.</S>
        <S ID="S-37772">Many websites are available in multiple languages, and unlike other potential sources&#8212; such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (<REF ID="R-19" RPTR="25">Smith et al., 2010</REF>)&#8212; it is common to find document pairs that are direct translations of one another.</S>
        <S ID="S-37773">This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process.</S>
      </P>
      <P>
        <S ID="S-37774">Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (<REF ID="R-15" RPTR="16">Nie et al., 1999</REF>; <REF ID="R-05" RPTR="5">Chen and Nie, 2000</REF>; <REF ID="R-18" RPTR="24">Resnik, 1999</REF>; <REF ID="R-17" RPTR="21">Resnik and Smith, 2003</REF>).</S>
        <S ID="S-37775">However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process them.</S>
        <S ID="S-37776">For most researchers, this is prohibitively expensive.</S>
        <S ID="S-37777">As a consequence, web-mined parallel text has become the exclusive purview of large companies with the computational resources to crawl, store, and process the entire Web.</S>
      </P>
      <P>
        <S ID="S-37778">To put web-mined parallel text back in the hands of individual researchers, we mine parallel text from the Common Crawl, a regularly updated 81-terabyte snapshot of the public internet hosted</S>
      </P>
      <P>
        <S ID="S-37779">on Amazon&#8217;s Elastic Cloud (EC2) service.</S>
        <S ID="S-37780">2 Using the Common Crawl completely removes the bottleneck of web crawling, and makes it possible to run algorithms on a substantial portion of the web at very low cost.</S>
        <S ID="S-37781">Starting from nothing other than a set of language codes, our extension of the STRAND algorithm (<REF ID="R-17" RPTR="22">Resnik and Smith, 2003</REF>) identifies potentially parallel documents using cues from URLs and document content (&#167;2).</S>
        <S ID="S-37782">We conduct an extensive empirical exploration of the web-mined data, demonstrating coverage in a wide variety of languages and domains (&#167;3).</S>
        <S ID="S-37783">Even without extensive pre-processing, the data improves translation performance on strong baseline news translation systems in five different language pairs (&#167;4).</S>
        <S ID="S-37784">On general domain and speech translation tasks where test conditions substantially differ from standard government and news training text, web-mined training data improves performance substantially, resulting in improvements of up to 1.5 BLEU on standard test sets, and 5 BLEU on test sets outside of the news domain.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>2 Mining the Common Crawl</HEADER>
      <P>
        <S ID="S-37785">The Common Crawl corpus is hosted on Amazon&#8217;s Simple Storage Service (S3).</S>
        <S ID="S-37786">It can be downloaded to a local cluster, but the transfer cost is prohibitive at roughly 10 cents per gigabyte, making the total over $8000 for the full dataset.</S>
        <S ID="S-37787">3 However, it is unnecessary to obtain a copy of the data since it can be accessed freely from Amazon&#8217;s Elastic Compute Cloud (EC2) or Elastic MapReduce (EMR) services.</S>
        <S ID="S-37788">In our pipeline, we perform the first step of identifying candidate document pairs using Amazon EMR, download the resulting document pairs, and perform the remaining steps on our local cluster.</S>
        <S ID="S-37789">We chose EMR because our candidate matching strategy fit naturally into the Map-Reduce framework (<REF ID="R-06" RPTR="6">Dean and Ghemawat, 2004</REF>).</S>
      </P>
      <P>
        <S ID="S-37790">Our system is based on the STRAND algorithm (<REF ID="R-17" RPTR="23">Resnik and Smith, 2003</REF>):</S>
      </P>
      <P>
        <S ID="S-37791">1.</S>
        <S ID="S-37792">Candidate pair selection: Retrieve candidate document pairs from the CommonCrawl corpus.</S>
      </P>
      <P>
        <S ID="S-37793">2.</S>
        <S ID="S-37794">Structural Filtering:</S>
      </P>
      <P>
        <S ID="S-37795">(a) Convert the HTML of each document</S>
      </P>
      <P>
        <S ID="S-37796">2 commoncrawl.org 3 http://aws.amazon.com/s3/pricing/</S>
      </P>
      <P>
        <S ID="S-37797">into a sequence of start tags, end tags,</S>
      </P>
      <P>
        <S ID="S-37798">and text chunks.</S>
        <S ID="S-37799">(b) Align the linearized HTML of candidate</S>
      </P>
      <P>
        <S ID="S-37800">document pairs.</S>
        <S ID="S-37801">(c) Decide whether to accept or reject each</S>
      </P>
      <P>
        <S ID="S-37802">pair based on features of the alignment.</S>
      </P>
      <P>
        <S ID="S-37803">3.</S>
        <S ID="S-37804">Segmentation: For each text chunk, perform sentence and word segmentation.</S>
      </P>
      <P>
        <S ID="S-37805">4.</S>
        <S ID="S-37806">Sentence Alignment: For each aligned pair of text chunks, perform the sentence alignment method of <REF ID="R-07" RPTR="7">Gale and Church (1993)</REF>.</S>
      </P>
      <P>
        <S ID="S-37807">5.</S>
        <S ID="S-37808">Sentence Filtering: Remove sentences that appear to be boilerplate.</S>
      </P>
      <P>
        <S ID="S-37809">Candidate Pair Selection We adopt a strategy similar to that of <REF ID="R-17" RPTR="19">Resnik and Smith (2003)</REF> for finding candidate parallel documents, adapted to the parallel architecture of Map-Reduce.</S>
        <S ID="S-37810">The mapper operates on each website entry in the CommonCrawl data.</S>
        <S ID="S-37811">It scans the URL string for some indicator of its language.</S>
        <S ID="S-37812">Specifically, we check for:</S>
      </P>
      <P>
        <S ID="S-37813">1.</S>
        <S ID="S-37814">Two/three letter language codes (ISO-639).</S>
      </P>
      <P>
        <S ID="S-37815">2.</S>
        <S ID="S-37816">Language names in English and in the language of origin.</S>
      </P>
      <P>
        <S ID="S-37817">If either is present in a URL and surrounded by non-alphanumeric characters, the URL is identified as a potential match and the mapper outputs a key value pair in which the key is the original URL with the matching string replaced by *, and the value is the original URL, language name, and full HTML of the page.</S>
        <S ID="S-37818">For example, if we encounter the URL www.website.com/fr/, we output the following.</S>
      </P>
      <P>
        <S ID="S-37819">&#8226; Key: www.website.com/*/</S>
      </P>
      <P>
        <S ID="S-37820">&#8226; Value: www.website.com/fr/, French, (full website entry)</S>
      </P>
      <P>
        <S ID="S-37821">The reducer then receives all websites mapped to the same &#8220;language independent&#8221; URL.</S>
        <S ID="S-37822">If two or more websites are associated with the same key, the reducer will output all associated values, as long as they are not in the same language, as determined by the language identifier in the URL.</S>
        <S ID="S-37823">This URL-based matching is a simple and inexpensive solution to the problem of finding candidate document pairs.</S>
        <S ID="S-37824">The mapper will discard</S>
      </P>
      <P>
        <S ID="S-37825">most, and neither the mapper nor the reducer do anything with the HTML of the documents aside from reading and writing them.</S>
        <S ID="S-37826">This approach is very simple and likely misses many good potential candidates, but has the advantage that it requires no information other than a set of language codes, and runs in time roughly linear in the size of the dataset.</S>
      </P>
      <P>
        <S ID="S-37827">Structural Filtering A major component of the STRAND system is the alignment of HTML documents.</S>
        <S ID="S-37828">This alignment is used to determine which document pairs are actually parallel, and if they are, to align pairs of text blocks within the documents.</S>
      </P>
      <P>
        <S ID="S-37829">The first step of structural filtering is to linearize the HTML.</S>
        <S ID="S-37830">This means converting its DOM tree into a sequence of start tags, end tags, and chunks of text.</S>
        <S ID="S-37831">Some tags (those usually found within text, such as &#8220;font&#8221; and &#8220;a&#8221;) are ignored during this step.</S>
        <S ID="S-37832">Next, the tag/chunk sequences are aligned using dynamic programming.</S>
        <S ID="S-37833">The objective of the alignment is to maximize the number of matching items.</S>
      </P>
      <P>
        <S ID="S-37834">Given this alignment, <REF ID="R-17" RPTR="20">Resnik and Smith (2003)</REF> define a small set of features which indicate the alignment quality.</S>
        <S ID="S-37835">They annotated a set of document pairs as parallel or non-parallel, and trained a classifier on this data.</S>
        <S ID="S-37836">We also annotated 101 Spanish-English document pairs in this way and trained a maximum entropy classifier.</S>
        <S ID="S-37837">However, even when using the best performing subset of features, the classifier only performed as well as a naive classifier which labeled every document pair as parallel, in both accuracy and F1.</S>
        <S ID="S-37838">For this reason, we excluded the classifier from our pipeline.</S>
        <S ID="S-37839">The strong performance of the naive baseline was likely due to the unbalanced nature of the annotated data&#8212; 80% of the document pairs that we annotated were parallel.</S>
      </P>
      <P>
        <S ID="S-37840">Segmentation The text chunks from the previous step may contain several sentences, so before the sentence alignment step we must perform sentence segmentation.</S>
        <S ID="S-37841">We use the Punkt sentence splitter from NLTK (<REF ID="R-10" RPTR="12">Loper and Bird, 2002</REF>) to perform both sentence and word segmentation on each text chunk.</S>
      </P>
      <P>
        <S ID="S-37842">Sentence Alignment For each aligned text chunk pair, we perform sentence alignment using the algorithm of <REF ID="R-07" RPTR="8">Gale and Church (1993)</REF>.</S>
      </P>
      <P>
        <S ID="S-37843">Sentence Filtering Since we do not perform any boilerplate removal in earlier steps, there are many sentence pairs produced by the pipeline which contain menu items or other bits of text which are not useful to an SMT system.</S>
        <S ID="S-37844">We avoid performing any complex boilerplate removal and only remove segment pairs where either the source and target text are identical, or where the source or target segments appear more than once in the extracted corpus.</S>
      </P>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>3 Analysis of the Common Crawl Data</HEADER>
      <P>
        <S ID="S-37891">We ran our algorithm on the 2009-2010 version of the crawl, consisting of 32.3 terabytes of data.</S>
        <S ID="S-37892">Since the full dataset is hosted on EC2, the only cost to us is CPU time charged by Amazon, which came to a total of about $400, and data storage/transfer costs for our output, which came to roughly $100.</S>
        <S ID="S-37893">For practical reasons we split the run into seven subsets, on which the full algorithm was run independently.</S>
        <S ID="S-37894">This is different from running a single Map-Reduce job over the entire dataset, since websites in different subsets of the data cannot be matched.</S>
        <S ID="S-37895">However, since the data is stored as it is crawled, it is likely that matching websites will be found in the same split of the data.</S>
        <S ID="S-37896">Table 1 shows the amount of raw parallel data obtained for a large selection of language pairs.</S>
      </P>
      <P>
        <S ID="S-37897">As far as we know, ours is the first system built to mine parallel text from the Common Crawl.</S>
        <S ID="S-37898">Since the resource is new, we wanted to understand the quantity, quality, and type of data that we are likely to obtain from it.</S>
        <S ID="S-37899">To this end, we conducted a number of experiments to measure these features.</S>
        <S ID="S-37900">Since our mining heuristics are very simple, these results can be construed as a lower bound on what is actually possible.</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>3.1 Recall Estimates</HEADER>
        <P>
          <S ID="S-37845">Our first question is about recall: of all the possible parallel text that is actually available on the Web, how much does our algorithm actually find in the Common Crawl?</S>
          <S ID="S-37846">Although this question is difficult to answer precisely, we can estimate an answer by comparing our mined URLs against a large collection of previously mined URLs that were found using targeted techniques: those in the French-English Gigaword corpus (<REF ID="R-03" RPTR="2">Callison-Burch et al., 2011</REF>).</S>
        </P>
        <P>
          <S ID="S-37847">We found that 45% of the URL pairs would</S>
        </P>
        <P>
          <S ID="S-37848">have been discovered by our heuristics, though we actually only find 3.6% of these URLs in our output.</S>
          <S ID="S-37849">4 If we had included &#8220;f&#8221; and &#8220;e&#8221; as identifiers for French and English respectively, coverage of the URL pairs would increase to 74%.</S>
          <S ID="S-37850">However, we chose not to include single letter identifiers in our experiments due to the high number of false positives they generated in preliminary experiments.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.2 Precision Estimates</HEADER>
        <P>
          <S ID="S-37851">Since our algorithms rely on cues that are mostly external to the contents of the extracted data and have no knowledge of actual languages, we wanted to evaluate the precision of our algorithm: how much of the mined data actually consists of parallel sentences?</S>
        </P>
        <P>
          <S ID="S-37852">To measure this, we conducted a manual analysis of 200 randomly selected sentence pairs for each of three language pairs.</S>
          <S ID="S-37853">The texts are heterogeneous, covering several topical domains like tourism, advertising, technical specifications, finances, e-commerce and medicine.</S>
          <S ID="S-37854">For German- English, 78% of the extracted data represent perfect translations, 4% are paraphrases of each other (convey a similar meaning, but cannot be used for SMT training) and 18% represent misalignments.</S>
          <S ID="S-37855">Furthermore, 22% of the true positives are potentially machine translations (judging by the quality), whereas in 13% of the cases one of the sentences contains additional content not ex-</S>
        </P>
        <P>
          <S ID="S-37856">4 The difference is likely due to the coverage of the CommonCrawl corpus.</S>
        </P>
        <P>
          <S ID="S-37857">pressed in the other.</S>
          <S ID="S-37858">As for the false positives, 13.5% of them have either the source or target sentence in the wrong language, and the remaining ones representing failures in the alignment process.</S>
          <S ID="S-37859">Across three languages, our inspection revealed that around 80% of randomly sampled data appeared to contain good translations (Table 2).</S>
          <S ID="S-37860">Although this analysis suggests that language identification and SMT output detection (Venugopal et al., 2011) may be useful additions to the pipeline, we regard this as reasonably high precision for our simple algorithm.</S>
        </P>
        <P>
          <S ID="S-37861">In addition to the manual evaluation of precision, we applied language identification to our extracted parallel data for several additional languages.</S>
          <S ID="S-37862">We used the &#8220;langid.py&#8221; tool (<REF ID="R-12" RPTR="14">Lui and Baldwin, 2012</REF>) at the segment level, and report the percentage of sentence pairs where both sentences were recognized as the correct language.</S>
          <S ID="S-37863">Table 3 shows our results.</S>
          <S ID="S-37864">Comparing against our manual evaluation from Table 2, it appears that many sentence pairs are being incorrectly judged as nonparallel.</S>
          <S ID="S-37865">This is likely because language identification tends to perform poorly on short segments.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>3.3 Domain Name and Topic Analysis</HEADER>
        <P>
          <S ID="S-37866">Although the above measures tell us something about how well our algorithms perform in aggregate for specific language pairs, we also wondered about the actual contents of the data.</S>
          <S ID="S-37867">A major difficulty in applying SMT even on languages for which we have significant quantities of parallel text is that most of that parallel text is in the news and government domains.</S>
          <S ID="S-37868">When applied to other genres, such systems are notoriously brittle.</S>
          <S ID="S-37869">What kind of genres are represented in the Common Crawl data?</S>
        </P>
        <P>
          <S ID="S-37870">We first looked at the domain names which contributed the most data.</S>
          <S ID="S-37871">Table 4 gives the top five domains by the number of tokens.</S>
          <S ID="S-37872">The top two domain names are related to travel, and they account for about 10% of the total data.</S>
        </P>
        <P>
          <S ID="S-37873">We also applied Latent Dirichlet Allocation (LDA; <REF ID="R-00" RPTR="0">Blei et al., 2003</REF>) to learn a distribution over latent topics in the extracted data, as this is a popular exploratory data analysis method.</S>
          <S ID="S-37874">In LDA a topic is a unigram distribution over words, and each document is modeled as a distribution over topics.</S>
          <S ID="S-37875">To create a set of documents from the extracted CommonCrawl data, we took the English side of the extracted parallel segments for each URL in the Spanish-English portion of the data.</S>
          <S ID="S-37876">This gave us a total of 444, 022 documents.</S>
          <S ID="S-37877">In our first experiment, we used the MALLET toolkit (<REF ID="R-13" RPTR="15">McCallum, 2002</REF>) to generate 20 topics, which are shown in Table 5.</S>
        </P>
        <P>
          <S ID="S-37878">Some of the topics that LDA finds correspond closely with specific domains, such as topics 1 (blingee.com) and 2 (opensubtitles.org).</S>
          <S ID="S-37879">Several of the topics correspond to the travel domain.</S>
          <S ID="S-37880">Foreign stop words appear in a few of the topics.</S>
          <S ID="S-37881">Since our system does not include any language identification, this is not surprising.</S>
          <S ID="S-37882">5 However it does suggest an avenue for possible improvement.</S>
          <S ID="S-37883">In our second LDA experiment, we compared our extracted CommonCrawl data with Europarl.</S>
          <S ID="S-37884">We created a set of documents from both CommonCrawl and Europarl, and again used MAL- LET to generate 100 topics for this data.</S>
          <S ID="S-37885">6 We then labeled each document by its most likely topic (as determined by that topic&#8217;s mixture weights), and counted the number of documents from Europarl and CommonCrawl for which each topic was most prominent.</S>
          <S ID="S-37886">While this is very rough, it gives some idea of where each topic is coming from.</S>
          <S ID="S-37887">Table 6 shows a sample of these topics.</S>
          <S ID="S-37888">In addition to exploring topics in the datasets, we also performed additional intrinsic evaluation at the domain level, choosing top domains for three language pairs.</S>
          <S ID="S-37889">We specifically classified sentence pairs as useful or boilerplate (Table 7).</S>
          <S ID="S-37890">Among our observations, we find that commercial websites tend to contain less boilerplate material than encyclopedic websites, and that the ratios tend to be similar across languages in the same domain.</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>4 Machine Translation Experiments</HEADER>
      <P>
        <S ID="S-37930">For our SMT experiments, we use the Moses toolkit (<REF ID="R-08" RPTR="9">Koehn et al., 2007</REF>).</S>
        <S ID="S-37931">In these experiments, a baseline system is trained on an existing parallel corpus, and the experimental system is trained on the baseline corpus plus the mined parallel data.</S>
        <S ID="S-37932">In all experiments we include the target side of the mined parallel data in the language model, in order to distinguish whether results are due to influences from parallel or monolingual data.</S>
      </P>
      <P>
        <S ID="S-37933">5 We used MALLET&#8217;s stop word removal, but that is only</S>
      </P>
      <P>
        <S ID="S-37934">for English.</S>
        <S ID="S-37935">6 Documents were created from Europarl by taking</S>
      </P>
      <P>
        <S ID="S-37936">&#8220;SPEAKER&#8221; tags as document boundaries, giving us 208,431 documents total.</S>
      </P>
      <P>
        <S ID="S-37937">Index Most Likely Tokens 1 glitter graphics profile comments share love size girl friends happy blingee cute anime twilight sexy emo 2 subtitles online web users files rar movies prg akas dwls xvid dvdrip avi results download eng cd movie 3 miles hotels city search hotel home page list overview select tokyo discount destinations china japan 4 english language students details skype american university school languages words england british college 5 translation japanese english chinese dictionary french german spanish korean russian italian dutch 6 products services ni system power high software design technology control national applications industry 7 en de el instructions amd hyper riv saab kfreebsd poland user fr pln org wikimedia pl commons fran norway 8 information service travel services contact number time account card site credit company business terms 9 people time life day good years work make god give lot long world book today great year end things 10 show km map hotels de hotel beach spain san italy resort del mexico rome portugal home santa berlin la 11 rotary international world club korea foundation district business year global hong kong president ri 12 hotel reviews stay guest rooms service facilities room smoking submitted customers desk score united hour 13 free site blog views video download page google web nero internet http search news links category tv 14 casino game games play domaine ago days music online poker free video film sports golf live world tags bet 15 water food attribution health mango japan massage medical body baby natural yen commons traditional 16 file system windows server linux installation user files set debian version support program install type 17 united kingdom states america house london street park road city inn paris york st france home canada 18 km show map hotels hotel featured search station museum amsterdam airport centre home city rue germany 19 hotel room location staff good breakfast rooms friendly nice clean great excellent comfortable helpful 20 de la en le el hotel es het del und die il est der les des das du para</S>
      </P>
      <DIV DEPTH="1">
        <HEADER>4.1 News Domain Translation</HEADER>
        <P>
          <S ID="S-37901">Our first set of experiments are based on systems built for the 2012 Workshop on Statistical Machine Translation (WMT) (<REF ID="R-04" RPTR="4">Callison-Burch et al., 2012</REF>) using all available parallel and monolingual data for that task, aside from the French-English Gigaword.</S>
          <S ID="S-37902">In these experiments, we use 5-gram language models when the target language is English or German, and 4-gram language models for French and Spanish.</S>
          <S ID="S-37903">We tune model weights using minimum error rate training (MERT; <REF ID="R-16" RPTR="18">Och, 2003</REF>) on the WMT 2008 test data.</S>
          <S ID="S-37904">The results are given in Table 8.</S>
          <S ID="S-37905">For all language pairs and both test sets (WMT 2011 and WMT 2012), we show an improvement of around 0.5 BLEU.</S>
        </P>
        <P>
          <S ID="S-37906">We also included the French-English Gigaword in separate experiments given in Table 9, and Table 10 compares the sizes of the datasets used.</S>
          <S ID="S-37907">These results show that even on top of a different, larger parallel corpus mined from the web, adding CommonCrawl data still yields an improvement.</S>
        </P>
      </DIV>
      <DIV DEPTH="1">
        <HEADER>4.2 Open Domain Translation</HEADER>
        <P>
          <S ID="S-37908">A substantial appeal of web-mined parallel data is that it might be suitable to translation of domains other than news, and our topic modeling analysis (&#167;3.3) suggested that this might indeed be the case.</S>
          <S ID="S-37909">We therefore performed an additional set of experiments for Spanish-English, but we include test sets from outside the news domain.</S>
        </P>
        <P>
          <S ID="S-37910">For these experiments, we also include training data mined from Wikipedia using a simplified version of the sentence aligner described by <REF ID="R-19" RPTR="26">Smith et al. (2010)</REF>, in order to determine how the effect of such data compares with the effect of webmined data.</S>
          <S ID="S-37911">The baseline system was trained using only the Europarl corpus (<REF ID="R-09" RPTR="11">Koehn, 2005</REF>) as parallel data, and all experiments use the same language model trained on the target sides of Europarl, the English side of all linked Spanish- English Wikipedia articles, and the English side of the mined CommonCrawl data.</S>
          <S ID="S-37912">We use a 5- gram language model and tune using MERT (Och,</S>
        </P>
        <P>
          <S ID="S-37913">2003) on the WMT 2009 test set.</S>
        </P>
        <P>
          <S ID="S-37914">Unfortunately, it is difficult to obtain meaningful results on some open domain test sets such as the Wikipedia dataset used by <REF ID="R-19" RPTR="27">Smith et al. (2010)</REF>.</S>
          <S ID="S-37915">Wikipedia copied across the public internet, and we did not have a simple way to filter such data from our mined datasets.</S>
        </P>
        <P>
          <S ID="S-37916">We therefore considered two tests that were less likely to be problematic.</S>
          <S ID="S-37917">The Tatoeba corpus (<REF ID="R-20" RPTR="29">Tiedemann, 2009</REF>) is a collection of example sentences translated into many languages by volunteers.</S>
          <S ID="S-37918">The front page of tatoeba.org was discovered by our URL matching heuristics, but we excluded any sentence pairs that were found in the CommonCrawl data from this test set.</S>
        </P>
        <P>
          <S ID="S-37919">The second dataset is a set of crowdsourced translation of Spanish speech transcriptions from the Spanish Fisher corpus.</S>
          <S ID="S-37920">7 As part of a research effort on cross-lingual speech applications, we obtained English translations of the data using Amazon Mechanical Turk, following a protocol similar to one described by Zaidan and Callison- Burch (2011): we provided clear instructions, employed several quality control measures, and obtained redundant translations of the complete dataset (<REF ID="R-11" RPTR="13">Lopez et al., 2013</REF>).</S>
          <S ID="S-37921">The advantage of this data for our open domain translation test is twofold.</S>
          <S ID="S-37922">First, the Fisher dataset consists of conversations in various Spanish dialects on a wide variety of prompted topics.</S>
          <S ID="S-37923">Second, because we obtained the translations ourselves, we could be absolutely assured that they did not appear in some form anywhere on the Web, making it an ideal blind test.</S>
        </P>
        <P>
          <S ID="S-37924">We used 1000 sentences from each of the Tatoeba and Fisher datasets as test.</S>
          <S ID="S-37925">For comparison, we also test on the WMT 2010 test set (<REF ID="R-02" RPTR="1">Callison-Burch et al., 2010</REF>).</S>
          <S ID="S-37926">Following Munteanu and Marcu (2005), we show the n-gram coverage of each corpus (percentage of n-grams from the test corpus which are also found in the training corpora) in Table 11.</S>
          <S ID="S-37927">Table 12 gives end-to-end results, which show a strong improvement on the WMT test set (1.5 BLEU), and larger</S>
        </P>
        <P>
          <S ID="S-37928">7 Linguistic Data Consortium LDC2010T04.</S>
        </P>
        <P>
          <S ID="S-37929">improvements on Tatoeba and Fisher (almost 5 BLEU).</S>
        </P>
      </DIV>
    </DIV>
    <DIV DEPTH="0">
      <HEADER>5 Discussion</HEADER>
      <P>
        <S ID="S-37938">Web-mined parallel texts have been an exclusive resource of large companies for several years.</S>
        <S ID="S-37939">However, when web-mined parallel text is available to everyone at little or no cost, there will be much greater potential for groundbreaking research to come from all corners.</S>
        <S ID="S-37940">With the advent of public services such as Amazon Web Services and the Common Crawl, this may soon be a reality.</S>
        <S ID="S-37941">As we have shown, it is possible to obtain parallel text for many language pairs in a variety of domains very cheaply and quickly, and in sufficient quantity and quality to improve statistical machine translation systems.</S>
        <S ID="S-37942">However, our effort has merely scratched the surface of what is possible with this resource.</S>
        <S ID="S-37943">We will make our code and data available so that others can build on these results.</S>
        <S ID="S-37944">Because our system is so simple, we believe that our results represent lower bounds on the gains that should be expected in performance of systems previously trained only on curated datasets.</S>
        <S ID="S-37945">There are many possible means through which the system could be improved, including more sophisticated techniques for identifying matching URLs, better alignment, better language identification, better filtering of data, and better exploitation of resulting cross-domain datasets.</S>
        <S ID="S-37946">Many of the components of our pipeline were basic, leaving considerable room for improvement.</S>
        <S ID="S-37947">For example, the URL matching strategy could easily be improved for a given language pair by spending a little time crafting regular expressions tailored to some major websites.</S>
        <S ID="S-37948"><REF ID="R-03" RPTR="3">Callison-Burch et al. (2011)</REF> gathered almost 1 trillion tokens of French-English parallel data this way.</S>
        <S ID="S-37949">Another strategy for mining parallel webpage pairs is to scan the HTML for links to the same page in another language (<REF ID="R-15" RPTR="17">Nie et al., 1999</REF>).</S>
        <S ID="S-37950">Other, more sophisticated techniques may also be possible.</S>
        <S ID="S-37951"><REF ID="R-22" RPTR="31">Uszkoreit et al. (2010)</REF>, for example, translated all non-English webpages into English using an existing translation system and used near-duplicate detection methods to find candidate parallel document pairs.</S>
        <S ID="S-37952"><REF ID="R-21" RPTR="30">Ture and Lin (2012)</REF> had a similar approach for finding parallel Wikipedia documents by using near-duplicate detection, though they did not need to apply a full translation system to all non-English documents.</S>
        <S ID="S-37953">1381 Instead, they represented documents in bag-ofwords vector space, and projected non-English document vectors into the English vector space using the translation probabilities of a word alignment model.</S>
        <S ID="S-37954">By comparison, one appeal of our simple approach is that it requires only a table of language codes.</S>
        <S ID="S-37955">However, with this system in place, we could obtain enough parallel data to bootstrap these more sophisticated approaches.</S>
        <S ID="S-37956">It is also compelling to consider ways in which web-mined data obtained from scratch could be used to bootstrap other mining approaches.</S>
        <S ID="S-37957">For example, <REF ID="R-19" RPTR="28">Smith et al. (2010)</REF> mine parallel sentences from comparable documents in Wikipedia, demonstrating substantial gains on open domain translation.</S>
        <S ID="S-37958">However, their approach required seed parallel data to learn models used in a classifier.</S>
        <S ID="S-37959">We imagine a two-step process, first obtaining parallel data from the web, followed by comparable data from sources such as Wikipedia using models bootstrapped from the web-mined data.</S>
        <S ID="S-37960">Such a process could be used to build translation systems for new language pairs in a very short period of time, hence fulfilling one of the original promises of SMT.</S>
      </P>
    </DIV>
  </BODY>
  <ACKNOWLEDGMENTS>
    <P>
      <S ID="S-37961">Thanks to Ann Irvine, Jonathan Weese, and our anonymous reviewers from NAACL and ACL for comments on previous drafts.</S>
      <S ID="S-37962">The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement 288487 (MosesCore).</S>
      <S ID="S-37963">This research was partially funded by the Johns Hopkins University Human Language Technology Center of Excellence, and by gifts from Google and Microsoft.</S>
    </P>
  </ACKNOWLEDGMENTS>
  <REFERENCES>
    <REFERENCE ID="0">
      <RAUTHOR>David M Blei</RAUTHOR>
      <REFTITLE>Latent dirichlet allocation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="1">
      <RAUTHOR>Res</RAUTHOR>
      <REFTITLE></REFTITLE>
      <DATE></DATE>
    </REFERENCE>
    <REFERENCE ID="2">
      <RAUTHOR>Chris Callison-Burch</RAUTHOR>
      <REFTITLE>Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="3">
      <RAUTHOR>Chris Callison-Burch</RAUTHOR>
      <REFTITLE>Findings of the 2011 workshop on statistical machine translation.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="4">
      <RAUTHOR>Chris Callison-Burch</RAUTHOR>
      <REFTITLE>Findings of the 2012 workshop on statistical machine translation.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="5">
      <RAUTHOR>Jiang Chen</RAUTHOR>
      <REFTITLE>Parallel web text mining for cross-language ir. In</REFTITLE>
      <DATE>2000</DATE>
    </REFERENCE>
    <REFERENCE ID="6">
      <RAUTHOR>J Dean</RAUTHOR>
      <REFTITLE>Mapreduce: simplified data processing on large clusters.</REFTITLE>
      <DATE>2004</DATE>
    </REFERENCE>
    <REFERENCE ID="7">
      <RAUTHOR>William A Gale</RAUTHOR>
      <REFTITLE>A program for aligning sentences in bilingual corpora.</REFTITLE>
      <DATE>1993</DATE>
    </REFERENCE>
    <REFERENCE ID="8">
      <RAUTHOR>Philipp Koehn</RAUTHOR>
      <REFTITLE>Moses: open source toolkit for statistical machine translation.</REFTITLE>
      <DATE>2007</DATE>
    </REFERENCE>
    <REFERENCE ID="9">
      <RAUTHOR>P Koehn</RAUTHOR>
      <REFTITLE>Europarl: A parallel corpus for statistical machine translation.</REFTITLE>
      <DATE>2005</DATE>
    </REFERENCE>
    <REFERENCE ID="10">
      <RAUTHOR>Edward Loper</RAUTHOR>
      <REFTITLE>Nltk: the natural language toolkit.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="11">
      <RAUTHOR>Adam Lopez</RAUTHOR>
      <REFTITLE>Parallel speech, transcription, and translation: The Fisher and Callhome Spanish-English speech translation corpora.</REFTITLE>
      <DATE>2013</DATE>
    </REFERENCE>
    <REFERENCE ID="12">
      <RAUTHOR>Marco Lui</RAUTHOR>
      <REFTITLE>langid.py: an off-the-shelf language identification tool.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="13">
      <RAUTHOR>Andrew Kachites McCallum</RAUTHOR>
      <REFTITLE>Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu. 1382 Stefan Munteanu and Daniel Marcu.</REFTITLE>
      <DATE>2002</DATE>
    </REFERENCE>
    <REFERENCE ID="14">
      <RAUTHOR>Omar F Zaidan</RAUTHOR>
      <REFTITLE>Crowdsourcing translation: Professional quality from non-professionals.</REFTITLE>
      <DATE>2011</DATE>
    </REFERENCE>
    <REFERENCE ID="15">
      <RAUTHOR>Jian-Yun Nie</RAUTHOR>
      <REFTITLE>Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web.</REFTITLE>
      <DATE>1999</DATE>
    </REFERENCE>
    <REFERENCE ID="16">
      <RAUTHOR>Franz Josef Och</RAUTHOR>
      <REFTITLE>Minimum error rate training in statistical machine translation.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="17">
      <RAUTHOR>P Resnik</RAUTHOR>
      <REFTITLE>The web as a parallel corpus.</REFTITLE>
      <DATE>2003</DATE>
    </REFERENCE>
    <REFERENCE ID="18">
      <RAUTHOR>Philip Resnik</RAUTHOR>
      <REFTITLE>Mining the web for bilingual text.</REFTITLE>
      <DATE>1999</DATE>
    </REFERENCE>
    <REFERENCE ID="19">
      <RAUTHOR>Jason R Smith</RAUTHOR>
      <REFTITLE>Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
    <REFERENCE ID="20">
      <RAUTHOR>J&#246;rg Tiedemann</RAUTHOR>
      <REFTITLE>News from OPUS - A collection of multilingual parallel corpora with tools and interfaces.</REFTITLE>
      <DATE>2009</DATE>
    </REFERENCE>
    <REFERENCE ID="21">
      <RAUTHOR>Ferhan Ture</RAUTHOR>
      <REFTITLE>Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling.</REFTITLE>
      <DATE>2012</DATE>
    </REFERENCE>
    <REFERENCE ID="22">
      <RAUTHOR>Jakob Uszkoreit</RAUTHOR>
      <REFTITLE>Large scale parallel document mining for machine translation.</REFTITLE>
      <DATE>2010</DATE>
    </REFERENCE>
  </REFERENCES>
</PAPER>
